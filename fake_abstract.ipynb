{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import re\n",
    "import flask\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "mpl.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from flask import Flask, render_template, request\n",
    "from flask_script import Manager\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ CACHING & DATA RETRIEVAL ###################\n",
    "# -----------------------------------------------------------------------------\n",
    "# Constants\n",
    "# -----------------------------------------------------------------------------\n",
    "CACHE_FNAME = 'cache_file.json'\n",
    "MODEL_FNAME = 'markov_model.pkl'\n",
    "DATETIME_FORMAT = \"%Y-%m-%d %H:%M:%S.%f\"\n",
    "DEBUG = False\n",
    "# MAKE SURE TO DROP TABLE EVEN WITHOUT DEBUG, BEFORE YOU RERUN IT\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Load cache file\n",
    "# -----------------------------------------------------------------------------\n",
    "try:\n",
    "    with open(CACHE_FNAME, 'r') as cache_file:\n",
    "        cache_json = cache_file.read()\n",
    "        CACHE_DICTION = json.loads(cache_json)\n",
    "except:\n",
    "    CACHE_DICTION = {}\n",
    "\n",
    "# CITE: Anand Doshi, nytimes.py\n",
    "def has_cache_expired(timestamp_str, expire_in_days): # BUG 1\n",
    "    \"\"\"Check if cache timestamp is over expire_in_days old\"\"\"\n",
    "    # gives current datetime\n",
    "    now = datetime.now()\n",
    "\n",
    "    # datetime.strptime converts a formatted string into datetime object\n",
    "    cache_timestamp = datetime.strptime(timestamp_str, DATETIME_FORMAT)\n",
    "\n",
    "    # subtracting two datetime objects gives you a timedelta object\n",
    "    delta = now - cache_timestamp\n",
    "    delta_in_days = delta.days\n",
    "\n",
    "    # now that we have days as integers, we can just use comparison\n",
    "    # and decide if cache has expired or not\n",
    "    if delta_in_days < expire_in_days: #BUG 2\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "# CITE: Jackie Cohen, Runestone Virtual Textbook\n",
    "def params_unique_combination(baseurl, params_d, private_keys=[\"api_key\"]):\n",
    "    alphabetized_keys = sorted(params_d.keys())\n",
    "    res = []\n",
    "    for k in alphabetized_keys:\n",
    "        if k not in private_keys:\n",
    "            res.append(\"{}-{}\".format(k, params_d[k]))\n",
    "    return baseurl + \"_\".join(res)\n",
    "\n",
    "# CITE: Anand Doshi, nytimes.py\n",
    "def get_from_cache(url, params_d):\n",
    "    \"\"\"If URL exists in cache and has not expired, return the html, else return None\"\"\"\n",
    "    cache_key = params_unique_combination(url, params_d)\n",
    "    if cache_key in CACHE_DICTION:\n",
    "        url_dict = CACHE_DICTION[cache_key]\n",
    " #       html = CACHE_DICTION[url]['html']\n",
    "        if has_cache_expired(url_dict['timestamp'], url_dict['expire_in_days']):\n",
    "            # also remove old copy from cache\n",
    "            del CACHE_DICTION[cache_key]\n",
    "            html = None\n",
    "        else:\n",
    "            html = CACHE_DICTION[cache_key]['html']\n",
    "    else:\n",
    "        html = None\n",
    "\n",
    "    return html\n",
    "\n",
    "# CITE: Anand Doshi, nytimes.py\n",
    "def set_in_cache(url, params_d, html, expire_in_days):\n",
    "    \"\"\"Add URL and html to the cache dictionary, and save the whole dictionary to a file as json\"\"\"\n",
    "    cache_key = params_unique_combination(url, params_d)\n",
    "    \n",
    "    CACHE_DICTION[cache_key] = {\n",
    "        'html': html,\n",
    "        'timestamp': datetime.now().strftime(DATETIME_FORMAT),\n",
    "        'expire_in_days': expire_in_days\n",
    "    }\n",
    "\n",
    "    with open(CACHE_FNAME, 'w') as cache_file:\n",
    "        cache_json = json.dumps(CACHE_DICTION)\n",
    "        cache_file.write(cache_json)\n",
    "\n",
    "def save_model_cache(order, model, expire_in_days):\n",
    "    \"\"\"Add order to the cache dictionary, and save the whole dictionary to a file as json\"\"\"\n",
    "    cache_key = str(order)\n",
    "    \n",
    "    markov_dict[cache_key] = {\n",
    "        'model': model,\n",
    "        'timestamp': datetime.now().strftime(DATETIME_FORMAT),\n",
    "        'expire_in_days': expire_in_days\n",
    "    }\n",
    "    \n",
    "    with open(MODEL_FNAME,\"wb\") as cache_file:\n",
    "        pickle.dump(markov_dict,cache_file)\n",
    "\n",
    "# CITE: Anand Doshi, nytimes.py\n",
    "def get_html_from_url(url, params_d, expire_in_days=365): #Added params_d\n",
    "    \"\"\"Check in cache, if not found, load html, save in cache and then return that html\"\"\"\n",
    "    # check in cache\n",
    "    html = get_from_cache(url, params_d)\n",
    " #   print(html)\n",
    "    if html is not None:\n",
    "        if DEBUG:\n",
    "            print('Loading from cache: {0}'.format(url))\n",
    "    else:\n",
    "        if DEBUG:\n",
    "            print('Fetching a fresh copy: {0}'.format(url))\n",
    " #       print()\n",
    "\n",
    "        # fetch fresh\n",
    "        response = requests.get(url, params=params_d)\n",
    "\n",
    "        # Deleted line about encoding because it was messing up my shit\n",
    "\n",
    "        html = response.text\n",
    "\n",
    "        # cache it\n",
    "        set_in_cache(url, params_d, html, expire_in_days)\n",
    "\n",
    "    return html\n",
    "\n",
    "def search_cvpr(baseurl):\n",
    "    params_d = {}\n",
    "\t\n",
    "    google_results = get_html_from_url(baseurl, params_d, expire_in_days=1)\n",
    "    google_soup = BeautifulSoup(google_results, 'html.parser')\n",
    "\n",
    "    # return google_soup.prettify()\n",
    "\n",
    "\t# returns list of paper htmls for processing by class Paper\n",
    "    #return google_soup.find_all('div',{'class':'gs_r gs_or gs_scl'})\n",
    "    return google_soup.find_all('dt',{'class':'ptitle'})\n",
    "\n",
    "def find_abstract(baseurl):\n",
    "    params_d = {}\n",
    "\t\n",
    "    google_results = get_html_from_url(baseurl, params_d, expire_in_days=1)\n",
    "    google_soup = BeautifulSoup(google_results, 'html.parser')\n",
    "\n",
    "    # return google_soup.prettify()\n",
    "\n",
    "\t# returns list of paper htmls for processing by class Paper\n",
    "    #return google_soup.find_all('div',{'class':'gs_r gs_or gs_scl'})\n",
    "    return google_soup.find_all('div',{'id':'abstract'})\n",
    "\n",
    "######################## END CACHING #############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def build_markov_model(markov_model, text, order=1):\n",
    "    words = text.split()\n",
    "    words.append(\"*E*\")\n",
    "    \n",
    "    if '*S*' in markov_model:\n",
    "        if tuple(words[0:order]) in markov_model['*S*']:\n",
    "            markov_model['*S*'][tuple(words[0:order])] += 1\n",
    "        else:\n",
    "            markov_model['*S*'][tuple(words[0:order])] = 1\n",
    "    else:\n",
    "        markov_model['*S*'] = {}\n",
    "        markov_model['*S*'][tuple(words[0:order])] = 1\n",
    "    \n",
    "    for i in range(0, len(words)-order):\n",
    "        word_set = tuple(words[i:i+order])\n",
    "        \n",
    "        if word_set in markov_model:\n",
    "            if words[i+order] in markov_model[word_set]:\n",
    "                markov_model[word_set][words[i+order]] += 1\n",
    "            else:\n",
    "                markov_model[word_set][words[i+order]] = 1\n",
    "        else:\n",
    "            markov_model[word_set] = {}\n",
    "            markov_model[word_set][words[i+order]] = 1\n",
    "                            \n",
    "    return markov_model\n",
    "\n",
    "def get_next_word(current_word, markov_model):\n",
    "\n",
    "    # Sum counts for all transitions from a state\n",
    "    state_sum = sum(markov_model[current_word].values())\n",
    "\n",
    "    # Get a random value 0 <= value < 1\n",
    "    random_val = random.randint(1, state_sum)\n",
    "    \n",
    "    # Pick a next_state based on their probabilities\n",
    "    for next_state in markov_model[current_word]:\n",
    "        if markov_model[current_word][next_state] >= random_val:\n",
    "            return next_state\n",
    "        else:\n",
    "            random_val -= markov_model[current_word][next_state]\n",
    "    \n",
    "def generate_random_text(markov_model, word_count, order):\n",
    "    \n",
    "    # We must start at the initial state of the model\n",
    "    current_word = \"*S*\"\n",
    "    current_tuple = get_next_word(current_word, markov_model)\n",
    "    \n",
    "    # Keeping track of the sentence as a list (ignoring the start state)\n",
    "    sentence = list(current_tuple)\n",
    "\n",
    "    # Until the model generates an end state, keep adding random words\n",
    "    while current_word != \"*E*\" or count < word_count * .8: # true word count is less than 90% of target wc\n",
    "        current_word = get_next_word(current_tuple, markov_model)\n",
    "        \n",
    "        # Don't append the end state to our output        \n",
    "        if current_word != \"*E*\":\n",
    "            sentence.append(current_word)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "            \n",
    "        current_list = list(current_tuple)\n",
    "        current_list.pop(0)\n",
    "        current_list.append(current_word)\n",
    "        current_tuple = tuple(current_list)\n",
    "        \n",
    "        count = len(sentence) * order\n",
    "        \n",
    "        if '.' in current_word and count > word_count:\n",
    "            current_word = \"*E*\" # stop early if you've already passed wc\n",
    "\n",
    "    # Return the words with spaces between them\n",
    "    return [' '.join(sentence), count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def markov_wrapper(order):\n",
    "    # -----------------------------------------------------------------------------\n",
    "    # Load model file\n",
    "    # -----------------------------------------------------------------------------\n",
    "    try:\n",
    "        with open(MODEL_FNAME, 'rb') as cache_file:\n",
    "            markov_dict = pickle.load(cache_file)\n",
    "            markov_model = markov_dict[str(order)]['model']\n",
    "        print('Using Cached Data')\n",
    "    except:\n",
    "        print('Creating New Dictionary')\n",
    "        markov_model = {}\n",
    "        \n",
    "        for year in tqdm(list(result_dict.keys())):\n",
    "            t =result_dict[year]\n",
    "            for idx,dt in enumerate(t):\n",
    "                try:\n",
    "                    a = dt.find('a')\n",
    "                    link = a.get('href')\n",
    "    \n",
    "                    baseurl2 = baseurl + link\n",
    "                    #if DEBUG:\n",
    "                        #print(baseurl2)\n",
    "    \n",
    "                    find_div = 'abstract'#,{\"class\":\"abstract\"}\n",
    "                    d = find_abstract(baseurl2)\n",
    "                    abstract = d[0].text\n",
    "\n",
    "                    markov_model = build_markov_model(markov_model, abstract , 1) \n",
    "                except:\n",
    "                    continue\n",
    "        save_model_cache(str(order), markov_model, 365)\n",
    "    return markov_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###################################################### INTERFACE ######################################################\n",
    "\n",
    "def interface():\n",
    "\torder = input(\"Order N of Markov Model (e.g. 1)\")\n",
    "\n",
    "######################################################\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 0\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def my_form():\n",
    "\treturn render_template('interface.html')\n",
    "\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def my_form_post():\n",
    "    order = int(request.form['text'])\n",
    "    word_count = int(request.form['text2'])\n",
    "\n",
    "    results = generate_random_text(markov_wrapper(order), word_count, order)\n",
    "    return render_template('results.html', order = order, fake_abstract = results[0], wc = results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = \"http://openaccess.thecvf.com/\"\n",
    "years = [str(2010 + x) for x in range(5,10)]\n",
    "result_dict = {}\n",
    "\n",
    "for year in years:\n",
    "    subscript = \"CVPR%s.py\" % year\n",
    "    result_dict[year] = search_cvpr(baseurl + subscript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [19/Dec/2019 23:51:42] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run() # Runs the flask server in a special way that makes it nice to debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things to do:\n",
    "# 1. Give people the choice of what year they want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
