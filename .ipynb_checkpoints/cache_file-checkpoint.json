{"http://openaccess.thecvf.com/CVPR2018.py": {"html": "\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\">\n<html>\n<head>\n<meta content=\"text/html; charset=UTF-8\" http-equiv=\"content-type\">\n<title>CVPR 2018 Open Access Repository</title>\n<link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css\">\n<script type=\"text/javascript\" src=\"https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js\"></script>\n<script type=\"text/javascript\" src=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js\"></script>\n<script type=\"text/javascript\" src=\"./static/jquery.js\"></script>\n<link rel=\"stylesheet\" type=\"text/css\" href=\"static/conf.css\">\n</head>\n<body>\n<div id=\"header\">\n<div id=\"header_left\">\n<a href=\"http://cvpr2018.thecvf.com\"><img src=\"img/cvpr2018_logo.jpg\" width=\"175\" border=\"0\" alt=\"CVPR 2018\"></a>\n<a href=\"http://www.cv-foundation.org/\"><img src=\"img/cropped-cvf-s.jpg\" width=\"175\" height=\"112\" border=\"0\" alt=\"CVF\"></a>\n</div>\n<div id=\"header_right\">\n<div id=\"header_title\">\n<a href=\"http://cvpr2018.thecvf.com\">CVPR 2018</a> open access\n</div>\n<div id=\"help\" >\nThese CVPR 2018 papers are the Open Access versions, provided by the <a href=\"http://www.cv-foundation.org/\">Computer Vision Foundation.</a><br> Except for the watermark, they are identical to the accepted versions; the final published version of the proceedings is available on IEEE Xplore.\n</div>\n<div id=\"disclaimer\" >\nThis material is presented to ensure timely dissemination of scholarly and technical work.\nCopyright and all rights therein are retained by authors or by other copyright holders.\nAll persons copying this information are expected to adhere to the terms and constraints invoked by each author's copyright.<br><br>\n<form action=\"./CVPR2018_search.py\" method=\"post\">\n<input type=\"text\" name=\"query\">\n<input type=\"submit\" value=\"Search\">\n</form>\n</div>\n</div>\n<div id=\"header_sponsor\">\n<p style=\"vertical-align:center; text-align: center\"> <strong>Powered by:</strong></p>\n<img src=\"img/ms-azure-logo.png\" width=\"100\" alt=\"Microsoft Azure\">\n<p> </p>\n<p> </p>\n<p style=\"vertical-align:center; text-align: center\"> <strong>Sponsored by:</strong></p>\n<img src=\"img/amazon-logo.png\" width=\"100\" alt=\"Amazon\">\n<img src=\"img/facebook_logo.jpg\" width=\"100\" alt=\"Facebook\">\n<img src=\"img/Google_2015_logo.svg\" width=\"100\" alt=\"Google\">\n</div>\n</div>\n<div class=\"clear\">\n</div>\n<div id=\"content\">\n<h3>Papers</h3>\n<dl>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Das_Embodied_Question_Answering_CVPR_2018_paper.html\">Embodied Question Answering</a></dt>\n<dd>\n<form id=\"form-AbhishekDasEmbodiedQuestionAnswering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Abhishek Das\">\n<a href=\"#\" onclick=\"document.getElementById('form-AbhishekDasEmbodiedQuestionAnswering').submit();\">Abhishek Das</a>,\n</form>\n<form id=\"form-SamyakDattaEmbodiedQuestionAnswering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Samyak Datta\">\n<a href=\"#\" onclick=\"document.getElementById('form-SamyakDattaEmbodiedQuestionAnswering').submit();\">Samyak Datta</a>,\n</form>\n<form id=\"form-GeorgiaGkioxariEmbodiedQuestionAnswering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Georgia Gkioxari\">\n<a href=\"#\" onclick=\"document.getElementById('form-GeorgiaGkioxariEmbodiedQuestionAnswering').submit();\">Georgia Gkioxari</a>,\n</form>\n<form id=\"form-StefanLeeEmbodiedQuestionAnswering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stefan Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-StefanLeeEmbodiedQuestionAnswering').submit();\">Stefan Lee</a>,\n</form>\n<form id=\"form-DeviParikhEmbodiedQuestionAnswering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Devi Parikh\">\n<a href=\"#\" onclick=\"document.getElementById('form-DeviParikhEmbodiedQuestionAnswering').submit();\">Devi Parikh</a>,\n</form>\n<form id=\"form-DhruvBatraEmbodiedQuestionAnswering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dhruv Batra\">\n<a href=\"#\" onclick=\"document.getElementById('form-DhruvBatraEmbodiedQuestionAnswering').submit();\">Dhruv Batra</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Das_Embodied_Question_Answering_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0052-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.11543\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Das_2018_CVPR,<br>\nauthor = {Das, Abhishek and Datta, Samyak and Gkioxari, Georgia and Lee, Stefan and Parikh, Devi and Batra, Dhruv},<br>\ntitle = {Embodied Question Answering},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Misra_Learning_by_Asking_CVPR_2018_paper.html\">Learning by Asking Questions</a></dt>\n<dd>\n<form id=\"form-IshanMisraLearningbyAsking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ishan Misra\">\n<a href=\"#\" onclick=\"document.getElementById('form-IshanMisraLearningbyAsking').submit();\">Ishan Misra</a>,\n</form>\n<form id=\"form-RossGirshickLearningbyAsking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ross Girshick\">\n<a href=\"#\" onclick=\"document.getElementById('form-RossGirshickLearningbyAsking').submit();\">Ross Girshick</a>,\n</form>\n<form id=\"form-RobFergusLearningbyAsking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rob Fergus\">\n<a href=\"#\" onclick=\"document.getElementById('form-RobFergusLearningbyAsking').submit();\">Rob Fergus</a>,\n</form>\n<form id=\"form-MartialHebertLearningbyAsking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Martial Hebert\">\n<a href=\"#\" onclick=\"document.getElementById('form-MartialHebertLearningbyAsking').submit();\">Martial Hebert</a>,\n</form>\n<form id=\"form-AbhinavGuptaLearningbyAsking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Abhinav Gupta\">\n<a href=\"#\" onclick=\"document.getElementById('form-AbhinavGuptaLearningbyAsking').submit();\">Abhinav Gupta</a>,\n</form>\n<form id=\"form-LaurensvanLearningbyAsking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Laurens van der Maaten\">\n<a href=\"#\" onclick=\"document.getElementById('form-LaurensvanLearningbyAsking').submit();\">Laurens van der Maaten</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Misra_Learning_by_Asking_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1806.08554\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Misra_2018_CVPR,<br>\nauthor = {Misra, Ishan and Girshick, Ross and Fergus, Rob and Hebert, Martial and Gupta, Abhinav and van der Maaten, Laurens},<br>\ntitle = {Learning by Asking Questions},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Bai_Finding_Tiny_Faces_CVPR_2018_paper.html\">Finding Tiny Faces in the Wild With Generative Adversarial Network</a></dt>\n<dd>\n<form id=\"form-YanchengBaiFindingTinyFaces\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yancheng Bai\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanchengBaiFindingTinyFaces').submit();\">Yancheng Bai</a>,\n</form>\n<form id=\"form-YongqiangZhangFindingTinyFaces\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yongqiang Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YongqiangZhangFindingTinyFaces').submit();\">Yongqiang Zhang</a>,\n</form>\n<form id=\"form-MingliDingFindingTinyFaces\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mingli Ding\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingliDingFindingTinyFaces').submit();\">Mingli Ding</a>,\n</form>\n<form id=\"form-BernardGhanemFindingTinyFaces\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bernard Ghanem\">\n<a href=\"#\" onclick=\"document.getElementById('form-BernardGhanemFindingTinyFaces').submit();\">Bernard Ghanem</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Bai_Finding_Tiny_Faces_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Bai_2018_CVPR,<br>\nauthor = {Bai, Yancheng and Zhang, Yongqiang and Ding, Mingli and Ghanem, Bernard},<br>\ntitle = {Finding Tiny Faces in the Wild With Generative Adversarial Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yang_Learning_Face_Age_CVPR_2018_paper.html\">Learning Face Age Progression: A Pyramid Architecture of GANs</a></dt>\n<dd>\n<form id=\"form-HongyuYangLearningFaceAge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hongyu Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HongyuYangLearningFaceAge').submit();\">Hongyu Yang</a>,\n</form>\n<form id=\"form-DiHuangLearningFaceAge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Di Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-DiHuangLearningFaceAge').submit();\">Di Huang</a>,\n</form>\n<form id=\"form-YunhongWangLearningFaceAge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yunhong Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YunhongWangLearningFaceAge').submit();\">Yunhong Wang</a>,\n</form>\n<form id=\"form-AnilK.LearningFaceAge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anil K. Jain\">\n<a href=\"#\" onclick=\"document.getElementById('form-AnilK.LearningFaceAge').submit();\">Anil K. Jain</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yang_Learning_Face_Age_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3633-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.10352\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yang_2018_CVPR,<br>\nauthor = {Yang, Hongyu and Huang, Di and Wang, Yunhong and Jain, Anil K.},<br>\ntitle = {Learning Face Age Progression: A Pyramid Architecture of GANs},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chang_PairedCycleGAN_Asymmetric_Style_CVPR_2018_paper.html\">PairedCycleGAN: Asymmetric Style Transfer for Applying and Removing Makeup</a></dt>\n<dd>\n<form id=\"form-HuiwenChangPairedCycleGANAsymmetricStyle\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huiwen Chang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuiwenChangPairedCycleGANAsymmetricStyle').submit();\">Huiwen Chang</a>,\n</form>\n<form id=\"form-JingwanLuPairedCycleGANAsymmetricStyle\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jingwan Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingwanLuPairedCycleGANAsymmetricStyle').submit();\">Jingwan Lu</a>,\n</form>\n<form id=\"form-FisherYuPairedCycleGANAsymmetricStyle\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fisher Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-FisherYuPairedCycleGANAsymmetricStyle').submit();\">Fisher Yu</a>,\n</form>\n<form id=\"form-AdamFinkelsteinPairedCycleGANAsymmetricStyle\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Adam Finkelstein\">\n<a href=\"#\" onclick=\"document.getElementById('form-AdamFinkelsteinPairedCycleGANAsymmetricStyle').submit();\">Adam Finkelstein</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chang_PairedCycleGAN_Asymmetric_Style_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chang_2018_CVPR,<br>\nauthor = {Chang, Huiwen and Lu, Jingwan and Yu, Fisher and Finkelstein, Adam},<br>\ntitle = {PairedCycleGAN: Asymmetric Style Transfer for Applying and Removing Makeup},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Mueller_GANerated_Hands_for_CVPR_2018_paper.html\">GANerated Hands for Real-Time 3D Hand Tracking From Monocular RGB</a></dt>\n<dd>\n<form id=\"form-FranziskaMuellerGANeratedHandsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Franziska Mueller\">\n<a href=\"#\" onclick=\"document.getElementById('form-FranziskaMuellerGANeratedHandsfor').submit();\">Franziska Mueller</a>,\n</form>\n<form id=\"form-FlorianBernardGANeratedHandsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Florian Bernard\">\n<a href=\"#\" onclick=\"document.getElementById('form-FlorianBernardGANeratedHandsfor').submit();\">Florian Bernard</a>,\n</form>\n<form id=\"form-OleksandrSotnychenkoGANeratedHandsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Oleksandr Sotnychenko\">\n<a href=\"#\" onclick=\"document.getElementById('form-OleksandrSotnychenkoGANeratedHandsfor').submit();\">Oleksandr Sotnychenko</a>,\n</form>\n<form id=\"form-DushyantMehtaGANeratedHandsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dushyant Mehta\">\n<a href=\"#\" onclick=\"document.getElementById('form-DushyantMehtaGANeratedHandsfor').submit();\">Dushyant Mehta</a>,\n</form>\n<form id=\"form-SrinathSridharGANeratedHandsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Srinath Sridhar\">\n<a href=\"#\" onclick=\"document.getElementById('form-SrinathSridharGANeratedHandsfor').submit();\">Srinath Sridhar</a>,\n</form>\n<form id=\"form-DanCasasGANeratedHandsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dan Casas\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanCasasGANeratedHandsfor').submit();\">Dan Casas</a>,\n</form>\n<form id=\"form-ChristianTheobaltGANeratedHandsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Christian Theobalt\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChristianTheobaltGANeratedHandsfor').submit();\">Christian Theobalt</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Mueller_GANerated_Hands_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0736-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.01057\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Mueller_2018_CVPR,<br>\nauthor = {Mueller, Franziska and Bernard, Florian and Sotnychenko, Oleksandr and Mehta, Dushyant and Sridhar, Srinath and Casas, Dan and Theobalt, Christian},<br>\ntitle = {GANerated Hands for Real-Time 3D Hand Tracking From Monocular RGB},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Poier_Learning_Pose_Specific_CVPR_2018_paper.html\">Learning Pose Specific Representations by Predicting Different Views</a></dt>\n<dd>\n<form id=\"form-GeorgPoierLearningPoseSpecific\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Georg Poier\">\n<a href=\"#\" onclick=\"document.getElementById('form-GeorgPoierLearningPoseSpecific').submit();\">Georg Poier</a>,\n</form>\n<form id=\"form-DavidSchinaglLearningPoseSpecific\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"David Schinagl\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavidSchinaglLearningPoseSpecific').submit();\">David Schinagl</a>,\n</form>\n<form id=\"form-HorstBischofLearningPoseSpecific\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Horst Bischof\">\n<a href=\"#\" onclick=\"document.getElementById('form-HorstBischofLearningPoseSpecific').submit();\">Horst Bischof</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Poier_Learning_Pose_Specific_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1772-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.03390\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Poier_2018_CVPR,<br>\nauthor = {Poier, Georg and Schinagl, David and Bischof, Horst},<br>\ntitle = {Learning Pose Specific Representations by Predicting Different Views},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Fang_Weakly_and_Semi_CVPR_2018_paper.html\">Weakly and Semi Supervised Human Body Part Parsing via Pose-Guided Knowledge Transfer</a></dt>\n<dd>\n<form id=\"form-Hao-ShuFangWeaklyandSemi\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hao-Shu Fang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Hao-ShuFangWeaklyandSemi').submit();\">Hao-Shu Fang</a>,\n</form>\n<form id=\"form-GuansongLuWeaklyandSemi\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guansong Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuansongLuWeaklyandSemi').submit();\">Guansong Lu</a>,\n</form>\n<form id=\"form-XiaolinFangWeaklyandSemi\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaolin Fang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaolinFangWeaklyandSemi').submit();\">Xiaolin Fang</a>,\n</form>\n<form id=\"form-JianwenXieWeaklyandSemi\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianwen Xie\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianwenXieWeaklyandSemi').submit();\">Jianwen Xie</a>,\n</form>\n<form id=\"form-Yu-WingTaiWeaklyandSemi\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu-Wing Tai\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yu-WingTaiWeaklyandSemi').submit();\">Yu-Wing Tai</a>,\n</form>\n<form id=\"form-CewuLuWeaklyandSemi\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cewu Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-CewuLuWeaklyandSemi').submit();\">Cewu Lu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Fang_Weakly_and_Semi_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.04310\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Fang_2018_CVPR,<br>\nauthor = {Fang, Hao-Shu and Lu, Guansong and Fang, Xiaolin and Xie, Jianwen and Tai, Yu-Wing and Lu, Cewu},<br>\ntitle = {Weakly and Semi Supervised Human Body Part Parsing via Pose-Guided Knowledge Transfer},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wei_Person_Transfer_GAN_CVPR_2018_paper.html\">Person Transfer GAN to Bridge Domain Gap for Person Re-Identification</a></dt>\n<dd>\n<form id=\"form-LonghuiWeiPersonTransferGAN\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Longhui Wei\">\n<a href=\"#\" onclick=\"document.getElementById('form-LonghuiWeiPersonTransferGAN').submit();\">Longhui Wei</a>,\n</form>\n<form id=\"form-ShiliangZhangPersonTransferGAN\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shiliang Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShiliangZhangPersonTransferGAN').submit();\">Shiliang Zhang</a>,\n</form>\n<form id=\"form-WenGaoPersonTransferGAN\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wen Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenGaoPersonTransferGAN').submit();\">Wen Gao</a>,\n</form>\n<form id=\"form-QiTianPersonTransferGAN\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qi Tian\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiTianPersonTransferGAN').submit();\">Qi Tian</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wei_Person_Transfer_GAN_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.08565\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wei_2018_CVPR,<br>\nauthor = {Wei, Longhui and Zhang, Shiliang and Gao, Wen and Tian, Qi},<br>\ntitle = {Person Transfer GAN to Bridge Domain Gap for Person Re-Identification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Spurr_Cross-Modal_Deep_Variational_CVPR_2018_paper.html\">Cross-Modal Deep Variational Hand Pose Estimation</a></dt>\n<dd>\n<form id=\"form-AdrianSpurrCrossModalDeepVariational\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Adrian Spurr\">\n<a href=\"#\" onclick=\"document.getElementById('form-AdrianSpurrCrossModalDeepVariational').submit();\">Adrian Spurr</a>,\n</form>\n<form id=\"form-JieSongCrossModalDeepVariational\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jie Song\">\n<a href=\"#\" onclick=\"document.getElementById('form-JieSongCrossModalDeepVariational').submit();\">Jie Song</a>,\n</form>\n<form id=\"form-SeonwookParkCrossModalDeepVariational\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Seonwook Park\">\n<a href=\"#\" onclick=\"document.getElementById('form-SeonwookParkCrossModalDeepVariational').submit();\">Seonwook Park</a>,\n</form>\n<form id=\"form-OtmarHilligesCrossModalDeepVariational\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Otmar Hilliges\">\n<a href=\"#\" onclick=\"document.getElementById('form-OtmarHilligesCrossModalDeepVariational').submit();\">Otmar Hilliges</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Spurr_Cross-Modal_Deep_Variational_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3284-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.11404\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Spurr_2018_CVPR,<br>\nauthor = {Spurr, Adrian and Song, Jie and Park, Seonwook and Hilliges, Otmar},<br>\ntitle = {Cross-Modal Deep Variational Hand Pose Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ma_Disentangled_Person_Image_CVPR_2018_paper.html\">Disentangled Person Image Generation</a></dt>\n<dd>\n<form id=\"form-LiqianMaDisentangledPersonImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liqian Ma\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiqianMaDisentangledPersonImage').submit();\">Liqian Ma</a>,\n</form>\n<form id=\"form-QianruSunDisentangledPersonImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qianru Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-QianruSunDisentangledPersonImage').submit();\">Qianru Sun</a>,\n</form>\n<form id=\"form-StamatiosGeorgoulisDisentangledPersonImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stamatios Georgoulis\">\n<a href=\"#\" onclick=\"document.getElementById('form-StamatiosGeorgoulisDisentangledPersonImage').submit();\">Stamatios Georgoulis</a>,\n</form>\n<form id=\"form-LucVanDisentangledPersonImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Luc Van Gool\">\n<a href=\"#\" onclick=\"document.getElementById('form-LucVanDisentangledPersonImage').submit();\">Luc Van Gool</a>,\n</form>\n<form id=\"form-BerntSchieleDisentangledPersonImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bernt Schiele\">\n<a href=\"#\" onclick=\"document.getElementById('form-BerntSchieleDisentangledPersonImage').submit();\">Bernt Schiele</a>,\n</form>\n<form id=\"form-MarioFritzDisentangledPersonImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mario Fritz\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarioFritzDisentangledPersonImage').submit();\">Mario Fritz</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ma_Disentangled_Person_Image_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1801-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.02621\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ma_2018_CVPR,<br>\nauthor = {Ma, Liqian and Sun, Qianru and Georgoulis, Stamatios and Van Gool, Luc and Schiele, Bernt and Fritz, Mario},<br>\ntitle = {Disentangled Person Image Generation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Bulat_Super-FAN_Integrated_Facial_CVPR_2018_paper.html\">Super-FAN: Integrated Facial Landmark Localization and Super-Resolution of Real-World Low Resolution Faces in Arbitrary Poses With GANs</a></dt>\n<dd>\n<form id=\"form-AdrianBulatSuperFANIntegratedFacial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Adrian Bulat\">\n<a href=\"#\" onclick=\"document.getElementById('form-AdrianBulatSuperFANIntegratedFacial').submit();\">Adrian Bulat</a>,\n</form>\n<form id=\"form-GeorgiosTzimiropoulosSuperFANIntegratedFacial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Georgios Tzimiropoulos\">\n<a href=\"#\" onclick=\"document.getElementById('form-GeorgiosTzimiropoulosSuperFANIntegratedFacial').submit();\">Georgios Tzimiropoulos</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Bulat_Super-FAN_Integrated_Facial_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0568-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.02765\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Bulat_2018_CVPR,<br>\nauthor = {Bulat, Adrian and Tzimiropoulos, Georgios},<br>\ntitle = {Super-FAN: Integrated Facial Landmark Localization and Super-Resolution of Real-World Low Resolution Faces in Arbitrary Poses With GANs},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Si_Multistage_Adversarial_Losses_CVPR_2018_paper.html\">Multistage Adversarial Losses for Pose-Based Human Image Synthesis</a></dt>\n<dd>\n<form id=\"form-ChenyangSiMultistageAdversarialLosses\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chenyang Si\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenyangSiMultistageAdversarialLosses').submit();\">Chenyang Si</a>,\n</form>\n<form id=\"form-WeiWangMultistageAdversarialLosses\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiWangMultistageAdversarialLosses').submit();\">Wei Wang</a>,\n</form>\n<form id=\"form-LiangWangMultistageAdversarialLosses\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiangWangMultistageAdversarialLosses').submit();\">Liang Wang</a>,\n</form>\n<form id=\"form-TieniuTanMultistageAdversarialLosses\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tieniu Tan\">\n<a href=\"#\" onclick=\"document.getElementById('form-TieniuTanMultistageAdversarialLosses').submit();\">Tieniu Tan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Si_Multistage_Adversarial_Losses_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Si_2018_CVPR,<br>\nauthor = {Si, Chenyang and Wang, Wei and Wang, Liang and Tan, Tieniu},<br>\ntitle = {Multistage Adversarial Losses for Pose-Based Human Image Synthesis},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Eriksson_Rotation_Averaging_and_CVPR_2018_paper.html\">Rotation Averaging and Strong Duality</a></dt>\n<dd>\n<form id=\"form-AndersErikssonRotationAveragingand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anders Eriksson\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndersErikssonRotationAveragingand').submit();\">Anders Eriksson</a>,\n</form>\n<form id=\"form-CarlOlssonRotationAveragingand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Carl Olsson\">\n<a href=\"#\" onclick=\"document.getElementById('form-CarlOlssonRotationAveragingand').submit();\">Carl Olsson</a>,\n</form>\n<form id=\"form-FredrikKahlRotationAveragingand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fredrik Kahl\">\n<a href=\"#\" onclick=\"document.getElementById('form-FredrikKahlRotationAveragingand').submit();\">Fredrik Kahl</a>,\n</form>\n<form id=\"form-Tat-JunChinRotationAveragingand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tat-Jun Chin\">\n<a href=\"#\" onclick=\"document.getElementById('form-Tat-JunChinRotationAveragingand').submit();\">Tat-Jun Chin</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Eriksson_Rotation_Averaging_and_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0984-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1705.01362\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Eriksson_2018_CVPR,<br>\nauthor = {Eriksson, Anders and Olsson, Carl and Kahl, Fredrik and Chin, Tat-Jun},<br>\ntitle = {Rotation Averaging and Strong Duality},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Camposeco_Hybrid_Camera_Pose_CVPR_2018_paper.html\">Hybrid Camera Pose Estimation</a></dt>\n<dd>\n<form id=\"form-FedericoCamposecoHybridCameraPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Federico Camposeco\">\n<a href=\"#\" onclick=\"document.getElementById('form-FedericoCamposecoHybridCameraPose').submit();\">Federico Camposeco</a>,\n</form>\n<form id=\"form-AndreaCohenHybridCameraPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrea Cohen\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndreaCohenHybridCameraPose').submit();\">Andrea Cohen</a>,\n</form>\n<form id=\"form-MarcPollefeysHybridCameraPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Marc Pollefeys\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarcPollefeysHybridCameraPose').submit();\">Marc Pollefeys</a>,\n</form>\n<form id=\"form-TorstenSattlerHybridCameraPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Torsten Sattler\">\n<a href=\"#\" onclick=\"document.getElementById('form-TorstenSattlerHybridCameraPose').submit();\">Torsten Sattler</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Camposeco_Hybrid_Camera_Pose_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2462-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Camposeco_2018_CVPR,<br>\nauthor = {Camposeco, Federico and Cohen, Andrea and Pollefeys, Marc and Sattler, Torsten},<br>\ntitle = {Hybrid Camera Pose Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Briales_A_Certifiably_Globally_CVPR_2018_paper.html\">A Certifiably Globally Optimal Solution to the Non-Minimal Relative Pose Problem</a></dt>\n<dd>\n<form id=\"form-JesusBrialesACertifiablyGlobally\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jesus Briales\">\n<a href=\"#\" onclick=\"document.getElementById('form-JesusBrialesACertifiablyGlobally').submit();\">Jesus Briales</a>,\n</form>\n<form id=\"form-LaurentKneipACertifiablyGlobally\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Laurent Kneip\">\n<a href=\"#\" onclick=\"document.getElementById('form-LaurentKneipACertifiablyGlobally').submit();\">Laurent Kneip</a>,\n</form>\n<form id=\"form-JavierGonzalez-JimenezACertifiablyGlobally\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Javier Gonzalez-Jimenez\">\n<a href=\"#\" onclick=\"document.getElementById('form-JavierGonzalez-JimenezACertifiablyGlobally').submit();\">Javier Gonzalez-Jimenez</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Briales_A_Certifiably_Globally_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3968-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Briales_2018_CVPR,<br>\nauthor = {Briales, Jesus and Kneip, Laurent and Gonzalez-Jimenez, Javier},<br>\ntitle = {A Certifiably Globally Optimal Solution to the Non-Minimal Relative Pose Problem},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Luo_Single_View_Stereo_CVPR_2018_paper.html\">Single View Stereo Matching</a></dt>\n<dd>\n<form id=\"form-YueLuoSingleViewStereo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yue Luo\">\n<a href=\"#\" onclick=\"document.getElementById('form-YueLuoSingleViewStereo').submit();\">Yue Luo</a>,\n</form>\n<form id=\"form-JimmyRenSingleViewStereo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jimmy Ren\">\n<a href=\"#\" onclick=\"document.getElementById('form-JimmyRenSingleViewStereo').submit();\">Jimmy Ren</a>,\n</form>\n<form id=\"form-MudeLinSingleViewStereo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mude Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-MudeLinSingleViewStereo').submit();\">Mude Lin</a>,\n</form>\n<form id=\"form-JiahaoPangSingleViewStereo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiahao Pang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiahaoPangSingleViewStereo').submit();\">Jiahao Pang</a>,\n</form>\n<form id=\"form-WenxiuSunSingleViewStereo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenxiu Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenxiuSunSingleViewStereo').submit();\">Wenxiu Sun</a>,\n</form>\n<form id=\"form-HongshengLiSingleViewStereo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hongsheng Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-HongshengLiSingleViewStereo').submit();\">Hongsheng Li</a>,\n</form>\n<form id=\"form-LiangLinSingleViewStereo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liang Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiangLinSingleViewStereo').submit();\">Liang Lin</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Luo_Single_View_Stereo_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.02612\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Luo_2018_CVPR,<br>\nauthor = {Luo, Yue and Ren, Jimmy and Lin, Mude and Pang, Jiahao and Sun, Wenxiu and Li, Hongsheng and Lin, Liang},<br>\ntitle = {Single View Stereo Matching},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Haefner_Fight_Ill-Posedness_With_CVPR_2018_paper.html\">Fight Ill-Posedness With Ill-Posedness: Single-Shot Variational Depth Super-Resolution From Shading</a></dt>\n<dd>\n<form id=\"form-BjoernHaefnerFightIllPosednessWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bjoern Haefner\">\n<a href=\"#\" onclick=\"document.getElementById('form-BjoernHaefnerFightIllPosednessWith').submit();\">Bjoern Haefner</a>,\n</form>\n<form id=\"form-YvainQu\u00c3\u00a9auFightIllPosednessWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yvain Qu\u00c3\u00a9au\">\n<a href=\"#\" onclick=\"document.getElementById('form-YvainQu\u00c3\u00a9auFightIllPosednessWith').submit();\">Yvain Qu\u00c3\u00a9au</a>,\n</form>\n<form id=\"form-ThomasM\u00c3\u00b6llenhoffFightIllPosednessWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Thomas M\u00c3\u00b6llenhoff\">\n<a href=\"#\" onclick=\"document.getElementById('form-ThomasM\u00c3\u00b6llenhoffFightIllPosednessWith').submit();\">Thomas M\u00c3\u00b6llenhoff</a>,\n</form>\n<form id=\"form-DanielCremersFightIllPosednessWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daniel Cremers\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanielCremersFightIllPosednessWith').submit();\">Daniel Cremers</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Haefner_Fight_Ill-Posedness_With_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2980-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Haefner_2018_CVPR,<br>\nauthor = {Haefner, Bjoern and Qu\u00c3\u00a9au, Yvain and M\u00c3\u00b6llenhoff, Thomas and Cremers, Daniel},<br>\ntitle = {Fight Ill-Posedness With Ill-Posedness: Single-Shot Variational Depth Super-Resolution From Shading},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Deep_Depth_Completion_CVPR_2018_paper.html\">Deep Depth Completion of a Single RGB-D Image</a></dt>\n<dd>\n<form id=\"form-YindaZhangDeepDepthCompletion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yinda Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YindaZhangDeepDepthCompletion').submit();\">Yinda Zhang</a>,\n</form>\n<form id=\"form-ThomasFunkhouserDeepDepthCompletion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Thomas Funkhouser\">\n<a href=\"#\" onclick=\"document.getElementById('form-ThomasFunkhouserDeepDepthCompletion').submit();\">Thomas Funkhouser</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Deep_Depth_Completion_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3324-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.09326\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Yinda and Funkhouser, Thomas},<br>\ntitle = {Deep Depth Completion of a Single RGB-D Image},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yu_Multi-View_Harmonized_Bilinear_CVPR_2018_paper.html\">Multi-View Harmonized Bilinear Network for 3D Object Recognition</a></dt>\n<dd>\n<form id=\"form-TanYuMultiViewHarmonizedBilinear\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tan Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-TanYuMultiViewHarmonizedBilinear').submit();\">Tan Yu</a>,\n</form>\n<form id=\"form-JingjingMengMultiViewHarmonizedBilinear\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jingjing Meng\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingjingMengMultiViewHarmonizedBilinear').submit();\">Jingjing Meng</a>,\n</form>\n<form id=\"form-JunsongYuanMultiViewHarmonizedBilinear\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junsong Yuan\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunsongYuanMultiViewHarmonizedBilinear').submit();\">Junsong Yuan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yu_Multi-View_Harmonized_Bilinear_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yu_2018_CVPR,<br>\nauthor = {Yu, Tan and Meng, Jingjing and Yuan, Junsong},<br>\ntitle = {Multi-View Harmonized Bilinear Network for 3D Object Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Deng_PPFNet_Global_Context_CVPR_2018_paper.html\">PPFNet: Global Context Aware Local Features for Robust 3D Point Matching</a></dt>\n<dd>\n<form id=\"form-HaowenDengPPFNetGlobalContext\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Haowen Deng\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaowenDengPPFNetGlobalContext').submit();\">Haowen Deng</a>,\n</form>\n<form id=\"form-TolgaBirdalPPFNetGlobalContext\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tolga Birdal\">\n<a href=\"#\" onclick=\"document.getElementById('form-TolgaBirdalPPFNetGlobalContext').submit();\">Tolga Birdal</a>,\n</form>\n<form id=\"form-SlobodanIlicPPFNetGlobalContext\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Slobodan Ilic\">\n<a href=\"#\" onclick=\"document.getElementById('form-SlobodanIlicPPFNetGlobalContext').submit();\">Slobodan Ilic</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Deng_PPFNet_Global_Context_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.02669\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Deng_2018_CVPR,<br>\nauthor = {Deng, Haowen and Birdal, Tolga and Ilic, Slobodan},<br>\ntitle = {PPFNet: Global Context Aware Local Features for Robust 3D Point Matching},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yang_FoldingNet_Point_Cloud_CVPR_2018_paper.html\">FoldingNet: Point Cloud Auto-Encoder via Deep Grid Deformation</a></dt>\n<dd>\n<form id=\"form-YaoqingYangFoldingNetPointCloud\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yaoqing Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YaoqingYangFoldingNetPointCloud').submit();\">Yaoqing Yang</a>,\n</form>\n<form id=\"form-ChenFengFoldingNetPointCloud\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chen Feng\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenFengFoldingNetPointCloud').submit();\">Chen Feng</a>,\n</form>\n<form id=\"form-YiruShenFoldingNetPointCloud\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yiru Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiruShenFoldingNetPointCloud').submit();\">Yiru Shen</a>,\n</form>\n<form id=\"form-DongTianFoldingNetPointCloud\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dong Tian\">\n<a href=\"#\" onclick=\"document.getElementById('form-DongTianFoldingNetPointCloud').submit();\">Dong Tian</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yang_FoldingNet_Point_Cloud_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1129-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.07262\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yang_2018_CVPR,<br>\nauthor = {Yang, Yaoqing and Feng, Chen and Shen, Yiru and Tian, Dong},<br>\ntitle = {FoldingNet: Point Cloud Auto-Encoder via Deep Grid Deformation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Groueix_A_Papier-Mache_Approach_CVPR_2018_paper.html\">A Papier-M\u00c3\u00a2ch\u00c3\u00a9 Approach to Learning 3D Surface Generation</a></dt>\n<dd>\n<form id=\"form-ThibaultGroueixAPapierMchApproach\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Thibault Groueix\">\n<a href=\"#\" onclick=\"document.getElementById('form-ThibaultGroueixAPapierMchApproach').submit();\">Thibault Groueix</a>,\n</form>\n<form id=\"form-MatthewFisherAPapierMchApproach\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Matthew Fisher\">\n<a href=\"#\" onclick=\"document.getElementById('form-MatthewFisherAPapierMchApproach').submit();\">Matthew Fisher</a>,\n</form>\n<form id=\"form-VladimirG.APapierMchApproach\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vladimir G. Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-VladimirG.APapierMchApproach').submit();\">Vladimir G. Kim</a>,\n</form>\n<form id=\"form-BryanC.APapierMchApproach\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bryan C. Russell\">\n<a href=\"#\" onclick=\"document.getElementById('form-BryanC.APapierMchApproach').submit();\">Bryan C. Russell</a>,\n</form>\n<form id=\"form-MathieuAubryAPapierMchApproach\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mathieu Aubry\">\n<a href=\"#\" onclick=\"document.getElementById('form-MathieuAubryAPapierMchApproach').submit();\">Mathieu Aubry</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Groueix_A_Papier-Mache_Approach_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1775-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Groueix_2018_CVPR,<br>\nauthor = {Groueix, Thibault and Fisher, Matthew and Kim, Vladimir G. and Russell, Bryan C. and Aubry, Mathieu},<br>\ntitle = {A Papier-M\u00c3\u00a2ch\u00c3\u00a9 Approach to Learning 3D Surface Generation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yang_LEGO_Learning_Edge_CVPR_2018_paper.html\">LEGO: Learning Edge With Geometry All at Once by Watching Videos</a></dt>\n<dd>\n<form id=\"form-ZhenhengYangLEGOLearningEdge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhenheng Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhenhengYangLEGOLearningEdge').submit();\">Zhenheng Yang</a>,\n</form>\n<form id=\"form-PengWangLEGOLearningEdge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peng Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-PengWangLEGOLearningEdge').submit();\">Peng Wang</a>,\n</form>\n<form id=\"form-YangWangLEGOLearningEdge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YangWangLEGOLearningEdge').submit();\">Yang Wang</a>,\n</form>\n<form id=\"form-WeiXuLEGOLearningEdge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiXuLEGOLearningEdge').submit();\">Wei Xu</a>,\n</form>\n<form id=\"form-RamNevatiaLEGOLearningEdge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ram Nevatia\">\n<a href=\"#\" onclick=\"document.getElementById('form-RamNevatiaLEGOLearningEdge').submit();\">Ram Nevatia</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yang_LEGO_Learning_Edge_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2629-supp.zip\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.05648\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yang_2018_CVPR,<br>\nauthor = {Yang, Zhenheng and Wang, Peng and Wang, Yang and Xu, Wei and Nevatia, Ram},<br>\ntitle = {LEGO: Learning Edge With Geometry All at Once by Watching Videos},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Barath_Five-Point_Fundamental_Matrix_CVPR_2018_paper.html\">Five-Point Fundamental Matrix Estimation for Uncalibrated Cameras</a></dt>\n<dd>\n<form id=\"form-DanielBarathFivePointFundamentalMatrix\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daniel Barath\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanielBarathFivePointFundamentalMatrix').submit();\">Daniel Barath</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Barath_Five-Point_Fundamental_Matrix_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.00260\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Barath_2018_CVPR,<br>\nauthor = {Barath, Daniel},<br>\ntitle = {Five-Point Fundamental Matrix Estimation for Uncalibrated Cameras},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xu_PointFusion_Deep_Sensor_CVPR_2018_paper.html\">PointFusion: Deep Sensor Fusion for 3D Bounding Box Estimation</a></dt>\n<dd>\n<form id=\"form-DanfeiXuPointFusionDeepSensor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Danfei Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanfeiXuPointFusionDeepSensor').submit();\">Danfei Xu</a>,\n</form>\n<form id=\"form-DragomirAnguelovPointFusionDeepSensor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dragomir Anguelov\">\n<a href=\"#\" onclick=\"document.getElementById('form-DragomirAnguelovPointFusionDeepSensor').submit();\">Dragomir Anguelov</a>,\n</form>\n<form id=\"form-AsheshJainPointFusionDeepSensor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ashesh Jain\">\n<a href=\"#\" onclick=\"document.getElementById('form-AsheshJainPointFusionDeepSensor').submit();\">Ashesh Jain</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xu_PointFusion_Deep_Sensor_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.10871\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xu_2018_CVPR,<br>\nauthor = {Xu, Danfei and Anguelov, Dragomir and Jain, Ashesh},<br>\ntitle = {PointFusion: Deep Sensor Fusion for 3D Bounding Box Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kumar_Scalable_Dense_Non-Rigid_CVPR_2018_paper.html\">Scalable Dense Non-Rigid Structure-From-Motion: A Grassmannian Perspective</a></dt>\n<dd>\n<form id=\"form-SuryanshKumarScalableDenseNonRigid\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Suryansh Kumar\">\n<a href=\"#\" onclick=\"document.getElementById('form-SuryanshKumarScalableDenseNonRigid').submit();\">Suryansh Kumar</a>,\n</form>\n<form id=\"form-AnoopCherianScalableDenseNonRigid\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anoop Cherian\">\n<a href=\"#\" onclick=\"document.getElementById('form-AnoopCherianScalableDenseNonRigid').submit();\">Anoop Cherian</a>,\n</form>\n<form id=\"form-YuchaoDaiScalableDenseNonRigid\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuchao Dai\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuchaoDaiScalableDenseNonRigid').submit();\">Yuchao Dai</a>,\n</form>\n<form id=\"form-HongdongLiScalableDenseNonRigid\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hongdong Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-HongdongLiScalableDenseNonRigid').submit();\">Hongdong Li</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kumar_Scalable_Dense_Non-Rigid_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1350-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.00233\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kumar_2018_CVPR,<br>\nauthor = {Kumar, Suryansh and Cherian, Anoop and Dai, Yuchao and Li, Hongdong},<br>\ntitle = {Scalable Dense Non-Rigid Structure-From-Motion: A Grassmannian Perspective},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Feng_GVCNN_Group-View_Convolutional_CVPR_2018_paper.html\">GVCNN: Group-View Convolutional Neural Networks for 3D Shape Recognition</a></dt>\n<dd>\n<form id=\"form-YifanFengGVCNNGroupViewConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yifan Feng\">\n<a href=\"#\" onclick=\"document.getElementById('form-YifanFengGVCNNGroupViewConvolutional').submit();\">Yifan Feng</a>,\n</form>\n<form id=\"form-ZizhaoZhangGVCNNGroupViewConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zizhao Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZizhaoZhangGVCNNGroupViewConvolutional').submit();\">Zizhao Zhang</a>,\n</form>\n<form id=\"form-XibinZhaoGVCNNGroupViewConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xibin Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-XibinZhaoGVCNNGroupViewConvolutional').submit();\">Xibin Zhao</a>,\n</form>\n<form id=\"form-RongrongJiGVCNNGroupViewConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rongrong Ji\">\n<a href=\"#\" onclick=\"document.getElementById('form-RongrongJiGVCNNGroupViewConvolutional').submit();\">Rongrong Ji</a>,\n</form>\n<form id=\"form-YueGaoGVCNNGroupViewConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yue Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-YueGaoGVCNNGroupViewConvolutional').submit();\">Yue Gao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Feng_GVCNN_Group-View_Convolutional_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Feng_2018_CVPR,<br>\nauthor = {Feng, Yifan and Zhang, Zizhao and Zhao, Xibin and Ji, Rongrong and Gao, Yue},<br>\ntitle = {GVCNN: Group-View Convolutional Neural Networks for 3D Shape Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sun_Depth_and_Transient_CVPR_2018_paper.html\">Depth and Transient Imaging With Compressive SPAD Array Cameras</a></dt>\n<dd>\n<form id=\"form-QilinSunDepthandTransient\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qilin Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-QilinSunDepthandTransient').submit();\">Qilin Sun</a>,\n</form>\n<form id=\"form-XiongDunDepthandTransient\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiong Dun\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiongDunDepthandTransient').submit();\">Xiong Dun</a>,\n</form>\n<form id=\"form-YifanPengDepthandTransient\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yifan Peng\">\n<a href=\"#\" onclick=\"document.getElementById('form-YifanPengDepthandTransient').submit();\">Yifan Peng</a>,\n</form>\n<form id=\"form-WolfgangHeidrichDepthandTransient\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wolfgang Heidrich\">\n<a href=\"#\" onclick=\"document.getElementById('form-WolfgangHeidrichDepthandTransient').submit();\">Wolfgang Heidrich</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sun_Depth_and_Transient_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sun_2018_CVPR,<br>\nauthor = {Sun, Qilin and Dun, Xiong and Peng, Yifan and Heidrich, Wolfgang},<br>\ntitle = {Depth and Transient Imaging With Compressive SPAD Array Cameras},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Qi_GeoNet_Geometric_Neural_CVPR_2018_paper.html\">GeoNet: Geometric Neural Network for Joint Depth and Surface Normal Estimation</a></dt>\n<dd>\n<form id=\"form-XiaojuanQiGeoNetGeometricNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaojuan Qi\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaojuanQiGeoNetGeometricNeural').submit();\">Xiaojuan Qi</a>,\n</form>\n<form id=\"form-RenjieLiaoGeoNetGeometricNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Renjie Liao\">\n<a href=\"#\" onclick=\"document.getElementById('form-RenjieLiaoGeoNetGeometricNeural').submit();\">Renjie Liao</a>,\n</form>\n<form id=\"form-ZhengzheLiuGeoNetGeometricNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhengzhe Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhengzheLiuGeoNetGeometricNeural').submit();\">Zhengzhe Liu</a>,\n</form>\n<form id=\"form-RaquelUrtasunGeoNetGeometricNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Raquel Urtasun\">\n<a href=\"#\" onclick=\"document.getElementById('form-RaquelUrtasunGeoNetGeometricNeural').submit();\">Raquel Urtasun</a>,\n</form>\n<form id=\"form-JiayaJiaGeoNetGeometricNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiaya Jia\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiayaJiaGeoNetGeometricNeural').submit();\">Jiaya Jia</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Qi_GeoNet_Geometric_Neural_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Qi_2018_CVPR,<br>\nauthor = {Qi, Xiaojuan and Liao, Renjie and Liu, Zhengzhe and Urtasun, Raquel and Jia, Jiaya},<br>\ntitle = {GeoNet: Geometric Neural Network for Joint Depth and Surface Normal Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tekin_Real-Time_Seamless_Single_CVPR_2018_paper.html\">Real-Time Seamless Single Shot 6D Object Pose Prediction</a></dt>\n<dd>\n<form id=\"form-BugraTekinRealTimeSeamlessSingle\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bugra Tekin\">\n<a href=\"#\" onclick=\"document.getElementById('form-BugraTekinRealTimeSeamlessSingle').submit();\">Bugra Tekin</a>,\n</form>\n<form id=\"form-SudiptaN.RealTimeSeamlessSingle\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sudipta N. Sinha\">\n<a href=\"#\" onclick=\"document.getElementById('form-SudiptaN.RealTimeSeamlessSingle').submit();\">Sudipta N. Sinha</a>,\n</form>\n<form id=\"form-PascalFuaRealTimeSeamlessSingle\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pascal Fua\">\n<a href=\"#\" onclick=\"document.getElementById('form-PascalFuaRealTimeSeamlessSingle').submit();\">Pascal Fua</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tekin_Real-Time_Seamless_Single_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3117-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.08848\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tekin_2018_CVPR,<br>\nauthor = {Tekin, Bugra and Sinha, Sudipta N. and Fua, Pascal},<br>\ntitle = {Real-Time Seamless Single Shot 6D Object Pose Prediction},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tulsiani_Factoring_Shape_Pose_CVPR_2018_paper.html\">Factoring Shape, Pose, and Layout From the 2D Image of a 3D Scene</a></dt>\n<dd>\n<form id=\"form-ShubhamTulsianiFactoringShapePose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shubham Tulsiani\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShubhamTulsianiFactoringShapePose').submit();\">Shubham Tulsiani</a>,\n</form>\n<form id=\"form-SaurabhGuptaFactoringShapePose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Saurabh Gupta\">\n<a href=\"#\" onclick=\"document.getElementById('form-SaurabhGuptaFactoringShapePose').submit();\">Saurabh Gupta</a>,\n</form>\n<form id=\"form-DavidF.FactoringShapePose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"David F. Fouhey\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavidF.FactoringShapePose').submit();\">David F. Fouhey</a>,\n</form>\n<form id=\"form-AlexeiA.FactoringShapePose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexei A. Efros\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexeiA.FactoringShapePose').submit();\">Alexei A. Efros</a>,\n</form>\n<form id=\"form-JitendraMalikFactoringShapePose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jitendra Malik\">\n<a href=\"#\" onclick=\"document.getElementById('form-JitendraMalikFactoringShapePose').submit();\">Jitendra Malik</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tulsiani_Factoring_Shape_Pose_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0757-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tulsiani_2018_CVPR,<br>\nauthor = {Tulsiani, Shubham and Gupta, Saurabh and Fouhey, David F. and Efros, Alexei A. and Malik, Jitendra},<br>\ntitle = {Factoring Shape, Pose, and Layout From the 2D Image of a 3D Scene},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xian_Monocular_Relative_Depth_CVPR_2018_paper.html\">Monocular Relative Depth Perception With Web Stereo Data Supervision</a></dt>\n<dd>\n<form id=\"form-KeXianMonocularRelativeDepth\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ke Xian\">\n<a href=\"#\" onclick=\"document.getElementById('form-KeXianMonocularRelativeDepth').submit();\">Ke Xian</a>,\n</form>\n<form id=\"form-ChunhuaShenMonocularRelativeDepth\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chunhua Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChunhuaShenMonocularRelativeDepth').submit();\">Chunhua Shen</a>,\n</form>\n<form id=\"form-ZhiguoCaoMonocularRelativeDepth\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhiguo Cao\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhiguoCaoMonocularRelativeDepth').submit();\">Zhiguo Cao</a>,\n</form>\n<form id=\"form-HaoLuMonocularRelativeDepth\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hao Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaoLuMonocularRelativeDepth').submit();\">Hao Lu</a>,\n</form>\n<form id=\"form-YangXiaoMonocularRelativeDepth\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yang Xiao\">\n<a href=\"#\" onclick=\"document.getElementById('form-YangXiaoMonocularRelativeDepth').submit();\">Yang Xiao</a>,\n</form>\n<form id=\"form-RuiboLiMonocularRelativeDepth\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ruibo Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-RuiboLiMonocularRelativeDepth').submit();\">Ruibo Li</a>,\n</form>\n<form id=\"form-ZhenboLuoMonocularRelativeDepth\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhenbo Luo\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhenboLuoMonocularRelativeDepth').submit();\">Zhenbo Luo</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xian_Monocular_Relative_Depth_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xian_2018_CVPR,<br>\nauthor = {Xian, Ke and Shen, Chunhua and Cao, Zhiguo and Lu, Hao and Xiao, Yang and Li, Ruibo and Luo, Zhenbo},<br>\ntitle = {Monocular Relative Depth Perception With Web Stereo Data Supervision},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ovren_Spline_Error_Weighting_CVPR_2018_paper.html\">Spline Error Weighting for Robust Visual-Inertial Fusion</a></dt>\n<dd>\n<form id=\"form-HannesOvr\u00c3\u00a9nSplineErrorWeighting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hannes Ovr\u00c3\u00a9n\">\n<a href=\"#\" onclick=\"document.getElementById('form-HannesOvr\u00c3\u00a9nSplineErrorWeighting').submit();\">Hannes Ovr\u00c3\u00a9n</a>,\n</form>\n<form id=\"form-Per-ErikForss\u00c3\u00a9nSplineErrorWeighting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Per-Erik Forss\u00c3\u00a9n\">\n<a href=\"#\" onclick=\"document.getElementById('form-Per-ErikForss\u00c3\u00a9nSplineErrorWeighting').submit();\">Per-Erik Forss\u00c3\u00a9n</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ovren_Spline_Error_Weighting_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2138-supp.zip\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.04820\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ovr\u00c3\u00a9n_2018_CVPR,<br>\nauthor = {Ovr\u00c3\u00a9n, Hannes and Forss\u00c3\u00a9n, Per-Erik},<br>\ntitle = {Spline Error Weighting for Robust Visual-Inertial Fusion},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lee_Single-Image_Depth_Estimation_CVPR_2018_paper.html\">Single-Image Depth Estimation Based on Fourier Domain Analysis</a></dt>\n<dd>\n<form id=\"form-Jae-HanLeeSingleImageDepthEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jae-Han Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jae-HanLeeSingleImageDepthEstimation').submit();\">Jae-Han Lee</a>,\n</form>\n<form id=\"form-MinhyeokHeoSingleImageDepthEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Minhyeok Heo\">\n<a href=\"#\" onclick=\"document.getElementById('form-MinhyeokHeoSingleImageDepthEstimation').submit();\">Minhyeok Heo</a>,\n</form>\n<form id=\"form-Kyung-RaeKimSingleImageDepthEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kyung-Rae Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-Kyung-RaeKimSingleImageDepthEstimation').submit();\">Kyung-Rae Kim</a>,\n</form>\n<form id=\"form-Chang-SuKimSingleImageDepthEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chang-Su Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-Chang-SuKimSingleImageDepthEstimation').submit();\">Chang-Su Kim</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lee_Single-Image_Depth_Estimation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2873-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lee_2018_CVPR,<br>\nauthor = {Lee, Jae-Han and Heo, Minhyeok and Kim, Kyung-Rae and Kim, Chang-Su},<br>\ntitle = {Single-Image Depth Estimation Based on Fourier Domain Analysis},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhan_Unsupervised_Learning_of_CVPR_2018_paper.html\">Unsupervised Learning of Monocular Depth Estimation and Visual Odometry With Deep Feature Reconstruction</a></dt>\n<dd>\n<form id=\"form-HuangyingZhanUnsupervisedLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huangying Zhan\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuangyingZhanUnsupervisedLearningof').submit();\">Huangying Zhan</a>,\n</form>\n<form id=\"form-RaviGargUnsupervisedLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ravi Garg\">\n<a href=\"#\" onclick=\"document.getElementById('form-RaviGargUnsupervisedLearningof').submit();\">Ravi Garg</a>,\n</form>\n<form id=\"form-ChamaraSarojUnsupervisedLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chamara Saroj Weerasekera\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChamaraSarojUnsupervisedLearningof').submit();\">Chamara Saroj Weerasekera</a>,\n</form>\n<form id=\"form-KejieLiUnsupervisedLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kejie Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-KejieLiUnsupervisedLearningof').submit();\">Kejie Li</a>,\n</form>\n<form id=\"form-HarshAgarwalUnsupervisedLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Harsh Agarwal\">\n<a href=\"#\" onclick=\"document.getElementById('form-HarshAgarwalUnsupervisedLearningof').submit();\">Harsh Agarwal</a>,\n</form>\n<form id=\"form-IanReidUnsupervisedLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ian Reid\">\n<a href=\"#\" onclick=\"document.getElementById('form-IanReidUnsupervisedLearningof').submit();\">Ian Reid</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhan_Unsupervised_Learning_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/4186-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.03893\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhan_2018_CVPR,<br>\nauthor = {Zhan, Huangying and Garg, Ravi and Saroj Weerasekera, Chamara and Li, Kejie and Agarwal, Harsh and Reid, Ian},<br>\ntitle = {Unsupervised Learning of Monocular Depth Estimation and Visual Odometry With Deep Feature Reconstruction},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Girdhar_Detect-and-Track_Efficient_Pose_CVPR_2018_paper.html\">Detect-and-Track: Efficient Pose Estimation in Videos</a></dt>\n<dd>\n<form id=\"form-RohitGirdharDetectandTrackEfficientPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rohit Girdhar\">\n<a href=\"#\" onclick=\"document.getElementById('form-RohitGirdharDetectandTrackEfficientPose').submit();\">Rohit Girdhar</a>,\n</form>\n<form id=\"form-GeorgiaGkioxariDetectandTrackEfficientPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Georgia Gkioxari\">\n<a href=\"#\" onclick=\"document.getElementById('form-GeorgiaGkioxariDetectandTrackEfficientPose').submit();\">Georgia Gkioxari</a>,\n</form>\n<form id=\"form-LorenzoTorresaniDetectandTrackEfficientPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lorenzo Torresani\">\n<a href=\"#\" onclick=\"document.getElementById('form-LorenzoTorresaniDetectandTrackEfficientPose').submit();\">Lorenzo Torresani</a>,\n</form>\n<form id=\"form-ManoharPaluriDetectandTrackEfficientPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Manohar Paluri\">\n<a href=\"#\" onclick=\"document.getElementById('form-ManoharPaluriDetectandTrackEfficientPose').submit();\">Manohar Paluri</a>,\n</form>\n<form id=\"form-DuTranDetectandTrackEfficientPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Du Tran\">\n<a href=\"#\" onclick=\"document.getElementById('form-DuTranDetectandTrackEfficientPose').submit();\">Du Tran</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Girdhar_Detect-and-Track_Efficient_Pose_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.09184\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Girdhar_2018_CVPR,<br>\nauthor = {Girdhar, Rohit and Gkioxari, Georgia and Torresani, Lorenzo and Paluri, Manohar and Tran, Du},<br>\ntitle = {Detect-and-Track: Efficient Pose Estimation in Videos},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Dong_Supervision-by-Registration_An_Unsupervised_CVPR_2018_paper.html\">Supervision-by-Registration: An Unsupervised Approach to Improve the Precision of Facial Landmark Detectors</a></dt>\n<dd>\n<form id=\"form-XuanyiDongSupervisionbyRegistrationAnUnsupervised\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xuanyi Dong\">\n<a href=\"#\" onclick=\"document.getElementById('form-XuanyiDongSupervisionbyRegistrationAnUnsupervised').submit();\">Xuanyi Dong</a>,\n</form>\n<form id=\"form-Shoou-IYuSupervisionbyRegistrationAnUnsupervised\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shoou-I Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Shoou-IYuSupervisionbyRegistrationAnUnsupervised').submit();\">Shoou-I Yu</a>,\n</form>\n<form id=\"form-XinshuoWengSupervisionbyRegistrationAnUnsupervised\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xinshuo Weng\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinshuoWengSupervisionbyRegistrationAnUnsupervised').submit();\">Xinshuo Weng</a>,\n</form>\n<form id=\"form-Shih-EnWeiSupervisionbyRegistrationAnUnsupervised\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shih-En Wei\">\n<a href=\"#\" onclick=\"document.getElementById('form-Shih-EnWeiSupervisionbyRegistrationAnUnsupervised').submit();\">Shih-En Wei</a>,\n</form>\n<form id=\"form-YiYangSupervisionbyRegistrationAnUnsupervised\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiYangSupervisionbyRegistrationAnUnsupervised').submit();\">Yi Yang</a>,\n</form>\n<form id=\"form-YaserSheikhSupervisionbyRegistrationAnUnsupervised\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yaser Sheikh\">\n<a href=\"#\" onclick=\"document.getElementById('form-YaserSheikhSupervisionbyRegistrationAnUnsupervised').submit();\">Yaser Sheikh</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Dong_Supervision-by-Registration_An_Unsupervised_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1807.00966\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Dong_2018_CVPR,<br>\nauthor = {Dong, Xuanyi and Yu, Shoou-I and Weng, Xinshuo and Wei, Shih-En and Yang, Yi and Sheikh, Yaser},<br>\ntitle = {Supervision-by-Registration: An Unsupervised Approach to Improve the Precision of Facial Landmark Detectors},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Diversity_Regularized_Spatiotemporal_CVPR_2018_paper.html\">Diversity Regularized Spatiotemporal Attention for Video-Based Person Re-Identification</a></dt>\n<dd>\n<form id=\"form-ShuangLiDiversityRegularizedSpatiotemporal\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuang Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuangLiDiversityRegularizedSpatiotemporal').submit();\">Shuang Li</a>,\n</form>\n<form id=\"form-SlawomirBakDiversityRegularizedSpatiotemporal\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Slawomir Bak\">\n<a href=\"#\" onclick=\"document.getElementById('form-SlawomirBakDiversityRegularizedSpatiotemporal').submit();\">Slawomir Bak</a>,\n</form>\n<form id=\"form-PeterCarrDiversityRegularizedSpatiotemporal\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peter Carr\">\n<a href=\"#\" onclick=\"document.getElementById('form-PeterCarrDiversityRegularizedSpatiotemporal').submit();\">Peter Carr</a>,\n</form>\n<form id=\"form-XiaogangWangDiversityRegularizedSpatiotemporal\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaogang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaogangWangDiversityRegularizedSpatiotemporal').submit();\">Xiaogang Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Diversity_Regularized_Spatiotemporal_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0312-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.09882\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Shuang and Bak, Slawomir and Carr, Peter and Wang, Xiaogang},<br>\ntitle = {Diversity Regularized Spatiotemporal Attention for Video-Based Person Re-Identification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Dong_Style_Aggregated_Network_CVPR_2018_paper.html\">Style Aggregated Network for Facial Landmark Detection</a></dt>\n<dd>\n<form id=\"form-XuanyiDongStyleAggregatedNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xuanyi Dong\">\n<a href=\"#\" onclick=\"document.getElementById('form-XuanyiDongStyleAggregatedNetwork').submit();\">Xuanyi Dong</a>,\n</form>\n<form id=\"form-YanYanStyleAggregatedNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yan Yan\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanYanStyleAggregatedNetwork').submit();\">Yan Yan</a>,\n</form>\n<form id=\"form-WanliOuyangStyleAggregatedNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wanli Ouyang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WanliOuyangStyleAggregatedNetwork').submit();\">Wanli Ouyang</a>,\n</form>\n<form id=\"form-YiYangStyleAggregatedNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiYangStyleAggregatedNetwork').submit();\">Yi Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Dong_Style_Aggregated_Network_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.04108\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Dong_2018_CVPR,<br>\nauthor = {Dong, Xuanyi and Yan, Yan and Ouyang, Wanli and Yang, Yi},<br>\ntitle = {Style Aggregated Network for Facial Landmark Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_Learning_Deep_Models_CVPR_2018_paper.html\">Learning Deep Models for Face Anti-Spoofing: Binary or Auxiliary Supervision</a></dt>\n<dd>\n<form id=\"form-YaojieLiuLearningDeepModels\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yaojie Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YaojieLiuLearningDeepModels').submit();\">Yaojie Liu</a>,\n</form>\n<form id=\"form-AminJourablooLearningDeepModels\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Amin Jourabloo\">\n<a href=\"#\" onclick=\"document.getElementById('form-AminJourablooLearningDeepModels').submit();\">Amin Jourabloo</a>,\n</form>\n<form id=\"form-XiaomingLiuLearningDeepModels\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaoming Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaomingLiuLearningDeepModels').submit();\">Xiaoming Liu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_Learning_Deep_Models_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.11097\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Yaojie and Jourabloo, Amin and Liu, Xiaoming},<br>\ntitle = {Learning Deep Models for Face Anti-Spoofing: Binary or Auxiliary Supervision},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Deep_Cost-Sensitive_and_CVPR_2018_paper.html\">Deep Cost-Sensitive and Order-Preserving Feature Learning for Cross-Population Age Estimation</a></dt>\n<dd>\n<form id=\"form-KaiLiDeepCostSensitiveand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kai Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaiLiDeepCostSensitiveand').submit();\">Kai Li</a>,\n</form>\n<form id=\"form-JunliangXingDeepCostSensitiveand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junliang Xing\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunliangXingDeepCostSensitiveand').submit();\">Junliang Xing</a>,\n</form>\n<form id=\"form-ChiSuDeepCostSensitiveand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chi Su\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChiSuDeepCostSensitiveand').submit();\">Chi Su</a>,\n</form>\n<form id=\"form-WeimingHuDeepCostSensitiveand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weiming Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeimingHuDeepCostSensitiveand').submit();\">Weiming Hu</a>,\n</form>\n<form id=\"form-YundongZhangDeepCostSensitiveand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yundong Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YundongZhangDeepCostSensitiveand').submit();\">Yundong Zhang</a>,\n</form>\n<form id=\"form-StephenMaybankDeepCostSensitiveand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stephen Maybank\">\n<a href=\"#\" onclick=\"document.getElementById('form-StephenMaybankDeepCostSensitiveand').submit();\">Stephen Maybank</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Deep_Cost-Sensitive_and_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Kai and Xing, Junliang and Su, Chi and Hu, Weiming and Zhang, Yundong and Maybank, Stephen},<br>\ntitle = {Deep Cost-Sensitive and Order-Preserving Feature Learning for Cross-Population Age Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Garcia-Hernando_First-Person_Hand_Action_CVPR_2018_paper.html\">First-Person Hand Action Benchmark With RGB-D Videos and 3D Hand Pose Annotations</a></dt>\n<dd>\n<form id=\"form-GuillermoGarcia-HernandoFirstPersonHandAction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guillermo Garcia-Hernando\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuillermoGarcia-HernandoFirstPersonHandAction').submit();\">Guillermo Garcia-Hernando</a>,\n</form>\n<form id=\"form-ShanxinYuanFirstPersonHandAction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shanxin Yuan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShanxinYuanFirstPersonHandAction').submit();\">Shanxin Yuan</a>,\n</form>\n<form id=\"form-SeungryulBaekFirstPersonHandAction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Seungryul Baek\">\n<a href=\"#\" onclick=\"document.getElementById('form-SeungryulBaekFirstPersonHandAction').submit();\">Seungryul Baek</a>,\n</form>\n<form id=\"form-Tae-KyunKimFirstPersonHandAction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tae-Kyun Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-Tae-KyunKimFirstPersonHandAction').submit();\">Tae-Kyun Kim</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Garcia-Hernando_First-Person_Hand_Action_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1704.02463\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Garcia-Hernando_2018_CVPR,<br>\nauthor = {Garcia-Hernando, Guillermo and Yuan, Shanxin and Baek, Seungryul and Kim, Tae-Kyun},<br>\ntitle = {First-Person Hand Action Benchmark With RGB-D Videos and 3D Hand Pose Annotations},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sarfraz_A_Pose-Sensitive_Embedding_CVPR_2018_paper.html\">A Pose-Sensitive Embedding for Person Re-Identification With Expanded Cross Neighborhood Re-Ranking</a></dt>\n<dd>\n<form id=\"form-M.SaquibAPoseSensitiveEmbedding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"M. Saquib Sarfraz\">\n<a href=\"#\" onclick=\"document.getElementById('form-M.SaquibAPoseSensitiveEmbedding').submit();\">M. Saquib Sarfraz</a>,\n</form>\n<form id=\"form-ArneSchumannAPoseSensitiveEmbedding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Arne Schumann\">\n<a href=\"#\" onclick=\"document.getElementById('form-ArneSchumannAPoseSensitiveEmbedding').submit();\">Arne Schumann</a>,\n</form>\n<form id=\"form-AndreasEberleAPoseSensitiveEmbedding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andreas Eberle\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndreasEberleAPoseSensitiveEmbedding').submit();\">Andreas Eberle</a>,\n</form>\n<form id=\"form-RainerStiefelhagenAPoseSensitiveEmbedding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rainer Stiefelhagen\">\n<a href=\"#\" onclick=\"document.getElementById('form-RainerStiefelhagenAPoseSensitiveEmbedding').submit();\">Rainer Stiefelhagen</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sarfraz_A_Pose-Sensitive_Embedding_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.10378\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sarfraz_2018_CVPR,<br>\nauthor = {Saquib Sarfraz, M. and Schumann, Arne and Eberle, Andreas and Stiefelhagen, Rainer},<br>\ntitle = {A Pose-Sensitive Embedding for Person Re-Identification With Expanded Cross Neighborhood Re-Ranking},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kumar_Disentangling_3D_Pose_CVPR_2018_paper.html\">Disentangling 3D Pose in a Dendritic CNN for Unconstrained 2D Face Alignment</a></dt>\n<dd>\n<form id=\"form-AmitKumarDisentangling3DPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Amit Kumar\">\n<a href=\"#\" onclick=\"document.getElementById('form-AmitKumarDisentangling3DPose').submit();\">Amit Kumar</a>,\n</form>\n<form id=\"form-RamaChellappaDisentangling3DPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rama Chellappa\">\n<a href=\"#\" onclick=\"document.getElementById('form-RamaChellappaDisentangling3DPose').submit();\">Rama Chellappa</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kumar_Disentangling_3D_Pose_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1230-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.06713\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kumar_2018_CVPR,<br>\nauthor = {Kumar, Amit and Chellappa, Rama},<br>\ntitle = {Disentangling 3D Pose in a Dendritic CNN for Unconstrained 2D Face Alignment},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_A_Hierarchical_Generative_CVPR_2018_paper.html\">A Hierarchical Generative Model for Eye Image Synthesis and Eye Gaze Estimation</a></dt>\n<dd>\n<form id=\"form-KangWangAHierarchicalGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-KangWangAHierarchicalGenerative').submit();\">Kang Wang</a>,\n</form>\n<form id=\"form-RuiZhaoAHierarchicalGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rui Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-RuiZhaoAHierarchicalGenerative').submit();\">Rui Zhao</a>,\n</form>\n<form id=\"form-QiangJiAHierarchicalGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qiang Ji\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiangJiAHierarchicalGenerative').submit();\">Qiang Ji</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_A_Hierarchical_Generative_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Kang and Zhao, Rui and Ji, Qiang},<br>\ntitle = {A Hierarchical Generative Model for Eye Image Synthesis and Eye Gaze Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhou_MiCT_Mixed_3D2D_CVPR_2018_paper.html\">MiCT: Mixed 3D/2D Convolutional Tube for Human Action Recognition</a></dt>\n<dd>\n<form id=\"form-YizhouZhouMiCTMixed3D2D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yizhou Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-YizhouZhouMiCTMixed3D2D').submit();\">Yizhou Zhou</a>,\n</form>\n<form id=\"form-XiaoyanSunMiCTMixed3D2D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaoyan Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaoyanSunMiCTMixed3D2D').submit();\">Xiaoyan Sun</a>,\n</form>\n<form id=\"form-Zheng-JunZhaMiCTMixed3D2D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zheng-Jun Zha\">\n<a href=\"#\" onclick=\"document.getElementById('form-Zheng-JunZhaMiCTMixed3D2D').submit();\">Zheng-Jun Zha</a>,\n</form>\n<form id=\"form-WenjunZengMiCTMixed3D2D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenjun Zeng\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenjunZengMiCTMixed3D2D').submit();\">Wenjun Zeng</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhou_MiCT_Mixed_3D2D_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhou_2018_CVPR,<br>\nauthor = {Zhou, Yizhou and Sun, Xiaoyan and Zha, Zheng-Jun and Zeng, Wenjun},<br>\ntitle = {MiCT: Mixed 3D/2D Convolutional Tube for Human Action Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Pavlakos_Learning_to_Estimate_CVPR_2018_paper.html\">Learning to Estimate 3D Human Pose and Shape From a Single Color Image</a></dt>\n<dd>\n<form id=\"form-GeorgiosPavlakosLearningtoEstimate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Georgios Pavlakos\">\n<a href=\"#\" onclick=\"document.getElementById('form-GeorgiosPavlakosLearningtoEstimate').submit();\">Georgios Pavlakos</a>,\n</form>\n<form id=\"form-LuyangZhuLearningtoEstimate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Luyang Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-LuyangZhuLearningtoEstimate').submit();\">Luyang Zhu</a>,\n</form>\n<form id=\"form-XiaoweiZhouLearningtoEstimate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaowei Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaoweiZhouLearningtoEstimate').submit();\">Xiaowei Zhou</a>,\n</form>\n<form id=\"form-KostasDaniilidisLearningtoEstimate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kostas Daniilidis\">\n<a href=\"#\" onclick=\"document.getElementById('form-KostasDaniilidisLearningtoEstimate').submit();\">Kostas Daniilidis</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Pavlakos_Learning_to_Estimate_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3736-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.04092\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Pavlakos_2018_CVPR,<br>\nauthor = {Pavlakos, Georgios and Zhu, Luyang and Zhou, Xiaowei and Daniilidis, Kostas},<br>\ntitle = {Learning to Estimate 3D Human Pose and Shape From a Single Color Image},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Baradel_Glimpse_Clouds_Human_CVPR_2018_paper.html\">Glimpse Clouds: Human Activity Recognition From Unstructured Feature Points</a></dt>\n<dd>\n<form id=\"form-FabienBaradelGlimpseCloudsHuman\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fabien Baradel\">\n<a href=\"#\" onclick=\"document.getElementById('form-FabienBaradelGlimpseCloudsHuman').submit();\">Fabien Baradel</a>,\n</form>\n<form id=\"form-ChristianWolfGlimpseCloudsHuman\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Christian Wolf\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChristianWolfGlimpseCloudsHuman').submit();\">Christian Wolf</a>,\n</form>\n<form id=\"form-JulienMilleGlimpseCloudsHuman\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Julien Mille\">\n<a href=\"#\" onclick=\"document.getElementById('form-JulienMilleGlimpseCloudsHuman').submit();\">Julien Mille</a>,\n</form>\n<form id=\"form-GrahamW.GlimpseCloudsHuman\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Graham W. Taylor\">\n<a href=\"#\" onclick=\"document.getElementById('form-GrahamW.GlimpseCloudsHuman').submit();\">Graham W. Taylor</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Baradel_Glimpse_Clouds_Human_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.07898\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Baradel_2018_CVPR,<br>\nauthor = {Baradel, Fabien and Wolf, Christian and Mille, Julien and Taylor, Graham W.},<br>\ntitle = {Glimpse Clouds: Human Activity Recognition From Unstructured Feature Points},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Choi_Context-Aware_Deep_Feature_CVPR_2018_paper.html\">Context-Aware Deep Feature Compression for High-Speed Visual Tracking</a></dt>\n<dd>\n<form id=\"form-JongwonChoiContextAwareDeepFeature\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jongwon Choi\">\n<a href=\"#\" onclick=\"document.getElementById('form-JongwonChoiContextAwareDeepFeature').submit();\">Jongwon Choi</a>,\n</form>\n<form id=\"form-HyungJinContextAwareDeepFeature\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hyung Jin Chang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HyungJinContextAwareDeepFeature').submit();\">Hyung Jin Chang</a>,\n</form>\n<form id=\"form-TobiasFischerContextAwareDeepFeature\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tobias Fischer\">\n<a href=\"#\" onclick=\"document.getElementById('form-TobiasFischerContextAwareDeepFeature').submit();\">Tobias Fischer</a>,\n</form>\n<form id=\"form-SangdooYunContextAwareDeepFeature\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sangdoo Yun\">\n<a href=\"#\" onclick=\"document.getElementById('form-SangdooYunContextAwareDeepFeature').submit();\">Sangdoo Yun</a>,\n</form>\n<form id=\"form-KyuewangLeeContextAwareDeepFeature\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kyuewang Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-KyuewangLeeContextAwareDeepFeature').submit();\">Kyuewang Lee</a>,\n</form>\n<form id=\"form-JiyeoupJeongContextAwareDeepFeature\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiyeoup Jeong\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiyeoupJeongContextAwareDeepFeature').submit();\">Jiyeoup Jeong</a>,\n</form>\n<form id=\"form-YiannisDemirisContextAwareDeepFeature\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yiannis Demiris\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiannisDemirisContextAwareDeepFeature').submit();\">Yiannis Demiris</a>,\n</form>\n<form id=\"form-JinYoungContextAwareDeepFeature\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jin Young Choi\">\n<a href=\"#\" onclick=\"document.getElementById('form-JinYoungContextAwareDeepFeature').submit();\">Jin Young Choi</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Choi_Context-Aware_Deep_Feature_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0892-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.10537\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Choi_2018_CVPR,<br>\nauthor = {Choi, Jongwon and Jin Chang, Hyung and Fischer, Tobias and Yun, Sangdoo and Lee, Kyuewang and Jeong, Jiyeoup and Demiris, Yiannis and Young Choi, Jin},<br>\ntitle = {Context-Aware Deep Feature Compression for High-Speed Visual Tracking},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sun_Correlation_Tracking_via_CVPR_2018_paper.html\">Correlation Tracking via Joint Discrimination and Reliability Learning</a></dt>\n<dd>\n<form id=\"form-ChongSunCorrelationTrackingvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chong Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChongSunCorrelationTrackingvia').submit();\">Chong Sun</a>,\n</form>\n<form id=\"form-DongWangCorrelationTrackingvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dong Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-DongWangCorrelationTrackingvia').submit();\">Dong Wang</a>,\n</form>\n<form id=\"form-HuchuanLuCorrelationTrackingvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huchuan Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuchuanLuCorrelationTrackingvia').submit();\">Huchuan Lu</a>,\n</form>\n<form id=\"form-Ming-HsuanYangCorrelationTrackingvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming-Hsuan Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ming-HsuanYangCorrelationTrackingvia').submit();\">Ming-Hsuan Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sun_Correlation_Tracking_via_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.08965\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sun_2018_CVPR,<br>\nauthor = {Sun, Chong and Wang, Dong and Lu, Huchuan and Yang, Ming-Hsuan},<br>\ntitle = {Correlation Tracking via Joint Discrimination and Reliability Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Meyer_PhaseNet_for_Video_CVPR_2018_paper.html\">PhaseNet for Video Frame Interpolation</a></dt>\n<dd>\n<form id=\"form-SimoneMeyerPhaseNetforVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Simone Meyer\">\n<a href=\"#\" onclick=\"document.getElementById('form-SimoneMeyerPhaseNetforVideo').submit();\">Simone Meyer</a>,\n</form>\n<form id=\"form-AbdelazizDjelouahPhaseNetforVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Abdelaziz Djelouah\">\n<a href=\"#\" onclick=\"document.getElementById('form-AbdelazizDjelouahPhaseNetforVideo').submit();\">Abdelaziz Djelouah</a>,\n</form>\n<form id=\"form-BrianMcWilliamsPhaseNetforVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Brian McWilliams\">\n<a href=\"#\" onclick=\"document.getElementById('form-BrianMcWilliamsPhaseNetforVideo').submit();\">Brian McWilliams</a>,\n</form>\n<form id=\"form-AlexanderSorkine-HornungPhaseNetforVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexander Sorkine-Hornung\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexanderSorkine-HornungPhaseNetforVideo').submit();\">Alexander Sorkine-Hornung</a>,\n</form>\n<form id=\"form-MarkusGrossPhaseNetforVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Markus Gross\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarkusGrossPhaseNetforVideo').submit();\">Markus Gross</a>,\n</form>\n<form id=\"form-ChristopherSchroersPhaseNetforVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Christopher Schroers\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChristopherSchroersPhaseNetforVideo').submit();\">Christopher Schroers</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Meyer_PhaseNet_for_Video_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1790-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00884\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Meyer_2018_CVPR,<br>\nauthor = {Meyer, Simone and Djelouah, Abdelaziz and McWilliams, Brian and Sorkine-Hornung, Alexander and Gross, Markus and Schroers, Christopher},<br>\ntitle = {PhaseNet for Video Frame Interpolation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Bideau_The_Best_of_CVPR_2018_paper.html\">The Best of Both Worlds: Combining CNNs and Geometric Constraints for Hierarchical Motion Segmentation</a></dt>\n<dd>\n<form id=\"form-PiaBideauTheBestof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pia Bideau\">\n<a href=\"#\" onclick=\"document.getElementById('form-PiaBideauTheBestof').submit();\">Pia Bideau</a>,\n</form>\n<form id=\"form-AruniRoyChowdhuryTheBestof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Aruni RoyChowdhury\">\n<a href=\"#\" onclick=\"document.getElementById('form-AruniRoyChowdhuryTheBestof').submit();\">Aruni RoyChowdhury</a>,\n</form>\n<form id=\"form-RakeshR.TheBestof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rakesh R. Menon\">\n<a href=\"#\" onclick=\"document.getElementById('form-RakeshR.TheBestof').submit();\">Rakesh R. Menon</a>,\n</form>\n<form id=\"form-ErikLearned-MillerTheBestof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Erik Learned-Miller\">\n<a href=\"#\" onclick=\"document.getElementById('form-ErikLearned-MillerTheBestof').submit();\">Erik Learned-Miller</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Bideau_The_Best_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0569-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Bideau_2018_CVPR,<br>\nauthor = {Bideau, Pia and RoyChowdhury, Aruni and Menon, Rakesh R. and Learned-Miller, Erik},<br>\ntitle = {The Best of Both Worlds: Combining CNNs and Geometric Constraints for Hierarchical Motion Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Dong_Hyperparameter_Optimization_for_CVPR_2018_paper.html\">Hyperparameter Optimization for Tracking With Continuous Deep Q-Learning</a></dt>\n<dd>\n<form id=\"form-XingpingDongHyperparameterOptimizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xingping Dong\">\n<a href=\"#\" onclick=\"document.getElementById('form-XingpingDongHyperparameterOptimizationfor').submit();\">Xingping Dong</a>,\n</form>\n<form id=\"form-JianbingShenHyperparameterOptimizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianbing Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianbingShenHyperparameterOptimizationfor').submit();\">Jianbing Shen</a>,\n</form>\n<form id=\"form-WenguanWangHyperparameterOptimizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenguan Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenguanWangHyperparameterOptimizationfor').submit();\">Wenguan Wang</a>,\n</form>\n<form id=\"form-YuLiuHyperparameterOptimizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuLiuHyperparameterOptimizationfor').submit();\">Yu Liu</a>,\n</form>\n<form id=\"form-LingShaoHyperparameterOptimizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ling Shao\">\n<a href=\"#\" onclick=\"document.getElementById('form-LingShaoHyperparameterOptimizationfor').submit();\">Ling Shao</a>,\n</form>\n<form id=\"form-FatihPorikliHyperparameterOptimizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fatih Porikli\">\n<a href=\"#\" onclick=\"document.getElementById('form-FatihPorikliHyperparameterOptimizationfor').submit();\">Fatih Porikli</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Dong_Hyperparameter_Optimization_for_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Dong_2018_CVPR,<br>\nauthor = {Dong, Xingping and Shen, Jianbing and Wang, Wenguan and Liu, Yu and Shao, Ling and Porikli, Fatih},<br>\ntitle = {Hyperparameter Optimization for Tracking With Continuous Deep Q-Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhou_Scale-Transferrable_Object_Detection_CVPR_2018_paper.html\">Scale-Transferrable Object Detection</a></dt>\n<dd>\n<form id=\"form-PengZhouScaleTransferrableObjectDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peng Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-PengZhouScaleTransferrableObjectDetection').submit();\">Peng Zhou</a>,\n</form>\n<form id=\"form-BingbingNiScaleTransferrableObjectDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bingbing Ni\">\n<a href=\"#\" onclick=\"document.getElementById('form-BingbingNiScaleTransferrableObjectDetection').submit();\">Bingbing Ni</a>,\n</form>\n<form id=\"form-CongGengScaleTransferrableObjectDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cong Geng\">\n<a href=\"#\" onclick=\"document.getElementById('form-CongGengScaleTransferrableObjectDetection').submit();\">Cong Geng</a>,\n</form>\n<form id=\"form-JianguoHuScaleTransferrableObjectDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianguo Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianguoHuScaleTransferrableObjectDetection').submit();\">Jianguo Hu</a>,\n</form>\n<form id=\"form-YiXuScaleTransferrableObjectDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiXuScaleTransferrableObjectDetection').submit();\">Yi Xu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhou_Scale-Transferrable_Object_Detection_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhou_2018_CVPR,<br>\nauthor = {Zhou, Peng and Ni, Bingbing and Geng, Cong and Hu, Jianguo and Xu, Yi},<br>\ntitle = {Scale-Transferrable Object Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lin_A_Prior-Less_Method_CVPR_2018_paper.html\">A Prior-Less Method for Multi-Face Tracking in Unconstrained Videos</a></dt>\n<dd>\n<form id=\"form-Chung-ChingLinAPriorLessMethod\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chung-Ching Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-Chung-ChingLinAPriorLessMethod').submit();\">Chung-Ching Lin</a>,\n</form>\n<form id=\"form-YingHungAPriorLessMethod\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ying Hung\">\n<a href=\"#\" onclick=\"document.getElementById('form-YingHungAPriorLessMethod').submit();\">Ying Hung</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lin_A_Prior-Less_Method_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3502-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lin_2018_CVPR,<br>\nauthor = {Lin, Chung-Ching and Hung, Ying},<br>\ntitle = {A Prior-Less Method for Multi-Face Tracking in Unconstrained Videos},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhu_End-to-End_Flow_Correlation_CVPR_2018_paper.html\">End-to-End Flow Correlation Tracking With Spatial-Temporal Attention</a></dt>\n<dd>\n<form id=\"form-ZhengZhuEndtoEndFlowCorrelation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zheng Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhengZhuEndtoEndFlowCorrelation').submit();\">Zheng Zhu</a>,\n</form>\n<form id=\"form-WeiWuEndtoEndFlowCorrelation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiWuEndtoEndFlowCorrelation').submit();\">Wei Wu</a>,\n</form>\n<form id=\"form-WeiZouEndtoEndFlowCorrelation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Zou\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiZouEndtoEndFlowCorrelation').submit();\">Wei Zou</a>,\n</form>\n<form id=\"form-JunjieYanEndtoEndFlowCorrelation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junjie Yan\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunjieYanEndtoEndFlowCorrelation').submit();\">Junjie Yan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhu_End-to-End_Flow_Correlation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1264-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.01124\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhu_2018_CVPR,<br>\nauthor = {Zhu, Zheng and Wu, Wei and Zou, Wei and Yan, Junjie},<br>\ntitle = {End-to-End Flow Correlation Tracking With Spatial-Temporal Attention},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xue_Deep_Texture_Manifold_CVPR_2018_paper.html\">Deep Texture Manifold for Ground Terrain Recognition</a></dt>\n<dd>\n<form id=\"form-JiaXueDeepTextureManifold\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jia Xue\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiaXueDeepTextureManifold').submit();\">Jia Xue</a>,\n</form>\n<form id=\"form-HangZhangDeepTextureManifold\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hang Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HangZhangDeepTextureManifold').submit();\">Hang Zhang</a>,\n</form>\n<form id=\"form-KristinDanaDeepTextureManifold\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kristin Dana\">\n<a href=\"#\" onclick=\"document.getElementById('form-KristinDanaDeepTextureManifold').submit();\">Kristin Dana</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xue_Deep_Texture_Manifold_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.10896\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xue_2018_CVPR,<br>\nauthor = {Xue, Jia and Zhang, Hang and Dana, Kristin},<br>\ntitle = {Deep Texture Manifold for Ground Terrain Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tu_Learning_Superpixels_With_CVPR_2018_paper.html\">Learning Superpixels With Segmentation-Aware Affinity Loss</a></dt>\n<dd>\n<form id=\"form-Wei-ChihTuLearningSuperpixelsWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei-Chih Tu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Wei-ChihTuLearningSuperpixelsWith').submit();\">Wei-Chih Tu</a>,\n</form>\n<form id=\"form-Ming-YuLiuLearningSuperpixelsWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming-Yu Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ming-YuLiuLearningSuperpixelsWith').submit();\">Ming-Yu Liu</a>,\n</form>\n<form id=\"form-VarunJampaniLearningSuperpixelsWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Varun Jampani\">\n<a href=\"#\" onclick=\"document.getElementById('form-VarunJampaniLearningSuperpixelsWith').submit();\">Varun Jampani</a>,\n</form>\n<form id=\"form-DeqingSunLearningSuperpixelsWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Deqing Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-DeqingSunLearningSuperpixelsWith').submit();\">Deqing Sun</a>,\n</form>\n<form id=\"form-Shao-YiChienLearningSuperpixelsWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shao-Yi Chien\">\n<a href=\"#\" onclick=\"document.getElementById('form-Shao-YiChienLearningSuperpixelsWith').submit();\">Shao-Yi Chien</a>,\n</form>\n<form id=\"form-Ming-HsuanYangLearningSuperpixelsWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming-Hsuan Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ming-HsuanYangLearningSuperpixelsWith').submit();\">Ming-Hsuan Yang</a>,\n</form>\n<form id=\"form-JanKautzLearningSuperpixelsWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jan Kautz\">\n<a href=\"#\" onclick=\"document.getElementById('form-JanKautzLearningSuperpixelsWith').submit();\">Jan Kautz</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tu_Learning_Superpixels_With_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0102-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tu_2018_CVPR,<br>\nauthor = {Tu, Wei-Chih and Liu, Ming-Yu and Jampani, Varun and Sun, Deqing and Chien, Shao-Yi and Yang, Ming-Hsuan and Kautz, Jan},<br>\ntitle = {Learning Superpixels With Segmentation-Aware Affinity Loss},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Interactive_Image_Segmentation_CVPR_2018_paper.html\">Interactive Image Segmentation With Latent Diversity</a></dt>\n<dd>\n<form id=\"form-ZhuwenLiInteractiveImageSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhuwen Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhuwenLiInteractiveImageSegmentation').submit();\">Zhuwen Li</a>,\n</form>\n<form id=\"form-QifengChenInteractiveImageSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qifeng Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-QifengChenInteractiveImageSegmentation').submit();\">Qifeng Chen</a>,\n</form>\n<form id=\"form-VladlenKoltunInteractiveImageSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vladlen Koltun\">\n<a href=\"#\" onclick=\"document.getElementById('form-VladlenKoltunInteractiveImageSegmentation').submit();\">Vladlen Koltun</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Interactive_Image_Segmentation_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Zhuwen and Chen, Qifeng and Koltun, Vladlen},<br>\ntitle = {Interactive Image Segmentation With Latent Diversity},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_The_Unreasonable_Effectiveness_CVPR_2018_paper.html\">The Unreasonable Effectiveness of Deep Features as a Perceptual Metric</a></dt>\n<dd>\n<form id=\"form-RichardZhangTheUnreasonableEffectiveness\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Richard Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-RichardZhangTheUnreasonableEffectiveness').submit();\">Richard Zhang</a>,\n</form>\n<form id=\"form-PhillipIsolaTheUnreasonableEffectiveness\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Phillip Isola\">\n<a href=\"#\" onclick=\"document.getElementById('form-PhillipIsolaTheUnreasonableEffectiveness').submit();\">Phillip Isola</a>,\n</form>\n<form id=\"form-AlexeiA.TheUnreasonableEffectiveness\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexei A. Efros\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexeiA.TheUnreasonableEffectiveness').submit();\">Alexei A. Efros</a>,\n</form>\n<form id=\"form-EliShechtmanTheUnreasonableEffectiveness\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Eli Shechtman\">\n<a href=\"#\" onclick=\"document.getElementById('form-EliShechtmanTheUnreasonableEffectiveness').submit();\">Eli Shechtman</a>,\n</form>\n<form id=\"form-OliverWangTheUnreasonableEffectiveness\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Oliver Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-OliverWangTheUnreasonableEffectiveness').submit();\">Oliver Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_The_Unreasonable_Effectiveness_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.03924\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Richard and Isola, Phillip and Efros, Alexei A. and Shechtman, Eli and Wang, Oliver},<br>\ntitle = {The Unreasonable Effectiveness of Deep Features as a Perceptual Metric},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/He_Local_Descriptors_Optimized_CVPR_2018_paper.html\">Local Descriptors Optimized for Average Precision</a></dt>\n<dd>\n<form id=\"form-KunHeLocalDescriptorsOptimized\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kun He\">\n<a href=\"#\" onclick=\"document.getElementById('form-KunHeLocalDescriptorsOptimized').submit();\">Kun He</a>,\n</form>\n<form id=\"form-YanLuLocalDescriptorsOptimized\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yan Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanLuLocalDescriptorsOptimized').submit();\">Yan Lu</a>,\n</form>\n<form id=\"form-StanSclaroffLocalDescriptorsOptimized\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stan Sclaroff\">\n<a href=\"#\" onclick=\"document.getElementById('form-StanSclaroffLocalDescriptorsOptimized').submit();\">Stan Sclaroff</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/He_Local_Descriptors_Optimized_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0368-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.05312\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{He_2018_CVPR,<br>\nauthor = {He, Kun and Lu, Yan and Sclaroff, Stan},<br>\ntitle = {Local Descriptors Optimized for Average Precision},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Recovering_Realistic_Texture_CVPR_2018_paper.html\">Recovering Realistic Texture in Image Super-Resolution by Deep Spatial Feature Transform</a></dt>\n<dd>\n<form id=\"form-XintaoWangRecoveringRealisticTexture\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xintao Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XintaoWangRecoveringRealisticTexture').submit();\">Xintao Wang</a>,\n</form>\n<form id=\"form-KeYuRecoveringRealisticTexture\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ke Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-KeYuRecoveringRealisticTexture').submit();\">Ke Yu</a>,\n</form>\n<form id=\"form-ChaoDongRecoveringRealisticTexture\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chao Dong\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChaoDongRecoveringRealisticTexture').submit();\">Chao Dong</a>,\n</form>\n<form id=\"form-ChenChangeRecoveringRealisticTexture\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chen Change Loy\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenChangeRecoveringRealisticTexture').submit();\">Chen Change Loy</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Recovering_Realistic_Texture_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.02815\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Xintao and Yu, Ke and Dong, Chao and Change Loy, Chen},<br>\ntitle = {Recovering Realistic Texture in Image Super-Resolution by Deep Spatial Feature Transform},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Maninis_Deep_Extreme_Cut_CVPR_2018_paper.html\">Deep Extreme Cut: From Extreme Points to Object Segmentation</a></dt>\n<dd>\n<form id=\"form-Kevis-KokitsiManinisDeepExtremeCut\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kevis-Kokitsi Maninis\">\n<a href=\"#\" onclick=\"document.getElementById('form-Kevis-KokitsiManinisDeepExtremeCut').submit();\">Kevis-Kokitsi Maninis</a>,\n</form>\n<form id=\"form-SergiCaellesDeepExtremeCut\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sergi Caelles\">\n<a href=\"#\" onclick=\"document.getElementById('form-SergiCaellesDeepExtremeCut').submit();\">Sergi Caelles</a>,\n</form>\n<form id=\"form-JordiPont-TusetDeepExtremeCut\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jordi Pont-Tuset\">\n<a href=\"#\" onclick=\"document.getElementById('form-JordiPont-TusetDeepExtremeCut').submit();\">Jordi Pont-Tuset</a>,\n</form>\n<form id=\"form-LucVanDeepExtremeCut\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Luc Van Gool\">\n<a href=\"#\" onclick=\"document.getElementById('form-LucVanDeepExtremeCut').submit();\">Luc Van Gool</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Maninis_Deep_Extreme_Cut_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.09081\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Maninis_2018_CVPR,<br>\nauthor = {Maninis, Kevis-Kokitsi and Caelles, Sergi and Pont-Tuset, Jordi and Van Gool, Luc},<br>\ntitle = {Deep Extreme Cut: From Extreme Points to Object Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Huang_Learning_to_Parse_CVPR_2018_paper.html\">Learning to Parse Wireframes in Images of Man-Made Environments</a></dt>\n<dd>\n<form id=\"form-KunHuangLearningtoParse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kun Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-KunHuangLearningtoParse').submit();\">Kun Huang</a>,\n</form>\n<form id=\"form-YifanWangLearningtoParse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yifan Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YifanWangLearningtoParse').submit();\">Yifan Wang</a>,\n</form>\n<form id=\"form-ZihanZhouLearningtoParse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zihan Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZihanZhouLearningtoParse').submit();\">Zihan Zhou</a>,\n</form>\n<form id=\"form-TianjiaoDingLearningtoParse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tianjiao Ding\">\n<a href=\"#\" onclick=\"document.getElementById('form-TianjiaoDingLearningtoParse').submit();\">Tianjiao Ding</a>,\n</form>\n<form id=\"form-ShenghuaGaoLearningtoParse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shenghua Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShenghuaGaoLearningtoParse').submit();\">Shenghua Gao</a>,\n</form>\n<form id=\"form-YiMaLearningtoParse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi Ma\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiMaLearningtoParse').submit();\">Yi Ma</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Huang_Learning_to_Parse_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1446-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Huang_2018_CVPR,<br>\nauthor = {Huang, Kun and Wang, Yifan and Zhou, Zihan and Ding, Tianjiao and Gao, Shenghua and Ma, Yi},<br>\ntitle = {Learning to Parse Wireframes in Images of Man-Made Environments},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Vasu_Occlusion-Aware_Rolling_Shutter_CVPR_2018_paper.html\">Occlusion-Aware Rolling Shutter Rectification of 3D Scenes</a></dt>\n<dd>\n<form id=\"form-SubeeshVasuOcclusionAwareRollingShutter\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Subeesh Vasu\">\n<a href=\"#\" onclick=\"document.getElementById('form-SubeeshVasuOcclusionAwareRollingShutter').submit();\">Subeesh Vasu</a>,\n</form>\n<form id=\"form-MaheshMohanOcclusionAwareRollingShutter\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mahesh Mohan M. R.\">\n<a href=\"#\" onclick=\"document.getElementById('form-MaheshMohanOcclusionAwareRollingShutter').submit();\">Mahesh Mohan M. R.</a>,\n</form>\n<form id=\"form-A.N.OcclusionAwareRollingShutter\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"A. N. Rajagopalan\">\n<a href=\"#\" onclick=\"document.getElementById('form-A.N.OcclusionAwareRollingShutter').submit();\">A. N. Rajagopalan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Vasu_Occlusion-Aware_Rolling_Shutter_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1800-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Vasu_2018_CVPR,<br>\nauthor = {Vasu, Subeesh and Mohan, Mahesh M. R. and Rajagopalan, A. N.},<br>\ntitle = {Occlusion-Aware Rolling Shutter Rectification of 3D Scenes},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yi_Content-Sensitive_Supervoxels_via_CVPR_2018_paper.html\">Content-Sensitive Supervoxels via Uniform Tessellations on Video Manifolds</a></dt>\n<dd>\n<form id=\"form-RanYiContentSensitiveSupervoxelsvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ran Yi\">\n<a href=\"#\" onclick=\"document.getElementById('form-RanYiContentSensitiveSupervoxelsvia').submit();\">Ran Yi</a>,\n</form>\n<form id=\"form-Yong-JinLiuContentSensitiveSupervoxelsvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yong-Jin Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yong-JinLiuContentSensitiveSupervoxelsvia').submit();\">Yong-Jin Liu</a>,\n</form>\n<form id=\"form-Yu-KunLaiContentSensitiveSupervoxelsvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu-Kun Lai\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yu-KunLaiContentSensitiveSupervoxelsvia').submit();\">Yu-Kun Lai</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yi_Content-Sensitive_Supervoxels_via_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2102-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yi_2018_CVPR,<br>\nauthor = {Yi, Ran and Liu, Yong-Jin and Lai, Yu-Kun},<br>\ntitle = {Content-Sensitive Supervoxels via Uniform Tessellations on Video Manifolds},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Cheng_Intrinsic_Image_Transformation_CVPR_2018_paper.html\">Intrinsic Image Transformation via Scale Space Decomposition</a></dt>\n<dd>\n<form id=\"form-LechaoChengIntrinsicImageTransformation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lechao Cheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-LechaoChengIntrinsicImageTransformation').submit();\">Lechao Cheng</a>,\n</form>\n<form id=\"form-ChengyiZhangIntrinsicImageTransformation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chengyi Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChengyiZhangIntrinsicImageTransformation').submit();\">Chengyi Zhang</a>,\n</form>\n<form id=\"form-ZichengLiaoIntrinsicImageTransformation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zicheng Liao\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZichengLiaoIntrinsicImageTransformation').submit();\">Zicheng Liao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Cheng_Intrinsic_Image_Transformation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.10253\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Cheng_2018_CVPR,<br>\nauthor = {Cheng, Lechao and Zhang, Chengyi and Liao, Zicheng},<br>\ntitle = {Intrinsic Image Transformation via Scale Space Decomposition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Khan_Learned_Shape-Tailored_Descriptors_CVPR_2018_paper.html\">Learned Shape-Tailored Descriptors for Segmentation</a></dt>\n<dd>\n<form id=\"form-NaeemullahKhanLearnedShapeTailoredDescriptors\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Naeemullah Khan\">\n<a href=\"#\" onclick=\"document.getElementById('form-NaeemullahKhanLearnedShapeTailoredDescriptors').submit();\">Naeemullah Khan</a>,\n</form>\n<form id=\"form-GaneshSundaramoorthiLearnedShapeTailoredDescriptors\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ganesh Sundaramoorthi\">\n<a href=\"#\" onclick=\"document.getElementById('form-GaneshSundaramoorthiLearnedShapeTailoredDescriptors').submit();\">Ganesh Sundaramoorthi</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Khan_Learned_Shape-Tailored_Descriptors_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2834-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Khan_2018_CVPR,<br>\nauthor = {Khan, Naeemullah and Sundaramoorthi, Ganesh},<br>\ntitle = {Learned Shape-Tailored Descriptors for Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xu_PAD-Net_Multi-Tasks_Guided_CVPR_2018_paper.html\">PAD-Net: Multi-Tasks Guided Prediction-and-Distillation Network for Simultaneous Depth Estimation and Scene Parsing</a></dt>\n<dd>\n<form id=\"form-DanXuPADNetMultiTasksGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dan Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanXuPADNetMultiTasksGuided').submit();\">Dan Xu</a>,\n</form>\n<form id=\"form-WanliOuyangPADNetMultiTasksGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wanli Ouyang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WanliOuyangPADNetMultiTasksGuided').submit();\">Wanli Ouyang</a>,\n</form>\n<form id=\"form-XiaogangWangPADNetMultiTasksGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaogang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaogangWangPADNetMultiTasksGuided').submit();\">Xiaogang Wang</a>,\n</form>\n<form id=\"form-NicuSebePADNetMultiTasksGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nicu Sebe\">\n<a href=\"#\" onclick=\"document.getElementById('form-NicuSebePADNetMultiTasksGuided').submit();\">Nicu Sebe</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xu_PAD-Net_Multi-Tasks_Guided_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.04409\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xu_2018_CVPR,<br>\nauthor = {Xu, Dan and Ouyang, Wanli and Wang, Xiaogang and Sebe, Nicu},<br>\ntitle = {PAD-Net: Multi-Tasks Guided Prediction-and-Distillation Network for Simultaneous Depth Estimation and Scene Parsing},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Multi-Image_Semantic_Matching_CVPR_2018_paper.html\">Multi-Image Semantic Matching by Mining Consistent Features</a></dt>\n<dd>\n<form id=\"form-QianqianWangMultiImageSemanticMatching\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qianqian Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-QianqianWangMultiImageSemanticMatching').submit();\">Qianqian Wang</a>,\n</form>\n<form id=\"form-XiaoweiZhouMultiImageSemanticMatching\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaowei Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaoweiZhouMultiImageSemanticMatching').submit();\">Xiaowei Zhou</a>,\n</form>\n<form id=\"form-KostasDaniilidisMultiImageSemanticMatching\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kostas Daniilidis\">\n<a href=\"#\" onclick=\"document.getElementById('form-KostasDaniilidisMultiImageSemanticMatching').submit();\">Kostas Daniilidis</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Multi-Image_Semantic_Matching_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.07641\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Qianqian and Zhou, Xiaowei and Daniilidis, Kostas},<br>\ntitle = {Multi-Image Semantic Matching by Mining Consistent Features},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Density-Aware_Single_Image_CVPR_2018_paper.html\">Density-Aware Single Image De-Raining Using a Multi-Stream Dense Network</a></dt>\n<dd>\n<form id=\"form-HeZhangDensityAwareSingleImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"He Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HeZhangDensityAwareSingleImage').submit();\">He Zhang</a>,\n</form>\n<form id=\"form-VishalM.DensityAwareSingleImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vishal M. Patel\">\n<a href=\"#\" onclick=\"document.getElementById('form-VishalM.DensityAwareSingleImage').submit();\">Vishal M. Patel</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Density-Aware_Single_Image_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.07412\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, He and Patel, Vishal M.},<br>\ntitle = {Density-Aware Single Image De-Raining Using a Multi-Stream Dense Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yu_Joint_Cuts_and_CVPR_2018_paper.html\">Joint Cuts and Matching of Partitions in One Graph</a></dt>\n<dd>\n<form id=\"form-TianshuYuJointCutsand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tianshu Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-TianshuYuJointCutsand').submit();\">Tianshu Yu</a>,\n</form>\n<form id=\"form-JunchiYanJointCutsand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junchi Yan\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunchiYanJointCutsand').submit();\">Junchi Yan</a>,\n</form>\n<form id=\"form-JieyiZhaoJointCutsand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jieyi Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-JieyiZhaoJointCutsand').submit();\">Jieyi Zhao</a>,\n</form>\n<form id=\"form-BaoxinLiJointCutsand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Baoxin Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-BaoxinLiJointCutsand').submit();\">Baoxin Li</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yu_Joint_Cuts_and_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.09584\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yu_2018_CVPR,<br>\nauthor = {Yu, Tianshu and Yan, Junchi and Zhao, Jieyi and Li, Baoxin},<br>\ntitle = {Joint Cuts and Matching of Partitions in One Graph},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Progressive_Attention_Guided_CVPR_2018_paper.html\">Progressive Attention Guided Recurrent Network for Salient Object Detection</a></dt>\n<dd>\n<form id=\"form-XiaoningZhangProgressiveAttentionGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaoning Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaoningZhangProgressiveAttentionGuided').submit();\">Xiaoning Zhang</a>,\n</form>\n<form id=\"form-TiantianWangProgressiveAttentionGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tiantian Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-TiantianWangProgressiveAttentionGuided').submit();\">Tiantian Wang</a>,\n</form>\n<form id=\"form-JinqingQiProgressiveAttentionGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jinqing Qi\">\n<a href=\"#\" onclick=\"document.getElementById('form-JinqingQiProgressiveAttentionGuided').submit();\">Jinqing Qi</a>,\n</form>\n<form id=\"form-HuchuanLuProgressiveAttentionGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huchuan Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuchuanLuProgressiveAttentionGuided').submit();\">Huchuan Lu</a>,\n</form>\n<form id=\"form-GangWangProgressiveAttentionGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-GangWangProgressiveAttentionGuided').submit();\">Gang Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Progressive_Attention_Guided_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Xiaoning and Wang, Tiantian and Qi, Jinqing and Lu, Huchuan and Wang, Gang},<br>\ntitle = {Progressive Attention Guided Recurrent Network for Salient Object Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hui_Fast_and_Accurate_CVPR_2018_paper.html\">Fast and Accurate Single Image Super-Resolution via Information Distillation Network</a></dt>\n<dd>\n<form id=\"form-ZhengHuiFastandAccurate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zheng Hui\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhengHuiFastandAccurate').submit();\">Zheng Hui</a>,\n</form>\n<form id=\"form-XiumeiWangFastandAccurate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiumei Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiumeiWangFastandAccurate').submit();\">Xiumei Wang</a>,\n</form>\n<form id=\"form-XinboGaoFastandAccurate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xinbo Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinboGaoFastandAccurate').submit();\">Xinbo Gao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hui_Fast_and_Accurate_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.09454\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hui_2018_CVPR,<br>\nauthor = {Hui, Zheng and Wang, Xiumei and Gao, Xinbo},<br>\ntitle = {Fast and Accurate Single Image Super-Resolution via Information Distillation Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lin_Hallucinated-IQA_No-Reference_Image_CVPR_2018_paper.html\">Hallucinated-IQA: No-Reference Image Quality Assessment via Adversarial Learning</a></dt>\n<dd>\n<form id=\"form-Kwan-YeeLinHallucinatedIQANoReferenceImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kwan-Yee Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-Kwan-YeeLinHallucinatedIQANoReferenceImage').submit();\">Kwan-Yee Lin</a>,\n</form>\n<form id=\"form-GuanxiangWangHallucinatedIQANoReferenceImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guanxiang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuanxiangWangHallucinatedIQANoReferenceImage').submit();\">Guanxiang Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lin_Hallucinated-IQA_No-Reference_Image_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1335-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.01681\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lin_2018_CVPR,<br>\nauthor = {Lin, Kwan-Yee and Wang, Guanxiang},<br>\ntitle = {Hallucinated-IQA: No-Reference Image Quality Assessment via Adversarial Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Mopuri_NAG_Network_for_CVPR_2018_paper.html\">NAG: Network for Adversary Generation</a></dt>\n<dd>\n<form id=\"form-KondaReddyNAGNetworkfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Konda Reddy Mopuri\">\n<a href=\"#\" onclick=\"document.getElementById('form-KondaReddyNAGNetworkfor').submit();\">Konda Reddy Mopuri</a>,\n</form>\n<form id=\"form-UtkarshOjhaNAGNetworkfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Utkarsh Ojha\">\n<a href=\"#\" onclick=\"document.getElementById('form-UtkarshOjhaNAGNetworkfor').submit();\">Utkarsh Ojha</a>,\n</form>\n<form id=\"form-UtsavGargNAGNetworkfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Utsav Garg\">\n<a href=\"#\" onclick=\"document.getElementById('form-UtsavGargNAGNetworkfor').submit();\">Utsav Garg</a>,\n</form>\n<form id=\"form-R.VenkateshNAGNetworkfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"R. Venkatesh Babu\">\n<a href=\"#\" onclick=\"document.getElementById('form-R.VenkateshNAGNetworkfor').submit();\">R. Venkatesh Babu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Mopuri_NAG_Network_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.03390\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Mopuri_2018_CVPR,<br>\nauthor = {Reddy Mopuri, Konda and Ojha, Utkarsh and Garg, Utsav and Venkatesh Babu, R.},<br>\ntitle = {NAG: Network for Adversary Generation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liang_Dynamic-Structured_Semantic_Propagation_CVPR_2018_paper.html\">Dynamic-Structured Semantic Propagation Network</a></dt>\n<dd>\n<form id=\"form-XiaodanLiangDynamicStructuredSemanticPropagation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaodan Liang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaodanLiangDynamicStructuredSemanticPropagation').submit();\">Xiaodan Liang</a>,\n</form>\n<form id=\"form-HongfeiZhouDynamicStructuredSemanticPropagation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hongfei Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-HongfeiZhouDynamicStructuredSemanticPropagation').submit();\">Hongfei Zhou</a>,\n</form>\n<form id=\"form-EricXingDynamicStructuredSemanticPropagation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Eric Xing\">\n<a href=\"#\" onclick=\"document.getElementById('form-EricXingDynamicStructuredSemanticPropagation').submit();\">Eric Xing</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liang_Dynamic-Structured_Semantic_Propagation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.06067\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liang_2018_CVPR,<br>\nauthor = {Liang, Xiaodan and Zhou, Hongfei and Xing, Eric},<br>\ntitle = {Dynamic-Structured Semantic Propagation Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ren_Cross-Domain_Self-Supervised_Multi-Task_CVPR_2018_paper.html\">Cross-Domain Self-Supervised Multi-Task Feature Learning Using Synthetic Imagery</a></dt>\n<dd>\n<form id=\"form-ZhongzhengRenCrossDomainSelfSupervisedMultiTask\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhongzheng Ren\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhongzhengRenCrossDomainSelfSupervisedMultiTask').submit();\">Zhongzheng Ren</a>,\n</form>\n<form id=\"form-YongJaeCrossDomainSelfSupervisedMultiTask\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yong Jae Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-YongJaeCrossDomainSelfSupervisedMultiTask').submit();\">Yong Jae Lee</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ren_Cross-Domain_Self-Supervised_Multi-Task_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.09082\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ren_2018_CVPR,<br>\nauthor = {Ren, Zhongzheng and Jae Lee, Yong},<br>\ntitle = {Cross-Domain Self-Supervised Multi-Task Feature Learning Using Synthetic Imagery},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hadad_A_Two-Step_Disentanglement_CVPR_2018_paper.html\">A Two-Step Disentanglement Method</a></dt>\n<dd>\n<form id=\"form-NaamaHadadATwoStepDisentanglement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Naama Hadad\">\n<a href=\"#\" onclick=\"document.getElementById('form-NaamaHadadATwoStepDisentanglement').submit();\">Naama Hadad</a>,\n</form>\n<form id=\"form-LiorWolfATwoStepDisentanglement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lior Wolf\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiorWolfATwoStepDisentanglement').submit();\">Lior Wolf</a>,\n</form>\n<form id=\"form-MoniShaharATwoStepDisentanglement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Moni Shahar\">\n<a href=\"#\" onclick=\"document.getElementById('form-MoniShaharATwoStepDisentanglement').submit();\">Moni Shahar</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hadad_A_Two-Step_Disentanglement_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hadad_2018_CVPR,<br>\nauthor = {Hadad, Naama and Wolf, Lior and Shahar, Moni},<br>\ntitle = {A Two-Step Disentanglement Method},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Merget_Robust_Facial_Landmark_CVPR_2018_paper.html\">Robust Facial Landmark Detection via a Fully-Convolutional Local-Global Context Network</a></dt>\n<dd>\n<form id=\"form-DanielMergetRobustFacialLandmark\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daniel Merget\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanielMergetRobustFacialLandmark').submit();\">Daniel Merget</a>,\n</form>\n<form id=\"form-MatthiasRockRobustFacialLandmark\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Matthias Rock\">\n<a href=\"#\" onclick=\"document.getElementById('form-MatthiasRockRobustFacialLandmark').submit();\">Matthias Rock</a>,\n</form>\n<form id=\"form-GerhardRigollRobustFacialLandmark\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gerhard Rigoll\">\n<a href=\"#\" onclick=\"document.getElementById('form-GerhardRigollRobustFacialLandmark').submit();\">Gerhard Rigoll</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Merget_Robust_Facial_Landmark_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Merget_2018_CVPR,<br>\nauthor = {Merget, Daniel and Rock, Matthias and Rigoll, Gerhard},<br>\ntitle = {Robust Facial Landmark Detection via a Fully-Convolutional Local-Global Context Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Huang_Decorrelated_Batch_Normalization_CVPR_2018_paper.html\">Decorrelated Batch Normalization</a></dt>\n<dd>\n<form id=\"form-LeiHuangDecorrelatedBatchNormalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lei Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeiHuangDecorrelatedBatchNormalization').submit();\">Lei Huang</a>,\n</form>\n<form id=\"form-DaweiYangDecorrelatedBatchNormalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dawei Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-DaweiYangDecorrelatedBatchNormalization').submit();\">Dawei Yang</a>,\n</form>\n<form id=\"form-BoLangDecorrelatedBatchNormalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bo Lang\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoLangDecorrelatedBatchNormalization').submit();\">Bo Lang</a>,\n</form>\n<form id=\"form-JiaDengDecorrelatedBatchNormalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jia Deng\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiaDengDecorrelatedBatchNormalization').submit();\">Jia Deng</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Huang_Decorrelated_Batch_Normalization_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1134-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.08450\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Huang_2018_CVPR,<br>\nauthor = {Huang, Lei and Yang, Dawei and Lang, Bo and Deng, Jia},<br>\ntitle = {Decorrelated Batch Normalization},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Song_Learning_to_Sketch_CVPR_2018_paper.html\">Learning to Sketch With Shortcut Cycle Consistency</a></dt>\n<dd>\n<form id=\"form-JifeiSongLearningtoSketch\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jifei Song\">\n<a href=\"#\" onclick=\"document.getElementById('form-JifeiSongLearningtoSketch').submit();\">Jifei Song</a>,\n</form>\n<form id=\"form-KaiyuePangLearningtoSketch\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kaiyue Pang\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaiyuePangLearningtoSketch').submit();\">Kaiyue Pang</a>,\n</form>\n<form id=\"form-Yi-ZheSongLearningtoSketch\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi-Zhe Song\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yi-ZheSongLearningtoSketch').submit();\">Yi-Zhe Song</a>,\n</form>\n<form id=\"form-TaoXiangLearningtoSketch\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tao Xiang\">\n<a href=\"#\" onclick=\"document.getElementById('form-TaoXiangLearningtoSketch').submit();\">Tao Xiang</a>,\n</form>\n<form id=\"form-TimothyM.LearningtoSketch\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Timothy M. Hospedales\">\n<a href=\"#\" onclick=\"document.getElementById('form-TimothyM.LearningtoSketch').submit();\">Timothy M. Hospedales</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Song_Learning_to_Sketch_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.00247\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Song_2018_CVPR,<br>\nauthor = {Song, Jifei and Pang, Kaiyue and Song, Yi-Zhe and Xiang, Tao and Hospedales, Timothy M.},<br>\ntitle = {Learning to Sketch With Shortcut Cycle Consistency},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Shen_Towards_a_Mathematical_CVPR_2018_paper.html\">Towards a Mathematical Understanding of the Difficulty in Learning With Feedforward Neural Networks</a></dt>\n<dd>\n<form id=\"form-HaoShenTowardsaMathematical\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hao Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaoShenTowardsaMathematical').submit();\">Hao Shen</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Shen_Towards_a_Mathematical_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1462-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1611.05827\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Shen_2018_CVPR,<br>\nauthor = {Shen, Hao},<br>\ntitle = {Towards a Mathematical Understanding of the Difficulty in Learning With Feedforward Neural Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Shen_FaceID-GAN_Learning_a_CVPR_2018_paper.html\">FaceID-GAN: Learning a Symmetry Three-Player GAN for Identity-Preserving Face Synthesis</a></dt>\n<dd>\n<form id=\"form-YujunShenFaceIDGANLearninga\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yujun Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-YujunShenFaceIDGANLearninga').submit();\">Yujun Shen</a>,\n</form>\n<form id=\"form-PingLuoFaceIDGANLearninga\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ping Luo\">\n<a href=\"#\" onclick=\"document.getElementById('form-PingLuoFaceIDGANLearninga').submit();\">Ping Luo</a>,\n</form>\n<form id=\"form-JunjieYanFaceIDGANLearninga\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junjie Yan\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunjieYanFaceIDGANLearninga').submit();\">Junjie Yan</a>,\n</form>\n<form id=\"form-XiaogangWangFaceIDGANLearninga\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaogang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaogangWangFaceIDGANLearninga').submit();\">Xiaogang Wang</a>,\n</form>\n<form id=\"form-XiaoouTangFaceIDGANLearninga\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaoou Tang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaoouTangFaceIDGANLearninga').submit();\">Xiaoou Tang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Shen_FaceID-GAN_Learning_a_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Shen_2018_CVPR,<br>\nauthor = {Shen, Yujun and Luo, Ping and Yan, Junjie and Wang, Xiaogang and Tang, Xiaoou},<br>\ntitle = {FaceID-GAN: Learning a Symmetry Three-Player GAN for Identity-Preserving Face Synthesis},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_A_Constrained_Deep_CVPR_2018_paper.html\">A Constrained Deep Neural Network for Ordinal Regression</a></dt>\n<dd>\n<form id=\"form-YanzhuLiuAConstrainedDeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yanzhu Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanzhuLiuAConstrainedDeep').submit();\">Yanzhu Liu</a>,\n</form>\n<form id=\"form-AdamsWaiAConstrainedDeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Adams Wai Kin Kong\">\n<a href=\"#\" onclick=\"document.getElementById('form-AdamsWaiAConstrainedDeep').submit();\">Adams Wai Kin Kong</a>,\n</form>\n<form id=\"form-ChiKeongAConstrainedDeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chi Keong Goh\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChiKeongAConstrainedDeep').submit();\">Chi Keong Goh</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_A_Constrained_Deep_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Yanzhu and Wai Kin Kong, Adams and Keong Goh, Chi},<br>\ntitle = {A Constrained Deep Neural Network for Ordinal Regression},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Modulated_Convolutional_Networks_CVPR_2018_paper.html\">Modulated Convolutional Networks</a></dt>\n<dd>\n<form id=\"form-XiaodiWangModulatedConvolutionalNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaodi Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaodiWangModulatedConvolutionalNetworks').submit();\">Xiaodi Wang</a>,\n</form>\n<form id=\"form-BaochangZhangModulatedConvolutionalNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Baochang Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-BaochangZhangModulatedConvolutionalNetworks').submit();\">Baochang Zhang</a>,\n</form>\n<form id=\"form-CeLiModulatedConvolutionalNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ce Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-CeLiModulatedConvolutionalNetworks').submit();\">Ce Li</a>,\n</form>\n<form id=\"form-RongrongJiModulatedConvolutionalNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rongrong Ji\">\n<a href=\"#\" onclick=\"document.getElementById('form-RongrongJiModulatedConvolutionalNetworks').submit();\">Rongrong Ji</a>,\n</form>\n<form id=\"form-JungongHanModulatedConvolutionalNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jungong Han\">\n<a href=\"#\" onclick=\"document.getElementById('form-JungongHanModulatedConvolutionalNetworks').submit();\">Jungong Han</a>,\n</form>\n<form id=\"form-XianbinCaoModulatedConvolutionalNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xianbin Cao\">\n<a href=\"#\" onclick=\"document.getElementById('form-XianbinCaoModulatedConvolutionalNetworks').submit();\">Xianbin Cao</a>,\n</form>\n<form id=\"form-JianzhuangLiuModulatedConvolutionalNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianzhuang Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianzhuangLiuModulatedConvolutionalNetworks').submit();\">Jianzhuang Liu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Modulated_Convolutional_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00227\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Xiaodi and Zhang, Baochang and Li, Ce and Ji, Rongrong and Han, Jungong and Cao, Xianbin and Liu, Jianzhuang},<br>\ntitle = {Modulated Convolutional Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Weiler_Learning_Steerable_Filters_CVPR_2018_paper.html\">Learning Steerable Filters for Rotation Equivariant CNNs</a></dt>\n<dd>\n<form id=\"form-MauriceWeilerLearningSteerableFilters\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Maurice Weiler\">\n<a href=\"#\" onclick=\"document.getElementById('form-MauriceWeilerLearningSteerableFilters').submit();\">Maurice Weiler</a>,\n</form>\n<form id=\"form-FredA.LearningSteerableFilters\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fred A. Hamprecht\">\n<a href=\"#\" onclick=\"document.getElementById('form-FredA.LearningSteerableFilters').submit();\">Fred A. Hamprecht</a>,\n</form>\n<form id=\"form-MartinStorathLearningSteerableFilters\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Martin Storath\">\n<a href=\"#\" onclick=\"document.getElementById('form-MartinStorathLearningSteerableFilters').submit();\">Martin Storath</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Weiler_Learning_Steerable_Filters_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3214-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.07289\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Weiler_2018_CVPR,<br>\nauthor = {Weiler, Maurice and Hamprecht, Fred A. and Storath, Martin},<br>\ntitle = {Learning Steerable Filters for Rotation Equivariant CNNs},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Acuna_Efficient_Interactive_Annotation_CVPR_2018_paper.html\">Efficient Interactive Annotation of Segmentation Datasets With Polygon-RNN++</a></dt>\n<dd>\n<form id=\"form-DavidAcunaEfficientInteractiveAnnotation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"David Acuna\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavidAcunaEfficientInteractiveAnnotation').submit();\">David Acuna</a>,\n</form>\n<form id=\"form-HuanLingEfficientInteractiveAnnotation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huan Ling\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuanLingEfficientInteractiveAnnotation').submit();\">Huan Ling</a>,\n</form>\n<form id=\"form-AmlanKarEfficientInteractiveAnnotation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Amlan Kar\">\n<a href=\"#\" onclick=\"document.getElementById('form-AmlanKarEfficientInteractiveAnnotation').submit();\">Amlan Kar</a>,\n</form>\n<form id=\"form-SanjaFidlerEfficientInteractiveAnnotation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sanja Fidler\">\n<a href=\"#\" onclick=\"document.getElementById('form-SanjaFidlerEfficientInteractiveAnnotation').submit();\">Sanja Fidler</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Acuna_Efficient_Interactive_Annotation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3409-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.09693\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Acuna_2018_CVPR,<br>\nauthor = {Acuna, David and Ling, Huan and Kar, Amlan and Fidler, Sanja},<br>\ntitle = {Efficient Interactive Annotation of Segmentation Datasets With Polygon-RNN++},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Fey_SplineCNN_Fast_Geometric_CVPR_2018_paper.html\">SplineCNN: Fast Geometric Deep Learning With Continuous B-Spline Kernels</a></dt>\n<dd>\n<form id=\"form-MatthiasFeySplineCNNFastGeometric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Matthias Fey\">\n<a href=\"#\" onclick=\"document.getElementById('form-MatthiasFeySplineCNNFastGeometric').submit();\">Matthias Fey</a>,\n</form>\n<form id=\"form-JanEricSplineCNNFastGeometric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jan Eric Lenssen\">\n<a href=\"#\" onclick=\"document.getElementById('form-JanEricSplineCNNFastGeometric').submit();\">Jan Eric Lenssen</a>,\n</form>\n<form id=\"form-FrankWeichertSplineCNNFastGeometric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Frank Weichert\">\n<a href=\"#\" onclick=\"document.getElementById('form-FrankWeichertSplineCNNFastGeometric').submit();\">Frank Weichert</a>,\n</form>\n<form id=\"form-HeinrichM\u00c3\u00bcllerSplineCNNFastGeometric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Heinrich M\u00c3\u00bcller\">\n<a href=\"#\" onclick=\"document.getElementById('form-HeinrichM\u00c3\u00bcllerSplineCNNFastGeometric').submit();\">Heinrich M\u00c3\u00bcller</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Fey_SplineCNN_Fast_Geometric_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3827-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.08920\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Fey_2018_CVPR,<br>\nauthor = {Fey, Matthias and Eric Lenssen, Jan and Weichert, Frank and M\u00c3\u00bcller, Heinrich},<br>\ntitle = {SplineCNN: Fast Geometric Deep Learning With Continuous B-Spline Kernels},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kossaifi_GAGAN_Geometry-Aware_Generative_CVPR_2018_paper.html\">GAGAN: Geometry-Aware Generative Adversarial Networks</a></dt>\n<dd>\n<form id=\"form-JeanKossaifiGAGANGeometryAwareGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jean Kossaifi\">\n<a href=\"#\" onclick=\"document.getElementById('form-JeanKossaifiGAGANGeometryAwareGenerative').submit();\">Jean Kossaifi</a>,\n</form>\n<form id=\"form-LinhTranGAGANGeometryAwareGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Linh Tran\">\n<a href=\"#\" onclick=\"document.getElementById('form-LinhTranGAGANGeometryAwareGenerative').submit();\">Linh Tran</a>,\n</form>\n<form id=\"form-YannisPanagakisGAGANGeometryAwareGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yannis Panagakis\">\n<a href=\"#\" onclick=\"document.getElementById('form-YannisPanagakisGAGANGeometryAwareGenerative').submit();\">Yannis Panagakis</a>,\n</form>\n<form id=\"form-MajaPanticGAGANGeometryAwareGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Maja Pantic\">\n<a href=\"#\" onclick=\"document.getElementById('form-MajaPanticGAGANGeometryAwareGenerative').submit();\">Maja Pantic</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kossaifi_GAGAN_Geometry-Aware_Generative_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.00684\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kossaifi_2018_CVPR,<br>\nauthor = {Kossaifi, Jean and Tran, Linh and Panagakis, Yannis and Pantic, Maja},<br>\ntitle = {GAGAN: Geometry-Aware Generative Adversarial Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Arnab_On_the_Robustness_CVPR_2018_paper.html\">On the Robustness of Semantic Segmentation Models to Adversarial Attacks</a></dt>\n<dd>\n<form id=\"form-AnuragArnabOntheRobustness\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anurag Arnab\">\n<a href=\"#\" onclick=\"document.getElementById('form-AnuragArnabOntheRobustness').submit();\">Anurag Arnab</a>,\n</form>\n<form id=\"form-OndrejMiksikOntheRobustness\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ondrej Miksik\">\n<a href=\"#\" onclick=\"document.getElementById('form-OndrejMiksikOntheRobustness').submit();\">Ondrej Miksik</a>,\n</form>\n<form id=\"form-PhilipH.S.OntheRobustness\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Philip H.S. Torr\">\n<a href=\"#\" onclick=\"document.getElementById('form-PhilipH.S.OntheRobustness').submit();\">Philip H.S. Torr</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Arnab_On_the_Robustness_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0261-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.09856\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Arnab_2018_CVPR,<br>\nauthor = {Arnab, Anurag and Miksik, Ondrej and Torr, Philip H.S.},<br>\ntitle = {On the Robustness of Semantic Segmentation Models to Adversarial Attacks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Feedback-Prop_Convolutional_Neural_CVPR_2018_paper.html\">Feedback-Prop: Convolutional Neural Network Inference Under Partial Evidence</a></dt>\n<dd>\n<form id=\"form-TianluWangFeedbackPropConvolutionalNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tianlu Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-TianluWangFeedbackPropConvolutionalNeural').submit();\">Tianlu Wang</a>,\n</form>\n<form id=\"form-KotaYamaguchiFeedbackPropConvolutionalNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kota Yamaguchi\">\n<a href=\"#\" onclick=\"document.getElementById('form-KotaYamaguchiFeedbackPropConvolutionalNeural').submit();\">Kota Yamaguchi</a>,\n</form>\n<form id=\"form-VicenteOrdonezFeedbackPropConvolutionalNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vicente Ordonez\">\n<a href=\"#\" onclick=\"document.getElementById('form-VicenteOrdonezFeedbackPropConvolutionalNeural').submit();\">Vicente Ordonez</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Feedback-Prop_Convolutional_Neural_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1710.08049\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Tianlu and Yamaguchi, Kota and Ordonez, Vicente},<br>\ntitle = {Feedback-Prop: Convolutional Neural Network Inference Under Partial Evidence},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yu_Super-Resolving_Very_Low-Resolution_CVPR_2018_paper.html\">Super-Resolving Very Low-Resolution Face Images With Supplementary Attributes</a></dt>\n<dd>\n<form id=\"form-XinYuSuperResolvingVeryLowResolution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xin Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinYuSuperResolvingVeryLowResolution').submit();\">Xin Yu</a>,\n</form>\n<form id=\"form-BasuraFernandoSuperResolvingVeryLowResolution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Basura Fernando\">\n<a href=\"#\" onclick=\"document.getElementById('form-BasuraFernandoSuperResolvingVeryLowResolution').submit();\">Basura Fernando</a>,\n</form>\n<form id=\"form-RichardHartleySuperResolvingVeryLowResolution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Richard Hartley\">\n<a href=\"#\" onclick=\"document.getElementById('form-RichardHartleySuperResolvingVeryLowResolution').submit();\">Richard Hartley</a>,\n</form>\n<form id=\"form-FatihPorikliSuperResolvingVeryLowResolution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fatih Porikli\">\n<a href=\"#\" onclick=\"document.getElementById('form-FatihPorikliSuperResolvingVeryLowResolution').submit();\">Fatih Porikli</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yu_Super-Resolving_Very_Low-Resolution_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yu_2018_CVPR,<br>\nauthor = {Yu, Xin and Fernando, Basura and Hartley, Richard and Porikli, Fatih},<br>\ntitle = {Super-Resolving Very Low-Resolution Face Images With Supplementary Attributes},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Qi_Frustum_PointNets_for_CVPR_2018_paper.html\">Frustum PointNets for 3D Object Detection From RGB-D Data</a></dt>\n<dd>\n<form id=\"form-CharlesR.FrustumPointNetsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Charles R. Qi\">\n<a href=\"#\" onclick=\"document.getElementById('form-CharlesR.FrustumPointNetsfor').submit();\">Charles R. Qi</a>,\n</form>\n<form id=\"form-WeiLiuFrustumPointNetsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiLiuFrustumPointNetsfor').submit();\">Wei Liu</a>,\n</form>\n<form id=\"form-ChenxiaWuFrustumPointNetsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chenxia Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenxiaWuFrustumPointNetsfor').submit();\">Chenxia Wu</a>,\n</form>\n<form id=\"form-HaoSuFrustumPointNetsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hao Su\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaoSuFrustumPointNetsfor').submit();\">Hao Su</a>,\n</form>\n<form id=\"form-LeonidasJ.FrustumPointNetsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Leonidas J. Guibas\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeonidasJ.FrustumPointNetsfor').submit();\">Leonidas J. Guibas</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Qi_Frustum_PointNets_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0019-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.08488\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Qi_2018_CVPR,<br>\nauthor = {Qi, Charles R. and Liu, Wei and Wu, Chenxia and Su, Hao and Guibas, Leonidas J.},<br>\ntitle = {Frustum PointNets for 3D Object Detection From RGB-D Data},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_W2F_A_Weakly-Supervised_CVPR_2018_paper.html\">W2F: A Weakly-Supervised to Fully-Supervised Framework for Object Detection</a></dt>\n<dd>\n<form id=\"form-YongqiangZhangW2FAWeaklySupervised\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yongqiang Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YongqiangZhangW2FAWeaklySupervised').submit();\">Yongqiang Zhang</a>,\n</form>\n<form id=\"form-YanchengBaiW2FAWeaklySupervised\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yancheng Bai\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanchengBaiW2FAWeaklySupervised').submit();\">Yancheng Bai</a>,\n</form>\n<form id=\"form-MingliDingW2FAWeaklySupervised\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mingli Ding\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingliDingW2FAWeaklySupervised').submit();\">Mingli Ding</a>,\n</form>\n<form id=\"form-YongqiangLiW2FAWeaklySupervised\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yongqiang Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-YongqiangLiW2FAWeaklySupervised').submit();\">Yongqiang Li</a>,\n</form>\n<form id=\"form-BernardGhanemW2FAWeaklySupervised\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bernard Ghanem\">\n<a href=\"#\" onclick=\"document.getElementById('form-BernardGhanemW2FAWeaklySupervised').submit();\">Bernard Ghanem</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_W2F_A_Weakly-Supervised_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0165-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Yongqiang and Bai, Yancheng and Ding, Mingli and Li, Yongqiang and Ghanem, Bernard},<br>\ntitle = {W2F: A Weakly-Supervised to Fully-Supervised Framework for Object Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ren_3D_Object_Detection_CVPR_2018_paper.html\">3D Object Detection With Latent Support Surfaces</a></dt>\n<dd>\n<form id=\"form-ZhileRen3DObjectDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhile Ren\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhileRen3DObjectDetection').submit();\">Zhile Ren</a>,\n</form>\n<form id=\"form-ErikB.3DObjectDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Erik B. Sudderth\">\n<a href=\"#\" onclick=\"document.getElementById('form-ErikB.3DObjectDetection').submit();\">Erik B. Sudderth</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ren_3D_Object_Detection_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ren_2018_CVPR,<br>\nauthor = {Ren, Zhile and Sudderth, Erik B.},<br>\ntitle = {3D Object Detection With Latent Support Surfaces},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Towards_Faster_Training_CVPR_2018_paper.html\">Towards Faster Training of Global Covariance Pooling Networks by Iterative Matrix Square Root Normalization</a></dt>\n<dd>\n<form id=\"form-PeihuaLiTowardsFasterTraining\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peihua Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-PeihuaLiTowardsFasterTraining').submit();\">Peihua Li</a>,\n</form>\n<form id=\"form-JiangtaoXieTowardsFasterTraining\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiangtao Xie\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiangtaoXieTowardsFasterTraining').submit();\">Jiangtao Xie</a>,\n</form>\n<form id=\"form-QilongWangTowardsFasterTraining\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qilong Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-QilongWangTowardsFasterTraining').submit();\">Qilong Wang</a>,\n</form>\n<form id=\"form-ZilinGaoTowardsFasterTraining\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zilin Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZilinGaoTowardsFasterTraining').submit();\">Zilin Gao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Towards_Faster_Training_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.01034\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Peihua and Xie, Jiangtao and Wang, Qilong and Gao, Zilin},<br>\ntitle = {Towards Faster Training of Global Covariance Pooling Networks by Iterative Matrix Square Root Normalization},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kong_Recurrent_Scene_Parsing_CVPR_2018_paper.html\">Recurrent Scene Parsing With Perspective Understanding in the Loop</a></dt>\n<dd>\n<form id=\"form-ShuKongRecurrentSceneParsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shu Kong\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuKongRecurrentSceneParsing').submit();\">Shu Kong</a>,\n</form>\n<form id=\"form-CharlessC.RecurrentSceneParsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Charless C. Fowlkes\">\n<a href=\"#\" onclick=\"document.getElementById('form-CharlessC.RecurrentSceneParsing').submit();\">Charless C. Fowlkes</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kong_Recurrent_Scene_Parsing_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0534-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1705.07238\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kong_2018_CVPR,<br>\nauthor = {Kong, Shu and Fowlkes, Charless C.},<br>\ntitle = {Recurrent Scene Parsing With Perspective Understanding in the Loop},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Noh_Improving_Occlusion_and_CVPR_2018_paper.html\">Improving Occlusion and Hard Negative Handling for Single-Stage Pedestrian Detectors</a></dt>\n<dd>\n<form id=\"form-JunhyugNohImprovingOcclusionand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junhyug Noh\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunhyugNohImprovingOcclusionand').submit();\">Junhyug Noh</a>,\n</form>\n<form id=\"form-SoochanLeeImprovingOcclusionand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Soochan Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-SoochanLeeImprovingOcclusionand').submit();\">Soochan Lee</a>,\n</form>\n<form id=\"form-BeomsuKimImprovingOcclusionand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Beomsu Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-BeomsuKimImprovingOcclusionand').submit();\">Beomsu Kim</a>,\n</form>\n<form id=\"form-GunheeKimImprovingOcclusionand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gunhee Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-GunheeKimImprovingOcclusionand').submit();\">Gunhee Kim</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Noh_Improving_Occlusion_and_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0620-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Noh_2018_CVPR,<br>\nauthor = {Noh, Junhyug and Lee, Soochan and Kim, Beomsu and Kim, Gunhee},<br>\ntitle = {Improving Occlusion and Hard Negative Handling for Single-Stage Pedestrian Detectors},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chuang_Learning_to_Act_CVPR_2018_paper.html\">Learning to Act Properly: Predicting and Explaining Affordances From Images</a></dt>\n<dd>\n<form id=\"form-Ching-YaoChuangLearningtoAct\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ching-Yao Chuang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ching-YaoChuangLearningtoAct').submit();\">Ching-Yao Chuang</a>,\n</form>\n<form id=\"form-JiamanLiLearningtoAct\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiaman Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiamanLiLearningtoAct').submit();\">Jiaman Li</a>,\n</form>\n<form id=\"form-AntonioTorralbaLearningtoAct\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Antonio Torralba\">\n<a href=\"#\" onclick=\"document.getElementById('form-AntonioTorralbaLearningtoAct').submit();\">Antonio Torralba</a>,\n</form>\n<form id=\"form-SanjaFidlerLearningtoAct\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sanja Fidler\">\n<a href=\"#\" onclick=\"document.getElementById('form-SanjaFidlerLearningtoAct').submit();\">Sanja Fidler</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chuang_Learning_to_Act_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.07576\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chuang_2018_CVPR,<br>\nauthor = {Chuang, Ching-Yao and Li, Jiaman and Torralba, Antonio and Fidler, Sanja},<br>\ntitle = {Learning to Act Properly: Predicting and Explaining Affordances From Images},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hua_Pointwise_Convolutional_Neural_CVPR_2018_paper.html\">Pointwise Convolutional Neural Networks</a></dt>\n<dd>\n<form id=\"form-Binh-SonHuaPointwiseConvolutionalNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Binh-Son Hua\">\n<a href=\"#\" onclick=\"document.getElementById('form-Binh-SonHuaPointwiseConvolutionalNeural').submit();\">Binh-Son Hua</a>,\n</form>\n<form id=\"form-Minh-KhoiTranPointwiseConvolutionalNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Minh-Khoi Tran\">\n<a href=\"#\" onclick=\"document.getElementById('form-Minh-KhoiTranPointwiseConvolutionalNeural').submit();\">Minh-Khoi Tran</a>,\n</form>\n<form id=\"form-Sai-KitYeungPointwiseConvolutionalNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sai-Kit Yeung\">\n<a href=\"#\" onclick=\"document.getElementById('form-Sai-KitYeungPointwiseConvolutionalNeural').submit();\">Sai-Kit Yeung</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hua_Pointwise_Convolutional_Neural_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.05245\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hua_2018_CVPR,<br>\nauthor = {Hua, Binh-Son and Tran, Minh-Khoi and Yeung, Sai-Kit},<br>\ntitle = {Pointwise Convolutional Neural Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Deng_Image-Image_Domain_Adaptation_CVPR_2018_paper.html\">Image-Image Domain Adaptation With Preserved Self-Similarity and Domain-Dissimilarity for Person Re-Identification</a></dt>\n<dd>\n<form id=\"form-WeijianDengImageImageDomainAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weijian Deng\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeijianDengImageImageDomainAdaptation').submit();\">Weijian Deng</a>,\n</form>\n<form id=\"form-LiangZhengImageImageDomainAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liang Zheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiangZhengImageImageDomainAdaptation').submit();\">Liang Zheng</a>,\n</form>\n<form id=\"form-QixiangYeImageImageDomainAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qixiang Ye\">\n<a href=\"#\" onclick=\"document.getElementById('form-QixiangYeImageImageDomainAdaptation').submit();\">Qixiang Ye</a>,\n</form>\n<form id=\"form-GuoliangKangImageImageDomainAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guoliang Kang\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuoliangKangImageImageDomainAdaptation').submit();\">Guoliang Kang</a>,\n</form>\n<form id=\"form-YiYangImageImageDomainAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiYangImageImageDomainAdaptation').submit();\">Yi Yang</a>,\n</form>\n<form id=\"form-JianbinJiaoImageImageDomainAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianbin Jiao\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianbinJiaoImageImageDomainAdaptation').submit();\">Jianbin Jiao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Deng_Image-Image_Domain_Adaptation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.07027\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Deng_2018_CVPR,<br>\nauthor = {Deng, Weijian and Zheng, Liang and Ye, Qixiang and Kang, Guoliang and Yang, Yi and Jiao, Jianbin},<br>\ntitle = {Image-Image Domain Adaptation With Preserved Self-Similarity and Domain-Dissimilarity for Person Re-Identification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhu_A_Generative_Adversarial_CVPR_2018_paper.html\">A Generative Adversarial Approach for Zero-Shot Learning From Noisy Texts</a></dt>\n<dd>\n<form id=\"form-YizheZhuAGenerativeAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yizhe Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YizheZhuAGenerativeAdversarial').submit();\">Yizhe Zhu</a>,\n</form>\n<form id=\"form-MohamedElhoseinyAGenerativeAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mohamed Elhoseiny\">\n<a href=\"#\" onclick=\"document.getElementById('form-MohamedElhoseinyAGenerativeAdversarial').submit();\">Mohamed Elhoseiny</a>,\n</form>\n<form id=\"form-BingchenLiuAGenerativeAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bingchen Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-BingchenLiuAGenerativeAdversarial').submit();\">Bingchen Liu</a>,\n</form>\n<form id=\"form-XiPengAGenerativeAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xi Peng\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiPengAGenerativeAdversarial').submit();\">Xi Peng</a>,\n</form>\n<form id=\"form-AhmedElgammalAGenerativeAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ahmed Elgammal\">\n<a href=\"#\" onclick=\"document.getElementById('form-AhmedElgammalAGenerativeAdversarial').submit();\">Ahmed Elgammal</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhu_A_Generative_Adversarial_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.01381\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhu_2018_CVPR,<br>\nauthor = {Zhu, Yizhe and Elhoseiny, Mohamed and Liu, Bingchen and Peng, Xi and Elgammal, Ahmed},<br>\ntitle = {A Generative Adversarial Approach for Zero-Shot Learning From Noisy Texts},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hwang_Tensorize_Factorize_and_CVPR_2018_paper.html\">Tensorize, Factorize and Regularize: Robust Visual Relationship Learning</a></dt>\n<dd>\n<form id=\"form-SeongJaeTensorizeFactorizeand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Seong Jae Hwang\">\n<a href=\"#\" onclick=\"document.getElementById('form-SeongJaeTensorizeFactorizeand').submit();\">Seong Jae Hwang</a>,\n</form>\n<form id=\"form-SathyaN.TensorizeFactorizeand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sathya N. Ravi\">\n<a href=\"#\" onclick=\"document.getElementById('form-SathyaN.TensorizeFactorizeand').submit();\">Sathya N. Ravi</a>,\n</form>\n<form id=\"form-ZiruiTaoTensorizeFactorizeand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zirui Tao\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZiruiTaoTensorizeFactorizeand').submit();\">Zirui Tao</a>,\n</form>\n<form id=\"form-HyunwooJ.TensorizeFactorizeand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hyunwoo J. Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-HyunwooJ.TensorizeFactorizeand').submit();\">Hyunwoo J. Kim</a>,\n</form>\n<form id=\"form-MaxwellD.TensorizeFactorizeand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Maxwell D. Collins\">\n<a href=\"#\" onclick=\"document.getElementById('form-MaxwellD.TensorizeFactorizeand').submit();\">Maxwell D. Collins</a>,\n</form>\n<form id=\"form-VikasSinghTensorizeFactorizeand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vikas Singh\">\n<a href=\"#\" onclick=\"document.getElementById('form-VikasSinghTensorizeFactorizeand').submit();\">Vikas Singh</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hwang_Tensorize_Factorize_and_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hwang_2018_CVPR,<br>\nauthor = {Jae Hwang, Seong and Ravi, Sathya N. and Tao, Zirui and Kim, Hyunwoo J. and Collins, Maxwell D. and Singh, Vikas},<br>\ntitle = {Tensorize, Factorize and Regularize: Robust Visual Relationship Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Song_Transductive_Unbiased_Embedding_CVPR_2018_paper.html\">Transductive Unbiased Embedding for Zero-Shot Learning</a></dt>\n<dd>\n<form id=\"form-JieSongTransductiveUnbiasedEmbedding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jie Song\">\n<a href=\"#\" onclick=\"document.getElementById('form-JieSongTransductiveUnbiasedEmbedding').submit();\">Jie Song</a>,\n</form>\n<form id=\"form-ChengchaoShenTransductiveUnbiasedEmbedding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chengchao Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChengchaoShenTransductiveUnbiasedEmbedding').submit();\">Chengchao Shen</a>,\n</form>\n<form id=\"form-YezhouYangTransductiveUnbiasedEmbedding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yezhou Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YezhouYangTransductiveUnbiasedEmbedding').submit();\">Yezhou Yang</a>,\n</form>\n<form id=\"form-YangLiuTransductiveUnbiasedEmbedding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yang Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YangLiuTransductiveUnbiasedEmbedding').submit();\">Yang Liu</a>,\n</form>\n<form id=\"form-MingliSongTransductiveUnbiasedEmbedding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mingli Song\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingliSongTransductiveUnbiasedEmbedding').submit();\">Mingli Song</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Song_Transductive_Unbiased_Embedding_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.11320\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Song_2018_CVPR,<br>\nauthor = {Song, Jie and Shen, Chengchao and Yang, Yezhou and Liu, Yang and Song, Mingli},<br>\ntitle = {Transductive Unbiased Embedding for Zero-Shot Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lee_Hierarchical_Novelty_Detection_CVPR_2018_paper.html\">Hierarchical Novelty Detection for Visual Object Recognition</a></dt>\n<dd>\n<form id=\"form-KibokLeeHierarchicalNoveltyDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kibok Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-KibokLeeHierarchicalNoveltyDetection').submit();\">Kibok Lee</a>,\n</form>\n<form id=\"form-KiminLeeHierarchicalNoveltyDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kimin Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-KiminLeeHierarchicalNoveltyDetection').submit();\">Kimin Lee</a>,\n</form>\n<form id=\"form-KyleMinHierarchicalNoveltyDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kyle Min\">\n<a href=\"#\" onclick=\"document.getElementById('form-KyleMinHierarchicalNoveltyDetection').submit();\">Kyle Min</a>,\n</form>\n<form id=\"form-YutingZhangHierarchicalNoveltyDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuting Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YutingZhangHierarchicalNoveltyDetection').submit();\">Yuting Zhang</a>,\n</form>\n<form id=\"form-JinwooShinHierarchicalNoveltyDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jinwoo Shin\">\n<a href=\"#\" onclick=\"document.getElementById('form-JinwooShinHierarchicalNoveltyDetection').submit();\">Jinwoo Shin</a>,\n</form>\n<form id=\"form-HonglakLeeHierarchicalNoveltyDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Honglak Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-HonglakLeeHierarchicalNoveltyDetection').submit();\">Honglak Lee</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lee_Hierarchical_Novelty_Detection_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2307-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00722\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lee_2018_CVPR,<br>\nauthor = {Lee, Kibok and Lee, Kimin and Min, Kyle and Zhang, Yuting and Shin, Jinwoo and Lee, Honglak},<br>\ntitle = {Hierarchical Novelty Detection for Visual Object Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_Zero-Shot_Visual_Recognition_CVPR_2018_paper.html\">Zero-Shot Visual Recognition Using Semantics-Preserving Adversarial Embedding Networks</a></dt>\n<dd>\n<form id=\"form-LongChenZeroShotVisualRecognition\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Long Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-LongChenZeroShotVisualRecognition').submit();\">Long Chen</a>,\n</form>\n<form id=\"form-HanwangZhangZeroShotVisualRecognition\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hanwang Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HanwangZhangZeroShotVisualRecognition').submit();\">Hanwang Zhang</a>,\n</form>\n<form id=\"form-JunXiaoZeroShotVisualRecognition\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jun Xiao\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunXiaoZeroShotVisualRecognition').submit();\">Jun Xiao</a>,\n</form>\n<form id=\"form-WeiLiuZeroShotVisualRecognition\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiLiuZeroShotVisualRecognition').submit();\">Wei Liu</a>,\n</form>\n<form id=\"form-Shih-FuChangZeroShotVisualRecognition\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shih-Fu Chang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Shih-FuChangZeroShotVisualRecognition').submit();\">Shih-Fu Chang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_Zero-Shot_Visual_Recognition_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.01928\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Long and Zhang, Hanwang and Xiao, Jun and Liu, Wei and Chang, Shih-Fu},<br>\ntitle = {Zero-Shot Visual Recognition Using Semantics-Preserving Adversarial Embedding Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhou_Learning_Rich_Features_CVPR_2018_paper.html\">Learning Rich Features for Image Manipulation Detection</a></dt>\n<dd>\n<form id=\"form-PengZhouLearningRichFeatures\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peng Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-PengZhouLearningRichFeatures').submit();\">Peng Zhou</a>,\n</form>\n<form id=\"form-XintongHanLearningRichFeatures\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xintong Han\">\n<a href=\"#\" onclick=\"document.getElementById('form-XintongHanLearningRichFeatures').submit();\">Xintong Han</a>,\n</form>\n<form id=\"form-VladI.LearningRichFeatures\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vlad I. Morariu\">\n<a href=\"#\" onclick=\"document.getElementById('form-VladI.LearningRichFeatures').submit();\">Vlad I. Morariu</a>,\n</form>\n<form id=\"form-LarryS.LearningRichFeatures\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Larry S. Davis\">\n<a href=\"#\" onclick=\"document.getElementById('form-LarryS.LearningRichFeatures').submit();\">Larry S. Davis</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhou_Learning_Rich_Features_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.04953\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhou_2018_CVPR,<br>\nauthor = {Zhou, Peng and Han, Xintong and Morariu, Vlad I. and Davis, Larry S.},<br>\ntitle = {Learning Rich Features for Image Manipulation Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kalayeh_Human_Semantic_Parsing_CVPR_2018_paper.html\">Human Semantic Parsing for Person Re-Identification</a></dt>\n<dd>\n<form id=\"form-MahdiM.HumanSemanticParsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mahdi M. Kalayeh\">\n<a href=\"#\" onclick=\"document.getElementById('form-MahdiM.HumanSemanticParsing').submit();\">Mahdi M. Kalayeh</a>,\n</form>\n<form id=\"form-EmrahBasaranHumanSemanticParsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Emrah Basaran\">\n<a href=\"#\" onclick=\"document.getElementById('form-EmrahBasaranHumanSemanticParsing').submit();\">Emrah Basaran</a>,\n</form>\n<form id=\"form-MuhittinG\u00c3\u00b6kmenHumanSemanticParsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Muhittin G\u00c3\u00b6kmen\">\n<a href=\"#\" onclick=\"document.getElementById('form-MuhittinG\u00c3\u00b6kmenHumanSemanticParsing').submit();\">Muhittin G\u00c3\u00b6kmen</a>,\n</form>\n<form id=\"form-MustafaE.HumanSemanticParsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mustafa E. Kamasak\">\n<a href=\"#\" onclick=\"document.getElementById('form-MustafaE.HumanSemanticParsing').submit();\">Mustafa E. Kamasak</a>,\n</form>\n<form id=\"form-MubarakShahHumanSemanticParsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mubarak Shah\">\n<a href=\"#\" onclick=\"document.getElementById('form-MubarakShahHumanSemanticParsing').submit();\">Mubarak Shah</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kalayeh_Human_Semantic_Parsing_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00216\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kalayeh_2018_CVPR,<br>\nauthor = {Kalayeh, Mahdi M. and Basaran, Emrah and G\u00c3\u00b6kmen, Muhittin and Kamasak, Mustafa E. and Shah, Mubarak},<br>\ntitle = {Human Semantic Parsing for Person Re-Identification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Fan_Stacked_Latent_Attention_CVPR_2018_paper.html\">Stacked Latent Attention for Multimodal Reasoning</a></dt>\n<dd>\n<form id=\"form-HaoqiFanStackedLatentAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Haoqi Fan\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaoqiFanStackedLatentAttention').submit();\">Haoqi Fan</a>,\n</form>\n<form id=\"form-JiatongZhouStackedLatentAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiatong Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiatongZhouStackedLatentAttention').submit();\">Jiatong Zhou</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Fan_Stacked_Latent_Attention_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Fan_2018_CVPR,<br>\nauthor = {Fan, Haoqi and Zhou, Jiatong},<br>\ntitle = {Stacked Latent Attention for Multimodal Reasoning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Singh_R-FCN-3000_at_30fps_CVPR_2018_paper.html\">R-FCN-3000 at 30fps: Decoupling Detection and Classification</a></dt>\n<dd>\n<form id=\"form-BharatSinghRFCN3000at30fps\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bharat Singh\">\n<a href=\"#\" onclick=\"document.getElementById('form-BharatSinghRFCN3000at30fps').submit();\">Bharat Singh</a>,\n</form>\n<form id=\"form-HengduoLiRFCN3000at30fps\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hengduo Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-HengduoLiRFCN3000at30fps').submit();\">Hengduo Li</a>,\n</form>\n<form id=\"form-AbhishekSharmaRFCN3000at30fps\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Abhishek Sharma\">\n<a href=\"#\" onclick=\"document.getElementById('form-AbhishekSharmaRFCN3000at30fps').submit();\">Abhishek Sharma</a>,\n</form>\n<form id=\"form-LarryS.RFCN3000at30fps\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Larry S. Davis\">\n<a href=\"#\" onclick=\"document.getElementById('form-LarryS.RFCN3000at30fps').submit();\">Larry S. Davis</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Singh_R-FCN-3000_at_30fps_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.01802\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Singh_2018_CVPR,<br>\nauthor = {Singh, Bharat and Li, Hengduo and Sharma, Abhishek and Davis, Larry S.},<br>\ntitle = {R-FCN-3000 at 30fps: Decoupling Detection and Classification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_CSRNet_Dilated_Convolutional_CVPR_2018_paper.html\">CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes</a></dt>\n<dd>\n<form id=\"form-YuhongLiCSRNetDilatedConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuhong Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuhongLiCSRNetDilatedConvolutional').submit();\">Yuhong Li</a>,\n</form>\n<form id=\"form-XiaofanZhangCSRNetDilatedConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaofan Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaofanZhangCSRNetDilatedConvolutional').submit();\">Xiaofan Zhang</a>,\n</form>\n<form id=\"form-DemingChenCSRNetDilatedConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Deming Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-DemingChenCSRNetDilatedConvolutional').submit();\">Deming Chen</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_CSRNet_Dilated_Convolutional_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3727-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.10062\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Yuhong and Zhang, Xiaofan and Chen, Deming},<br>\ntitle = {CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Uijlings_Revisiting_Knowledge_Transfer_CVPR_2018_paper.html\">Revisiting Knowledge Transfer for Training Object Class Detectors</a></dt>\n<dd>\n<form id=\"form-JasperUijlingsRevisitingKnowledgeTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jasper Uijlings\">\n<a href=\"#\" onclick=\"document.getElementById('form-JasperUijlingsRevisitingKnowledgeTransfer').submit();\">Jasper Uijlings</a>,\n</form>\n<form id=\"form-StefanPopovRevisitingKnowledgeTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stefan Popov\">\n<a href=\"#\" onclick=\"document.getElementById('form-StefanPopovRevisitingKnowledgeTransfer').submit();\">Stefan Popov</a>,\n</form>\n<form id=\"form-VittorioFerrariRevisitingKnowledgeTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vittorio Ferrari\">\n<a href=\"#\" onclick=\"document.getElementById('form-VittorioFerrariRevisitingKnowledgeTransfer').submit();\">Vittorio Ferrari</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Uijlings_Revisiting_Knowledge_Transfer_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1708.06128\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Uijlings_2018_CVPR,<br>\nauthor = {Uijlings, Jasper and Popov, Stefan and Ferrari, Vittorio},<br>\ntitle = {Revisiting Knowledge Transfer for Training Object Class Detectors},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kim_Deep_Sparse_Coding_CVPR_2018_paper.html\">Deep Sparse Coding for Invariant Multimodal Halle Berry Neurons</a></dt>\n<dd>\n<form id=\"form-EdwardKimDeepSparseCoding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Edward Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-EdwardKimDeepSparseCoding').submit();\">Edward Kim</a>,\n</form>\n<form id=\"form-DarrylHannanDeepSparseCoding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Darryl Hannan\">\n<a href=\"#\" onclick=\"document.getElementById('form-DarrylHannanDeepSparseCoding').submit();\">Darryl Hannan</a>,\n</form>\n<form id=\"form-GarrettKenyonDeepSparseCoding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Garrett Kenyon\">\n<a href=\"#\" onclick=\"document.getElementById('form-GarrettKenyonDeepSparseCoding').submit();\">Garrett Kenyon</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kim_Deep_Sparse_Coding_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.07998\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kim_2018_CVPR,<br>\nauthor = {Kim, Edward and Hannan, Darryl and Kenyon, Garrett},<br>\ntitle = {Deep Sparse Coding for Invariant Multimodal Halle Berry Neurons},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ehret_On_the_Convergence_CVPR_2018_paper.html\">On the Convergence of PatchMatch and Its Variants</a></dt>\n<dd>\n<form id=\"form-ThibaudEhretOntheConvergence\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Thibaud Ehret\">\n<a href=\"#\" onclick=\"document.getElementById('form-ThibaudEhretOntheConvergence').submit();\">Thibaud Ehret</a>,\n</form>\n<form id=\"form-PabloAriasOntheConvergence\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pablo Arias\">\n<a href=\"#\" onclick=\"document.getElementById('form-PabloAriasOntheConvergence').submit();\">Pablo Arias</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ehret_On_the_Convergence_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3993-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ehret_2018_CVPR,<br>\nauthor = {Ehret, Thibaud and Arias, Pablo},<br>\ntitle = {On the Convergence of PatchMatch and Its Variants},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chao_Rethinking_the_Faster_CVPR_2018_paper.html\">Rethinking the Faster R-CNN Architecture for Temporal Action Localization</a></dt>\n<dd>\n<form id=\"form-Yu-WeiChaoRethinkingtheFaster\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu-Wei Chao\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yu-WeiChaoRethinkingtheFaster').submit();\">Yu-Wei Chao</a>,\n</form>\n<form id=\"form-SudheendraVijayanarasimhanRethinkingtheFaster\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sudheendra Vijayanarasimhan\">\n<a href=\"#\" onclick=\"document.getElementById('form-SudheendraVijayanarasimhanRethinkingtheFaster').submit();\">Sudheendra Vijayanarasimhan</a>,\n</form>\n<form id=\"form-BryanSeyboldRethinkingtheFaster\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bryan Seybold\">\n<a href=\"#\" onclick=\"document.getElementById('form-BryanSeyboldRethinkingtheFaster').submit();\">Bryan Seybold</a>,\n</form>\n<form id=\"form-DavidA.RethinkingtheFaster\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"David A. Ross\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavidA.RethinkingtheFaster').submit();\">David A. Ross</a>,\n</form>\n<form id=\"form-JiaDengRethinkingtheFaster\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jia Deng\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiaDengRethinkingtheFaster').submit();\">Jia Deng</a>,\n</form>\n<form id=\"form-RahulSukthankarRethinkingtheFaster\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rahul Sukthankar\">\n<a href=\"#\" onclick=\"document.getElementById('form-RahulSukthankarRethinkingtheFaster').submit();\">Rahul Sukthankar</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chao_Rethinking_the_Faster_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0024-supp.zip\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.07667\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chao_2018_CVPR,<br>\nauthor = {Chao, Yu-Wei and Vijayanarasimhan, Sudheendra and Seybold, Bryan and Ross, David A. and Deng, Jia and Sukthankar, Rahul},<br>\ntitle = {Rethinking the Faster R-CNN Architecture for Temporal Action Localization},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xiao_MoNet_Deep_Motion_CVPR_2018_paper.html\">MoNet: Deep Motion Exploitation for Video Object Segmentation</a></dt>\n<dd>\n<form id=\"form-HuaxinXiaoMoNetDeepMotion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huaxin Xiao\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuaxinXiaoMoNetDeepMotion').submit();\">Huaxin Xiao</a>,\n</form>\n<form id=\"form-JiashiFengMoNetDeepMotion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiashi Feng\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiashiFengMoNetDeepMotion').submit();\">Jiashi Feng</a>,\n</form>\n<form id=\"form-GuoshengLinMoNetDeepMotion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guosheng Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuoshengLinMoNetDeepMotion').submit();\">Guosheng Lin</a>,\n</form>\n<form id=\"form-YuLiuMoNetDeepMotion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuLiuMoNetDeepMotion').submit();\">Yu Liu</a>,\n</form>\n<form id=\"form-MaojunZhangMoNetDeepMotion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Maojun Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-MaojunZhangMoNetDeepMotion').submit();\">Maojun Zhang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xiao_MoNet_Deep_Motion_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0224-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xiao_2018_CVPR,<br>\nauthor = {Xiao, Huaxin and Feng, Jiashi and Lin, Guosheng and Liu, Yu and Zhang, Maojun},<br>\ntitle = {MoNet: Deep Motion Exploitation for Video Object Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Video_Representation_Learning_CVPR_2018_paper.html\">Video Representation Learning Using Discriminative Pooling</a></dt>\n<dd>\n<form id=\"form-JueWangVideoRepresentationLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jue Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JueWangVideoRepresentationLearning').submit();\">Jue Wang</a>,\n</form>\n<form id=\"form-AnoopCherianVideoRepresentationLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anoop Cherian\">\n<a href=\"#\" onclick=\"document.getElementById('form-AnoopCherianVideoRepresentationLearning').submit();\">Anoop Cherian</a>,\n</form>\n<form id=\"form-FatihPorikliVideoRepresentationLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fatih Porikli\">\n<a href=\"#\" onclick=\"document.getElementById('form-FatihPorikliVideoRepresentationLearning').submit();\">Fatih Porikli</a>,\n</form>\n<form id=\"form-StephenGouldVideoRepresentationLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stephen Gould\">\n<a href=\"#\" onclick=\"document.getElementById('form-StephenGouldVideoRepresentationLearning').submit();\">Stephen Gould</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Video_Representation_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.10628\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Jue and Cherian, Anoop and Porikli, Fatih and Gould, Stephen},<br>\ntitle = {Video Representation Learning Using Discriminative Pooling},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_Recognizing_Human_Actions_CVPR_2018_paper.html\">Recognizing Human Actions as the Evolution of Pose Estimation Maps</a></dt>\n<dd>\n<form id=\"form-MengyuanLiuRecognizingHumanActions\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mengyuan Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-MengyuanLiuRecognizingHumanActions').submit();\">Mengyuan Liu</a>,\n</form>\n<form id=\"form-JunsongYuanRecognizingHumanActions\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junsong Yuan\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunsongYuanRecognizingHumanActions').submit();\">Junsong Yuan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_Recognizing_Human_Actions_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Mengyuan and Yuan, Junsong},<br>\ntitle = {Recognizing Human Actions as the Evolution of Pose Estimation Maps},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_Video_Person_Re-Identification_CVPR_2018_paper.html\">Video Person Re-Identification With Competitive Snippet-Similarity Aggregation and Co-Attentive Snippet Embedding</a></dt>\n<dd>\n<form id=\"form-DapengChenVideoPersonReIdentification\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dapeng Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-DapengChenVideoPersonReIdentification').submit();\">Dapeng Chen</a>,\n</form>\n<form id=\"form-HongshengLiVideoPersonReIdentification\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hongsheng Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-HongshengLiVideoPersonReIdentification').submit();\">Hongsheng Li</a>,\n</form>\n<form id=\"form-TongXiaoVideoPersonReIdentification\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tong Xiao\">\n<a href=\"#\" onclick=\"document.getElementById('form-TongXiaoVideoPersonReIdentification').submit();\">Tong Xiao</a>,\n</form>\n<form id=\"form-ShuaiYiVideoPersonReIdentification\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuai Yi\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuaiYiVideoPersonReIdentification').submit();\">Shuai Yi</a>,\n</form>\n<form id=\"form-XiaogangWangVideoPersonReIdentification\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaogang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaogangWangVideoPersonReIdentification').submit();\">Xiaogang Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_Video_Person_Re-Identification_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Dapeng and Li, Hongsheng and Xiao, Tong and Yi, Shuai and Wang, Xiaogang},<br>\ntitle = {Video Person Re-Identification With Competitive Snippet-Similarity Aggregation and Co-Attentive Snippet Embedding},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Song_Mask-Guided_Contrastive_Attention_CVPR_2018_paper.html\">Mask-Guided Contrastive Attention Model for Person Re-Identification</a></dt>\n<dd>\n<form id=\"form-ChunfengSongMaskGuidedContrastiveAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chunfeng Song\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChunfengSongMaskGuidedContrastiveAttention').submit();\">Chunfeng Song</a>,\n</form>\n<form id=\"form-YanHuangMaskGuidedContrastiveAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yan Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanHuangMaskGuidedContrastiveAttention').submit();\">Yan Huang</a>,\n</form>\n<form id=\"form-WanliOuyangMaskGuidedContrastiveAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wanli Ouyang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WanliOuyangMaskGuidedContrastiveAttention').submit();\">Wanli Ouyang</a>,\n</form>\n<form id=\"form-LiangWangMaskGuidedContrastiveAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiangWangMaskGuidedContrastiveAttention').submit();\">Liang Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Song_Mask-Guided_Contrastive_Attention_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1085-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Song_2018_CVPR,<br>\nauthor = {Song, Chunfeng and Huang, Yan and Ouyang, Wanli and Wang, Liang},<br>\ntitle = {Mask-Guided Contrastive Attention Model for Person Re-Identification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_Blazingly_Fast_Video_CVPR_2018_paper.html\">Blazingly Fast Video Object Segmentation With Pixel-Wise Metric Learning</a></dt>\n<dd>\n<form id=\"form-YuhuaChenBlazinglyFastVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuhua Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuhuaChenBlazinglyFastVideo').submit();\">Yuhua Chen</a>,\n</form>\n<form id=\"form-JordiPont-TusetBlazinglyFastVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jordi Pont-Tuset\">\n<a href=\"#\" onclick=\"document.getElementById('form-JordiPont-TusetBlazinglyFastVideo').submit();\">Jordi Pont-Tuset</a>,\n</form>\n<form id=\"form-AlbertoMontesBlazinglyFastVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alberto Montes\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlbertoMontesBlazinglyFastVideo').submit();\">Alberto Montes</a>,\n</form>\n<form id=\"form-LucVanBlazinglyFastVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Luc Van Gool\">\n<a href=\"#\" onclick=\"document.getElementById('form-LucVanBlazinglyFastVideo').submit();\">Luc Van Gool</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_Blazingly_Fast_Video_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.03131\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Yuhua and Pont-Tuset, Jordi and Montes, Alberto and Van Gool, Luc},<br>\ntitle = {Blazingly Fast Video Object Segmentation With Pixel-Wise Metric Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sung_Learning_to_Compare_CVPR_2018_paper.html\">Learning to Compare: Relation Network for Few-Shot Learning</a></dt>\n<dd>\n<form id=\"form-FloodSungLearningtoCompare\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Flood Sung\">\n<a href=\"#\" onclick=\"document.getElementById('form-FloodSungLearningtoCompare').submit();\">Flood Sung</a>,\n</form>\n<form id=\"form-YongxinYangLearningtoCompare\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yongxin Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YongxinYangLearningtoCompare').submit();\">Yongxin Yang</a>,\n</form>\n<form id=\"form-LiZhangLearningtoCompare\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Li Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiZhangLearningtoCompare').submit();\">Li Zhang</a>,\n</form>\n<form id=\"form-TaoXiangLearningtoCompare\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tao Xiang\">\n<a href=\"#\" onclick=\"document.getElementById('form-TaoXiangLearningtoCompare').submit();\">Tao Xiang</a>,\n</form>\n<form id=\"form-PhilipH.S.LearningtoCompare\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Philip H.S. Torr\">\n<a href=\"#\" onclick=\"document.getElementById('form-PhilipH.S.LearningtoCompare').submit();\">Philip H.S. Torr</a>,\n</form>\n<form id=\"form-TimothyM.LearningtoCompare\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Timothy M. Hospedales\">\n<a href=\"#\" onclick=\"document.getElementById('form-TimothyM.LearningtoCompare').submit();\">Timothy M. Hospedales</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sung_Learning_to_Compare_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.06025\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sung_2018_CVPR,<br>\nauthor = {Sung, Flood and Yang, Yongxin and Zhang, Li and Xiang, Tao and Torr, Philip H.S. and Hospedales, Timothy M.},<br>\ntitle = {Learning to Compare: Relation Network for Few-Shot Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Caesar_COCO-Stuff_Thing_and_CVPR_2018_paper.html\">COCO-Stuff: Thing and Stuff Classes in Context</a></dt>\n<dd>\n<form id=\"form-HolgerCaesarCOCOStuffThingand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Holger Caesar\">\n<a href=\"#\" onclick=\"document.getElementById('form-HolgerCaesarCOCOStuffThingand').submit();\">Holger Caesar</a>,\n</form>\n<form id=\"form-JasperUijlingsCOCOStuffThingand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jasper Uijlings\">\n<a href=\"#\" onclick=\"document.getElementById('form-JasperUijlingsCOCOStuffThingand').submit();\">Jasper Uijlings</a>,\n</form>\n<form id=\"form-VittorioFerrariCOCOStuffThingand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vittorio Ferrari\">\n<a href=\"#\" onclick=\"document.getElementById('form-VittorioFerrariCOCOStuffThingand').submit();\">Vittorio Ferrari</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Caesar_COCO-Stuff_Thing_and_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1612.03716\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Caesar_2018_CVPR,<br>\nauthor = {Caesar, Holger and Uijlings, Jasper and Ferrari, Vittorio},<br>\ntitle = {COCO-Stuff: Thing and Stuff Classes in Context},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Johnson_Image_Generation_From_CVPR_2018_paper.html\">Image Generation From Scene Graphs</a></dt>\n<dd>\n<form id=\"form-JustinJohnsonImageGenerationFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Justin Johnson\">\n<a href=\"#\" onclick=\"document.getElementById('form-JustinJohnsonImageGenerationFrom').submit();\">Justin Johnson</a>,\n</form>\n<form id=\"form-AgrimGuptaImageGenerationFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Agrim Gupta\">\n<a href=\"#\" onclick=\"document.getElementById('form-AgrimGuptaImageGenerationFrom').submit();\">Agrim Gupta</a>,\n</form>\n<form id=\"form-LiFei-FeiImageGenerationFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Li Fei-Fei\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiFei-FeiImageGenerationFrom').submit();\">Li Fei-Fei</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Johnson_Image_Generation_From_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.01622\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Johnson_2018_CVPR,<br>\nauthor = {Johnson, Justin and Gupta, Agrim and Fei-Fei, Li},<br>\ntitle = {Image Generation From Scene Graphs},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Cao_Deep_Cauchy_Hashing_CVPR_2018_paper.html\">Deep Cauchy Hashing for Hamming Space Retrieval</a></dt>\n<dd>\n<form id=\"form-YueCaoDeepCauchyHashing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yue Cao\">\n<a href=\"#\" onclick=\"document.getElementById('form-YueCaoDeepCauchyHashing').submit();\">Yue Cao</a>,\n</form>\n<form id=\"form-MingshengLongDeepCauchyHashing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mingsheng Long\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingshengLongDeepCauchyHashing').submit();\">Mingsheng Long</a>,\n</form>\n<form id=\"form-BinLiuDeepCauchyHashing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bin Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-BinLiuDeepCauchyHashing').submit();\">Bin Liu</a>,\n</form>\n<form id=\"form-JianminWangDeepCauchyHashing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianmin Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianminWangDeepCauchyHashing').submit();\">Jianmin Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Cao_Deep_Cauchy_Hashing_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Cao_2018_CVPR,<br>\nauthor = {Cao, Yue and Long, Mingsheng and Liu, Bin and Wang, Jianmin},<br>\ntitle = {Deep Cauchy Hashing for Hamming Space Retrieval},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Jayaraman_Learning_to_Look_CVPR_2018_paper.html\">Learning to Look Around: Intelligently Exploring Unseen Environments for Unknown Tasks</a></dt>\n<dd>\n<form id=\"form-DineshJayaramanLearningtoLook\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dinesh Jayaraman\">\n<a href=\"#\" onclick=\"document.getElementById('form-DineshJayaramanLearningtoLook').submit();\">Dinesh Jayaraman</a>,\n</form>\n<form id=\"form-KristenGraumanLearningtoLook\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kristen Grauman\">\n<a href=\"#\" onclick=\"document.getElementById('form-KristenGraumanLearningtoLook').submit();\">Kristen Grauman</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Jayaraman_Learning_to_Look_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1709.00507\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Jayaraman_2018_CVPR,<br>\nauthor = {Jayaraman, Dinesh and Grauman, Kristen},<br>\ntitle = {Learning to Look Around: Intelligently Exploring Unseen Environments for Unknown Tasks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Multi-Scale_Location-Aware_Kernel_CVPR_2018_paper.html\">Multi-Scale Location-Aware Kernel Representation for Object Detection</a></dt>\n<dd>\n<form id=\"form-HaoWangMultiScaleLocationAwareKernel\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hao Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaoWangMultiScaleLocationAwareKernel').submit();\">Hao Wang</a>,\n</form>\n<form id=\"form-QilongWangMultiScaleLocationAwareKernel\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qilong Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-QilongWangMultiScaleLocationAwareKernel').submit();\">Qilong Wang</a>,\n</form>\n<form id=\"form-MingqiGaoMultiScaleLocationAwareKernel\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mingqi Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingqiGaoMultiScaleLocationAwareKernel').submit();\">Mingqi Gao</a>,\n</form>\n<form id=\"form-PeihuaLiMultiScaleLocationAwareKernel\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peihua Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-PeihuaLiMultiScaleLocationAwareKernel').submit();\">Peihua Li</a>,\n</form>\n<form id=\"form-WangmengZuoMultiScaleLocationAwareKernel\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wangmeng Zuo\">\n<a href=\"#\" onclick=\"document.getElementById('form-WangmengZuoMultiScaleLocationAwareKernel').submit();\">Wangmeng Zuo</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Multi-Scale_Location-Aware_Kernel_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00428\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Hao and Wang, Qilong and Gao, Mingqi and Li, Peihua and Zuo, Wangmeng},<br>\ntitle = {Multi-Scale Location-Aware Kernel Representation for Object Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yang_Clinical_Skin_Lesion_CVPR_2018_paper.html\">Clinical Skin Lesion Diagnosis Using Representations Inspired by Dermatologist Criteria</a></dt>\n<dd>\n<form id=\"form-JufengYangClinicalSkinLesion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jufeng Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JufengYangClinicalSkinLesion').submit();\">Jufeng Yang</a>,\n</form>\n<form id=\"form-XiaoxiaoSunClinicalSkinLesion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaoxiao Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaoxiaoSunClinicalSkinLesion').submit();\">Xiaoxiao Sun</a>,\n</form>\n<form id=\"form-JieLiangClinicalSkinLesion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jie Liang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JieLiangClinicalSkinLesion').submit();\">Jie Liang</a>,\n</form>\n<form id=\"form-PaulL.ClinicalSkinLesion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Paul L. Rosin\">\n<a href=\"#\" onclick=\"document.getElementById('form-PaulL.ClinicalSkinLesion').submit();\">Paul L. Rosin</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yang_Clinical_Skin_Lesion_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yang_2018_CVPR,<br>\nauthor = {Yang, Jufeng and Sun, Xiaoxiao and Liang, Jie and Rosin, Paul L.},<br>\ntitle = {Clinical Skin Lesion Diagnosis Using Representations Inspired by Dermatologist Criteria},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_Compare_and_Contrast_CVPR_2018_paper.html\">Compare and Contrast: Learning Prominent Visual Differences</a></dt>\n<dd>\n<form id=\"form-StevenChenCompareandContrast\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Steven Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-StevenChenCompareandContrast').submit();\">Steven Chen</a>,\n</form>\n<form id=\"form-KristenGraumanCompareandContrast\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kristen Grauman\">\n<a href=\"#\" onclick=\"document.getElementById('form-KristenGraumanCompareandContrast').submit();\">Kristen Grauman</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_Compare_and_Contrast_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2318-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00112\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Steven and Grauman, Kristen},<br>\ntitle = {Compare and Contrast: Learning Prominent Visual Differences},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ge_Multi-Evidence_Filtering_and_CVPR_2018_paper.html\">Multi-Evidence Filtering and Fusion for Multi-Label Classification, Object Detection and Semantic Segmentation Based on Weakly Supervised Learning</a></dt>\n<dd>\n<form id=\"form-WeifengGeMultiEvidenceFilteringand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weifeng Ge\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeifengGeMultiEvidenceFilteringand').submit();\">Weifeng Ge</a>,\n</form>\n<form id=\"form-SibeiYangMultiEvidenceFilteringand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sibei Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-SibeiYangMultiEvidenceFilteringand').submit();\">Sibei Yang</a>,\n</form>\n<form id=\"form-YizhouYuMultiEvidenceFilteringand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yizhou Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YizhouYuMultiEvidenceFilteringand').submit();\">Yizhou Yu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ge_Multi-Evidence_Filtering_and_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2752-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ge_2018_CVPR,<br>\nauthor = {Ge, Weifeng and Yang, Sibei and Yu, Yizhou},<br>\ntitle = {Multi-Evidence Filtering and Fusion for Multi-Label Classification, Object Detection and Semantic Segmentation Based on Weakly Supervised Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Cao_HashGAN_Deep_Learning_CVPR_2018_paper.html\">HashGAN: Deep Learning to Hash With Pair Conditional Wasserstein GAN</a></dt>\n<dd>\n<form id=\"form-YueCaoHashGANDeepLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yue Cao\">\n<a href=\"#\" onclick=\"document.getElementById('form-YueCaoHashGANDeepLearning').submit();\">Yue Cao</a>,\n</form>\n<form id=\"form-BinLiuHashGANDeepLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bin Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-BinLiuHashGANDeepLearning').submit();\">Bin Liu</a>,\n</form>\n<form id=\"form-MingshengLongHashGANDeepLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mingsheng Long\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingshengLongHashGANDeepLearning').submit();\">Mingsheng Long</a>,\n</form>\n<form id=\"form-JianminWangHashGANDeepLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianmin Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianminWangHashGANDeepLearning').submit();\">Jianmin Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Cao_HashGAN_Deep_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Cao_2018_CVPR,<br>\nauthor = {Cao, Yue and Liu, Bin and Long, Mingsheng and Wang, Jianmin},<br>\ntitle = {HashGAN: Deep Learning to Hash With Pair Conditional Wasserstein GAN},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wan_Min-Entropy_Latent_Model_CVPR_2018_paper.html\">Min-Entropy Latent Model for Weakly Supervised Object Detection</a></dt>\n<dd>\n<form id=\"form-FangWanMinEntropyLatentModel\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fang Wan\">\n<a href=\"#\" onclick=\"document.getElementById('form-FangWanMinEntropyLatentModel').submit();\">Fang Wan</a>,\n</form>\n<form id=\"form-PengxuWeiMinEntropyLatentModel\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pengxu Wei\">\n<a href=\"#\" onclick=\"document.getElementById('form-PengxuWeiMinEntropyLatentModel').submit();\">Pengxu Wei</a>,\n</form>\n<form id=\"form-JianbinJiaoMinEntropyLatentModel\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianbin Jiao\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianbinJiaoMinEntropyLatentModel').submit();\">Jianbin Jiao</a>,\n</form>\n<form id=\"form-ZhenjunHanMinEntropyLatentModel\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhenjun Han\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhenjunHanMinEntropyLatentModel').submit();\">Zhenjun Han</a>,\n</form>\n<form id=\"form-QixiangYeMinEntropyLatentModel\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qixiang Ye\">\n<a href=\"#\" onclick=\"document.getElementById('form-QixiangYeMinEntropyLatentModel').submit();\">Qixiang Ye</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wan_Min-Entropy_Latent_Model_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wan_2018_CVPR,<br>\nauthor = {Wan, Fang and Wei, Pengxu and Jiao, Jianbin and Han, Zhenjun and Ye, Qixiang},<br>\ntitle = {Min-Entropy Latent Model for Weakly Supervised Object Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yu_MAttNet_Modular_Attention_CVPR_2018_paper.html\">MAttNet: Modular Attention Network for Referring Expression Comprehension</a></dt>\n<dd>\n<form id=\"form-LichengYuMAttNetModularAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Licheng Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-LichengYuMAttNetModularAttention').submit();\">Licheng Yu</a>,\n</form>\n<form id=\"form-ZheLinMAttNetModularAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhe Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZheLinMAttNetModularAttention').submit();\">Zhe Lin</a>,\n</form>\n<form id=\"form-XiaohuiShenMAttNetModularAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaohui Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaohuiShenMAttNetModularAttention').submit();\">Xiaohui Shen</a>,\n</form>\n<form id=\"form-JimeiYangMAttNetModularAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jimei Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JimeiYangMAttNetModularAttention').submit();\">Jimei Yang</a>,\n</form>\n<form id=\"form-XinLuMAttNetModularAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xin Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinLuMAttNetModularAttention').submit();\">Xin Lu</a>,\n</form>\n<form id=\"form-MohitBansalMAttNetModularAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mohit Bansal\">\n<a href=\"#\" onclick=\"document.getElementById('form-MohitBansalMAttNetModularAttention').submit();\">Mohit Bansal</a>,\n</form>\n<form id=\"form-TamaraL.MAttNetModularAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tamara L. Berg\">\n<a href=\"#\" onclick=\"document.getElementById('form-TamaraL.MAttNetModularAttention').submit();\">Tamara L. Berg</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yu_MAttNet_Modular_Attention_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0594-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.08186\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yu_2018_CVPR,<br>\nauthor = {Yu, Licheng and Lin, Zhe and Shen, Xiaohui and Yang, Jimei and Lu, Xin and Bansal, Mohit and Berg, Tamara L.},<br>\ntitle = {MAttNet: Modular Attention Network for Referring Expression Comprehension},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xu_AttnGAN_Fine-Grained_Text_CVPR_2018_paper.html\">AttnGAN: Fine-Grained Text to Image Generation With Attentional Generative Adversarial Networks</a></dt>\n<dd>\n<form id=\"form-TaoXuAttnGANFineGrainedText\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tao Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-TaoXuAttnGANFineGrainedText').submit();\">Tao Xu</a>,\n</form>\n<form id=\"form-PengchuanZhangAttnGANFineGrainedText\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pengchuan Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-PengchuanZhangAttnGANFineGrainedText').submit();\">Pengchuan Zhang</a>,\n</form>\n<form id=\"form-QiuyuanHuangAttnGANFineGrainedText\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qiuyuan Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiuyuanHuangAttnGANFineGrainedText').submit();\">Qiuyuan Huang</a>,\n</form>\n<form id=\"form-HanZhangAttnGANFineGrainedText\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Han Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HanZhangAttnGANFineGrainedText').submit();\">Han Zhang</a>,\n</form>\n<form id=\"form-ZheGanAttnGANFineGrainedText\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhe Gan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZheGanAttnGANFineGrainedText').submit();\">Zhe Gan</a>,\n</form>\n<form id=\"form-XiaoleiHuangAttnGANFineGrainedText\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaolei Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaoleiHuangAttnGANFineGrainedText').submit();\">Xiaolei Huang</a>,\n</form>\n<form id=\"form-XiaodongHeAttnGANFineGrainedText\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaodong He\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaodongHeAttnGANFineGrainedText').submit();\">Xiaodong He</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xu_AttnGAN_Fine-Grained_Text_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.10485\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xu_2018_CVPR,<br>\nauthor = {Xu, Tao and Zhang, Pengchuan and Huang, Qiuyuan and Zhang, Han and Gan, Zhe and Huang, Xiaolei and He, Xiaodong},<br>\ntitle = {AttnGAN: Fine-Grained Text to Image Generation With Attentional Generative Adversarial Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Adversarial_Complementary_Learning_CVPR_2018_paper.html\">Adversarial Complementary Learning for Weakly Supervised Object Localization</a></dt>\n<dd>\n<form id=\"form-XiaolinZhangAdversarialComplementaryLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaolin Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaolinZhangAdversarialComplementaryLearning').submit();\">Xiaolin Zhang</a>,\n</form>\n<form id=\"form-YunchaoWeiAdversarialComplementaryLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yunchao Wei\">\n<a href=\"#\" onclick=\"document.getElementById('form-YunchaoWeiAdversarialComplementaryLearning').submit();\">Yunchao Wei</a>,\n</form>\n<form id=\"form-JiashiFengAdversarialComplementaryLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiashi Feng\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiashiFengAdversarialComplementaryLearning').submit();\">Jiashi Feng</a>,\n</form>\n<form id=\"form-YiYangAdversarialComplementaryLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiYangAdversarialComplementaryLearning').submit();\">Yi Yang</a>,\n</form>\n<form id=\"form-ThomasS.AdversarialComplementaryLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Thomas S. Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ThomasS.AdversarialComplementaryLearning').submit();\">Thomas S. Huang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Adversarial_Complementary_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.06962\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Xiaolin and Wei, Yunchao and Feng, Jiashi and Yang, Yi and Huang, Thomas S.},<br>\ntitle = {Adversarial Complementary Learning for Weakly Supervised Object Localization},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hong_Conditional_Generative_Adversarial_CVPR_2018_paper.html\">Conditional Generative Adversarial Network for Structured Domain Adaptation</a></dt>\n<dd>\n<form id=\"form-WeixiangHongConditionalGenerativeAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weixiang Hong\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeixiangHongConditionalGenerativeAdversarial').submit();\">Weixiang Hong</a>,\n</form>\n<form id=\"form-ZhenzhenWangConditionalGenerativeAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhenzhen Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhenzhenWangConditionalGenerativeAdversarial').submit();\">Zhenzhen Wang</a>,\n</form>\n<form id=\"form-MingYangConditionalGenerativeAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingYangConditionalGenerativeAdversarial').submit();\">Ming Yang</a>,\n</form>\n<form id=\"form-JunsongYuanConditionalGenerativeAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junsong Yuan\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunsongYuanConditionalGenerativeAdversarial').submit();\">Junsong Yuan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hong_Conditional_Generative_Adversarial_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hong_2018_CVPR,<br>\nauthor = {Hong, Weixiang and Wang, Zhenzhen and Yang, Ming and Yuan, Junsong},<br>\ntitle = {Conditional Generative Adversarial Network for Structured Domain Adaptation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_GroupCap_Group-Based_Image_CVPR_2018_paper.html\">GroupCap: Group-Based Image Captioning With Structured Relevance and Diversity Constraints</a></dt>\n<dd>\n<form id=\"form-FuhaiChenGroupCapGroupBasedImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fuhai Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-FuhaiChenGroupCapGroupBasedImage').submit();\">Fuhai Chen</a>,\n</form>\n<form id=\"form-RongrongJiGroupCapGroupBasedImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rongrong Ji\">\n<a href=\"#\" onclick=\"document.getElementById('form-RongrongJiGroupCapGroupBasedImage').submit();\">Rongrong Ji</a>,\n</form>\n<form id=\"form-XiaoshuaiSunGroupCapGroupBasedImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaoshuai Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaoshuaiSunGroupCapGroupBasedImage').submit();\">Xiaoshuai Sun</a>,\n</form>\n<form id=\"form-YongjianWuGroupCapGroupBasedImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yongjian Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YongjianWuGroupCapGroupBasedImage').submit();\">Yongjian Wu</a>,\n</form>\n<form id=\"form-JinsongSuGroupCapGroupBasedImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jinsong Su\">\n<a href=\"#\" onclick=\"document.getElementById('form-JinsongSuGroupCapGroupBasedImage').submit();\">Jinsong Su</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_GroupCap_Group-Based_Image_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Fuhai and Ji, Rongrong and Sun, Xiaoshuai and Wu, Yongjian and Su, Jinsong},<br>\ntitle = {GroupCap: Group-Based Image Captioning With Structured Relevance and Diversity Constraints},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Weakly-Supervised_Semantic_Segmentation_CVPR_2018_paper.html\">Weakly-Supervised Semantic Segmentation by Iteratively Mining Common Object Features</a></dt>\n<dd>\n<form id=\"form-XiangWangWeaklySupervisedSemanticSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiangWangWeaklySupervisedSemanticSegmentation').submit();\">Xiang Wang</a>,\n</form>\n<form id=\"form-ShaodiYouWeaklySupervisedSemanticSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shaodi You\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShaodiYouWeaklySupervisedSemanticSegmentation').submit();\">Shaodi You</a>,\n</form>\n<form id=\"form-XiLiWeaklySupervisedSemanticSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xi Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiLiWeaklySupervisedSemanticSegmentation').submit();\">Xi Li</a>,\n</form>\n<form id=\"form-HuiminMaWeaklySupervisedSemanticSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huimin Ma\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuiminMaWeaklySupervisedSemanticSegmentation').submit();\">Huimin Ma</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Weakly-Supervised_Semantic_Segmentation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1806.04659\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Xiang and You, Shaodi and Li, Xi and Ma, Huimin},<br>\ntitle = {Weakly-Supervised Semantic Segmentation by Iteratively Mining Common Object Features},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Shen_Bootstrapping_the_Performance_CVPR_2018_paper.html\">Bootstrapping the Performance of Webly Supervised Semantic Segmentation</a></dt>\n<dd>\n<form id=\"form-TongShenBootstrappingthePerformance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tong Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-TongShenBootstrappingthePerformance').submit();\">Tong Shen</a>,\n</form>\n<form id=\"form-GuoshengLinBootstrappingthePerformance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guosheng Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuoshengLinBootstrappingthePerformance').submit();\">Guosheng Lin</a>,\n</form>\n<form id=\"form-ChunhuaShenBootstrappingthePerformance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chunhua Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChunhuaShenBootstrappingthePerformance').submit();\">Chunhua Shen</a>,\n</form>\n<form id=\"form-IanReidBootstrappingthePerformance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ian Reid\">\n<a href=\"#\" onclick=\"document.getElementById('form-IanReidBootstrappingthePerformance').submit();\">Ian Reid</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Shen_Bootstrapping_the_Performance_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Shen_2018_CVPR,<br>\nauthor = {Shen, Tong and Lin, Guosheng and Shen, Chunhua and Reid, Ian},<br>\ntitle = {Bootstrapping the Performance of Webly Supervised Semantic Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_DeepVoting_A_Robust_CVPR_2018_paper.html\">DeepVoting: A Robust and Explainable Deep Network for Semantic Part Detection Under Partial Occlusion</a></dt>\n<dd>\n<form id=\"form-ZhishuaiZhangDeepVotingARobust\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhishuai Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhishuaiZhangDeepVotingARobust').submit();\">Zhishuai Zhang</a>,\n</form>\n<form id=\"form-CihangXieDeepVotingARobust\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cihang Xie\">\n<a href=\"#\" onclick=\"document.getElementById('form-CihangXieDeepVotingARobust').submit();\">Cihang Xie</a>,\n</form>\n<form id=\"form-JianyuWangDeepVotingARobust\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianyu Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianyuWangDeepVotingARobust').submit();\">Jianyu Wang</a>,\n</form>\n<form id=\"form-LingxiXieDeepVotingARobust\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lingxi Xie\">\n<a href=\"#\" onclick=\"document.getElementById('form-LingxiXieDeepVotingARobust').submit();\">Lingxi Xie</a>,\n</form>\n<form id=\"form-AlanL.DeepVotingARobust\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alan L. Yuille\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlanL.DeepVotingARobust').submit();\">Alan L. Yuille</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_DeepVoting_A_Robust_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1564-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1709.04577\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Zhishuai and Xie, Cihang and Wang, Jianyu and Xie, Lingxi and Yuille, Alan L.},<br>\ntitle = {DeepVoting: A Robust and Explainable Deep Network for Semantic Part Detection Under Partial Occlusion},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Geometry-Aware_Scene_Text_CVPR_2018_paper.html\">Geometry-Aware Scene Text Detection With Instance Transformation Network</a></dt>\n<dd>\n<form id=\"form-FangfangWangGeometryAwareSceneText\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fangfang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-FangfangWangGeometryAwareSceneText').submit();\">Fangfang Wang</a>,\n</form>\n<form id=\"form-LimingZhaoGeometryAwareSceneText\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liming Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-LimingZhaoGeometryAwareSceneText').submit();\">Liming Zhao</a>,\n</form>\n<form id=\"form-XiLiGeometryAwareSceneText\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xi Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiLiGeometryAwareSceneText').submit();\">Xi Li</a>,\n</form>\n<form id=\"form-XinchaoWangGeometryAwareSceneText\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xinchao Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinchaoWangGeometryAwareSceneText').submit();\">Xinchao Wang</a>,\n</form>\n<form id=\"form-DachengTaoGeometryAwareSceneText\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dacheng Tao\">\n<a href=\"#\" onclick=\"document.getElementById('form-DachengTaoGeometryAwareSceneText').submit();\">Dacheng Tao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Geometry-Aware_Scene_Text_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Fangfang and Zhao, Liming and Li, Xi and Wang, Xinchao and Tao, Dacheng},<br>\ntitle = {Geometry-Aware Scene Text Detection With Instance Transformation Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sun_Optical_Flow_Guided_CVPR_2018_paper.html\">Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition</a></dt>\n<dd>\n<form id=\"form-ShuyangSunOpticalFlowGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuyang Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuyangSunOpticalFlowGuided').submit();\">Shuyang Sun</a>,\n</form>\n<form id=\"form-ZhanghuiKuangOpticalFlowGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhanghui Kuang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhanghuiKuangOpticalFlowGuided').submit();\">Zhanghui Kuang</a>,\n</form>\n<form id=\"form-LuShengOpticalFlowGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lu Sheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-LuShengOpticalFlowGuided').submit();\">Lu Sheng</a>,\n</form>\n<form id=\"form-WanliOuyangOpticalFlowGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wanli Ouyang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WanliOuyangOpticalFlowGuided').submit();\">Wanli Ouyang</a>,\n</form>\n<form id=\"form-WeiZhangOpticalFlowGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiZhangOpticalFlowGuided').submit();\">Wei Zhang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sun_Optical_Flow_Guided_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.11152\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sun_2018_CVPR,<br>\nauthor = {Sun, Shuyang and Kuang, Zhanghui and Sheng, Lu and Ouyang, Wanli and Zhang, Wei},<br>\ntitle = {Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hu_Motion-Guided_Cascaded_Refinement_CVPR_2018_paper.html\">Motion-Guided Cascaded Refinement Network for Video Object Segmentation</a></dt>\n<dd>\n<form id=\"form-PingHuMotionGuidedCascadedRefinement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ping Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-PingHuMotionGuidedCascadedRefinement').submit();\">Ping Hu</a>,\n</form>\n<form id=\"form-GangWangMotionGuidedCascadedRefinement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-GangWangMotionGuidedCascadedRefinement').submit();\">Gang Wang</a>,\n</form>\n<form id=\"form-XiangfeiKongMotionGuidedCascadedRefinement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiangfei Kong\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiangfeiKongMotionGuidedCascadedRefinement').submit();\">Xiangfei Kong</a>,\n</form>\n<form id=\"form-JasonKuenMotionGuidedCascadedRefinement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jason Kuen\">\n<a href=\"#\" onclick=\"document.getElementById('form-JasonKuenMotionGuidedCascadedRefinement').submit();\">Jason Kuen</a>,\n</form>\n<form id=\"form-Yap-PengTanMotionGuidedCascadedRefinement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yap-Peng Tan\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yap-PengTanMotionGuidedCascadedRefinement').submit();\">Yap-Peng Tan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hu_Motion-Guided_Cascaded_Refinement_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hu_2018_CVPR,<br>\nauthor = {Hu, Ping and Wang, Gang and Kong, Xiangfei and Kuen, Jason and Tan, Yap-Peng},<br>\ntitle = {Motion-Guided Cascaded Refinement Network for Video Object Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lee_A_Memory_Network_CVPR_2018_paper.html\">A Memory Network Approach for Story-Based Temporal Summarization of 360\u00c2\u00b0 Videos</a></dt>\n<dd>\n<form id=\"form-SanghoLeeAMemoryNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sangho Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-SanghoLeeAMemoryNetwork').submit();\">Sangho Lee</a>,\n</form>\n<form id=\"form-JinyoungSungAMemoryNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jinyoung Sung\">\n<a href=\"#\" onclick=\"document.getElementById('form-JinyoungSungAMemoryNetwork').submit();\">Jinyoung Sung</a>,\n</form>\n<form id=\"form-YoungjaeYuAMemoryNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Youngjae Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YoungjaeYuAMemoryNetwork').submit();\">Youngjae Yu</a>,\n</form>\n<form id=\"form-GunheeKimAMemoryNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gunhee Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-GunheeKimAMemoryNetwork').submit();\">Gunhee Kim</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lee_A_Memory_Network_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lee_2018_CVPR,<br>\nauthor = {Lee, Sangho and Sung, Jinyoung and Yu, Youngjae and Kim, Gunhee},<br>\ntitle = {A Memory Network Approach for Story-Based Temporal Summarization of 360\u00c2\u00b0 Videos},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Cheng_Cube_Padding_for_CVPR_2018_paper.html\">Cube Padding for Weakly-Supervised Saliency Prediction in 360\u00c2\u00b0 Videos</a></dt>\n<dd>\n<form id=\"form-Hsien-TzuChengCubePaddingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hsien-Tzu Cheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-Hsien-TzuChengCubePaddingfor').submit();\">Hsien-Tzu Cheng</a>,\n</form>\n<form id=\"form-Chun-HungChaoCubePaddingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chun-Hung Chao\">\n<a href=\"#\" onclick=\"document.getElementById('form-Chun-HungChaoCubePaddingfor').submit();\">Chun-Hung Chao</a>,\n</form>\n<form id=\"form-Jin-DongDongCubePaddingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jin-Dong Dong\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jin-DongDongCubePaddingfor').submit();\">Jin-Dong Dong</a>,\n</form>\n<form id=\"form-Hao-KaiWenCubePaddingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hao-Kai Wen\">\n<a href=\"#\" onclick=\"document.getElementById('form-Hao-KaiWenCubePaddingfor').submit();\">Hao-Kai Wen</a>,\n</form>\n<form id=\"form-Tyng-LuhLiuCubePaddingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tyng-Luh Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Tyng-LuhLiuCubePaddingfor').submit();\">Tyng-Luh Liu</a>,\n</form>\n<form id=\"form-MinSunCubePaddingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Min Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-MinSunCubePaddingfor').submit();\">Min Sun</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Cheng_Cube_Padding_for_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Cheng_2018_CVPR,<br>\nauthor = {Cheng, Hsien-Tzu and Chao, Chun-Hung and Dong, Jin-Dong and Wen, Hao-Kai and Liu, Tyng-Luh and Sun, Min},<br>\ntitle = {Cube Padding for Weakly-Supervised Saliency Prediction in 360\u00c2\u00b0 Videos},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Appearance-and-Relation_Networks_for_CVPR_2018_paper.html\">Appearance-and-Relation Networks for Video Classification</a></dt>\n<dd>\n<form id=\"form-LiminWangAppearanceandRelationNetworksfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Limin Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiminWangAppearanceandRelationNetworksfor').submit();\">Limin Wang</a>,\n</form>\n<form id=\"form-WeiLiAppearanceandRelationNetworksfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiLiAppearanceandRelationNetworksfor').submit();\">Wei Li</a>,\n</form>\n<form id=\"form-WenLiAppearanceandRelationNetworksfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wen Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenLiAppearanceandRelationNetworksfor').submit();\">Wen Li</a>,\n</form>\n<form id=\"form-LucVanAppearanceandRelationNetworksfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Luc Van Gool\">\n<a href=\"#\" onclick=\"document.getElementById('form-LucVanAppearanceandRelationNetworksfor').submit();\">Luc Van Gool</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Appearance-and-Relation_Networks_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.09125\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Limin and Li, Wei and Li, Wen and Van Gool, Luc},<br>\ntitle = {Appearance-and-Relation Networks for Video Classification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Bargal_Excitation_Backprop_for_CVPR_2018_paper.html\">Excitation Backprop for RNNs</a></dt>\n<dd>\n<form id=\"form-SarahAdelExcitationBackpropfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sarah Adel Bargal\">\n<a href=\"#\" onclick=\"document.getElementById('form-SarahAdelExcitationBackpropfor').submit();\">Sarah Adel Bargal</a>,\n</form>\n<form id=\"form-AndreaZuninoExcitationBackpropfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrea Zunino\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndreaZuninoExcitationBackpropfor').submit();\">Andrea Zunino</a>,\n</form>\n<form id=\"form-DonghyunKimExcitationBackpropfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Donghyun Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-DonghyunKimExcitationBackpropfor').submit();\">Donghyun Kim</a>,\n</form>\n<form id=\"form-JianmingZhangExcitationBackpropfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianming Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianmingZhangExcitationBackpropfor').submit();\">Jianming Zhang</a>,\n</form>\n<form id=\"form-VittorioMurinoExcitationBackpropfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vittorio Murino\">\n<a href=\"#\" onclick=\"document.getElementById('form-VittorioMurinoExcitationBackpropfor').submit();\">Vittorio Murino</a>,\n</form>\n<form id=\"form-StanSclaroffExcitationBackpropfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stan Sclaroff\">\n<a href=\"#\" onclick=\"document.getElementById('form-StanSclaroffExcitationBackpropfor').submit();\">Stan Sclaroff</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Bargal_Excitation_Backprop_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0316-supp.zip\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.06778\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Bargal_2018_CVPR,<br>\nauthor = {Adel Bargal, Sarah and Zunino, Andrea and Kim, Donghyun and Zhang, Jianming and Murino, Vittorio and Sclaroff, Stan},<br>\ntitle = {Excitation Backprop for RNNs},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yang_One-Shot_Action_Localization_CVPR_2018_paper.html\">One-Shot Action Localization by Learning Sequence Matching Network</a></dt>\n<dd>\n<form id=\"form-HongtaoYangOneShotActionLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hongtao Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HongtaoYangOneShotActionLocalization').submit();\">Hongtao Yang</a>,\n</form>\n<form id=\"form-XumingHeOneShotActionLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xuming He\">\n<a href=\"#\" onclick=\"document.getElementById('form-XumingHeOneShotActionLocalization').submit();\">Xuming He</a>,\n</form>\n<form id=\"form-FatihPorikliOneShotActionLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fatih Porikli\">\n<a href=\"#\" onclick=\"document.getElementById('form-FatihPorikliOneShotActionLocalization').submit();\">Fatih Porikli</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yang_One-Shot_Action_Localization_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yang_2018_CVPR,<br>\nauthor = {Yang, Hongtao and He, Xuming and Porikli, Fatih},<br>\ntitle = {One-Shot Action Localization by Learning Sequence Matching Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xu_Structure_Preserving_Video_CVPR_2018_paper.html\">Structure Preserving Video Prediction</a></dt>\n<dd>\n<form id=\"form-JingweiXuStructurePreservingVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jingwei Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingweiXuStructurePreservingVideo').submit();\">Jingwei Xu</a>,\n</form>\n<form id=\"form-BingbingNiStructurePreservingVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bingbing Ni\">\n<a href=\"#\" onclick=\"document.getElementById('form-BingbingNiStructurePreservingVideo').submit();\">Bingbing Ni</a>,\n</form>\n<form id=\"form-ZefanLiStructurePreservingVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zefan Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZefanLiStructurePreservingVideo').submit();\">Zefan Li</a>,\n</form>\n<form id=\"form-ShuoChengStructurePreservingVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuo Cheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuoChengStructurePreservingVideo').submit();\">Shuo Cheng</a>,\n</form>\n<form id=\"form-XiaokangYangStructurePreservingVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaokang Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaokangYangStructurePreservingVideo').submit();\">Xiaokang Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xu_Structure_Preserving_Video_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xu_2018_CVPR,<br>\nauthor = {Xu, Jingwei and Ni, Bingbing and Li, Zefan and Cheng, Shuo and Yang, Xiaokang},<br>\ntitle = {Structure Preserving Video Prediction},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Person_Re-Identification_With_CVPR_2018_paper.html\">Person Re-Identification With Cascaded Pairwise Convolutions</a></dt>\n<dd>\n<form id=\"form-YichengWangPersonReIdentificationWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yicheng Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YichengWangPersonReIdentificationWith').submit();\">Yicheng Wang</a>,\n</form>\n<form id=\"form-ZhenzhongChenPersonReIdentificationWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhenzhong Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhenzhongChenPersonReIdentificationWith').submit();\">Zhenzhong Chen</a>,\n</form>\n<form id=\"form-FengWuPersonReIdentificationWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Feng Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-FengWuPersonReIdentificationWith').submit();\">Feng Wu</a>,\n</form>\n<form id=\"form-GangWangPersonReIdentificationWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-GangWangPersonReIdentificationWith').submit();\">Gang Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Person_Re-Identification_With_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1860-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Yicheng and Chen, Zhenzhong and Wu, Feng and Wang, Gang},<br>\ntitle = {Person Re-Identification With Cascaded Pairwise Convolutions},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zlateski_On_the_Importance_CVPR_2018_paper.html\">On the Importance of Label Quality for Semantic Segmentation</a></dt>\n<dd>\n<form id=\"form-AleksandarZlateskiOntheImportance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Aleksandar Zlateski\">\n<a href=\"#\" onclick=\"document.getElementById('form-AleksandarZlateskiOntheImportance').submit();\">Aleksandar Zlateski</a>,\n</form>\n<form id=\"form-RonnachaiJaroensriOntheImportance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ronnachai Jaroensri\">\n<a href=\"#\" onclick=\"document.getElementById('form-RonnachaiJaroensriOntheImportance').submit();\">Ronnachai Jaroensri</a>,\n</form>\n<form id=\"form-PrafullSharmaOntheImportance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Prafull Sharma\">\n<a href=\"#\" onclick=\"document.getElementById('form-PrafullSharmaOntheImportance').submit();\">Prafull Sharma</a>,\n</form>\n<form id=\"form-Fr\u00c3\u00a9doDurandOntheImportance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fr\u00c3\u00a9do Durand\">\n<a href=\"#\" onclick=\"document.getElementById('form-Fr\u00c3\u00a9doDurandOntheImportance').submit();\">Fr\u00c3\u00a9do Durand</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zlateski_On_the_Importance_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zlateski_2018_CVPR,<br>\nauthor = {Zlateski, Aleksandar and Jaroensri, Ronnachai and Sharma, Prafull and Durand, Fr\u00c3\u00a9do},<br>\ntitle = {On the Importance of Label Quality for Semantic Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chang_Scalable_and_Effective_CVPR_2018_paper.html\">Scalable and Effective Deep CCA via Soft Decorrelation</a></dt>\n<dd>\n<form id=\"form-XiaobinChangScalableandEffective\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaobin Chang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaobinChangScalableandEffective').submit();\">Xiaobin Chang</a>,\n</form>\n<form id=\"form-TaoXiangScalableandEffective\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tao Xiang\">\n<a href=\"#\" onclick=\"document.getElementById('form-TaoXiangScalableandEffective').submit();\">Tao Xiang</a>,\n</form>\n<form id=\"form-TimothyM.ScalableandEffective\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Timothy M. Hospedales\">\n<a href=\"#\" onclick=\"document.getElementById('form-TimothyM.ScalableandEffective').submit();\">Timothy M. Hospedales</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chang_Scalable_and_Effective_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1707.09669\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chang_2018_CVPR,<br>\nauthor = {Chang, Xiaobin and Xiang, Tao and Hospedales, Timothy M.},<br>\ntitle = {Scalable and Effective Deep CCA via Soft Decorrelation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hu_Duplex_Generative_Adversarial_CVPR_2018_paper.html\">Duplex Generative Adversarial Network for Unsupervised Domain Adaptation</a></dt>\n<dd>\n<form id=\"form-LanqingHuDuplexGenerativeAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lanqing Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-LanqingHuDuplexGenerativeAdversarial').submit();\">Lanqing Hu</a>,\n</form>\n<form id=\"form-MeinaKanDuplexGenerativeAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Meina Kan\">\n<a href=\"#\" onclick=\"document.getElementById('form-MeinaKanDuplexGenerativeAdversarial').submit();\">Meina Kan</a>,\n</form>\n<form id=\"form-ShiguangShanDuplexGenerativeAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shiguang Shan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShiguangShanDuplexGenerativeAdversarial').submit();\">Shiguang Shan</a>,\n</form>\n<form id=\"form-XilinChenDuplexGenerativeAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xilin Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-XilinChenDuplexGenerativeAdversarial').submit();\">Xilin Chen</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hu_Duplex_Generative_Adversarial_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1172-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hu_2018_CVPR,<br>\nauthor = {Hu, Lanqing and Kan, Meina and Shan, Shiguang and Chen, Xilin},<br>\ntitle = {Duplex Generative Adversarial Network for Unsupervised Domain Adaptation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Bai_Edit_Probability_for_CVPR_2018_paper.html\">Edit Probability for Scene Text Recognition</a></dt>\n<dd>\n<form id=\"form-FanBaiEditProbabilityfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fan Bai\">\n<a href=\"#\" onclick=\"document.getElementById('form-FanBaiEditProbabilityfor').submit();\">Fan Bai</a>,\n</form>\n<form id=\"form-ZhanzhanChengEditProbabilityfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhanzhan Cheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhanzhanChengEditProbabilityfor').submit();\">Zhanzhan Cheng</a>,\n</form>\n<form id=\"form-YiNiuEditProbabilityfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi Niu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiNiuEditProbabilityfor').submit();\">Yi Niu</a>,\n</form>\n<form id=\"form-ShiliangPuEditProbabilityfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shiliang Pu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShiliangPuEditProbabilityfor').submit();\">Shiliang Pu</a>,\n</form>\n<form id=\"form-ShuigengZhouEditProbabilityfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuigeng Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuigengZhouEditProbabilityfor').submit();\">Shuigeng Zhou</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Bai_Edit_Probability_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.03384\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Bai_2018_CVPR,<br>\nauthor = {Bai, Fan and Cheng, Zhanzhan and Niu, Yi and Pu, Shiliang and Zhou, Shuigeng},<br>\ntitle = {Edit Probability for Scene Text Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Qi_Global_Versus_Localized_CVPR_2018_paper.html\">Global Versus Localized Generative Adversarial Nets</a></dt>\n<dd>\n<form id=\"form-Guo-JunQiGlobalVersusLocalized\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guo-Jun Qi\">\n<a href=\"#\" onclick=\"document.getElementById('form-Guo-JunQiGlobalVersusLocalized').submit();\">Guo-Jun Qi</a>,\n</form>\n<form id=\"form-LihengZhangGlobalVersusLocalized\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liheng Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LihengZhangGlobalVersusLocalized').submit();\">Liheng Zhang</a>,\n</form>\n<form id=\"form-HaoHuGlobalVersusLocalized\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hao Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaoHuGlobalVersusLocalized').submit();\">Hao Hu</a>,\n</form>\n<form id=\"form-MarziehEdrakiGlobalVersusLocalized\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Marzieh Edraki\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarziehEdrakiGlobalVersusLocalized').submit();\">Marzieh Edraki</a>,\n</form>\n<form id=\"form-JingdongWangGlobalVersusLocalized\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jingdong Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingdongWangGlobalVersusLocalized').submit();\">Jingdong Wang</a>,\n</form>\n<form id=\"form-Xian-ShengHuaGlobalVersusLocalized\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xian-Sheng Hua\">\n<a href=\"#\" onclick=\"document.getElementById('form-Xian-ShengHuaGlobalVersusLocalized').submit();\">Xian-Sheng Hua</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Qi_Global_Versus_Localized_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1552-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.06020\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Qi_2018_CVPR,<br>\nauthor = {Qi, Guo-Jun and Zhang, Liheng and Hu, Hao and Edraki, Marzieh and Wang, Jingdong and Hua, Xian-Sheng},<br>\ntitle = {Global Versus Localized Generative Adversarial Nets},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tulyakov_MoCoGAN_Decomposing_Motion_CVPR_2018_paper.html\">MoCoGAN: Decomposing Motion and Content for Video Generation</a></dt>\n<dd>\n<form id=\"form-SergeyTulyakovMoCoGANDecomposingMotion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sergey Tulyakov\">\n<a href=\"#\" onclick=\"document.getElementById('form-SergeyTulyakovMoCoGANDecomposingMotion').submit();\">Sergey Tulyakov</a>,\n</form>\n<form id=\"form-Ming-YuLiuMoCoGANDecomposingMotion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming-Yu Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ming-YuLiuMoCoGANDecomposingMotion').submit();\">Ming-Yu Liu</a>,\n</form>\n<form id=\"form-XiaodongYangMoCoGANDecomposingMotion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaodong Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaodongYangMoCoGANDecomposingMotion').submit();\">Xiaodong Yang</a>,\n</form>\n<form id=\"form-JanKautzMoCoGANDecomposingMotion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jan Kautz\">\n<a href=\"#\" onclick=\"document.getElementById('form-JanKautzMoCoGANDecomposingMotion').submit();\">Jan Kautz</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tulyakov_MoCoGAN_Decomposing_Motion_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1707.04993\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tulyakov_2018_CVPR,<br>\nauthor = {Tulyakov, Sergey and Liu, Ming-Yu and Yang, Xiaodong and Kautz, Jan},<br>\ntitle = {MoCoGAN: Decomposing Motion and Content for Video Generation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Pan_Recurrent_Residual_Module_CVPR_2018_paper.html\">Recurrent Residual Module for Fast Inference in Videos</a></dt>\n<dd>\n<form id=\"form-BowenPanRecurrentResidualModule\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bowen Pan\">\n<a href=\"#\" onclick=\"document.getElementById('form-BowenPanRecurrentResidualModule').submit();\">Bowen Pan</a>,\n</form>\n<form id=\"form-WuweiLinRecurrentResidualModule\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wuwei Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-WuweiLinRecurrentResidualModule').submit();\">Wuwei Lin</a>,\n</form>\n<form id=\"form-XiaolinFangRecurrentResidualModule\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaolin Fang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaolinFangRecurrentResidualModule').submit();\">Xiaolin Fang</a>,\n</form>\n<form id=\"form-ChaoqinHuangRecurrentResidualModule\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chaoqin Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChaoqinHuangRecurrentResidualModule').submit();\">Chaoqin Huang</a>,\n</form>\n<form id=\"form-BoleiZhouRecurrentResidualModule\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bolei Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoleiZhouRecurrentResidualModule').submit();\">Bolei Zhou</a>,\n</form>\n<form id=\"form-CewuLuRecurrentResidualModule\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cewu Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-CewuLuRecurrentResidualModule').submit();\">Cewu Lu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Pan_Recurrent_Residual_Module_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.09723\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Pan_2018_CVPR,<br>\nauthor = {Pan, Bowen and Lin, Wuwei and Fang, Xiaolin and Huang, Chaoqin and Zhou, Bolei and Lu, Cewu},<br>\ntitle = {Recurrent Residual Module for Fast Inference in Videos},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Honari_Improving_Landmark_Localization_CVPR_2018_paper.html\">Improving Landmark Localization With Semi-Supervised Learning</a></dt>\n<dd>\n<form id=\"form-SinaHonariImprovingLandmarkLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sina Honari\">\n<a href=\"#\" onclick=\"document.getElementById('form-SinaHonariImprovingLandmarkLocalization').submit();\">Sina Honari</a>,\n</form>\n<form id=\"form-PavloMolchanovImprovingLandmarkLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pavlo Molchanov\">\n<a href=\"#\" onclick=\"document.getElementById('form-PavloMolchanovImprovingLandmarkLocalization').submit();\">Pavlo Molchanov</a>,\n</form>\n<form id=\"form-StephenTyreeImprovingLandmarkLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stephen Tyree\">\n<a href=\"#\" onclick=\"document.getElementById('form-StephenTyreeImprovingLandmarkLocalization').submit();\">Stephen Tyree</a>,\n</form>\n<form id=\"form-PascalVincentImprovingLandmarkLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pascal Vincent\">\n<a href=\"#\" onclick=\"document.getElementById('form-PascalVincentImprovingLandmarkLocalization').submit();\">Pascal Vincent</a>,\n</form>\n<form id=\"form-ChristopherPalImprovingLandmarkLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Christopher Pal\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChristopherPalImprovingLandmarkLocalization').submit();\">Christopher Pal</a>,\n</form>\n<form id=\"form-JanKautzImprovingLandmarkLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jan Kautz\">\n<a href=\"#\" onclick=\"document.getElementById('form-JanKautzImprovingLandmarkLocalization').submit();\">Jan Kautz</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Honari_Improving_Landmark_Localization_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2285-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1709.01591\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Honari_2018_CVPR,<br>\nauthor = {Honari, Sina and Molchanov, Pavlo and Tyree, Stephen and Vincent, Pascal and Pal, Christopher and Kautz, Jan},<br>\ntitle = {Improving Landmark Localization With Semi-Supervised Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Pal_Adversarial_Data_Programming_CVPR_2018_paper.html\">Adversarial Data Programming: Using GANs to Relax the Bottleneck of Curated Labeled Data</a></dt>\n<dd>\n<form id=\"form-ArghyaPalAdversarialDataProgramming\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Arghya Pal\">\n<a href=\"#\" onclick=\"document.getElementById('form-ArghyaPalAdversarialDataProgramming').submit();\">Arghya Pal</a>,\n</form>\n<form id=\"form-VineethN.AdversarialDataProgramming\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vineeth N. Balasubramanian\">\n<a href=\"#\" onclick=\"document.getElementById('form-VineethN.AdversarialDataProgramming').submit();\">Vineeth N. Balasubramanian</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Pal_Adversarial_Data_Programming_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2313-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.05137\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Pal_2018_CVPR,<br>\nauthor = {Pal, Arghya and Balasubramanian, Vineeth N.},<br>\ntitle = {Adversarial Data Programming: Using GANs to Relax the Bottleneck of Curated Labeled Data},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Plotz_Stochastic_Variational_Inference_CVPR_2018_paper.html\">Stochastic Variational Inference With Gradient Linearization</a></dt>\n<dd>\n<form id=\"form-TobiasPl\u00c3\u00b6tzStochasticVariationalInference\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tobias Pl\u00c3\u00b6tz\">\n<a href=\"#\" onclick=\"document.getElementById('form-TobiasPl\u00c3\u00b6tzStochasticVariationalInference').submit();\">Tobias Pl\u00c3\u00b6tz</a>,\n</form>\n<form id=\"form-AnneS.StochasticVariationalInference\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anne S. Wannenwetsch\">\n<a href=\"#\" onclick=\"document.getElementById('form-AnneS.StochasticVariationalInference').submit();\">Anne S. Wannenwetsch</a>,\n</form>\n<form id=\"form-StefanRothStochasticVariationalInference\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stefan Roth\">\n<a href=\"#\" onclick=\"document.getElementById('form-StefanRothStochasticVariationalInference').submit();\">Stefan Roth</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Plotz_Stochastic_Variational_Inference_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2434-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.10586\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Pl\u00c3\u00b6tz_2018_CVPR,<br>\nauthor = {Pl\u00c3\u00b6tz, Tobias and Wannenwetsch, Anne S. and Roth, Stefan},<br>\ntitle = {Stochastic Variational Inference With Gradient Linearization},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lee_Multi-Label_Zero-Shot_Learning_CVPR_2018_paper.html\">Multi-Label Zero-Shot Learning With Structured Knowledge Graphs</a></dt>\n<dd>\n<form id=\"form-Chung-WeiLeeMultiLabelZeroShotLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chung-Wei Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-Chung-WeiLeeMultiLabelZeroShotLearning').submit();\">Chung-Wei Lee</a>,\n</form>\n<form id=\"form-WeiFangMultiLabelZeroShotLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Fang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiFangMultiLabelZeroShotLearning').submit();\">Wei Fang</a>,\n</form>\n<form id=\"form-Chih-KuanYehMultiLabelZeroShotLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chih-Kuan Yeh\">\n<a href=\"#\" onclick=\"document.getElementById('form-Chih-KuanYehMultiLabelZeroShotLearning').submit();\">Chih-Kuan Yeh</a>,\n</form>\n<form id=\"form-Yu-ChiangFrankMultiLabelZeroShotLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu-Chiang Frank Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yu-ChiangFrankMultiLabelZeroShotLearning').submit();\">Yu-Chiang Frank Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lee_Multi-Label_Zero-Shot_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.06526\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lee_2018_CVPR,<br>\nauthor = {Lee, Chung-Wei and Fang, Wei and Yeh, Chih-Kuan and Frank Wang, Yu-Chiang},<br>\ntitle = {Multi-Label Zero-Shot Learning With Structured Knowledge Graphs},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Gordon_MorphNet_Fast__CVPR_2018_paper.html\">MorphNet: Fast & Simple Resource-Constrained Structure Learning of Deep Networks</a></dt>\n<dd>\n<form id=\"form-ArielGordonMorphNetFast\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ariel Gordon\">\n<a href=\"#\" onclick=\"document.getElementById('form-ArielGordonMorphNetFast').submit();\">Ariel Gordon</a>,\n</form>\n<form id=\"form-EladEbanMorphNetFast\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Elad Eban\">\n<a href=\"#\" onclick=\"document.getElementById('form-EladEbanMorphNetFast').submit();\">Elad Eban</a>,\n</form>\n<form id=\"form-OfirNachumMorphNetFast\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ofir Nachum\">\n<a href=\"#\" onclick=\"document.getElementById('form-OfirNachumMorphNetFast').submit();\">Ofir Nachum</a>,\n</form>\n<form id=\"form-BoChenMorphNetFast\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bo Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoChenMorphNetFast').submit();\">Bo Chen</a>,\n</form>\n<form id=\"form-HaoWuMorphNetFast\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hao Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaoWuMorphNetFast').submit();\">Hao Wu</a>,\n</form>\n<form id=\"form-Tien-JuYangMorphNetFast\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tien-Ju Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Tien-JuYangMorphNetFast').submit();\">Tien-Ju Yang</a>,\n</form>\n<form id=\"form-EdwardChoiMorphNetFast\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Edward Choi\">\n<a href=\"#\" onclick=\"document.getElementById('form-EdwardChoiMorphNetFast').submit();\">Edward Choi</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Gordon_MorphNet_Fast__CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2508-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.06798\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Gordon_2018_CVPR,<br>\nauthor = {Gordon, Ariel and Eban, Elad and Nachum, Ofir and Chen, Bo and Wu, Hao and Yang, Tien-Ju and Choi, Edward},<br>\ntitle = {MorphNet: Fast & Simple Resource-Constrained Structure Learning of Deep Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhou_Deep_Adversarial_Subspace_CVPR_2018_paper.html\">Deep Adversarial Subspace Clustering</a></dt>\n<dd>\n<form id=\"form-PanZhouDeepAdversarialSubspace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pan Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-PanZhouDeepAdversarialSubspace').submit();\">Pan Zhou</a>,\n</form>\n<form id=\"form-YunqingHouDeepAdversarialSubspace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yunqing Hou\">\n<a href=\"#\" onclick=\"document.getElementById('form-YunqingHouDeepAdversarialSubspace').submit();\">Yunqing Hou</a>,\n</form>\n<form id=\"form-JiashiFengDeepAdversarialSubspace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiashi Feng\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiashiFengDeepAdversarialSubspace').submit();\">Jiashi Feng</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhou_Deep_Adversarial_Subspace_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhou_2018_CVPR,<br>\nauthor = {Zhou, Pan and Hou, Yunqing and Feng, Jiashi},<br>\ntitle = {Deep Adversarial Subspace Clustering},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Towards_Human-Machine_Cooperation_CVPR_2018_paper.html\">Towards Human-Machine Cooperation: Self-Supervised Sample Mining for Object Detection</a></dt>\n<dd>\n<form id=\"form-KezeWangTowardsHumanMachineCooperation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Keze Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-KezeWangTowardsHumanMachineCooperation').submit();\">Keze Wang</a>,\n</form>\n<form id=\"form-XiaopengYanTowardsHumanMachineCooperation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaopeng Yan\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaopengYanTowardsHumanMachineCooperation').submit();\">Xiaopeng Yan</a>,\n</form>\n<form id=\"form-DongyuZhangTowardsHumanMachineCooperation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dongyu Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-DongyuZhangTowardsHumanMachineCooperation').submit();\">Dongyu Zhang</a>,\n</form>\n<form id=\"form-LeiZhangTowardsHumanMachineCooperation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lei Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeiZhangTowardsHumanMachineCooperation').submit();\">Lei Zhang</a>,\n</form>\n<form id=\"form-LiangLinTowardsHumanMachineCooperation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liang Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiangLinTowardsHumanMachineCooperation').submit();\">Liang Lin</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Towards_Human-Machine_Cooperation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.09867\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Keze and Yan, Xiaopeng and Zhang, Dongyu and Zhang, Lei and Lin, Liang},<br>\ntitle = {Towards Human-Machine Cooperation: Self-Supervised Sample Mining for Object Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Laude_Discrete-Continuous_ADMM_for_CVPR_2018_paper.html\">Discrete-Continuous ADMM for Transductive Inference in Higher-Order MRFs</a></dt>\n<dd>\n<form id=\"form-EmanuelLaudeDiscreteContinuousADMMfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Emanuel Laude\">\n<a href=\"#\" onclick=\"document.getElementById('form-EmanuelLaudeDiscreteContinuousADMMfor').submit();\">Emanuel Laude</a>,\n</form>\n<form id=\"form-Jan-HendrikLangeDiscreteContinuousADMMfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jan-Hendrik Lange\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jan-HendrikLangeDiscreteContinuousADMMfor').submit();\">Jan-Hendrik Lange</a>,\n</form>\n<form id=\"form-JonasSch\u00c3\u00bcpferDiscreteContinuousADMMfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jonas Sch\u00c3\u00bcpfer\">\n<a href=\"#\" onclick=\"document.getElementById('form-JonasSch\u00c3\u00bcpferDiscreteContinuousADMMfor').submit();\">Jonas Sch\u00c3\u00bcpfer</a>,\n</form>\n<form id=\"form-CsabaDomokosDiscreteContinuousADMMfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Csaba Domokos\">\n<a href=\"#\" onclick=\"document.getElementById('form-CsabaDomokosDiscreteContinuousADMMfor').submit();\">Csaba Domokos</a>,\n</form>\n<form id=\"form-LauraLeal-Taix\u00c3\u00a9DiscreteContinuousADMMfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Laura Leal-Taix\u00c3\u00a9\">\n<a href=\"#\" onclick=\"document.getElementById('form-LauraLeal-Taix\u00c3\u00a9DiscreteContinuousADMMfor').submit();\">Laura Leal-Taix\u00c3\u00a9</a>,\n</form>\n<form id=\"form-FrankR.DiscreteContinuousADMMfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Frank R. Schmidt\">\n<a href=\"#\" onclick=\"document.getElementById('form-FrankR.DiscreteContinuousADMMfor').submit();\">Frank R. Schmidt</a>,\n</form>\n<form id=\"form-BjoernAndresDiscreteContinuousADMMfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bjoern Andres\">\n<a href=\"#\" onclick=\"document.getElementById('form-BjoernAndresDiscreteContinuousADMMfor').submit();\">Bjoern Andres</a>,\n</form>\n<form id=\"form-DanielCremersDiscreteContinuousADMMfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daniel Cremers\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanielCremersDiscreteContinuousADMMfor').submit();\">Daniel Cremers</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Laude_Discrete-Continuous_ADMM_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3264-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1705.05020\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Laude_2018_CVPR,<br>\nauthor = {Laude, Emanuel and Lange, Jan-Hendrik and Sch\u00c3\u00bcpfer, Jonas and Domokos, Csaba and Leal-Taix\u00c3\u00a9, Laura and Schmidt, Frank R. and Andres, Bjoern and Cremers, Daniel},<br>\ntitle = {Discrete-Continuous ADMM for Transductive Inference in Higher-Order MRFs},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Eykholt_Robust_Physical-World_Attacks_CVPR_2018_paper.html\">Robust Physical-World Attacks on Deep Learning Visual Classification</a></dt>\n<dd>\n<form id=\"form-KevinEykholtRobustPhysicalWorldAttacks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kevin Eykholt\">\n<a href=\"#\" onclick=\"document.getElementById('form-KevinEykholtRobustPhysicalWorldAttacks').submit();\">Kevin Eykholt</a>,\n</form>\n<form id=\"form-IvanEvtimovRobustPhysicalWorldAttacks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ivan Evtimov\">\n<a href=\"#\" onclick=\"document.getElementById('form-IvanEvtimovRobustPhysicalWorldAttacks').submit();\">Ivan Evtimov</a>,\n</form>\n<form id=\"form-EarlenceFernandesRobustPhysicalWorldAttacks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Earlence Fernandes\">\n<a href=\"#\" onclick=\"document.getElementById('form-EarlenceFernandesRobustPhysicalWorldAttacks').submit();\">Earlence Fernandes</a>,\n</form>\n<form id=\"form-BoLiRobustPhysicalWorldAttacks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bo Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoLiRobustPhysicalWorldAttacks').submit();\">Bo Li</a>,\n</form>\n<form id=\"form-AmirRahmatiRobustPhysicalWorldAttacks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Amir Rahmati\">\n<a href=\"#\" onclick=\"document.getElementById('form-AmirRahmatiRobustPhysicalWorldAttacks').submit();\">Amir Rahmati</a>,\n</form>\n<form id=\"form-ChaoweiXiaoRobustPhysicalWorldAttacks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chaowei Xiao\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChaoweiXiaoRobustPhysicalWorldAttacks').submit();\">Chaowei Xiao</a>,\n</form>\n<form id=\"form-AtulPrakashRobustPhysicalWorldAttacks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Atul Prakash\">\n<a href=\"#\" onclick=\"document.getElementById('form-AtulPrakashRobustPhysicalWorldAttacks').submit();\">Atul Prakash</a>,\n</form>\n<form id=\"form-TadayoshiKohnoRobustPhysicalWorldAttacks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tadayoshi Kohno\">\n<a href=\"#\" onclick=\"document.getElementById('form-TadayoshiKohnoRobustPhysicalWorldAttacks').submit();\">Tadayoshi Kohno</a>,\n</form>\n<form id=\"form-DawnSongRobustPhysicalWorldAttacks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dawn Song\">\n<a href=\"#\" onclick=\"document.getElementById('form-DawnSongRobustPhysicalWorldAttacks').submit();\">Dawn Song</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Eykholt_Robust_Physical-World_Attacks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3407-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Eykholt_2018_CVPR,<br>\nauthor = {Eykholt, Kevin and Evtimov, Ivan and Fernandes, Earlence and Li, Bo and Rahmati, Amir and Xiao, Chaowei and Prakash, Atul and Kohno, Tadayoshi and Song, Dawn},<br>\ntitle = {Robust Physical-World Attacks on Deep Learning Visual Classification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Joo_Generating_a_Fusion_CVPR_2018_paper.html\">Generating a Fusion Image: One's Identity and Another's Shape</a></dt>\n<dd>\n<form id=\"form-DongGyuJooGeneratingaFusion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"DongGyu Joo\">\n<a href=\"#\" onclick=\"document.getElementById('form-DongGyuJooGeneratingaFusion').submit();\">DongGyu Joo</a>,\n</form>\n<form id=\"form-DoyeonKimGeneratingaFusion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Doyeon Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-DoyeonKimGeneratingaFusion').submit();\">Doyeon Kim</a>,\n</form>\n<form id=\"form-JunmoKimGeneratingaFusion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junmo Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunmoKimGeneratingaFusion').submit();\">Junmo Kim</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Joo_Generating_a_Fusion_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.07455\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Joo_2018_CVPR,<br>\nauthor = {Joo, DongGyu and Kim, Doyeon and Kim, Junmo},<br>\ntitle = {Generating a Fusion Image: One's Identity and Another's Shape},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zeng_Learning_to_Promote_CVPR_2018_paper.html\">Learning to Promote Saliency Detectors</a></dt>\n<dd>\n<form id=\"form-YuZengLearningtoPromote\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu Zeng\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuZengLearningtoPromote').submit();\">Yu Zeng</a>,\n</form>\n<form id=\"form-HuchuanLuLearningtoPromote\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huchuan Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuchuanLuLearningtoPromote').submit();\">Huchuan Lu</a>,\n</form>\n<form id=\"form-LiheZhangLearningtoPromote\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lihe Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiheZhangLearningtoPromote').submit();\">Lihe Zhang</a>,\n</form>\n<form id=\"form-MengyangFengLearningtoPromote\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mengyang Feng\">\n<a href=\"#\" onclick=\"document.getElementById('form-MengyangFengLearningtoPromote').submit();\">Mengyang Feng</a>,\n</form>\n<form id=\"form-AliBorjiLearningtoPromote\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ali Borji\">\n<a href=\"#\" onclick=\"document.getElementById('form-AliBorjiLearningtoPromote').submit();\">Ali Borji</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zeng_Learning_to_Promote_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1757-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zeng_2018_CVPR,<br>\nauthor = {Zeng, Yu and Lu, Huchuan and Zhang, Lihe and Feng, Mengyang and Borji, Ali},<br>\ntitle = {Learning to Promote Saliency Detectors},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Han_Image_Super-Resolution_via_CVPR_2018_paper.html\">Image Super-Resolution via Dual-State Recurrent Networks</a></dt>\n<dd>\n<form id=\"form-WeiHanImageSuperResolutionvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Han\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiHanImageSuperResolutionvia').submit();\">Wei Han</a>,\n</form>\n<form id=\"form-ShiyuChangImageSuperResolutionvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shiyu Chang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShiyuChangImageSuperResolutionvia').submit();\">Shiyu Chang</a>,\n</form>\n<form id=\"form-DingLiuImageSuperResolutionvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ding Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-DingLiuImageSuperResolutionvia').submit();\">Ding Liu</a>,\n</form>\n<form id=\"form-MoYuImageSuperResolutionvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mo Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-MoYuImageSuperResolutionvia').submit();\">Mo Yu</a>,\n</form>\n<form id=\"form-MichaelWitbrockImageSuperResolutionvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michael Witbrock\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichaelWitbrockImageSuperResolutionvia').submit();\">Michael Witbrock</a>,\n</form>\n<form id=\"form-ThomasS.ImageSuperResolutionvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Thomas S. Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ThomasS.ImageSuperResolutionvia').submit();\">Thomas S. Huang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Han_Image_Super-Resolution_via_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.02704\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Han_2018_CVPR,<br>\nauthor = {Han, Wei and Chang, Shiyu and Liu, Ding and Yu, Mo and Witbrock, Michael and Huang, Thomas S.},<br>\ntitle = {Image Super-Resolution via Dual-State Recurrent Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Haris_Deep_Back-Projection_Networks_CVPR_2018_paper.html\">Deep Back-Projection Networks for Super-Resolution</a></dt>\n<dd>\n<form id=\"form-MuhammadHarisDeepBackProjectionNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Muhammad Haris\">\n<a href=\"#\" onclick=\"document.getElementById('form-MuhammadHarisDeepBackProjectionNetworks').submit();\">Muhammad Haris</a>,\n</form>\n<form id=\"form-GregoryShakhnarovichDeepBackProjectionNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gregory Shakhnarovich\">\n<a href=\"#\" onclick=\"document.getElementById('form-GregoryShakhnarovichDeepBackProjectionNetworks').submit();\">Gregory Shakhnarovich</a>,\n</form>\n<form id=\"form-NorimichiUkitaDeepBackProjectionNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Norimichi Ukita\">\n<a href=\"#\" onclick=\"document.getElementById('form-NorimichiUkitaDeepBackProjectionNetworks').submit();\">Norimichi Ukita</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Haris_Deep_Back-Projection_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3606-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.02735\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Haris_2018_CVPR,<br>\nauthor = {Haris, Muhammad and Shakhnarovich, Gregory and Ukita, Norimichi},<br>\ntitle = {Deep Back-Projection Networks for Super-Resolution},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_Focus_Manipulation_Detection_CVPR_2018_paper.html\">Focus Manipulation Detection via Photometric Histogram Analysis</a></dt>\n<dd>\n<form id=\"form-CanChenFocusManipulationDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Can Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-CanChenFocusManipulationDetection').submit();\">Can Chen</a>,\n</form>\n<form id=\"form-ScottMcCloskeyFocusManipulationDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Scott McCloskey\">\n<a href=\"#\" onclick=\"document.getElementById('form-ScottMcCloskeyFocusManipulationDetection').submit();\">Scott McCloskey</a>,\n</form>\n<form id=\"form-JingyiYuFocusManipulationDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jingyi Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingyiYuFocusManipulationDetection').submit();\">Jingyi Yu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_Focus_Manipulation_Detection_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Can and McCloskey, Scott and Yu, Jingyi},<br>\ntitle = {Focus Manipulation Detection via Photometric Histogram Analysis},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Cahill_Compassionately_Conservative_Balanced_CVPR_2018_paper.html\">Compassionately Conservative Balanced Cuts for Image Segmentation</a></dt>\n<dd>\n<form id=\"form-NathanD.CompassionatelyConservativeBalanced\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nathan D. Cahill\">\n<a href=\"#\" onclick=\"document.getElementById('form-NathanD.CompassionatelyConservativeBalanced').submit();\">Nathan D. Cahill</a>,\n</form>\n<form id=\"form-TylerL.CompassionatelyConservativeBalanced\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tyler L. Hayes\">\n<a href=\"#\" onclick=\"document.getElementById('form-TylerL.CompassionatelyConservativeBalanced').submit();\">Tyler L. Hayes</a>,\n</form>\n<form id=\"form-ReneeT.CompassionatelyConservativeBalanced\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Renee T. Meinhold\">\n<a href=\"#\" onclick=\"document.getElementById('form-ReneeT.CompassionatelyConservativeBalanced').submit();\">Renee T. Meinhold</a>,\n</form>\n<form id=\"form-JohnF.CompassionatelyConservativeBalanced\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"John F. Hamilton\">\n<a href=\"#\" onclick=\"document.getElementById('form-JohnF.CompassionatelyConservativeBalanced').submit();\">John F. Hamilton</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Cahill_Compassionately_Conservative_Balanced_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.09903\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Cahill_2018_CVPR,<br>\nauthor = {Cahill, Nathan D. and Hayes, Tyler L. and Meinhold, Renee T. and Hamilton, John F.},<br>\ntitle = {Compassionately Conservative Balanced Cuts for Image Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Abdelhamed_A_High-Quality_Denoising_CVPR_2018_paper.html\">A High-Quality Denoising Dataset for Smartphone Cameras</a></dt>\n<dd>\n<form id=\"form-AbdelrahmanAbdelhamedAHighQualityDenoising\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Abdelrahman Abdelhamed\">\n<a href=\"#\" onclick=\"document.getElementById('form-AbdelrahmanAbdelhamedAHighQualityDenoising').submit();\">Abdelrahman Abdelhamed</a>,\n</form>\n<form id=\"form-StephenLinAHighQualityDenoising\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stephen Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-StephenLinAHighQualityDenoising').submit();\">Stephen Lin</a>,\n</form>\n<form id=\"form-MichaelS.AHighQualityDenoising\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michael S. Brown\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichaelS.AHighQualityDenoising').submit();\">Michael S. Brown</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Abdelhamed_A_High-Quality_Denoising_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Abdelhamed_2018_CVPR,<br>\nauthor = {Abdelhamed, Abdelrahman and Lin, Stephen and Brown, Michael S.},<br>\ntitle = {A High-Quality Denoising Dataset for Smartphone Cameras},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Niklaus_Context-Aware_Synthesis_for_CVPR_2018_paper.html\">Context-Aware Synthesis for Video Frame Interpolation</a></dt>\n<dd>\n<form id=\"form-SimonNiklausContextAwareSynthesisfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Simon Niklaus\">\n<a href=\"#\" onclick=\"document.getElementById('form-SimonNiklausContextAwareSynthesisfor').submit();\">Simon Niklaus</a>,\n</form>\n<form id=\"form-FengLiuContextAwareSynthesisfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Feng Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-FengLiuContextAwareSynthesisfor').submit();\">Feng Liu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Niklaus_Context-Aware_Synthesis_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.10967\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Niklaus_2018_CVPR,<br>\nauthor = {Niklaus, Simon and Liu, Feng},<br>\ntitle = {Context-Aware Synthesis for Video Frame Interpolation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Salient_Object_Detection_CVPR_2018_paper.html\">Salient Object Detection Driven by Fixation Prediction</a></dt>\n<dd>\n<form id=\"form-WenguanWangSalientObjectDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenguan Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenguanWangSalientObjectDetection').submit();\">Wenguan Wang</a>,\n</form>\n<form id=\"form-JianbingShenSalientObjectDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianbing Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianbingShenSalientObjectDetection').submit();\">Jianbing Shen</a>,\n</form>\n<form id=\"form-XingpingDongSalientObjectDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xingping Dong\">\n<a href=\"#\" onclick=\"document.getElementById('form-XingpingDongSalientObjectDetection').submit();\">Xingping Dong</a>,\n</form>\n<form id=\"form-AliBorjiSalientObjectDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ali Borji\">\n<a href=\"#\" onclick=\"document.getElementById('form-AliBorjiSalientObjectDetection').submit();\">Ali Borji</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Salient_Object_Detection_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Wenguan and Shen, Jianbing and Dong, Xingping and Borji, Ali},<br>\ntitle = {Salient Object Detection Driven by Fixation Prediction},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Jeon_Enhancing_the_Spatial_CVPR_2018_paper.html\">Enhancing the Spatial Resolution of Stereo Images Using a Parallax Prior</a></dt>\n<dd>\n<form id=\"form-DanielS.EnhancingtheSpatial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daniel S. Jeon\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanielS.EnhancingtheSpatial').submit();\">Daniel S. Jeon</a>,\n</form>\n<form id=\"form-Seung-HwanBaekEnhancingtheSpatial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Seung-Hwan Baek\">\n<a href=\"#\" onclick=\"document.getElementById('form-Seung-HwanBaekEnhancingtheSpatial').submit();\">Seung-Hwan Baek</a>,\n</form>\n<form id=\"form-InchangChoiEnhancingtheSpatial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Inchang Choi\">\n<a href=\"#\" onclick=\"document.getElementById('form-InchangChoiEnhancingtheSpatial').submit();\">Inchang Choi</a>,\n</form>\n<form id=\"form-MinH.EnhancingtheSpatial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Min H. Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-MinH.EnhancingtheSpatial').submit();\">Min H. Kim</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Jeon_Enhancing_the_Spatial_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0493-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Jeon_2018_CVPR,<br>\nauthor = {Jeon, Daniel S. and Baek, Seung-Hwan and Choi, Inchang and Kim, Min H.},<br>\ntitle = {Enhancing the Spatial Resolution of Stereo Images Using a Parallax Prior},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sironi_HATS_Histograms_of_CVPR_2018_paper.html\">HATS: Histograms of Averaged Time Surfaces for Robust Event-Based Object Classification</a></dt>\n<dd>\n<form id=\"form-AmosSironiHATSHistogramsof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Amos Sironi\">\n<a href=\"#\" onclick=\"document.getElementById('form-AmosSironiHATSHistogramsof').submit();\">Amos Sironi</a>,\n</form>\n<form id=\"form-ManueleBrambillaHATSHistogramsof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Manuele Brambilla\">\n<a href=\"#\" onclick=\"document.getElementById('form-ManueleBrambillaHATSHistogramsof').submit();\">Manuele Brambilla</a>,\n</form>\n<form id=\"form-NicolasBourdisHATSHistogramsof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nicolas Bourdis\">\n<a href=\"#\" onclick=\"document.getElementById('form-NicolasBourdisHATSHistogramsof').submit();\">Nicolas Bourdis</a>,\n</form>\n<form id=\"form-XavierLagorceHATSHistogramsof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xavier Lagorce\">\n<a href=\"#\" onclick=\"document.getElementById('form-XavierLagorceHATSHistogramsof').submit();\">Xavier Lagorce</a>,\n</form>\n<form id=\"form-RyadBenosmanHATSHistogramsof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ryad Benosman\">\n<a href=\"#\" onclick=\"document.getElementById('form-RyadBenosmanHATSHistogramsof').submit();\">Ryad Benosman</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sironi_HATS_Histograms_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1083-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.07913\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sironi_2018_CVPR,<br>\nauthor = {Sironi, Amos and Brambilla, Manuele and Bourdis, Nicolas and Lagorce, Xavier and Benosman, Ryad},<br>\ntitle = {HATS: Histograms of Averaged Time Surfaces for Robust Event-Based Object Classification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_A_Bi-Directional_Message_CVPR_2018_paper.html\">A Bi-Directional Message Passing Model for Salient Object Detection</a></dt>\n<dd>\n<form id=\"form-LuZhangABiDirectionalMessage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lu Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LuZhangABiDirectionalMessage').submit();\">Lu Zhang</a>,\n</form>\n<form id=\"form-JuDaiABiDirectionalMessage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ju Dai\">\n<a href=\"#\" onclick=\"document.getElementById('form-JuDaiABiDirectionalMessage').submit();\">Ju Dai</a>,\n</form>\n<form id=\"form-HuchuanLuABiDirectionalMessage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huchuan Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuchuanLuABiDirectionalMessage').submit();\">Huchuan Lu</a>,\n</form>\n<form id=\"form-YouHeABiDirectionalMessage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"You He\">\n<a href=\"#\" onclick=\"document.getElementById('form-YouHeABiDirectionalMessage').submit();\">You He</a>,\n</form>\n<form id=\"form-GangWangABiDirectionalMessage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-GangWangABiDirectionalMessage').submit();\">Gang Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_A_Bi-Directional_Message_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Lu and Dai, Ju and Lu, Huchuan and He, You and Wang, Gang},<br>\ntitle = {A Bi-Directional Message Passing Model for Salient Object Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kat_Matching_Pixels_Using_CVPR_2018_paper.html\">Matching Pixels Using Co-Occurrence Statistics</a></dt>\n<dd>\n<form id=\"form-RotalKatMatchingPixelsUsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rotal Kat\">\n<a href=\"#\" onclick=\"document.getElementById('form-RotalKatMatchingPixelsUsing').submit();\">Rotal Kat</a>,\n</form>\n<form id=\"form-RoyJevnisekMatchingPixelsUsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Roy Jevnisek\">\n<a href=\"#\" onclick=\"document.getElementById('form-RoyJevnisekMatchingPixelsUsing').submit();\">Roy Jevnisek</a>,\n</form>\n<form id=\"form-ShaiAvidanMatchingPixelsUsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shai Avidan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShaiAvidanMatchingPixelsUsing').submit();\">Shai Avidan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kat_Matching_Pixels_Using_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kat_2018_CVPR,<br>\nauthor = {Kat, Rotal and Jevnisek, Roy and Avidan, Shai},<br>\ntitle = {Matching Pixels Using Co-Occurrence Statistics},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Song_SeedNet_Automatic_Seed_CVPR_2018_paper.html\">SeedNet: Automatic Seed Generation With Deep Reinforcement Learning for Robust Interactive Segmentation</a></dt>\n<dd>\n<form id=\"form-GwangmoSongSeedNetAutomaticSeed\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gwangmo Song\">\n<a href=\"#\" onclick=\"document.getElementById('form-GwangmoSongSeedNetAutomaticSeed').submit();\">Gwangmo Song</a>,\n</form>\n<form id=\"form-HeesooMyeongSeedNetAutomaticSeed\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Heesoo Myeong\">\n<a href=\"#\" onclick=\"document.getElementById('form-HeesooMyeongSeedNetAutomaticSeed').submit();\">Heesoo Myeong</a>,\n</form>\n<form id=\"form-KyoungMuSeedNetAutomaticSeed\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kyoung Mu Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-KyoungMuSeedNetAutomaticSeed').submit();\">Kyoung Mu Lee</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Song_SeedNet_Automatic_Seed_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2561-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Song_2018_CVPR,<br>\nauthor = {Song, Gwangmo and Myeong, Heesoo and Mu Lee, Kyoung},<br>\ntitle = {SeedNet: Automatic Seed Generation With Deep Reinforcement Learning for Robust Interactive Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Takeda_Jerk-Aware_Video_Acceleration_CVPR_2018_paper.html\">Jerk-Aware Video Acceleration Magnification</a></dt>\n<dd>\n<form id=\"form-ShoichiroTakedaJerkAwareVideoAcceleration\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shoichiro Takeda\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShoichiroTakedaJerkAwareVideoAcceleration').submit();\">Shoichiro Takeda</a>,\n</form>\n<form id=\"form-KazukiOkamiJerkAwareVideoAcceleration\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kazuki Okami\">\n<a href=\"#\" onclick=\"document.getElementById('form-KazukiOkamiJerkAwareVideoAcceleration').submit();\">Kazuki Okami</a>,\n</form>\n<form id=\"form-DanMikamiJerkAwareVideoAcceleration\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dan Mikami\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanMikamiJerkAwareVideoAcceleration').submit();\">Dan Mikami</a>,\n</form>\n<form id=\"form-MegumiIsogaiJerkAwareVideoAcceleration\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Megumi Isogai\">\n<a href=\"#\" onclick=\"document.getElementById('form-MegumiIsogaiJerkAwareVideoAcceleration').submit();\">Megumi Isogai</a>,\n</form>\n<form id=\"form-HideakiKimataJerkAwareVideoAcceleration\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hideaki Kimata\">\n<a href=\"#\" onclick=\"document.getElementById('form-HideakiKimataJerkAwareVideoAcceleration').submit();\">Hideaki Kimata</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Takeda_Jerk-Aware_Video_Acceleration_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2767-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Takeda_2018_CVPR,<br>\nauthor = {Takeda, Shoichiro and Okami, Kazuki and Mikami, Dan and Isogai, Megumi and Kimata, Hideaki},<br>\ntitle = {Jerk-Aware Video Acceleration Magnification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liao_Defense_Against_Adversarial_CVPR_2018_paper.html\">Defense Against Adversarial Attacks Using High-Level Representation Guided Denoiser</a></dt>\n<dd>\n<form id=\"form-FangzhouLiaoDefenseAgainstAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fangzhou Liao\">\n<a href=\"#\" onclick=\"document.getElementById('form-FangzhouLiaoDefenseAgainstAdversarial').submit();\">Fangzhou Liao</a>,\n</form>\n<form id=\"form-MingLiangDefenseAgainstAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming Liang\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingLiangDefenseAgainstAdversarial').submit();\">Ming Liang</a>,\n</form>\n<form id=\"form-YinpengDongDefenseAgainstAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yinpeng Dong\">\n<a href=\"#\" onclick=\"document.getElementById('form-YinpengDongDefenseAgainstAdversarial').submit();\">Yinpeng Dong</a>,\n</form>\n<form id=\"form-TianyuPangDefenseAgainstAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tianyu Pang\">\n<a href=\"#\" onclick=\"document.getElementById('form-TianyuPangDefenseAgainstAdversarial').submit();\">Tianyu Pang</a>,\n</form>\n<form id=\"form-XiaolinHuDefenseAgainstAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaolin Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaolinHuDefenseAgainstAdversarial').submit();\">Xiaolin Hu</a>,\n</form>\n<form id=\"form-JunZhuDefenseAgainstAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jun Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunZhuDefenseAgainstAdversarial').submit();\">Jun Zhu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liao_Defense_Against_Adversarial_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2790-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.02976\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liao_2018_CVPR,<br>\nauthor = {Liao, Fangzhou and Liang, Ming and Dong, Yinpeng and Pang, Tianyu and Hu, Xiaolin and Zhu, Jun},<br>\ntitle = {Defense Against Adversarial Attacks Using High-Level Representation Guided Denoiser},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Stacked_Conditional_Generative_CVPR_2018_paper.html\">Stacked Conditional Generative Adversarial Networks for Jointly Learning Shadow Detection and Shadow Removal</a></dt>\n<dd>\n<form id=\"form-JifengWangStackedConditionalGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jifeng Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JifengWangStackedConditionalGenerative').submit();\">Jifeng Wang</a>,\n</form>\n<form id=\"form-XiangLiStackedConditionalGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiang Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiangLiStackedConditionalGenerative').submit();\">Xiang Li</a>,\n</form>\n<form id=\"form-JianYangStackedConditionalGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jian Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianYangStackedConditionalGenerative').submit();\">Jian Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Stacked_Conditional_Generative_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.02478\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Jifeng and Li, Xiang and Yang, Jian},<br>\ntitle = {Stacked Conditional Generative Adversarial Networks for Jointly Learning Shadow Detection and Shadow Removal},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yang_Image_Correction_via_CVPR_2018_paper.html\">Image Correction via Deep Reciprocating HDR Transformation</a></dt>\n<dd>\n<form id=\"form-XinYangImageCorrectionvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xin Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinYangImageCorrectionvia').submit();\">Xin Yang</a>,\n</form>\n<form id=\"form-KeXuImageCorrectionvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ke Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-KeXuImageCorrectionvia').submit();\">Ke Xu</a>,\n</form>\n<form id=\"form-YibingSongImageCorrectionvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yibing Song\">\n<a href=\"#\" onclick=\"document.getElementById('form-YibingSongImageCorrectionvia').submit();\">Yibing Song</a>,\n</form>\n<form id=\"form-QiangZhangImageCorrectionvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qiang Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiangZhangImageCorrectionvia').submit();\">Qiang Zhang</a>,\n</form>\n<form id=\"form-XiaopengWeiImageCorrectionvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaopeng Wei\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaopengWeiImageCorrectionvia').submit();\">Xiaopeng Wei</a>,\n</form>\n<form id=\"form-RynsonW.H.ImageCorrectionvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rynson W.H. Lau\">\n<a href=\"#\" onclick=\"document.getElementById('form-RynsonW.H.ImageCorrectionvia').submit();\">Rynson W.H. Lau</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yang_Image_Correction_via_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.04371\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yang_2018_CVPR,<br>\nauthor = {Yang, Xin and Xu, Ke and Song, Yibing and Zhang, Qiang and Wei, Xiaopeng and Lau, Rynson W.H.},<br>\ntitle = {Image Correction via Deep Reciprocating HDR Transformation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Prashnani_PieAPP_Perceptual_Image-Error_CVPR_2018_paper.html\">PieAPP: Perceptual Image-Error Assessment Through Pairwise Preference</a></dt>\n<dd>\n<form id=\"form-EktaPrashnaniPieAPPPerceptualImageError\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ekta Prashnani\">\n<a href=\"#\" onclick=\"document.getElementById('form-EktaPrashnaniPieAPPPerceptualImageError').submit();\">Ekta Prashnani</a>,\n</form>\n<form id=\"form-HongCaiPieAPPPerceptualImageError\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hong Cai\">\n<a href=\"#\" onclick=\"document.getElementById('form-HongCaiPieAPPPerceptualImageError').submit();\">Hong Cai</a>,\n</form>\n<form id=\"form-YasaminMostofiPieAPPPerceptualImageError\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yasamin Mostofi\">\n<a href=\"#\" onclick=\"document.getElementById('form-YasaminMostofiPieAPPPerceptualImageError').submit();\">Yasamin Mostofi</a>,\n</form>\n<form id=\"form-PradeepSenPieAPPPerceptualImageError\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pradeep Sen\">\n<a href=\"#\" onclick=\"document.getElementById('form-PradeepSenPieAPPPerceptualImageError').submit();\">Pradeep Sen</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Prashnani_PieAPP_Perceptual_Image-Error_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3483-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1806.02067\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Prashnani_2018_CVPR,<br>\nauthor = {Prashnani, Ekta and Cai, Hong and Mostofi, Yasamin and Sen, Pradeep},<br>\ntitle = {PieAPP: Perceptual Image-Error Assessment Through Pairwise Preference},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tang_Normalized_Cut_Loss_CVPR_2018_paper.html\">Normalized Cut Loss for Weakly-Supervised CNN Segmentation</a></dt>\n<dd>\n<form id=\"form-MengTangNormalizedCutLoss\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Meng Tang\">\n<a href=\"#\" onclick=\"document.getElementById('form-MengTangNormalizedCutLoss').submit();\">Meng Tang</a>,\n</form>\n<form id=\"form-AbdelazizDjelouahNormalizedCutLoss\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Abdelaziz Djelouah\">\n<a href=\"#\" onclick=\"document.getElementById('form-AbdelazizDjelouahNormalizedCutLoss').submit();\">Abdelaziz Djelouah</a>,\n</form>\n<form id=\"form-FedericoPerazziNormalizedCutLoss\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Federico Perazzi\">\n<a href=\"#\" onclick=\"document.getElementById('form-FedericoPerazziNormalizedCutLoss').submit();\">Federico Perazzi</a>,\n</form>\n<form id=\"form-YuriBoykovNormalizedCutLoss\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuri Boykov\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuriBoykovNormalizedCutLoss').submit();\">Yuri Boykov</a>,\n</form>\n<form id=\"form-ChristopherSchroersNormalizedCutLoss\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Christopher Schroers\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChristopherSchroersNormalizedCutLoss').submit();\">Christopher Schroers</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tang_Normalized_Cut_Loss_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.01346\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tang_2018_CVPR,<br>\nauthor = {Tang, Meng and Djelouah, Abdelaziz and Perazzi, Federico and Boykov, Yuri and Schroers, Christopher},<br>\ntitle = {Normalized Cut Loss for Weakly-Supervised CNN Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_ISTA-Net_Interpretable_Optimization-Inspired_CVPR_2018_paper.html\">ISTA-Net: Interpretable Optimization-Inspired Deep Network for Image Compressive Sensing</a></dt>\n<dd>\n<form id=\"form-JianZhangISTANetInterpretableOptimizationInspired\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jian Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianZhangISTANetInterpretableOptimizationInspired').submit();\">Jian Zhang</a>,\n</form>\n<form id=\"form-BernardGhanemISTANetInterpretableOptimizationInspired\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bernard Ghanem\">\n<a href=\"#\" onclick=\"document.getElementById('form-BernardGhanemISTANetInterpretableOptimizationInspired').submit();\">Bernard Ghanem</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_ISTA-Net_Interpretable_Optimization-Inspired_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1706.07929\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Jian and Ghanem, Bernard},<br>\ntitle = {ISTA-Net: Interpretable Optimization-Inspired Deep Network for Image Compressive Sensing},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wu_Fast_End-to-End_Trainable_CVPR_2018_paper.html\">Fast End-to-End Trainable Guided Filter</a></dt>\n<dd>\n<form id=\"form-HuikaiWuFastEndtoEndTrainable\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huikai Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuikaiWuFastEndtoEndTrainable').submit();\">Huikai Wu</a>,\n</form>\n<form id=\"form-ShuaiZhengFastEndtoEndTrainable\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuai Zheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuaiZhengFastEndtoEndTrainable').submit();\">Shuai Zheng</a>,\n</form>\n<form id=\"form-JungeZhangFastEndtoEndTrainable\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junge Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JungeZhangFastEndtoEndTrainable').submit();\">Junge Zhang</a>,\n</form>\n<form id=\"form-KaiqiHuangFastEndtoEndTrainable\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kaiqi Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaiqiHuangFastEndtoEndTrainable').submit();\">Kaiqi Huang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wu_Fast_End-to-End_Trainable_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0542-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.05619\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wu_2018_CVPR,<br>\nauthor = {Wu, Huikai and Zheng, Shuai and Zhang, Junge and Huang, Kaiqi},<br>\ntitle = {Fast End-to-End Trainable Guided Filter},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Gilbert_Disentangling_Structure_and_CVPR_2018_paper.html\">Disentangling Structure and Aesthetics for Style-Aware Image Completion</a></dt>\n<dd>\n<form id=\"form-AndrewGilbertDisentanglingStructureand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrew Gilbert\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndrewGilbertDisentanglingStructureand').submit();\">Andrew Gilbert</a>,\n</form>\n<form id=\"form-JohnCollomosseDisentanglingStructureand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"John Collomosse\">\n<a href=\"#\" onclick=\"document.getElementById('form-JohnCollomosseDisentanglingStructureand').submit();\">John Collomosse</a>,\n</form>\n<form id=\"form-HailinJinDisentanglingStructureand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hailin Jin\">\n<a href=\"#\" onclick=\"document.getElementById('form-HailinJinDisentanglingStructureand').submit();\">Hailin Jin</a>,\n</form>\n<form id=\"form-BrianPriceDisentanglingStructureand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Brian Price\">\n<a href=\"#\" onclick=\"document.getElementById('form-BrianPriceDisentanglingStructureand').submit();\">Brian Price</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Gilbert_Disentangling_Structure_and_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0550-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Gilbert_2018_CVPR,<br>\nauthor = {Gilbert, Andrew and Collomosse, John and Jin, Hailin and Price, Brian},<br>\ntitle = {Disentangling Structure and Aesthetics for Style-Aware Image Completion},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yu_Learning_a_Discriminative_CVPR_2018_paper.html\">Learning a Discriminative Feature Network for Semantic Segmentation</a></dt>\n<dd>\n<form id=\"form-ChangqianYuLearningaDiscriminative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Changqian Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChangqianYuLearningaDiscriminative').submit();\">Changqian Yu</a>,\n</form>\n<form id=\"form-JingboWangLearningaDiscriminative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jingbo Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingboWangLearningaDiscriminative').submit();\">Jingbo Wang</a>,\n</form>\n<form id=\"form-ChaoPengLearningaDiscriminative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chao Peng\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChaoPengLearningaDiscriminative').submit();\">Chao Peng</a>,\n</form>\n<form id=\"form-ChangxinGaoLearningaDiscriminative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Changxin Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChangxinGaoLearningaDiscriminative').submit();\">Changxin Gao</a>,\n</form>\n<form id=\"form-GangYuLearningaDiscriminative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gang Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-GangYuLearningaDiscriminative').submit();\">Gang Yu</a>,\n</form>\n<form id=\"form-NongSangLearningaDiscriminative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nong Sang\">\n<a href=\"#\" onclick=\"document.getElementById('form-NongSangLearningaDiscriminative').submit();\">Nong Sang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yu_Learning_a_Discriminative_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.09337\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yu_2018_CVPR,<br>\nauthor = {Yu, Changqian and Wang, Jingbo and Peng, Chao and Gao, Changxin and Yu, Gang and Sang, Nong},<br>\ntitle = {Learning a Discriminative Feature Network for Semantic Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wei_Kernelized_Subspace_Pooling_CVPR_2018_paper.html\">Kernelized Subspace Pooling for Deep Local Descriptors</a></dt>\n<dd>\n<form id=\"form-XingWeiKernelizedSubspacePooling\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xing Wei\">\n<a href=\"#\" onclick=\"document.getElementById('form-XingWeiKernelizedSubspacePooling').submit();\">Xing Wei</a>,\n</form>\n<form id=\"form-YueZhangKernelizedSubspacePooling\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yue Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YueZhangKernelizedSubspacePooling').submit();\">Yue Zhang</a>,\n</form>\n<form id=\"form-YihongGongKernelizedSubspacePooling\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yihong Gong\">\n<a href=\"#\" onclick=\"document.getElementById('form-YihongGongKernelizedSubspacePooling').submit();\">Yihong Gong</a>,\n</form>\n<form id=\"form-NanningZhengKernelizedSubspacePooling\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nanning Zheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-NanningZhengKernelizedSubspacePooling').submit();\">Nanning Zheng</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wei_Kernelized_Subspace_Pooling_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wei_2018_CVPR,<br>\nauthor = {Wei, Xing and Zhang, Yue and Gong, Yihong and Zheng, Nanning},<br>\ntitle = {Kernelized Subspace Pooling for Deep Local Descriptors},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hong_pOSE_Pseudo_Object_CVPR_2018_paper.html\">pOSE: Pseudo Object Space Error for Initialization-Free Bundle Adjustment</a></dt>\n<dd>\n<form id=\"form-JeHyeongpOSEPseudoObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Je Hyeong Hong\">\n<a href=\"#\" onclick=\"document.getElementById('form-JeHyeongpOSEPseudoObject').submit();\">Je Hyeong Hong</a>,\n</form>\n<form id=\"form-ChristopherZachpOSEPseudoObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Christopher Zach\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChristopherZachpOSEPseudoObject').submit();\">Christopher Zach</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hong_pOSE_Pseudo_Object_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hong_2018_CVPR,<br>\nauthor = {Hyeong Hong, Je and Zach, Christopher},<br>\ntitle = {pOSE: Pseudo Object Space Error for Initialization-Free Bundle Adjustment},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Litany_Deformable_Shape_Completion_CVPR_2018_paper.html\">Deformable Shape Completion With Graph Convolutional Autoencoders</a></dt>\n<dd>\n<form id=\"form-OrLitanyDeformableShapeCompletion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Or Litany\">\n<a href=\"#\" onclick=\"document.getElementById('form-OrLitanyDeformableShapeCompletion').submit();\">Or Litany</a>,\n</form>\n<form id=\"form-AlexBronsteinDeformableShapeCompletion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alex Bronstein\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexBronsteinDeformableShapeCompletion').submit();\">Alex Bronstein</a>,\n</form>\n<form id=\"form-MichaelBronsteinDeformableShapeCompletion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michael Bronstein\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichaelBronsteinDeformableShapeCompletion').submit();\">Michael Bronstein</a>,\n</form>\n<form id=\"form-AmeeshMakadiaDeformableShapeCompletion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ameesh Makadia\">\n<a href=\"#\" onclick=\"document.getElementById('form-AmeeshMakadiaDeformableShapeCompletion').submit();\">Ameesh Makadia</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Litany_Deformable_Shape_Completion_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0095-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.00268\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Litany_2018_CVPR,<br>\nauthor = {Litany, Or and Bronstein, Alex and Bronstein, Michael and Makadia, Ameesh},<br>\ntitle = {Deformable Shape Completion With Graph Convolutional Autoencoders},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Gilani_Learning_From_Millions_CVPR_2018_paper.html\">Learning From Millions of 3D Scans for Large-Scale 3D Face Recognition</a></dt>\n<dd>\n<form id=\"form-SyedZulqarnainLearningFromMillions\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Syed Zulqarnain Gilani\">\n<a href=\"#\" onclick=\"document.getElementById('form-SyedZulqarnainLearningFromMillions').submit();\">Syed Zulqarnain Gilani</a>,\n</form>\n<form id=\"form-AjmalMianLearningFromMillions\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ajmal Mian\">\n<a href=\"#\" onclick=\"document.getElementById('form-AjmalMianLearningFromMillions').submit();\">Ajmal Mian</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Gilani_Learning_From_Millions_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.05942\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Gilani_2018_CVPR,<br>\nauthor = {Zulqarnain Gilani, Syed and Mian, Ajmal},<br>\ntitle = {Learning From Millions of 3D Scans for Large-Scale 3D Face Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Reddy_CarFusion_Combining_Point_CVPR_2018_paper.html\">CarFusion: Combining Point Tracking and Part Detection for Dynamic 3D Reconstruction of Vehicles</a></dt>\n<dd>\n<form id=\"form-N.DineshCarFusionCombiningPoint\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"N. Dinesh Reddy\">\n<a href=\"#\" onclick=\"document.getElementById('form-N.DineshCarFusionCombiningPoint').submit();\">N. Dinesh Reddy</a>,\n</form>\n<form id=\"form-MinhVoCarFusionCombiningPoint\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Minh Vo\">\n<a href=\"#\" onclick=\"document.getElementById('form-MinhVoCarFusionCombiningPoint').submit();\">Minh Vo</a>,\n</form>\n<form id=\"form-SrinivasaG.CarFusionCombiningPoint\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Srinivasa G. Narasimhan\">\n<a href=\"#\" onclick=\"document.getElementById('form-SrinivasaG.CarFusionCombiningPoint').submit();\">Srinivasa G. Narasimhan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Reddy_CarFusion_Combining_Point_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0890-supp.zip\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Reddy_2018_CVPR,<br>\nauthor = {Dinesh Reddy, N. and Vo, Minh and Narasimhan, Srinivasa G.},<br>\ntitle = {CarFusion: Combining Point Tracking and Part Detection for Dynamic 3D Reconstruction of Vehicles},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhi_Deep_Material-Aware_Cross-Spectral_CVPR_2018_paper.html\">Deep Material-Aware Cross-Spectral Stereo Matching</a></dt>\n<dd>\n<form id=\"form-TianchengZhiDeepMaterialAwareCrossSpectral\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tiancheng Zhi\">\n<a href=\"#\" onclick=\"document.getElementById('form-TianchengZhiDeepMaterialAwareCrossSpectral').submit();\">Tiancheng Zhi</a>,\n</form>\n<form id=\"form-BernardoR.DeepMaterialAwareCrossSpectral\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bernardo R. Pires\">\n<a href=\"#\" onclick=\"document.getElementById('form-BernardoR.DeepMaterialAwareCrossSpectral').submit();\">Bernardo R. Pires</a>,\n</form>\n<form id=\"form-MartialHebertDeepMaterialAwareCrossSpectral\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Martial Hebert\">\n<a href=\"#\" onclick=\"document.getElementById('form-MartialHebertDeepMaterialAwareCrossSpectral').submit();\">Martial Hebert</a>,\n</form>\n<form id=\"form-SrinivasaG.DeepMaterialAwareCrossSpectral\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Srinivasa G. Narasimhan\">\n<a href=\"#\" onclick=\"document.getElementById('form-SrinivasaG.DeepMaterialAwareCrossSpectral').submit();\">Srinivasa G. Narasimhan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhi_Deep_Material-Aware_Cross-Spectral_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0894-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhi_2018_CVPR,<br>\nauthor = {Zhi, Tiancheng and Pires, Bernardo R. and Hebert, Martial and Narasimhan, Srinivasa G.},<br>\ntitle = {Deep Material-Aware Cross-Spectral Stereo Matching},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Price_Augmenting_Crowd-Sourced_3D_CVPR_2018_paper.html\">Augmenting Crowd-Sourced 3D Reconstructions Using Semantic Detections</a></dt>\n<dd>\n<form id=\"form-TruePriceAugmentingCrowdSourced3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"True Price\">\n<a href=\"#\" onclick=\"document.getElementById('form-TruePriceAugmentingCrowdSourced3D').submit();\">True Price</a>,\n</form>\n<form id=\"form-JohannesL.AugmentingCrowdSourced3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Johannes L. Sch\u00c3\u00b6nberger\">\n<a href=\"#\" onclick=\"document.getElementById('form-JohannesL.AugmentingCrowdSourced3D').submit();\">Johannes L. Sch\u00c3\u00b6nberger</a>,\n</form>\n<form id=\"form-ZhenWeiAugmentingCrowdSourced3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhen Wei\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhenWeiAugmentingCrowdSourced3D').submit();\">Zhen Wei</a>,\n</form>\n<form id=\"form-MarcPollefeysAugmentingCrowdSourced3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Marc Pollefeys\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarcPollefeysAugmentingCrowdSourced3D').submit();\">Marc Pollefeys</a>,\n</form>\n<form id=\"form-Jan-MichaelFrahmAugmentingCrowdSourced3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jan-Michael Frahm\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jan-MichaelFrahmAugmentingCrowdSourced3D').submit();\">Jan-Michael Frahm</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Price_Augmenting_Crowd-Sourced_3D_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1213-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Price_2018_CVPR,<br>\nauthor = {Price, True and Sch\u00c3\u00b6nberger, Johannes L. and Wei, Zhen and Pollefeys, Marc and Frahm, Jan-Michael},<br>\ntitle = {Augmenting Crowd-Sourced 3D Reconstructions Using Semantic Detections},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Richter_Matryoshka_Networks_Predicting_CVPR_2018_paper.html\">Matryoshka Networks: Predicting 3D Geometry via Nested Shape Layers</a></dt>\n<dd>\n<form id=\"form-StephanR.MatryoshkaNetworksPredicting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stephan R. Richter\">\n<a href=\"#\" onclick=\"document.getElementById('form-StephanR.MatryoshkaNetworksPredicting').submit();\">Stephan R. Richter</a>,\n</form>\n<form id=\"form-StefanRothMatryoshkaNetworksPredicting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stefan Roth\">\n<a href=\"#\" onclick=\"document.getElementById('form-StefanRothMatryoshkaNetworksPredicting').submit();\">Stefan Roth</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Richter_Matryoshka_Networks_Predicting_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1524-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.10975\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Richter_2018_CVPR,<br>\nauthor = {Richter, Stephan R. and Roth, Stefan},<br>\ntitle = {Matryoshka Networks: Predicting 3D Geometry via Nested Shape Layers},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/He_Triplet-Center_Loss_for_CVPR_2018_paper.html\">Triplet-Center Loss for Multi-View 3D Object Retrieval</a></dt>\n<dd>\n<form id=\"form-XinweiHeTripletCenterLossfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xinwei He\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinweiHeTripletCenterLossfor').submit();\">Xinwei He</a>,\n</form>\n<form id=\"form-YangZhouTripletCenterLossfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yang Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-YangZhouTripletCenterLossfor').submit();\">Yang Zhou</a>,\n</form>\n<form id=\"form-ZhichaoZhouTripletCenterLossfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhichao Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhichaoZhouTripletCenterLossfor').submit();\">Zhichao Zhou</a>,\n</form>\n<form id=\"form-SongBaiTripletCenterLossfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Song Bai\">\n<a href=\"#\" onclick=\"document.getElementById('form-SongBaiTripletCenterLossfor').submit();\">Song Bai</a>,\n</form>\n<form id=\"form-XiangBaiTripletCenterLossfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiang Bai\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiangBaiTripletCenterLossfor').submit();\">Xiang Bai</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/He_Triplet-Center_Loss_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.06189\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{He_2018_CVPR,<br>\nauthor = {He, Xinwei and Zhou, Yang and Zhou, Zhichao and Bai, Song and Bai, Xiang},<br>\ntitle = {Triplet-Center Loss for Multi-View 3D Object Retrieval},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Stutz_Learning_3D_Shape_CVPR_2018_paper.html\">Learning 3D Shape Completion From Laser Scan Data With Weak Supervision</a></dt>\n<dd>\n<form id=\"form-DavidStutzLearning3DShape\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"David Stutz\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavidStutzLearning3DShape').submit();\">David Stutz</a>,\n</form>\n<form id=\"form-AndreasGeigerLearning3DShape\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andreas Geiger\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndreasGeigerLearning3DShape').submit();\">Andreas Geiger</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Stutz_Learning_3D_Shape_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1708-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Stutz_2018_CVPR,<br>\nauthor = {Stutz, David and Geiger, Andreas},<br>\ntitle = {Learning 3D Shape Completion From Laser Scan Data With Weak Supervision},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Georgakis_End-to-End_Learning_of_CVPR_2018_paper.html\">End-to-End Learning of Keypoint Detector and Descriptor for Pose Invariant 3D Matching</a></dt>\n<dd>\n<form id=\"form-GeorgiosGeorgakisEndtoEndLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Georgios Georgakis\">\n<a href=\"#\" onclick=\"document.getElementById('form-GeorgiosGeorgakisEndtoEndLearningof').submit();\">Georgios Georgakis</a>,\n</form>\n<form id=\"form-SrikrishnaKaranamEndtoEndLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Srikrishna Karanam\">\n<a href=\"#\" onclick=\"document.getElementById('form-SrikrishnaKaranamEndtoEndLearningof').submit();\">Srikrishna Karanam</a>,\n</form>\n<form id=\"form-ZiyanWuEndtoEndLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ziyan Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZiyanWuEndtoEndLearningof').submit();\">Ziyan Wu</a>,\n</form>\n<form id=\"form-JanErnstEndtoEndLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jan Ernst\">\n<a href=\"#\" onclick=\"document.getElementById('form-JanErnstEndtoEndLearningof').submit();\">Jan Ernst</a>,\n</form>\n<form id=\"form-JanaKo\u00c5\u00a1eck\u00c3\u00a1EndtoEndLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jana Ko\u00c5\u00a1eck\u00c3\u00a1\">\n<a href=\"#\" onclick=\"document.getElementById('form-JanaKo\u00c5\u00a1eck\u00c3\u00a1EndtoEndLearningof').submit();\">Jana Ko\u00c5\u00a1eck\u00c3\u00a1</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Georgakis_End-to-End_Learning_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2411-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.07869\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Georgakis_2018_CVPR,<br>\nauthor = {Georgakis, Georgios and Karanam, Srikrishna and Wu, Ziyan and Ernst, Jan and Ko\u00c5\u00a1eck\u00c3\u00a1, Jana},<br>\ntitle = {End-to-End Learning of Keypoint Detector and Descriptor for Pose Invariant 3D Matching},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_ICE-BA_Incremental_Consistent_CVPR_2018_paper.html\">ICE-BA: Incremental, Consistent and Efficient Bundle Adjustment for Visual-Inertial SLAM</a></dt>\n<dd>\n<form id=\"form-HaominLiuICEBAIncrementalConsistent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Haomin Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaominLiuICEBAIncrementalConsistent').submit();\">Haomin Liu</a>,\n</form>\n<form id=\"form-MingyuChenICEBAIncrementalConsistent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mingyu Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingyuChenICEBAIncrementalConsistent').submit();\">Mingyu Chen</a>,\n</form>\n<form id=\"form-GuofengZhangICEBAIncrementalConsistent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guofeng Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuofengZhangICEBAIncrementalConsistent').submit();\">Guofeng Zhang</a>,\n</form>\n<form id=\"form-HujunBaoICEBAIncrementalConsistent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hujun Bao\">\n<a href=\"#\" onclick=\"document.getElementById('form-HujunBaoICEBAIncrementalConsistent').submit();\">Hujun Bao</a>,\n</form>\n<form id=\"form-YingzeBaoICEBAIncrementalConsistent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yingze Bao\">\n<a href=\"#\" onclick=\"document.getElementById('form-YingzeBaoICEBAIncrementalConsistent').submit();\">Yingze Bao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_ICE-BA_Incremental_Consistent_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Haomin and Chen, Mingyu and Zhang, Guofeng and Bao, Hujun and Bao, Yingze},<br>\ntitle = {ICE-BA: Incremental, Consistent and Efficient Bundle Adjustment for Visual-Inertial SLAM},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yin_GeoNet_Unsupervised_Learning_CVPR_2018_paper.html\">GeoNet: Unsupervised Learning of Dense Depth, Optical Flow and Camera Pose</a></dt>\n<dd>\n<form id=\"form-ZhichaoYinGeoNetUnsupervisedLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhichao Yin\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhichaoYinGeoNetUnsupervisedLearning').submit();\">Zhichao Yin</a>,\n</form>\n<form id=\"form-JianpingShiGeoNetUnsupervisedLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianping Shi\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianpingShiGeoNetUnsupervisedLearning').submit();\">Jianping Shi</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yin_GeoNet_Unsupervised_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yin_2018_CVPR,<br>\nauthor = {Yin, Zhichao and Shi, Jianping},<br>\ntitle = {GeoNet: Unsupervised Learning of Dense Depth, Optical Flow and Camera Pose},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Pritts_Radially-Distorted_Conjugate_Translations_CVPR_2018_paper.html\">Radially-Distorted Conjugate Translations</a></dt>\n<dd>\n<form id=\"form-JamesPrittsRadiallyDistortedConjugateTranslations\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"James Pritts\">\n<a href=\"#\" onclick=\"document.getElementById('form-JamesPrittsRadiallyDistortedConjugateTranslations').submit();\">James Pritts</a>,\n</form>\n<form id=\"form-ZuzanaKukelovaRadiallyDistortedConjugateTranslations\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zuzana Kukelova\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZuzanaKukelovaRadiallyDistortedConjugateTranslations').submit();\">Zuzana Kukelova</a>,\n</form>\n<form id=\"form-ViktorLarssonRadiallyDistortedConjugateTranslations\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Viktor Larsson\">\n<a href=\"#\" onclick=\"document.getElementById('form-ViktorLarssonRadiallyDistortedConjugateTranslations').submit();\">Viktor Larsson</a>,\n</form>\n<form id=\"form-Ond\u00c5\u0099ejChumRadiallyDistortedConjugateTranslations\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ond\u00c5\u0099ej Chum\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ond\u00c5\u0099ejChumRadiallyDistortedConjugateTranslations').submit();\">Ond\u00c5\u0099ej Chum</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Pritts_Radially-Distorted_Conjugate_Translations_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3217-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.11339\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Pritts_2018_CVPR,<br>\nauthor = {Pritts, James and Kukelova, Zuzana and Larsson, Viktor and Chum, Ond\u00c5\u0099ej},<br>\ntitle = {Radially-Distorted Conjugate Translations},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Fu_Deep_Ordinal_Regression_CVPR_2018_paper.html\">Deep Ordinal Regression Network for Monocular Depth Estimation</a></dt>\n<dd>\n<form id=\"form-HuanFuDeepOrdinalRegression\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huan Fu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuanFuDeepOrdinalRegression').submit();\">Huan Fu</a>,\n</form>\n<form id=\"form-MingmingGongDeepOrdinalRegression\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mingming Gong\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingmingGongDeepOrdinalRegression').submit();\">Mingming Gong</a>,\n</form>\n<form id=\"form-ChaohuiWangDeepOrdinalRegression\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chaohui Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChaohuiWangDeepOrdinalRegression').submit();\">Chaohui Wang</a>,\n</form>\n<form id=\"form-KayhanBatmanghelichDeepOrdinalRegression\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kayhan Batmanghelich\">\n<a href=\"#\" onclick=\"document.getElementById('form-KayhanBatmanghelichDeepOrdinalRegression').submit();\">Kayhan Batmanghelich</a>,\n</form>\n<form id=\"form-DachengTaoDeepOrdinalRegression\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dacheng Tao\">\n<a href=\"#\" onclick=\"document.getElementById('form-DachengTaoDeepOrdinalRegression').submit();\">Dacheng Tao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Fu_Deep_Ordinal_Regression_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1806.02446\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Fu_2018_CVPR,<br>\nauthor = {Fu, Huan and Gong, Mingming and Wang, Chaohui and Batmanghelich, Kayhan and Tao, Dacheng},<br>\ntitle = {Deep Ordinal Regression Network for Monocular Depth Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Miraldo_Analytical_Modeling_of_CVPR_2018_paper.html\">Analytical Modeling of Vanishing Points and Curves in Catadioptric Cameras</a></dt>\n<dd>\n<form id=\"form-PedroMiraldoAnalyticalModelingof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pedro Miraldo\">\n<a href=\"#\" onclick=\"document.getElementById('form-PedroMiraldoAnalyticalModelingof').submit();\">Pedro Miraldo</a>,\n</form>\n<form id=\"form-FranciscoEirasAnalyticalModelingof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Francisco Eiras\">\n<a href=\"#\" onclick=\"document.getElementById('form-FranciscoEirasAnalyticalModelingof').submit();\">Francisco Eiras</a>,\n</form>\n<form id=\"form-SrikumarRamalingamAnalyticalModelingof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Srikumar Ramalingam\">\n<a href=\"#\" onclick=\"document.getElementById('form-SrikumarRamalingamAnalyticalModelingof').submit();\">Srikumar Ramalingam</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Miraldo_Analytical_Modeling_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3508-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.09460\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Miraldo_2018_CVPR,<br>\nauthor = {Miraldo, Pedro and Eiras, Francisco and Ramalingam, Srikumar},<br>\ntitle = {Analytical Modeling of Vanishing Points and Curves in Catadioptric Cameras},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Learning_Depth_From_CVPR_2018_paper.html\">Learning Depth From Monocular Videos Using Direct Methods</a></dt>\n<dd>\n<form id=\"form-ChaoyangWangLearningDepthFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chaoyang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChaoyangWangLearningDepthFrom').submit();\">Chaoyang Wang</a>,\n</form>\n<form id=\"form-Jos\u00c3\u00a9MiguelLearningDepthFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jos\u00c3\u00a9 Miguel Buenaposada\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jos\u00c3\u00a9MiguelLearningDepthFrom').submit();\">Jos\u00c3\u00a9 Miguel Buenaposada</a>,\n</form>\n<form id=\"form-RuiZhuLearningDepthFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rui Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-RuiZhuLearningDepthFrom').submit();\">Rui Zhu</a>,\n</form>\n<form id=\"form-SimonLuceyLearningDepthFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Simon Lucey\">\n<a href=\"#\" onclick=\"document.getElementById('form-SimonLuceyLearningDepthFrom').submit();\">Simon Lucey</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Learning_Depth_From_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.00175\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Chaoyang and Miguel Buenaposada, Jos\u00c3\u00a9 and Zhu, Rui and Lucey, Simon},<br>\ntitle = {Learning Depth From Monocular Videos Using Direct Methods},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Salience_Guided_Depth_CVPR_2018_paper.html\">Salience Guided Depth Calibration for Perceptually Optimized Compressive Light Field 3D Display</a></dt>\n<dd>\n<form id=\"form-ShizhengWangSalienceGuidedDepth\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shizheng Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShizhengWangSalienceGuidedDepth').submit();\">Shizheng Wang</a>,\n</form>\n<form id=\"form-WenjuanLiaoSalienceGuidedDepth\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenjuan Liao\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenjuanLiaoSalienceGuidedDepth').submit();\">Wenjuan Liao</a>,\n</form>\n<form id=\"form-PhilSurmanSalienceGuidedDepth\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Phil Surman\">\n<a href=\"#\" onclick=\"document.getElementById('form-PhilSurmanSalienceGuidedDepth').submit();\">Phil Surman</a>,\n</form>\n<form id=\"form-ZhigangTuSalienceGuidedDepth\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhigang Tu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhigangTuSalienceGuidedDepth').submit();\">Zhigang Tu</a>,\n</form>\n<form id=\"form-YuanjinZhengSalienceGuidedDepth\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuanjin Zheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuanjinZhengSalienceGuidedDepth').submit();\">Yuanjin Zheng</a>,\n</form>\n<form id=\"form-JunsongYuanSalienceGuidedDepth\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junsong Yuan\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunsongYuanSalienceGuidedDepth').submit();\">Junsong Yuan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Salience_Guided_Depth_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/4075-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Shizheng and Liao, Wenjuan and Surman, Phil and Tu, Zhigang and Zheng, Yuanjin and Yuan, Junsong},<br>\ntitle = {Salience Guided Depth Calibration for Perceptually Optimized Compressive Light Field 3D Display},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_MegaDepth_Learning_Single-View_CVPR_2018_paper.html\">MegaDepth: Learning Single-View Depth Prediction From Internet Photos</a></dt>\n<dd>\n<form id=\"form-ZhengqiLiMegaDepthLearningSingleView\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhengqi Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhengqiLiMegaDepthLearningSingleView').submit();\">Zhengqi Li</a>,\n</form>\n<form id=\"form-NoahSnavelyMegaDepthLearningSingleView\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Noah Snavely\">\n<a href=\"#\" onclick=\"document.getElementById('form-NoahSnavelyMegaDepthLearningSingleView').submit();\">Noah Snavely</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_MegaDepth_Learning_Single-View_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0109-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00607\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Zhengqi and Snavely, Noah},<br>\ntitle = {MegaDepth: Learning Single-View Depth Prediction From Internet Photos},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zou_LayoutNet_Reconstructing_the_CVPR_2018_paper.html\">LayoutNet: Reconstructing the 3D Room Layout From a Single RGB Image</a></dt>\n<dd>\n<form id=\"form-ChuhangZouLayoutNetReconstructingthe\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chuhang Zou\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChuhangZouLayoutNetReconstructingthe').submit();\">Chuhang Zou</a>,\n</form>\n<form id=\"form-AlexColburnLayoutNetReconstructingthe\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alex Colburn\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexColburnLayoutNetReconstructingthe').submit();\">Alex Colburn</a>,\n</form>\n<form id=\"form-QiShanLayoutNetReconstructingthe\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qi Shan\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiShanLayoutNetReconstructingthe').submit();\">Qi Shan</a>,\n</form>\n<form id=\"form-DerekHoiemLayoutNetReconstructingthe\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Derek Hoiem\">\n<a href=\"#\" onclick=\"document.getElementById('form-DerekHoiemLayoutNetReconstructingthe').submit();\">Derek Hoiem</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zou_LayoutNet_Reconstructing_the_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.08999\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zou_2018_CVPR,<br>\nauthor = {Zou, Chuhang and Colburn, Alex and Shan, Qi and Hoiem, Derek},<br>\ntitle = {LayoutNet: Reconstructing the 3D Room Layout From a Single RGB Image},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Batsos_CBMV_A_Coalesced_CVPR_2018_paper.html\">CBMV: A Coalesced Bidirectional Matching Volume for Disparity Estimation</a></dt>\n<dd>\n<form id=\"form-KonstantinosBatsosCBMVACoalesced\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Konstantinos Batsos\">\n<a href=\"#\" onclick=\"document.getElementById('form-KonstantinosBatsosCBMVACoalesced').submit();\">Konstantinos Batsos</a>,\n</form>\n<form id=\"form-ChangjiangCaiCBMVACoalesced\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Changjiang Cai\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChangjiangCaiCBMVACoalesced').submit();\">Changjiang Cai</a>,\n</form>\n<form id=\"form-PhilipposMordohaiCBMVACoalesced\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Philippos Mordohai\">\n<a href=\"#\" onclick=\"document.getElementById('form-PhilipposMordohaiCBMVACoalesced').submit();\">Philippos Mordohai</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Batsos_CBMV_A_Coalesced_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0598-supp.zip\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.01967\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Batsos_2018_CVPR,<br>\nauthor = {Batsos, Konstantinos and Cai, Changjiang and Mordohai, Philippos},<br>\ntitle = {CBMV: A Coalesced Bidirectional Matching Volume for Disparity Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Pang_Zoom_and_Learn_CVPR_2018_paper.html\">Zoom and Learn: Generalizing Deep Stereo Matching to Novel Domains</a></dt>\n<dd>\n<form id=\"form-JiahaoPangZoomandLearn\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiahao Pang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiahaoPangZoomandLearn').submit();\">Jiahao Pang</a>,\n</form>\n<form id=\"form-WenxiuSunZoomandLearn\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenxiu Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenxiuSunZoomandLearn').submit();\">Wenxiu Sun</a>,\n</form>\n<form id=\"form-ChengxiYangZoomandLearn\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chengxi Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChengxiYangZoomandLearn').submit();\">Chengxi Yang</a>,\n</form>\n<form id=\"form-JimmyRenZoomandLearn\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jimmy Ren\">\n<a href=\"#\" onclick=\"document.getElementById('form-JimmyRenZoomandLearn').submit();\">Jimmy Ren</a>,\n</form>\n<form id=\"form-RuichaoXiaoZoomandLearn\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ruichao Xiao\">\n<a href=\"#\" onclick=\"document.getElementById('form-RuichaoXiaoZoomandLearn').submit();\">Ruichao Xiao</a>,\n</form>\n<form id=\"form-JinZengZoomandLearn\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jin Zeng\">\n<a href=\"#\" onclick=\"document.getElementById('form-JinZengZoomandLearn').submit();\">Jin Zeng</a>,\n</form>\n<form id=\"form-LiangLinZoomandLearn\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liang Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiangLinZoomandLearn').submit();\">Liang Lin</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Pang_Zoom_and_Learn_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1078-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.06641\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Pang_2018_CVPR,<br>\nauthor = {Pang, Jiahao and Sun, Wenxiu and Yang, Chengxi and Ren, Jimmy and Xiao, Ruichao and Zeng, Jin and Lin, Liang},<br>\ntitle = {Zoom and Learn: Generalizing Deep Stereo Matching to Novel Domains},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_Exploring_Disentangled_Feature_CVPR_2018_paper.html\">Exploring Disentangled Feature Representation Beyond Face Identification</a></dt>\n<dd>\n<form id=\"form-YuLiuExploringDisentangledFeature\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuLiuExploringDisentangledFeature').submit();\">Yu Liu</a>,\n</form>\n<form id=\"form-FangyinWeiExploringDisentangledFeature\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fangyin Wei\">\n<a href=\"#\" onclick=\"document.getElementById('form-FangyinWeiExploringDisentangledFeature').submit();\">Fangyin Wei</a>,\n</form>\n<form id=\"form-JingShaoExploringDisentangledFeature\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jing Shao\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingShaoExploringDisentangledFeature').submit();\">Jing Shao</a>,\n</form>\n<form id=\"form-LuShengExploringDisentangledFeature\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lu Sheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-LuShengExploringDisentangledFeature').submit();\">Lu Sheng</a>,\n</form>\n<form id=\"form-JunjieYanExploringDisentangledFeature\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junjie Yan\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunjieYanExploringDisentangledFeature').submit();\">Junjie Yan</a>,\n</form>\n<form id=\"form-XiaogangWangExploringDisentangledFeature\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaogang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaogangWangExploringDisentangledFeature').submit();\">Xiaogang Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_Exploring_Disentangled_Feature_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.03487\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Yu and Wei, Fangyin and Shao, Jing and Sheng, Lu and Yan, Junjie and Wang, Xiaogang},<br>\ntitle = {Exploring Disentangled Feature Representation Beyond Face Identification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhao_Learning_Facial_Action_CVPR_2018_paper.html\">Learning Facial Action Units From Web Images With Scalable Weakly Supervised Clustering</a></dt>\n<dd>\n<form id=\"form-KailiZhaoLearningFacialAction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kaili Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-KailiZhaoLearningFacialAction').submit();\">Kaili Zhao</a>,\n</form>\n<form id=\"form-Wen-ShengChuLearningFacialAction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wen-Sheng Chu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Wen-ShengChuLearningFacialAction').submit();\">Wen-Sheng Chu</a>,\n</form>\n<form id=\"form-AleixM.LearningFacialAction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Aleix M. Martinez\">\n<a href=\"#\" onclick=\"document.getElementById('form-AleixM.LearningFacialAction').submit();\">Aleix M. Martinez</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhao_Learning_Facial_Action_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhao_2018_CVPR,<br>\nauthor = {Zhao, Kaili and Chu, Wen-Sheng and Martinez, Aleix M.},<br>\ntitle = {Learning Facial Action Units From Web Images With Scalable Weakly Supervised Clustering},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Nie_Human_Pose_Estimation_CVPR_2018_paper.html\">Human Pose Estimation With Parsing Induced Learner</a></dt>\n<dd>\n<form id=\"form-XuechengNieHumanPoseEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xuecheng Nie\">\n<a href=\"#\" onclick=\"document.getElementById('form-XuechengNieHumanPoseEstimation').submit();\">Xuecheng Nie</a>,\n</form>\n<form id=\"form-JiashiFengHumanPoseEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiashi Feng\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiashiFengHumanPoseEstimation').submit();\">Jiashi Feng</a>,\n</form>\n<form id=\"form-YimingZuoHumanPoseEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yiming Zuo\">\n<a href=\"#\" onclick=\"document.getElementById('form-YimingZuoHumanPoseEstimation').submit();\">Yiming Zuo</a>,\n</form>\n<form id=\"form-ShuichengYanHumanPoseEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuicheng Yan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuichengYanHumanPoseEstimation').submit();\">Shuicheng Yan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Nie_Human_Pose_Estimation_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Nie_2018_CVPR,<br>\nauthor = {Nie, Xuecheng and Feng, Jiashi and Zuo, Yiming and Yan, Shuicheng},<br>\ntitle = {Human Pose Estimation With Parsing Induced Learner},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chang_Multi-Level_Factorisation_Net_CVPR_2018_paper.html\">Multi-Level Factorisation Net for Person Re-Identification</a></dt>\n<dd>\n<form id=\"form-XiaobinChangMultiLevelFactorisationNet\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaobin Chang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaobinChangMultiLevelFactorisationNet').submit();\">Xiaobin Chang</a>,\n</form>\n<form id=\"form-TimothyM.MultiLevelFactorisationNet\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Timothy M. Hospedales\">\n<a href=\"#\" onclick=\"document.getElementById('form-TimothyM.MultiLevelFactorisationNet').submit();\">Timothy M. Hospedales</a>,\n</form>\n<form id=\"form-TaoXiangMultiLevelFactorisationNet\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tao Xiang\">\n<a href=\"#\" onclick=\"document.getElementById('form-TaoXiangMultiLevelFactorisationNet').submit();\">Tao Xiang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chang_Multi-Level_Factorisation_Net_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0468-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.09132\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chang_2018_CVPR,<br>\nauthor = {Chang, Xiaobin and Hospedales, Timothy M. and Xiang, Tao},<br>\ntitle = {Multi-Level Factorisation Net for Person Re-Identification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xu_Attention-Aware_Compositional_Network_CVPR_2018_paper.html\">Attention-Aware Compositional Network for Person Re-Identification</a></dt>\n<dd>\n<form id=\"form-JingXuAttentionAwareCompositionalNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jing Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingXuAttentionAwareCompositionalNetwork').submit();\">Jing Xu</a>,\n</form>\n<form id=\"form-RuiZhaoAttentionAwareCompositionalNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rui Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-RuiZhaoAttentionAwareCompositionalNetwork').submit();\">Rui Zhao</a>,\n</form>\n<form id=\"form-FengZhuAttentionAwareCompositionalNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Feng Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-FengZhuAttentionAwareCompositionalNetwork').submit();\">Feng Zhu</a>,\n</form>\n<form id=\"form-HuamingWangAttentionAwareCompositionalNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huaming Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuamingWangAttentionAwareCompositionalNetwork').submit();\">Huaming Wang</a>,\n</form>\n<form id=\"form-WanliOuyangAttentionAwareCompositionalNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wanli Ouyang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WanliOuyangAttentionAwareCompositionalNetwork').submit();\">Wanli Ouyang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xu_Attention-Aware_Compositional_Network_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.03344\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xu_2018_CVPR,<br>\nauthor = {Xu, Jing and Zhao, Rui and Zhu, Feng and Wang, Huaming and Ouyang, Wanli},<br>\ntitle = {Attention-Aware Compositional Network for Person Re-Identification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wu_Look_at_Boundary_CVPR_2018_paper.html\">Look at Boundary: A Boundary-Aware Face Alignment Algorithm</a></dt>\n<dd>\n<form id=\"form-WayneWuLookatBoundary\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wayne Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WayneWuLookatBoundary').submit();\">Wayne Wu</a>,\n</form>\n<form id=\"form-ChenQianLookatBoundary\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chen Qian\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenQianLookatBoundary').submit();\">Chen Qian</a>,\n</form>\n<form id=\"form-ShuoYangLookatBoundary\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuo Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuoYangLookatBoundary').submit();\">Shuo Yang</a>,\n</form>\n<form id=\"form-QuanWangLookatBoundary\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Quan Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-QuanWangLookatBoundary').submit();\">Quan Wang</a>,\n</form>\n<form id=\"form-YiciCaiLookatBoundary\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yici Cai\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiciCaiLookatBoundary').submit();\">Yici Cai</a>,\n</form>\n<form id=\"form-QiangZhouLookatBoundary\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qiang Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiangZhouLookatBoundary').submit();\">Qiang Zhou</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wu_Look_at_Boundary_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1330-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.10483\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wu_2018_CVPR,<br>\nauthor = {Wu, Wayne and Qian, Chen and Yang, Shuo and Wang, Quan and Cai, Yici and Zhou, Qiang},<br>\ntitle = {Look at Boundary: A Boundary-Aware Face Alignment Algorithm},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Fang_Demo2Vec_Reasoning_Object_CVPR_2018_paper.html\">Demo2Vec: Reasoning Object Affordances From Online Videos</a></dt>\n<dd>\n<form id=\"form-KuanFangDemo2VecReasoningObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kuan Fang\">\n<a href=\"#\" onclick=\"document.getElementById('form-KuanFangDemo2VecReasoningObject').submit();\">Kuan Fang</a>,\n</form>\n<form id=\"form-Te-LinWuDemo2VecReasoningObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Te-Lin Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Te-LinWuDemo2VecReasoningObject').submit();\">Te-Lin Wu</a>,\n</form>\n<form id=\"form-DanielYangDemo2VecReasoningObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daniel Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanielYangDemo2VecReasoningObject').submit();\">Daniel Yang</a>,\n</form>\n<form id=\"form-SilvioSavareseDemo2VecReasoningObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Silvio Savarese\">\n<a href=\"#\" onclick=\"document.getElementById('form-SilvioSavareseDemo2VecReasoningObject').submit();\">Silvio Savarese</a>,\n</form>\n<form id=\"form-JosephJ.Demo2VecReasoningObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Joseph J. Lim\">\n<a href=\"#\" onclick=\"document.getElementById('form-JosephJ.Demo2VecReasoningObject').submit();\">Joseph J. Lim</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Fang_Demo2Vec_Reasoning_Object_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Fang_2018_CVPR,<br>\nauthor = {Fang, Kuan and Wu, Te-Lin and Yang, Daniel and Savarese, Silvio and Lim, Joseph J.},<br>\ntitle = {Demo2Vec: Reasoning Object Affordances From Online Videos},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zanfir_Monocular_3D_Pose_CVPR_2018_paper.html\">Monocular 3D Pose and Shape Estimation of Multiple People in Natural Scenes - The Importance of Multiple Scene Constraints</a></dt>\n<dd>\n<form id=\"form-AndreiZanfirMonocular3DPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrei Zanfir\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndreiZanfirMonocular3DPose').submit();\">Andrei Zanfir</a>,\n</form>\n<form id=\"form-ElisabetaMarinoiuMonocular3DPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Elisabeta Marinoiu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ElisabetaMarinoiuMonocular3DPose').submit();\">Elisabeta Marinoiu</a>,\n</form>\n<form id=\"form-CristianSminchisescuMonocular3DPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cristian Sminchisescu\">\n<a href=\"#\" onclick=\"document.getElementById('form-CristianSminchisescuMonocular3DPose').submit();\">Cristian Sminchisescu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zanfir_Monocular_3D_Pose_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zanfir_2018_CVPR,<br>\nauthor = {Zanfir, Andrei and Marinoiu, Elisabeta and Sminchisescu, Cristian},<br>\ntitle = {Monocular 3D Pose and Shape Estimation of Multiple People in Natural Scenes - The Importance of Multiple Scene Constraints},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Marinoiu_3D_Human_Sensing_CVPR_2018_paper.html\">3D Human Sensing, Action and Emotion Recognition in Robot Assisted Therapy of Children With Autism</a></dt>\n<dd>\n<form id=\"form-ElisabetaMarinoiu3DHumanSensing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Elisabeta Marinoiu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ElisabetaMarinoiu3DHumanSensing').submit();\">Elisabeta Marinoiu</a>,\n</form>\n<form id=\"form-MihaiZanfir3DHumanSensing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mihai Zanfir\">\n<a href=\"#\" onclick=\"document.getElementById('form-MihaiZanfir3DHumanSensing').submit();\">Mihai Zanfir</a>,\n</form>\n<form id=\"form-VladOlaru3DHumanSensing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vlad Olaru\">\n<a href=\"#\" onclick=\"document.getElementById('form-VladOlaru3DHumanSensing').submit();\">Vlad Olaru</a>,\n</form>\n<form id=\"form-CristianSminchisescu3DHumanSensing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cristian Sminchisescu\">\n<a href=\"#\" onclick=\"document.getElementById('form-CristianSminchisescu3DHumanSensing').submit();\">Cristian Sminchisescu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Marinoiu_3D_Human_Sensing_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Marinoiu_2018_CVPR,<br>\nauthor = {Marinoiu, Elisabeta and Zanfir, Mihai and Olaru, Vlad and Sminchisescu, Cristian},<br>\ntitle = {3D Human Sensing, Action and Emotion Recognition in Robot Assisted Therapy of Children With Autism},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yang_Facial_Expression_Recognition_CVPR_2018_paper.html\">Facial Expression Recognition by De-Expression Residue Learning</a></dt>\n<dd>\n<form id=\"form-HuiyuanYangFacialExpressionRecognition\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huiyuan Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuiyuanYangFacialExpressionRecognition').submit();\">Huiyuan Yang</a>,\n</form>\n<form id=\"form-UmurCiftciFacialExpressionRecognition\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Umur Ciftci\">\n<a href=\"#\" onclick=\"document.getElementById('form-UmurCiftciFacialExpressionRecognition').submit();\">Umur Ciftci</a>,\n</form>\n<form id=\"form-LijunYinFacialExpressionRecognition\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lijun Yin\">\n<a href=\"#\" onclick=\"document.getElementById('form-LijunYinFacialExpressionRecognition').submit();\">Lijun Yin</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yang_Facial_Expression_Recognition_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yang_2018_CVPR,<br>\nauthor = {Yang, Huiyuan and Ciftci, Umur and Yin, Lijun},<br>\ntitle = {Facial Expression Recognition by De-Expression Residue Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xu_A_Causal_And-Or_CVPR_2018_paper.html\">A Causal And-Or Graph Model for Visibility Fluent Reasoning in Tracking Interacting Objects</a></dt>\n<dd>\n<form id=\"form-YuanluXuACausalAndOr\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuanlu Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuanluXuACausalAndOr').submit();\">Yuanlu Xu</a>,\n</form>\n<form id=\"form-LeiQinACausalAndOr\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lei Qin\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeiQinACausalAndOr').submit();\">Lei Qin</a>,\n</form>\n<form id=\"form-XiaobaiLiuACausalAndOr\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaobai Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaobaiLiuACausalAndOr').submit();\">Xiaobai Liu</a>,\n</form>\n<form id=\"form-JianwenXieACausalAndOr\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianwen Xie\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianwenXieACausalAndOr').submit();\">Jianwen Xie</a>,\n</form>\n<form id=\"form-Song-ChunZhuACausalAndOr\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Song-Chun Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Song-ChunZhuACausalAndOr').submit();\">Song-Chun Zhu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xu_A_Causal_And-Or_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1709.05437\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xu_2018_CVPR,<br>\nauthor = {Xu, Yuanlu and Qin, Lei and Liu, Xiaobai and Xie, Jianwen and Zhu, Song-Chun},<br>\ntitle = {A Causal And-Or Graph Model for Visibility Fluent Reasoning in Tracking Interacting Objects},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Peng_Weakly_Supervised_Facial_CVPR_2018_paper.html\">Weakly Supervised Facial Action Unit Recognition Through Adversarial Training</a></dt>\n<dd>\n<form id=\"form-GuozhuPengWeaklySupervisedFacial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guozhu Peng\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuozhuPengWeaklySupervisedFacial').submit();\">Guozhu Peng</a>,\n</form>\n<form id=\"form-ShangfeiWangWeaklySupervisedFacial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shangfei Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShangfeiWangWeaklySupervisedFacial').submit();\">Shangfei Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Peng_Weakly_Supervised_Facial_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Peng_2018_CVPR,<br>\nauthor = {Peng, Guozhu and Wang, Shangfei},<br>\ntitle = {Weakly Supervised Facial Action Unit Recognition Through Adversarial Training},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Cherian_Non-Linear_Temporal_Subspace_CVPR_2018_paper.html\">Non-Linear Temporal Subspace Representations for Activity Recognition</a></dt>\n<dd>\n<form id=\"form-AnoopCherianNonLinearTemporalSubspace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anoop Cherian\">\n<a href=\"#\" onclick=\"document.getElementById('form-AnoopCherianNonLinearTemporalSubspace').submit();\">Anoop Cherian</a>,\n</form>\n<form id=\"form-SuvritSraNonLinearTemporalSubspace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Suvrit Sra\">\n<a href=\"#\" onclick=\"document.getElementById('form-SuvritSraNonLinearTemporalSubspace').submit();\">Suvrit Sra</a>,\n</form>\n<form id=\"form-StephenGouldNonLinearTemporalSubspace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stephen Gould\">\n<a href=\"#\" onclick=\"document.getElementById('form-StephenGouldNonLinearTemporalSubspace').submit();\">Stephen Gould</a>,\n</form>\n<form id=\"form-RichardHartleyNonLinearTemporalSubspace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Richard Hartley\">\n<a href=\"#\" onclick=\"document.getElementById('form-RichardHartleyNonLinearTemporalSubspace').submit();\">Richard Hartley</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Cherian_Non-Linear_Temporal_Subspace_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.11064\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Cherian_2018_CVPR,<br>\nauthor = {Cherian, Anoop and Sra, Suvrit and Gould, Stephen and Hartley, Richard},<br>\ntitle = {Non-Linear Temporal Subspace Representations for Activity Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhao_Towards_Pose_Invariant_CVPR_2018_paper.html\">Towards Pose Invariant Face Recognition in the Wild</a></dt>\n<dd>\n<form id=\"form-JianZhaoTowardsPoseInvariant\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jian Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianZhaoTowardsPoseInvariant').submit();\">Jian Zhao</a>,\n</form>\n<form id=\"form-YuChengTowardsPoseInvariant\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu Cheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuChengTowardsPoseInvariant').submit();\">Yu Cheng</a>,\n</form>\n<form id=\"form-YanXuTowardsPoseInvariant\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yan Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanXuTowardsPoseInvariant').submit();\">Yan Xu</a>,\n</form>\n<form id=\"form-LinXiongTowardsPoseInvariant\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lin Xiong\">\n<a href=\"#\" onclick=\"document.getElementById('form-LinXiongTowardsPoseInvariant').submit();\">Lin Xiong</a>,\n</form>\n<form id=\"form-JianshuLiTowardsPoseInvariant\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianshu Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianshuLiTowardsPoseInvariant').submit();\">Jianshu Li</a>,\n</form>\n<form id=\"form-FangZhaoTowardsPoseInvariant\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fang Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-FangZhaoTowardsPoseInvariant').submit();\">Fang Zhao</a>,\n</form>\n<form id=\"form-KarlekarJayashreeTowardsPoseInvariant\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Karlekar Jayashree\">\n<a href=\"#\" onclick=\"document.getElementById('form-KarlekarJayashreeTowardsPoseInvariant').submit();\">Karlekar Jayashree</a>,\n</form>\n<form id=\"form-SugiriPranataTowardsPoseInvariant\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sugiri Pranata\">\n<a href=\"#\" onclick=\"document.getElementById('form-SugiriPranataTowardsPoseInvariant').submit();\">Sugiri Pranata</a>,\n</form>\n<form id=\"form-ShengmeiShenTowardsPoseInvariant\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shengmei Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShengmeiShenTowardsPoseInvariant').submit();\">Shengmei Shen</a>,\n</form>\n<form id=\"form-JunliangXingTowardsPoseInvariant\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junliang Xing\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunliangXingTowardsPoseInvariant').submit();\">Junliang Xing</a>,\n</form>\n<form id=\"form-ShuichengYanTowardsPoseInvariant\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuicheng Yan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuichengYanTowardsPoseInvariant').submit();\">Shuicheng Yan</a>,\n</form>\n<form id=\"form-JiashiFengTowardsPoseInvariant\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiashi Feng\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiashiFengTowardsPoseInvariant').submit();\">Jiashi Feng</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhao_Towards_Pose_Invariant_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhao_2018_CVPR,<br>\nauthor = {Zhao, Jian and Cheng, Yu and Xu, Yan and Xiong, Lin and Li, Jianshu and Zhao, Fang and Jayashree, Karlekar and Pranata, Sugiri and Shen, Shengmei and Xing, Junliang and Yan, Shuicheng and Feng, Jiashi},<br>\ntitle = {Towards Pose Invariant Face Recognition in the Wild},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Huang_Unifying_Identification_and_CVPR_2018_paper.html\">Unifying Identification and Context Learning for Person Recognition</a></dt>\n<dd>\n<form id=\"form-QingqiuHuangUnifyingIdentificationand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qingqiu Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-QingqiuHuangUnifyingIdentificationand').submit();\">Qingqiu Huang</a>,\n</form>\n<form id=\"form-YuXiongUnifyingIdentificationand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu Xiong\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuXiongUnifyingIdentificationand').submit();\">Yu Xiong</a>,\n</form>\n<form id=\"form-DahuaLinUnifyingIdentificationand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dahua Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-DahuaLinUnifyingIdentificationand').submit();\">Dahua Lin</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Huang_Unifying_Identification_and_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1806.03084\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Huang_2018_CVPR,<br>\nauthor = {Huang, Qingqiu and Xiong, Yu and Lin, Dahua},<br>\ntitle = {Unifying Identification and Context Learning for Person Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Peng_Jointly_Optimize_Data_CVPR_2018_paper.html\">Jointly Optimize Data Augmentation and Network Training: Adversarial Data Augmentation in Human Pose Estimation</a></dt>\n<dd>\n<form id=\"form-XiPengJointlyOptimizeData\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xi Peng\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiPengJointlyOptimizeData').submit();\">Xi Peng</a>,\n</form>\n<form id=\"form-ZhiqiangTangJointlyOptimizeData\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhiqiang Tang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhiqiangTangJointlyOptimizeData').submit();\">Zhiqiang Tang</a>,\n</form>\n<form id=\"form-FeiYangJointlyOptimizeData\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fei Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-FeiYangJointlyOptimizeData').submit();\">Fei Yang</a>,\n</form>\n<form id=\"form-RogerioS.JointlyOptimizeData\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rogerio S. Feris\">\n<a href=\"#\" onclick=\"document.getElementById('form-RogerioS.JointlyOptimizeData').submit();\">Rogerio S. Feris</a>,\n</form>\n<form id=\"form-DimitrisMetaxasJointlyOptimizeData\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dimitris Metaxas\">\n<a href=\"#\" onclick=\"document.getElementById('form-DimitrisMetaxasJointlyOptimizeData').submit();\">Dimitris Metaxas</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Peng_Jointly_Optimize_Data_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.09707\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Peng_2018_CVPR,<br>\nauthor = {Peng, Xi and Tang, Zhiqiang and Yang, Fei and Feris, Rogerio S. and Metaxas, Dimitris},<br>\ntitle = {Jointly Optimize Data Augmentation and Network Training: Adversarial Data Augmentation in Human Pose Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Feng_Wing_Loss_for_CVPR_2018_paper.html\">Wing Loss for Robust Facial Landmark Localisation With Convolutional Neural Networks</a></dt>\n<dd>\n<form id=\"form-Zhen-HuaFengWingLossfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhen-Hua Feng\">\n<a href=\"#\" onclick=\"document.getElementById('form-Zhen-HuaFengWingLossfor').submit();\">Zhen-Hua Feng</a>,\n</form>\n<form id=\"form-JosefKittlerWingLossfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Josef Kittler\">\n<a href=\"#\" onclick=\"document.getElementById('form-JosefKittlerWingLossfor').submit();\">Josef Kittler</a>,\n</form>\n<form id=\"form-MuhammadAwaisWingLossfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Muhammad Awais\">\n<a href=\"#\" onclick=\"document.getElementById('form-MuhammadAwaisWingLossfor').submit();\">Muhammad Awais</a>,\n</form>\n<form id=\"form-PatrikHuberWingLossfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Patrik Huber\">\n<a href=\"#\" onclick=\"document.getElementById('form-PatrikHuberWingLossfor').submit();\">Patrik Huber</a>,\n</form>\n<form id=\"form-Xiao-JunWuWingLossfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiao-Jun Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Xiao-JunWuWingLossfor').submit();\">Xiao-Jun Wu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Feng_Wing_Loss_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.06753\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Feng_2018_CVPR,<br>\nauthor = {Feng, Zhen-Hua and Kittler, Josef and Awais, Muhammad and Huber, Patrik and Wu, Xiao-Jun},<br>\ntitle = {Wing Loss for Robust Facial Landmark Localisation With Convolutional Neural Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yao_Multiple_Granularity_Group_CVPR_2018_paper.html\">Multiple Granularity Group Interaction Prediction</a></dt>\n<dd>\n<form id=\"form-TaipingYaoMultipleGranularityGroup\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Taiping Yao\">\n<a href=\"#\" onclick=\"document.getElementById('form-TaipingYaoMultipleGranularityGroup').submit();\">Taiping Yao</a>,\n</form>\n<form id=\"form-MinsiWangMultipleGranularityGroup\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Minsi Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-MinsiWangMultipleGranularityGroup').submit();\">Minsi Wang</a>,\n</form>\n<form id=\"form-BingbingNiMultipleGranularityGroup\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bingbing Ni\">\n<a href=\"#\" onclick=\"document.getElementById('form-BingbingNiMultipleGranularityGroup').submit();\">Bingbing Ni</a>,\n</form>\n<form id=\"form-HuaweiWeiMultipleGranularityGroup\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huawei Wei\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuaweiWeiMultipleGranularityGroup').submit();\">Huawei Wei</a>,\n</form>\n<form id=\"form-XiaokangYangMultipleGranularityGroup\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaokang Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaokangYangMultipleGranularityGroup').submit();\">Xiaokang Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yao_Multiple_Granularity_Group_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yao_2018_CVPR,<br>\nauthor = {Yao, Taiping and Wang, Minsi and Ni, Bingbing and Wei, Huawei and Yang, Xiaokang},<br>\ntitle = {Multiple Granularity Group Interaction Prediction},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Gupta_Social_GAN_Socially_CVPR_2018_paper.html\">Social GAN: Socially Acceptable Trajectories With Generative Adversarial Networks</a></dt>\n<dd>\n<form id=\"form-AgrimGuptaSocialGANSocially\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Agrim Gupta\">\n<a href=\"#\" onclick=\"document.getElementById('form-AgrimGuptaSocialGANSocially').submit();\">Agrim Gupta</a>,\n</form>\n<form id=\"form-JustinJohnsonSocialGANSocially\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Justin Johnson\">\n<a href=\"#\" onclick=\"document.getElementById('form-JustinJohnsonSocialGANSocially').submit();\">Justin Johnson</a>,\n</form>\n<form id=\"form-LiFei-FeiSocialGANSocially\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Li Fei-Fei\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiFei-FeiSocialGANSocially').submit();\">Li Fei-Fei</a>,\n</form>\n<form id=\"form-SilvioSavareseSocialGANSocially\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Silvio Savarese\">\n<a href=\"#\" onclick=\"document.getElementById('form-SilvioSavareseSocialGANSocially').submit();\">Silvio Savarese</a>,\n</form>\n<form id=\"form-AlexandreAlahiSocialGANSocially\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexandre Alahi\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexandreAlahiSocialGANSocially').submit();\">Alexandre Alahi</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Gupta_Social_GAN_Socially_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.10892\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Gupta_2018_CVPR,<br>\nauthor = {Gupta, Agrim and Johnson, Justin and Fei-Fei, Li and Savarese, Silvio and Alahi, Alexandre},<br>\ntitle = {Social GAN: Socially Acceptable Trajectories With Generative Adversarial Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Shen_Deep_Group-Shuffling_Random_CVPR_2018_paper.html\">Deep Group-Shuffling Random Walk for Person Re-Identification</a></dt>\n<dd>\n<form id=\"form-YantaoShenDeepGroupShufflingRandom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yantao Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-YantaoShenDeepGroupShufflingRandom').submit();\">Yantao Shen</a>,\n</form>\n<form id=\"form-HongshengLiDeepGroupShufflingRandom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hongsheng Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-HongshengLiDeepGroupShufflingRandom').submit();\">Hongsheng Li</a>,\n</form>\n<form id=\"form-TongXiaoDeepGroupShufflingRandom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tong Xiao\">\n<a href=\"#\" onclick=\"document.getElementById('form-TongXiaoDeepGroupShufflingRandom').submit();\">Tong Xiao</a>,\n</form>\n<form id=\"form-ShuaiYiDeepGroupShufflingRandom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuai Yi\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuaiYiDeepGroupShufflingRandom').submit();\">Shuai Yi</a>,\n</form>\n<form id=\"form-DapengChenDeepGroupShufflingRandom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dapeng Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-DapengChenDeepGroupShufflingRandom').submit();\">Dapeng Chen</a>,\n</form>\n<form id=\"form-XiaogangWangDeepGroupShufflingRandom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaogang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaogangWangDeepGroupShufflingRandom').submit();\">Xiaogang Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Shen_Deep_Group-Shuffling_Random_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1807.11178\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Shen_2018_CVPR,<br>\nauthor = {Shen, Yantao and Li, Hongsheng and Xiao, Tong and Yi, Shuai and Chen, Dapeng and Wang, Xiaogang},<br>\ntitle = {Deep Group-Shuffling Random Walk for Person Re-Identification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Transferable_Joint_Attribute-Identity_CVPR_2018_paper.html\">Transferable Joint Attribute-Identity Deep Learning for Unsupervised Person Re-Identification</a></dt>\n<dd>\n<form id=\"form-JingyaWangTransferableJointAttributeIdentity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jingya Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingyaWangTransferableJointAttributeIdentity').submit();\">Jingya Wang</a>,\n</form>\n<form id=\"form-XiatianZhuTransferableJointAttributeIdentity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiatian Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiatianZhuTransferableJointAttributeIdentity').submit();\">Xiatian Zhu</a>,\n</form>\n<form id=\"form-ShaogangGongTransferableJointAttributeIdentity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shaogang Gong\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShaogangGongTransferableJointAttributeIdentity').submit();\">Shaogang Gong</a>,\n</form>\n<form id=\"form-WeiLiTransferableJointAttributeIdentity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiLiTransferableJointAttributeIdentity').submit();\">Wei Li</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Transferable_Joint_Attribute-Identity_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.09786\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Jingya and Zhu, Xiatian and Gong, Shaogang and Li, Wei},<br>\ntitle = {Transferable Joint Attribute-Identity Deep Learning for Unsupervised Person Re-Identification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Harmonious_Attention_Network_CVPR_2018_paper.html\">Harmonious Attention Network for Person Re-Identification</a></dt>\n<dd>\n<form id=\"form-WeiLiHarmoniousAttentionNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiLiHarmoniousAttentionNetwork').submit();\">Wei Li</a>,\n</form>\n<form id=\"form-XiatianZhuHarmoniousAttentionNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiatian Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiatianZhuHarmoniousAttentionNetwork').submit();\">Xiatian Zhu</a>,\n</form>\n<form id=\"form-ShaogangGongHarmoniousAttentionNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shaogang Gong\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShaogangGongHarmoniousAttentionNetwork').submit();\">Shaogang Gong</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Harmonious_Attention_Network_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.08122\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Wei and Zhu, Xiatian and Gong, Shaogang},<br>\ntitle = {Harmonious Attention Network for Person Re-Identification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Shi_Real-Time_Rotation-Invariant_Face_CVPR_2018_paper.html\">Real-Time Rotation-Invariant Face Detection With Progressive Calibration Networks</a></dt>\n<dd>\n<form id=\"form-XuepengShiRealTimeRotationInvariantFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xuepeng Shi\">\n<a href=\"#\" onclick=\"document.getElementById('form-XuepengShiRealTimeRotationInvariantFace').submit();\">Xuepeng Shi</a>,\n</form>\n<form id=\"form-ShiguangShanRealTimeRotationInvariantFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shiguang Shan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShiguangShanRealTimeRotationInvariantFace').submit();\">Shiguang Shan</a>,\n</form>\n<form id=\"form-MeinaKanRealTimeRotationInvariantFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Meina Kan\">\n<a href=\"#\" onclick=\"document.getElementById('form-MeinaKanRealTimeRotationInvariantFace').submit();\">Meina Kan</a>,\n</form>\n<form id=\"form-ShuzheWuRealTimeRotationInvariantFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuzhe Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuzheWuRealTimeRotationInvariantFace').submit();\">Shuzhe Wu</a>,\n</form>\n<form id=\"form-XilinChenRealTimeRotationInvariantFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xilin Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-XilinChenRealTimeRotationInvariantFace').submit();\">Xilin Chen</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Shi_Real-Time_Rotation-Invariant_Face_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.06039\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Shi_2018_CVPR,<br>\nauthor = {Shi, Xuepeng and Shan, Shiguang and Kan, Meina and Wu, Shuzhe and Chen, Xilin},<br>\ntitle = {Real-Time Rotation-Invariant Face Detection With Progressive Calibration Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Shen_Deep_Regression_Forests_CVPR_2018_paper.html\">Deep Regression Forests for Age Estimation</a></dt>\n<dd>\n<form id=\"form-WeiShenDeepRegressionForests\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiShenDeepRegressionForests').submit();\">Wei Shen</a>,\n</form>\n<form id=\"form-YiluGuoDeepRegressionForests\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yilu Guo\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiluGuoDeepRegressionForests').submit();\">Yilu Guo</a>,\n</form>\n<form id=\"form-YanWangDeepRegressionForests\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yan Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanWangDeepRegressionForests').submit();\">Yan Wang</a>,\n</form>\n<form id=\"form-KaiZhaoDeepRegressionForests\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kai Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaiZhaoDeepRegressionForests').submit();\">Kai Zhao</a>,\n</form>\n<form id=\"form-BoWangDeepRegressionForests\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bo Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoWangDeepRegressionForests').submit();\">Bo Wang</a>,\n</form>\n<form id=\"form-AlanL.DeepRegressionForests\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alan L. Yuille\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlanL.DeepRegressionForests').submit();\">Alan L. Yuille</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Shen_Deep_Regression_Forests_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.07195\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Shen_2018_CVPR,<br>\nauthor = {Shen, Wei and Guo, Yilu and Wang, Yan and Zhao, Kai and Wang, Bo and Yuille, Alan L.},<br>\ntitle = {Deep Regression Forests for Age Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Weakly-Supervised_Deep_Convolutional_CVPR_2018_paper.html\">Weakly-Supervised Deep Convolutional Neural Network Learning for Facial Action Unit Intensity Estimation</a></dt>\n<dd>\n<form id=\"form-YongZhangWeaklySupervisedDeepConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yong Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YongZhangWeaklySupervisedDeepConvolutional').submit();\">Yong Zhang</a>,\n</form>\n<form id=\"form-WeimingDongWeaklySupervisedDeepConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weiming Dong\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeimingDongWeaklySupervisedDeepConvolutional').submit();\">Weiming Dong</a>,\n</form>\n<form id=\"form-Bao-GangHuWeaklySupervisedDeepConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bao-Gang Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Bao-GangHuWeaklySupervisedDeepConvolutional').submit();\">Bao-Gang Hu</a>,\n</form>\n<form id=\"form-QiangJiWeaklySupervisedDeepConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qiang Ji\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiangJiWeaklySupervisedDeepConvolutional').submit();\">Qiang Ji</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Weakly-Supervised_Deep_Convolutional_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1467-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Yong and Dong, Weiming and Hu, Bao-Gang and Ji, Qiang},<br>\ntitle = {Weakly-Supervised Deep Convolutional Neural Network Learning for Facial Action Unit Intensity Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Pernici_Memory_Based_Online_CVPR_2018_paper.html\">Memory Based Online Learning of Deep Representations From Video Streams</a></dt>\n<dd>\n<form id=\"form-FedericoPerniciMemoryBasedOnline\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Federico Pernici\">\n<a href=\"#\" onclick=\"document.getElementById('form-FedericoPerniciMemoryBasedOnline').submit();\">Federico Pernici</a>,\n</form>\n<form id=\"form-FedericoBartoliMemoryBasedOnline\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Federico Bartoli\">\n<a href=\"#\" onclick=\"document.getElementById('form-FedericoBartoliMemoryBasedOnline').submit();\">Federico Bartoli</a>,\n</form>\n<form id=\"form-MatteoBruniMemoryBasedOnline\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Matteo Bruni\">\n<a href=\"#\" onclick=\"document.getElementById('form-MatteoBruniMemoryBasedOnline').submit();\">Matteo Bruni</a>,\n</form>\n<form id=\"form-AlbertoDelMemoryBasedOnline\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alberto Del Bimbo\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlbertoDelMemoryBasedOnline').submit();\">Alberto Del Bimbo</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Pernici_Memory_Based_Online_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.07368\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Pernici_2018_CVPR,<br>\nauthor = {Pernici, Federico and Bartoli, Federico and Bruni, Matteo and Del Bimbo, Alberto},<br>\ntitle = {Memory Based Online Learning of Deep Representations From Video Streams},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Guo_Efficient_and_Deep_CVPR_2018_paper.html\">Efficient and Deep Person Re-Identification Using Multi-Level Similarity</a></dt>\n<dd>\n<form id=\"form-YiluanGuoEfficientandDeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yiluan Guo\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiluanGuoEfficientandDeep').submit();\">Yiluan Guo</a>,\n</form>\n<form id=\"form-Ngai-ManCheungEfficientandDeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ngai-Man Cheung\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ngai-ManCheungEfficientandDeep').submit();\">Ngai-Man Cheung</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Guo_Efficient_and_Deep_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2457-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.11353\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Guo_2018_CVPR,<br>\nauthor = {Guo, Yiluan and Cheung, Ngai-Man},<br>\ntitle = {Efficient and Deep Person Re-Identification Using Multi-Level Similarity},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xu_Multi-Level_Fusion_Based_CVPR_2018_paper.html\">Multi-Level Fusion Based 3D Object Detection From Monocular Images</a></dt>\n<dd>\n<form id=\"form-BinXuMultiLevelFusionBased\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bin Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-BinXuMultiLevelFusionBased').submit();\">Bin Xu</a>,\n</form>\n<form id=\"form-ZhenzhongChenMultiLevelFusionBased\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhenzhong Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhenzhongChenMultiLevelFusionBased').submit();\">Zhenzhong Chen</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xu_Multi-Level_Fusion_Based_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xu_2018_CVPR,<br>\nauthor = {Xu, Bin and Chen, Zhenzhong},<br>\ntitle = {Multi-Level Fusion Based 3D Object Detection From Monocular Images},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hold-Geoffroy_A_Perceptual_Measure_CVPR_2018_paper.html\">A Perceptual Measure for Deep Single Image Camera Calibration</a></dt>\n<dd>\n<form id=\"form-YannickHold-GeoffroyAPerceptualMeasure\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yannick Hold-Geoffroy\">\n<a href=\"#\" onclick=\"document.getElementById('form-YannickHold-GeoffroyAPerceptualMeasure').submit();\">Yannick Hold-Geoffroy</a>,\n</form>\n<form id=\"form-KalyanSunkavalliAPerceptualMeasure\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kalyan Sunkavalli\">\n<a href=\"#\" onclick=\"document.getElementById('form-KalyanSunkavalliAPerceptualMeasure').submit();\">Kalyan Sunkavalli</a>,\n</form>\n<form id=\"form-JonathanEisenmannAPerceptualMeasure\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jonathan Eisenmann\">\n<a href=\"#\" onclick=\"document.getElementById('form-JonathanEisenmannAPerceptualMeasure').submit();\">Jonathan Eisenmann</a>,\n</form>\n<form id=\"form-MatthewFisherAPerceptualMeasure\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Matthew Fisher\">\n<a href=\"#\" onclick=\"document.getElementById('form-MatthewFisherAPerceptualMeasure').submit();\">Matthew Fisher</a>,\n</form>\n<form id=\"form-EmilianoGambarettoAPerceptualMeasure\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Emiliano Gambaretto\">\n<a href=\"#\" onclick=\"document.getElementById('form-EmilianoGambarettoAPerceptualMeasure').submit();\">Emiliano Gambaretto</a>,\n</form>\n<form id=\"form-SunilHadapAPerceptualMeasure\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sunil Hadap\">\n<a href=\"#\" onclick=\"document.getElementById('form-SunilHadapAPerceptualMeasure').submit();\">Sunil Hadap</a>,\n</form>\n<form id=\"form-Jean-Fran\u00c3\u00a7oisLalondeAPerceptualMeasure\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jean-Fran\u00c3\u00a7ois Lalonde\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jean-Fran\u00c3\u00a7oisLalondeAPerceptualMeasure').submit();\">Jean-Fran\u00c3\u00a7ois Lalonde</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hold-Geoffroy_A_Perceptual_Measure_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.01259\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hold-Geoffroy_2018_CVPR,<br>\nauthor = {Hold-Geoffroy, Yannick and Sunkavalli, Kalyan and Eisenmann, Jonathan and Fisher, Matthew and Gambaretto, Emiliano and Hadap, Sunil and Lalonde, Jean-Fran\u00c3\u00a7ois},<br>\ntitle = {A Perceptual Measure for Deep Single Image Camera Calibration},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xiong_Learning_to_Generate_CVPR_2018_paper.html\">Learning to Generate Time-Lapse Videos Using Multi-Stage Dynamic Generative Adversarial Networks</a></dt>\n<dd>\n<form id=\"form-WeiXiongLearningtoGenerate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Xiong\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiXiongLearningtoGenerate').submit();\">Wei Xiong</a>,\n</form>\n<form id=\"form-WenhanLuoLearningtoGenerate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenhan Luo\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenhanLuoLearningtoGenerate').submit();\">Wenhan Luo</a>,\n</form>\n<form id=\"form-LinMaLearningtoGenerate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lin Ma\">\n<a href=\"#\" onclick=\"document.getElementById('form-LinMaLearningtoGenerate').submit();\">Lin Ma</a>,\n</form>\n<form id=\"form-WeiLiuLearningtoGenerate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiLiuLearningtoGenerate').submit();\">Wei Liu</a>,\n</form>\n<form id=\"form-JieboLuoLearningtoGenerate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiebo Luo\">\n<a href=\"#\" onclick=\"document.getElementById('form-JieboLuoLearningtoGenerate').submit();\">Jiebo Luo</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xiong_Learning_to_Generate_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1709.07592\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xiong_2018_CVPR,<br>\nauthor = {Xiong, Wei and Luo, Wenhan and Ma, Lin and Liu, Wei and Luo, Jiebo},<br>\ntitle = {Learning to Generate Time-Lapse Videos Using Multi-Stage Dynamic Generative Adversarial Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kligler_Document_Enhancement_Using_CVPR_2018_paper.html\">Document Enhancement Using Visibility Detection</a></dt>\n<dd>\n<form id=\"form-NetanelKliglerDocumentEnhancementUsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Netanel Kligler\">\n<a href=\"#\" onclick=\"document.getElementById('form-NetanelKliglerDocumentEnhancementUsing').submit();\">Netanel Kligler</a>,\n</form>\n<form id=\"form-SagiKatzDocumentEnhancementUsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sagi Katz\">\n<a href=\"#\" onclick=\"document.getElementById('form-SagiKatzDocumentEnhancementUsing').submit();\">Sagi Katz</a>,\n</form>\n<form id=\"form-AyelletTalDocumentEnhancementUsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ayellet Tal\">\n<a href=\"#\" onclick=\"document.getElementById('form-AyelletTalDocumentEnhancementUsing').submit();\">Ayellet Tal</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kligler_Document_Enhancement_Using_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kligler_2018_CVPR,<br>\nauthor = {Kligler, Netanel and Katz, Sagi and Tal, Ayellet},<br>\ntitle = {Document Enhancement Using Visibility Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Silva_A_Weighted_Sparse_CVPR_2018_paper.html\">A Weighted Sparse Sampling and Smoothing Frame Transition Approach for Semantic Fast-Forward First-Person Videos</a></dt>\n<dd>\n<form id=\"form-MichelSilvaAWeightedSparse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michel Silva\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichelSilvaAWeightedSparse').submit();\">Michel Silva</a>,\n</form>\n<form id=\"form-WashingtonRamosAWeightedSparse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Washington Ramos\">\n<a href=\"#\" onclick=\"document.getElementById('form-WashingtonRamosAWeightedSparse').submit();\">Washington Ramos</a>,\n</form>\n<form id=\"form-Jo\u00c3\u00a3oFerreiraAWeightedSparse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jo\u00c3\u00a3o Ferreira\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jo\u00c3\u00a3oFerreiraAWeightedSparse').submit();\">Jo\u00c3\u00a3o Ferreira</a>,\n</form>\n<form id=\"form-FelipeChamoneAWeightedSparse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Felipe Chamone\">\n<a href=\"#\" onclick=\"document.getElementById('form-FelipeChamoneAWeightedSparse').submit();\">Felipe Chamone</a>,\n</form>\n<form id=\"form-MarioCamposAWeightedSparse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mario Campos\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarioCamposAWeightedSparse').submit();\">Mario Campos</a>,\n</form>\n<form id=\"form-EricksonR.AWeightedSparse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Erickson R. Nascimento\">\n<a href=\"#\" onclick=\"document.getElementById('form-EricksonR.AWeightedSparse').submit();\">Erickson R. Nascimento</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Silva_A_Weighted_Sparse_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3780-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.08722\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Silva_2018_CVPR,<br>\nauthor = {Silva, Michel and Ramos, Washington and Ferreira, Jo\u00c3\u00a3o and Chamone, Felipe and Campos, Mario and Nascimento, Erickson R.},<br>\ntitle = {A Weighted Sparse Sampling and Smoothing Frame Transition Approach for Semantic Fast-Forward First-Person Videos},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ding_Context_Contrasted_Feature_CVPR_2018_paper.html\">Context Contrasted Feature and Gated Multi-Scale Aggregation for Scene Segmentation</a></dt>\n<dd>\n<form id=\"form-HenghuiDingContextContrastedFeature\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Henghui Ding\">\n<a href=\"#\" onclick=\"document.getElementById('form-HenghuiDingContextContrastedFeature').submit();\">Henghui Ding</a>,\n</form>\n<form id=\"form-XudongJiangContextContrastedFeature\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xudong Jiang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XudongJiangContextContrastedFeature').submit();\">Xudong Jiang</a>,\n</form>\n<form id=\"form-BingShuaiContextContrastedFeature\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bing Shuai\">\n<a href=\"#\" onclick=\"document.getElementById('form-BingShuaiContextContrastedFeature').submit();\">Bing Shuai</a>,\n</form>\n<form id=\"form-AiQunContextContrastedFeature\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ai Qun Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-AiQunContextContrastedFeature').submit();\">Ai Qun Liu</a>,\n</form>\n<form id=\"form-GangWangContextContrastedFeature\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-GangWangContextContrastedFeature').submit();\">Gang Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ding_Context_Contrasted_Feature_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ding_2018_CVPR,<br>\nauthor = {Ding, Henghui and Jiang, Xudong and Shuai, Bing and Qun Liu, Ai and Wang, Gang},<br>\ntitle = {Context Contrasted Feature and Gated Multi-Scale Aggregation for Scene Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yu_Deep_Layer_Aggregation_CVPR_2018_paper.html\">Deep Layer Aggregation</a></dt>\n<dd>\n<form id=\"form-FisherYuDeepLayerAggregation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fisher Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-FisherYuDeepLayerAggregation').submit();\">Fisher Yu</a>,\n</form>\n<form id=\"form-DequanWangDeepLayerAggregation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dequan Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-DequanWangDeepLayerAggregation').submit();\">Dequan Wang</a>,\n</form>\n<form id=\"form-EvanShelhamerDeepLayerAggregation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Evan Shelhamer\">\n<a href=\"#\" onclick=\"document.getElementById('form-EvanShelhamerDeepLayerAggregation').submit();\">Evan Shelhamer</a>,\n</form>\n<form id=\"form-TrevorDarrellDeepLayerAggregation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Trevor Darrell\">\n<a href=\"#\" onclick=\"document.getElementById('form-TrevorDarrellDeepLayerAggregation').submit();\">Trevor Darrell</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yu_Deep_Layer_Aggregation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1707.06484\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yu_2018_CVPR,<br>\nauthor = {Yu, Fisher and Wang, Dequan and Shelhamer, Evan and Darrell, Trevor},<br>\ntitle = {Deep Layer Aggregation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yang_Convolutional_Neural_Networks_CVPR_2018_paper.html\">Convolutional Neural Networks With Alternately Updated Clique</a></dt>\n<dd>\n<form id=\"form-YiboYangConvolutionalNeuralNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yibo Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiboYangConvolutionalNeuralNetworks').submit();\">Yibo Yang</a>,\n</form>\n<form id=\"form-ZhishengZhongConvolutionalNeuralNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhisheng Zhong\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhishengZhongConvolutionalNeuralNetworks').submit();\">Zhisheng Zhong</a>,\n</form>\n<form id=\"form-TianchengShenConvolutionalNeuralNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tiancheng Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-TianchengShenConvolutionalNeuralNetworks').submit();\">Tiancheng Shen</a>,\n</form>\n<form id=\"form-ZhouchenLinConvolutionalNeuralNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhouchen Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhouchenLinConvolutionalNeuralNetworks').submit();\">Zhouchen Lin</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yang_Convolutional_Neural_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.10419\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yang_2018_CVPR,<br>\nauthor = {Yang, Yibo and Zhong, Zhisheng and Shen, Tiancheng and Lin, Zhouchen},<br>\ntitle = {Convolutional Neural Networks With Alternately Updated Clique},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhong_Practical_Block-Wise_Neural_CVPR_2018_paper.html\">Practical Block-Wise Neural Network Architecture Generation</a></dt>\n<dd>\n<form id=\"form-ZhaoZhongPracticalBlockWiseNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhao Zhong\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhaoZhongPracticalBlockWiseNeural').submit();\">Zhao Zhong</a>,\n</form>\n<form id=\"form-JunjieYanPracticalBlockWiseNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junjie Yan\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunjieYanPracticalBlockWiseNeural').submit();\">Junjie Yan</a>,\n</form>\n<form id=\"form-WeiWuPracticalBlockWiseNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiWuPracticalBlockWiseNeural').submit();\">Wei Wu</a>,\n</form>\n<form id=\"form-JingShaoPracticalBlockWiseNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jing Shao\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingShaoPracticalBlockWiseNeural').submit();\">Jing Shao</a>,\n</form>\n<form id=\"form-Cheng-LinLiuPracticalBlockWiseNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cheng-Lin Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Cheng-LinLiuPracticalBlockWiseNeural').submit();\">Cheng-Lin Liu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhong_Practical_Block-Wise_Neural_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0181-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1708.05552\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhong_2018_CVPR,<br>\nauthor = {Zhong, Zhao and Yan, Junjie and Wu, Wei and Shao, Jing and Liu, Cheng-Lin},<br>\ntitle = {Practical Block-Wise Neural Network Architecture Generation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kligvasser_xUnit_Learning_a_CVPR_2018_paper.html\">xUnit: Learning a Spatial Activation Function for Efficient Image Restoration</a></dt>\n<dd>\n<form id=\"form-IdanKligvasserxUnitLearninga\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Idan Kligvasser\">\n<a href=\"#\" onclick=\"document.getElementById('form-IdanKligvasserxUnitLearninga').submit();\">Idan Kligvasser</a>,\n</form>\n<form id=\"form-TamarRottxUnitLearninga\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tamar Rott Shaham\">\n<a href=\"#\" onclick=\"document.getElementById('form-TamarRottxUnitLearninga').submit();\">Tamar Rott Shaham</a>,\n</form>\n<form id=\"form-TomerMichaelixUnitLearninga\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tomer Michaeli\">\n<a href=\"#\" onclick=\"document.getElementById('form-TomerMichaelixUnitLearninga').submit();\">Tomer Michaeli</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kligvasser_xUnit_Learning_a_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.06445\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kligvasser_2018_CVPR,<br>\nauthor = {Kligvasser, Idan and Rott Shaham, Tamar and Michaeli, Tomer},<br>\ntitle = {xUnit: Learning a Spatial Activation Function for Efficient Image Restoration},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yu_Crafting_a_Toolchain_CVPR_2018_paper.html\">Crafting a Toolchain for Image Restoration by Deep Reinforcement Learning</a></dt>\n<dd>\n<form id=\"form-KeYuCraftingaToolchain\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ke Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-KeYuCraftingaToolchain').submit();\">Ke Yu</a>,\n</form>\n<form id=\"form-ChaoDongCraftingaToolchain\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chao Dong\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChaoDongCraftingaToolchain').submit();\">Chao Dong</a>,\n</form>\n<form id=\"form-LiangLinCraftingaToolchain\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liang Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiangLinCraftingaToolchain').submit();\">Liang Lin</a>,\n</form>\n<form id=\"form-ChenChangeCraftingaToolchain\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chen Change Loy\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenChangeCraftingaToolchain').submit();\">Chen Change Loy</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yu_Crafting_a_Toolchain_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.03312\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yu_2018_CVPR,<br>\nauthor = {Yu, Ke and Dong, Chao and Lin, Liang and Change Loy, Chen},<br>\ntitle = {Crafting a Toolchain for Image Restoration by Deep Reinforcement Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Shaham_Deformation_Aware_Image_CVPR_2018_paper.html\">Deformation Aware Image Compression</a></dt>\n<dd>\n<form id=\"form-TamarRottDeformationAwareImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tamar Rott Shaham\">\n<a href=\"#\" onclick=\"document.getElementById('form-TamarRottDeformationAwareImage').submit();\">Tamar Rott Shaham</a>,\n</form>\n<form id=\"form-TomerMichaeliDeformationAwareImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tomer Michaeli\">\n<a href=\"#\" onclick=\"document.getElementById('form-TomerMichaeliDeformationAwareImage').submit();\">Tomer Michaeli</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Shaham_Deformation_Aware_Image_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2937-supp.zip\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.04593\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Shaham_2018_CVPR,<br>\nauthor = {Rott Shaham, Tamar and Michaeli, Tomer},<br>\ntitle = {Deformation Aware Image Compression},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hu_Distributable_Consistent_Multi-Object_CVPR_2018_paper.html\">Distributable Consistent Multi-Object Matching</a></dt>\n<dd>\n<form id=\"form-NanHuDistributableConsistentMultiObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nan Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-NanHuDistributableConsistentMultiObject').submit();\">Nan Hu</a>,\n</form>\n<form id=\"form-QixingHuangDistributableConsistentMultiObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qixing Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-QixingHuangDistributableConsistentMultiObject').submit();\">Qixing Huang</a>,\n</form>\n<form id=\"form-BorisThibertDistributableConsistentMultiObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Boris Thibert\">\n<a href=\"#\" onclick=\"document.getElementById('form-BorisThibertDistributableConsistentMultiObject').submit();\">Boris Thibert</a>,\n</form>\n<form id=\"form-LeonidasJ.DistributableConsistentMultiObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Leonidas J. Guibas\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeonidasJ.DistributableConsistentMultiObject').submit();\">Leonidas J. Guibas</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hu_Distributable_Consistent_Multi-Object_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1611.07191\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hu_2018_CVPR,<br>\nauthor = {Hu, Nan and Huang, Qixing and Thibert, Boris and Guibas, Leonidas J.},<br>\ntitle = {Distributable Consistent Multi-Object Matching},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Residual_Dense_Network_CVPR_2018_paper.html\">Residual Dense Network for Image Super-Resolution</a></dt>\n<dd>\n<form id=\"form-YulunZhangResidualDenseNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yulun Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YulunZhangResidualDenseNetwork').submit();\">Yulun Zhang</a>,\n</form>\n<form id=\"form-YapengTianResidualDenseNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yapeng Tian\">\n<a href=\"#\" onclick=\"document.getElementById('form-YapengTianResidualDenseNetwork').submit();\">Yapeng Tian</a>,\n</form>\n<form id=\"form-YuKongResidualDenseNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu Kong\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuKongResidualDenseNetwork').submit();\">Yu Kong</a>,\n</form>\n<form id=\"form-BinengZhongResidualDenseNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bineng Zhong\">\n<a href=\"#\" onclick=\"document.getElementById('form-BinengZhongResidualDenseNetwork').submit();\">Bineng Zhong</a>,\n</form>\n<form id=\"form-YunFuResidualDenseNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yun Fu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YunFuResidualDenseNetwork').submit();\">Yun Fu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Residual_Dense_Network_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.05902\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Yulun and Tian, Yapeng and Kong, Yu and Zhong, Bineng and Fu, Yun},<br>\ntitle = {Residual Dense Network for Image Super-Resolution},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Qian_Attentive_Generative_Adversarial_CVPR_2018_paper.html\">Attentive Generative Adversarial Network for Raindrop Removal From a Single Image</a></dt>\n<dd>\n<form id=\"form-RuiQianAttentiveGenerativeAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rui Qian\">\n<a href=\"#\" onclick=\"document.getElementById('form-RuiQianAttentiveGenerativeAdversarial').submit();\">Rui Qian</a>,\n</form>\n<form id=\"form-RobbyT.AttentiveGenerativeAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Robby T. Tan\">\n<a href=\"#\" onclick=\"document.getElementById('form-RobbyT.AttentiveGenerativeAdversarial').submit();\">Robby T. Tan</a>,\n</form>\n<form id=\"form-WenhanYangAttentiveGenerativeAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenhan Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenhanYangAttentiveGenerativeAdversarial').submit();\">Wenhan Yang</a>,\n</form>\n<form id=\"form-JiajunSuAttentiveGenerativeAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiajun Su\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiajunSuAttentiveGenerativeAdversarial').submit();\">Jiajun Su</a>,\n</form>\n<form id=\"form-JiayingLiuAttentiveGenerativeAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiaying Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiayingLiuAttentiveGenerativeAdversarial').submit();\">Jiaying Liu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Qian_Attentive_Generative_Adversarial_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.10098\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Qian_2018_CVPR,<br>\nauthor = {Qian, Rui and Tan, Robby T. and Yang, Wenhan and Su, Jiajun and Liu, Jiaying},<br>\ntitle = {Attentive Generative Adversarial Network for Raindrop Removal From a Single Image},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_FSRNet_End-to-End_Learning_CVPR_2018_paper.html\">FSRNet: End-to-End Learning Face Super-Resolution With Facial Priors</a></dt>\n<dd>\n<form id=\"form-YuChenFSRNetEndtoEndLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuChenFSRNetEndtoEndLearning').submit();\">Yu Chen</a>,\n</form>\n<form id=\"form-YingTaiFSRNetEndtoEndLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ying Tai\">\n<a href=\"#\" onclick=\"document.getElementById('form-YingTaiFSRNetEndtoEndLearning').submit();\">Ying Tai</a>,\n</form>\n<form id=\"form-XiaomingLiuFSRNetEndtoEndLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaoming Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaomingLiuFSRNetEndtoEndLearning').submit();\">Xiaoming Liu</a>,\n</form>\n<form id=\"form-ChunhuaShenFSRNetEndtoEndLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chunhua Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChunhuaShenFSRNetEndtoEndLearning').submit();\">Chunhua Shen</a>,\n</form>\n<form id=\"form-JianYangFSRNetEndtoEndLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jian Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianYangFSRNetEndtoEndLearning').submit();\">Jian Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_FSRNet_End-to-End_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.10703\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Yu and Tai, Ying and Liu, Xiaoming and Shen, Chunhua and Yang, Jian},<br>\ntitle = {FSRNet: End-to-End Learning Face Super-Resolution With Facial Priors},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Mildenhall_Burst_Denoising_With_CVPR_2018_paper.html\">Burst Denoising With Kernel Prediction Networks</a></dt>\n<dd>\n<form id=\"form-BenMildenhallBurstDenoisingWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ben Mildenhall\">\n<a href=\"#\" onclick=\"document.getElementById('form-BenMildenhallBurstDenoisingWith').submit();\">Ben Mildenhall</a>,\n</form>\n<form id=\"form-JonathanT.BurstDenoisingWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jonathan T. Barron\">\n<a href=\"#\" onclick=\"document.getElementById('form-JonathanT.BurstDenoisingWith').submit();\">Jonathan T. Barron</a>,\n</form>\n<form id=\"form-JiawenChenBurstDenoisingWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiawen Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiawenChenBurstDenoisingWith').submit();\">Jiawen Chen</a>,\n</form>\n<form id=\"form-DillonSharletBurstDenoisingWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dillon Sharlet\">\n<a href=\"#\" onclick=\"document.getElementById('form-DillonSharletBurstDenoisingWith').submit();\">Dillon Sharlet</a>,\n</form>\n<form id=\"form-RenNgBurstDenoisingWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ren Ng\">\n<a href=\"#\" onclick=\"document.getElementById('form-RenNgBurstDenoisingWith').submit();\">Ren Ng</a>,\n</form>\n<form id=\"form-RobertCarrollBurstDenoisingWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Robert Carroll\">\n<a href=\"#\" onclick=\"document.getElementById('form-RobertCarrollBurstDenoisingWith').submit();\">Robert Carroll</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Mildenhall_Burst_Denoising_With_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3761-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.02327\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Mildenhall_2018_CVPR,<br>\nauthor = {Mildenhall, Ben and Barron, Jonathan T. and Chen, Jiawen and Sharlet, Dillon and Ng, Ren and Carroll, Robert},<br>\ntitle = {Burst Denoising With Kernel Prediction Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Qu_Unsupervised_Sparse_Dirichlet-Net_CVPR_2018_paper.html\">Unsupervised Sparse Dirichlet-Net for Hyperspectral Image Super-Resolution</a></dt>\n<dd>\n<form id=\"form-YingQuUnsupervisedSparseDirichletNet\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ying Qu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YingQuUnsupervisedSparseDirichletNet').submit();\">Ying Qu</a>,\n</form>\n<form id=\"form-HairongQiUnsupervisedSparseDirichletNet\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hairong Qi\">\n<a href=\"#\" onclick=\"document.getElementById('form-HairongQiUnsupervisedSparseDirichletNet').submit();\">Hairong Qi</a>,\n</form>\n<form id=\"form-ChimanKwanUnsupervisedSparseDirichletNet\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chiman Kwan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChimanKwanUnsupervisedSparseDirichletNet').submit();\">Chiman Kwan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Qu_Unsupervised_Sparse_Dirichlet-Net_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.05042\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Qu_2018_CVPR,<br>\nauthor = {Qu, Ying and Qi, Hairong and Kwan, Chiman},<br>\ntitle = {Unsupervised Sparse Dirichlet-Net for Hyperspectral Image Super-Resolution},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Dynamic_Scene_Deblurring_CVPR_2018_paper.html\">Dynamic Scene Deblurring Using Spatially Variant Recurrent Neural Networks</a></dt>\n<dd>\n<form id=\"form-JiaweiZhangDynamicSceneDeblurring\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiawei Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiaweiZhangDynamicSceneDeblurring').submit();\">Jiawei Zhang</a>,\n</form>\n<form id=\"form-JinshanPanDynamicSceneDeblurring\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jinshan Pan\">\n<a href=\"#\" onclick=\"document.getElementById('form-JinshanPanDynamicSceneDeblurring').submit();\">Jinshan Pan</a>,\n</form>\n<form id=\"form-JimmyRenDynamicSceneDeblurring\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jimmy Ren\">\n<a href=\"#\" onclick=\"document.getElementById('form-JimmyRenDynamicSceneDeblurring').submit();\">Jimmy Ren</a>,\n</form>\n<form id=\"form-YibingSongDynamicSceneDeblurring\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yibing Song\">\n<a href=\"#\" onclick=\"document.getElementById('form-YibingSongDynamicSceneDeblurring').submit();\">Yibing Song</a>,\n</form>\n<form id=\"form-LinchaoBaoDynamicSceneDeblurring\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Linchao Bao\">\n<a href=\"#\" onclick=\"document.getElementById('form-LinchaoBaoDynamicSceneDeblurring').submit();\">Linchao Bao</a>,\n</form>\n<form id=\"form-RynsonW.H.DynamicSceneDeblurring\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rynson W.H. Lau\">\n<a href=\"#\" onclick=\"document.getElementById('form-RynsonW.H.DynamicSceneDeblurring').submit();\">Rynson W.H. Lau</a>,\n</form>\n<form id=\"form-Ming-HsuanYangDynamicSceneDeblurring\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming-Hsuan Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ming-HsuanYangDynamicSceneDeblurring').submit();\">Ming-Hsuan Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Dynamic_Scene_Deblurring_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Jiawei and Pan, Jinshan and Ren, Jimmy and Song, Yibing and Bao, Linchao and Lau, Rynson W.H. and Yang, Ming-Hsuan},<br>\ntitle = {Dynamic Scene Deblurring Using Spatially Variant Recurrent Neural Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Su_SPLATNet_Sparse_Lattice_CVPR_2018_paper.html\">SPLATNet: Sparse Lattice Networks for Point Cloud Processing</a></dt>\n<dd>\n<form id=\"form-HangSuSPLATNetSparseLattice\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hang Su\">\n<a href=\"#\" onclick=\"document.getElementById('form-HangSuSPLATNetSparseLattice').submit();\">Hang Su</a>,\n</form>\n<form id=\"form-VarunJampaniSPLATNetSparseLattice\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Varun Jampani\">\n<a href=\"#\" onclick=\"document.getElementById('form-VarunJampaniSPLATNetSparseLattice').submit();\">Varun Jampani</a>,\n</form>\n<form id=\"form-DeqingSunSPLATNetSparseLattice\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Deqing Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-DeqingSunSPLATNetSparseLattice').submit();\">Deqing Sun</a>,\n</form>\n<form id=\"form-SubhransuMajiSPLATNetSparseLattice\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Subhransu Maji\">\n<a href=\"#\" onclick=\"document.getElementById('form-SubhransuMajiSPLATNetSparseLattice').submit();\">Subhransu Maji</a>,\n</form>\n<form id=\"form-EvangelosKalogerakisSPLATNetSparseLattice\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Evangelos Kalogerakis\">\n<a href=\"#\" onclick=\"document.getElementById('form-EvangelosKalogerakisSPLATNetSparseLattice').submit();\">Evangelos Kalogerakis</a>,\n</form>\n<form id=\"form-Ming-HsuanYangSPLATNetSparseLattice\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming-Hsuan Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ming-HsuanYangSPLATNetSparseLattice').submit();\">Ming-Hsuan Yang</a>,\n</form>\n<form id=\"form-JanKautzSPLATNetSparseLattice\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jan Kautz\">\n<a href=\"#\" onclick=\"document.getElementById('form-JanKautzSPLATNetSparseLattice').submit();\">Jan Kautz</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Su_SPLATNet_Sparse_Lattice_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0326-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.08275\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Su_2018_CVPR,<br>\nauthor = {Su, Hang and Jampani, Varun and Sun, Deqing and Maji, Subhransu and Kalogerakis, Evangelos and Yang, Ming-Hsuan and Kautz, Jan},<br>\ntitle = {SPLATNet: Sparse Lattice Networks for Point Cloud Processing},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kostrikov_Surface_Networks_CVPR_2018_paper.html\">Surface Networks</a></dt>\n<dd>\n<form id=\"form-IlyaKostrikovSurfaceNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ilya Kostrikov\">\n<a href=\"#\" onclick=\"document.getElementById('form-IlyaKostrikovSurfaceNetworks').submit();\">Ilya Kostrikov</a>,\n</form>\n<form id=\"form-ZhongshiJiangSurfaceNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhongshi Jiang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhongshiJiangSurfaceNetworks').submit();\">Zhongshi Jiang</a>,\n</form>\n<form id=\"form-DanielePanozzoSurfaceNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daniele Panozzo\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanielePanozzoSurfaceNetworks').submit();\">Daniele Panozzo</a>,\n</form>\n<form id=\"form-DenisZorinSurfaceNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Denis Zorin\">\n<a href=\"#\" onclick=\"document.getElementById('form-DenisZorinSurfaceNetworks').submit();\">Denis Zorin</a>,\n</form>\n<form id=\"form-JoanBrunaSurfaceNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Joan Bruna\">\n<a href=\"#\" onclick=\"document.getElementById('form-JoanBrunaSurfaceNetworks').submit();\">Joan Bruna</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kostrikov_Surface_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3318-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1807.01697\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kostrikov_2018_CVPR,<br>\nauthor = {Kostrikov, Ilya and Jiang, Zhongshi and Panozzo, Daniele and Zorin, Denis and Bruna, Joan},<br>\ntitle = {Surface Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tewari_Self-Supervised_Multi-Level_Face_CVPR_2018_paper.html\">Self-Supervised Multi-Level Face Model Learning for Monocular Reconstruction at Over 250 Hz</a></dt>\n<dd>\n<form id=\"form-AyushTewariSelfSupervisedMultiLevelFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ayush Tewari\">\n<a href=\"#\" onclick=\"document.getElementById('form-AyushTewariSelfSupervisedMultiLevelFace').submit();\">Ayush Tewari</a>,\n</form>\n<form id=\"form-MichaelZollh\u00c3\u00b6ferSelfSupervisedMultiLevelFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michael Zollh\u00c3\u00b6fer\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichaelZollh\u00c3\u00b6ferSelfSupervisedMultiLevelFace').submit();\">Michael Zollh\u00c3\u00b6fer</a>,\n</form>\n<form id=\"form-PabloGarridoSelfSupervisedMultiLevelFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pablo Garrido\">\n<a href=\"#\" onclick=\"document.getElementById('form-PabloGarridoSelfSupervisedMultiLevelFace').submit();\">Pablo Garrido</a>,\n</form>\n<form id=\"form-FlorianBernardSelfSupervisedMultiLevelFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Florian Bernard\">\n<a href=\"#\" onclick=\"document.getElementById('form-FlorianBernardSelfSupervisedMultiLevelFace').submit();\">Florian Bernard</a>,\n</form>\n<form id=\"form-HyeongwooKimSelfSupervisedMultiLevelFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hyeongwoo Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-HyeongwooKimSelfSupervisedMultiLevelFace').submit();\">Hyeongwoo Kim</a>,\n</form>\n<form id=\"form-PatrickP\u00c3\u00a9rezSelfSupervisedMultiLevelFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Patrick P\u00c3\u00a9rez\">\n<a href=\"#\" onclick=\"document.getElementById('form-PatrickP\u00c3\u00a9rezSelfSupervisedMultiLevelFace').submit();\">Patrick P\u00c3\u00a9rez</a>,\n</form>\n<form id=\"form-ChristianTheobaltSelfSupervisedMultiLevelFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Christian Theobalt\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChristianTheobaltSelfSupervisedMultiLevelFace').submit();\">Christian Theobalt</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tewari_Self-Supervised_Multi-Level_Face_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3099-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.02859\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tewari_2018_CVPR,<br>\nauthor = {Tewari, Ayush and Zollh\u00c3\u00b6fer, Michael and Garrido, Pablo and Bernard, Florian and Kim, Hyeongwoo and P\u00c3\u00a9rez, Patrick and Theobalt, Christian},<br>\ntitle = {Self-Supervised Multi-Level Face Model Learning for Monocular Reconstruction at Over 250 Hz},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Bloesch_CodeSLAM_--_Learning_CVPR_2018_paper.html\">CodeSLAM \u00e2\u0080\u0094 Learning a Compact, Optimisable Representation for Dense Visual SLAM</a></dt>\n<dd>\n<form id=\"form-MichaelBloeschCodeSLAMLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michael Bloesch\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichaelBloeschCodeSLAMLearning').submit();\">Michael Bloesch</a>,\n</form>\n<form id=\"form-JanCzarnowskiCodeSLAMLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jan Czarnowski\">\n<a href=\"#\" onclick=\"document.getElementById('form-JanCzarnowskiCodeSLAMLearning').submit();\">Jan Czarnowski</a>,\n</form>\n<form id=\"form-RonaldClarkCodeSLAMLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ronald Clark\">\n<a href=\"#\" onclick=\"document.getElementById('form-RonaldClarkCodeSLAMLearning').submit();\">Ronald Clark</a>,\n</form>\n<form id=\"form-StefanLeuteneggerCodeSLAMLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stefan Leutenegger\">\n<a href=\"#\" onclick=\"document.getElementById('form-StefanLeuteneggerCodeSLAMLearning').submit();\">Stefan Leutenegger</a>,\n</form>\n<form id=\"form-AndrewJ.CodeSLAMLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrew J. Davison\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndrewJ.CodeSLAMLearning').submit();\">Andrew J. Davison</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Bloesch_CodeSLAM_--_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3124-supp.zip\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Bloesch_2018_CVPR,<br>\nauthor = {Bloesch, Michael and Czarnowski, Jan and Clark, Ronald and Leutenegger, Stefan and Davison, Andrew J.},<br>\ntitle = {CodeSLAM \u00e2\u0080\u0094 Learning a Compact, Optimisable Representation for Dense Visual SLAM},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_SGPN_Similarity_Group_CVPR_2018_paper.html\">SGPN: Similarity Group Proposal Network for 3D Point Cloud Instance Segmentation</a></dt>\n<dd>\n<form id=\"form-WeiyueWangSGPNSimilarityGroup\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weiyue Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiyueWangSGPNSimilarityGroup').submit();\">Weiyue Wang</a>,\n</form>\n<form id=\"form-RonaldYuSGPNSimilarityGroup\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ronald Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-RonaldYuSGPNSimilarityGroup').submit();\">Ronald Yu</a>,\n</form>\n<form id=\"form-QianguiHuangSGPNSimilarityGroup\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qiangui Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-QianguiHuangSGPNSimilarityGroup').submit();\">Qiangui Huang</a>,\n</form>\n<form id=\"form-UlrichNeumannSGPNSimilarityGroup\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ulrich Neumann\">\n<a href=\"#\" onclick=\"document.getElementById('form-UlrichNeumannSGPNSimilarityGroup').submit();\">Ulrich Neumann</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_SGPN_Similarity_Group_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0967-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.08588\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Weiyue and Yu, Ronald and Huang, Qiangui and Neumann, Ulrich},<br>\ntitle = {SGPN: Similarity Group Proposal Network for 3D Point Cloud Instance Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_PlaneNet_Piece-Wise_Planar_CVPR_2018_paper.html\">PlaneNet: Piece-Wise Planar Reconstruction From a Single RGB Image</a></dt>\n<dd>\n<form id=\"form-ChenLiuPlaneNetPieceWisePlanar\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chen Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenLiuPlaneNetPieceWisePlanar').submit();\">Chen Liu</a>,\n</form>\n<form id=\"form-JimeiYangPlaneNetPieceWisePlanar\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jimei Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JimeiYangPlaneNetPieceWisePlanar').submit();\">Jimei Yang</a>,\n</form>\n<form id=\"form-DuyguCeylanPlaneNetPieceWisePlanar\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Duygu Ceylan\">\n<a href=\"#\" onclick=\"document.getElementById('form-DuyguCeylanPlaneNetPieceWisePlanar').submit();\">Duygu Ceylan</a>,\n</form>\n<form id=\"form-ErsinYumerPlaneNetPieceWisePlanar\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ersin Yumer\">\n<a href=\"#\" onclick=\"document.getElementById('form-ErsinYumerPlaneNetPieceWisePlanar').submit();\">Ersin Yumer</a>,\n</form>\n<form id=\"form-YasutakaFurukawaPlaneNetPieceWisePlanar\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yasutaka Furukawa\">\n<a href=\"#\" onclick=\"document.getElementById('form-YasutakaFurukawaPlaneNetPieceWisePlanar').submit();\">Yasutaka Furukawa</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_PlaneNet_Piece-Wise_Planar_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1584-supp.zip\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.06278\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Chen and Yang, Jimei and Ceylan, Duygu and Yumer, Ersin and Furukawa, Yasutaka},<br>\ntitle = {PlaneNet: Piece-Wise Planar Reconstruction From a Single RGB Image},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Deep_Parametric_Continuous_CVPR_2018_paper.html\">Deep Parametric Continuous Convolutional Neural Networks</a></dt>\n<dd>\n<form id=\"form-ShenlongWangDeepParametricContinuous\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shenlong Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShenlongWangDeepParametricContinuous').submit();\">Shenlong Wang</a>,\n</form>\n<form id=\"form-SimonSuoDeepParametricContinuous\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Simon Suo\">\n<a href=\"#\" onclick=\"document.getElementById('form-SimonSuoDeepParametricContinuous').submit();\">Simon Suo</a>,\n</form>\n<form id=\"form-Wei-ChiuMaDeepParametricContinuous\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei-Chiu Ma\">\n<a href=\"#\" onclick=\"document.getElementById('form-Wei-ChiuMaDeepParametricContinuous').submit();\">Wei-Chiu Ma</a>,\n</form>\n<form id=\"form-AndreiPokrovskyDeepParametricContinuous\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrei Pokrovsky\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndreiPokrovskyDeepParametricContinuous').submit();\">Andrei Pokrovsky</a>,\n</form>\n<form id=\"form-RaquelUrtasunDeepParametricContinuous\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Raquel Urtasun\">\n<a href=\"#\" onclick=\"document.getElementById('form-RaquelUrtasunDeepParametricContinuous').submit();\">Raquel Urtasun</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Deep_Parametric_Continuous_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Shenlong and Suo, Simon and Ma, Wei-Chiu and Pokrovsky, Andrei and Urtasun, Raquel},<br>\ntitle = {Deep Parametric Continuous Convolutional Neural Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Verma_FeaStNet_Feature-Steered_Graph_CVPR_2018_paper.html\">FeaStNet: Feature-Steered Graph Convolutions for 3D Shape Analysis</a></dt>\n<dd>\n<form id=\"form-NitikaVermaFeaStNetFeatureSteeredGraph\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nitika Verma\">\n<a href=\"#\" onclick=\"document.getElementById('form-NitikaVermaFeaStNetFeatureSteeredGraph').submit();\">Nitika Verma</a>,\n</form>\n<form id=\"form-EdmondBoyerFeaStNetFeatureSteeredGraph\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Edmond Boyer\">\n<a href=\"#\" onclick=\"document.getElementById('form-EdmondBoyerFeaStNetFeatureSteeredGraph').submit();\">Edmond Boyer</a>,\n</form>\n<form id=\"form-JakobVerbeekFeaStNetFeatureSteeredGraph\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jakob Verbeek\">\n<a href=\"#\" onclick=\"document.getElementById('form-JakobVerbeekFeaStNetFeatureSteeredGraph').submit();\">Jakob Verbeek</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Verma_FeaStNet_Feature-Steered_Graph_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2589-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1706.05206\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Verma_2018_CVPR,<br>\nauthor = {Verma, Nitika and Boyer, Edmond and Verbeek, Jakob},<br>\ntitle = {FeaStNet: Feature-Steered Graph Convolutions for 3D Shape Analysis},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Agudo_Image_Collection_Pop-Up_CVPR_2018_paper.html\">Image Collection Pop-Up: 3D Reconstruction and Clustering of Rigid and Non-Rigid Categories</a></dt>\n<dd>\n<form id=\"form-AntonioAgudoImageCollectionPopUp\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Antonio Agudo\">\n<a href=\"#\" onclick=\"document.getElementById('form-AntonioAgudoImageCollectionPopUp').submit();\">Antonio Agudo</a>,\n</form>\n<form id=\"form-MelciorPijoanImageCollectionPopUp\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Melcior Pijoan\">\n<a href=\"#\" onclick=\"document.getElementById('form-MelciorPijoanImageCollectionPopUp').submit();\">Melcior Pijoan</a>,\n</form>\n<form id=\"form-FrancescMoreno-NoguerImageCollectionPopUp\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Francesc Moreno-Noguer\">\n<a href=\"#\" onclick=\"document.getElementById('form-FrancescMoreno-NoguerImageCollectionPopUp').submit();\">Francesc Moreno-Noguer</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Agudo_Image_Collection_Pop-Up_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Agudo_2018_CVPR,<br>\nauthor = {Agudo, Antonio and Pijoan, Melcior and Moreno-Noguer, Francesc},<br>\ntitle = {Image Collection Pop-Up: 3D Reconstruction and Clustering of Rigid and Non-Rigid Categories},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Brahmbhatt_Geometry-Aware_Learning_of_CVPR_2018_paper.html\">Geometry-Aware Learning of Maps for Camera Localization</a></dt>\n<dd>\n<form id=\"form-SamarthBrahmbhattGeometryAwareLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Samarth Brahmbhatt\">\n<a href=\"#\" onclick=\"document.getElementById('form-SamarthBrahmbhattGeometryAwareLearningof').submit();\">Samarth Brahmbhatt</a>,\n</form>\n<form id=\"form-JinweiGuGeometryAwareLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jinwei Gu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JinweiGuGeometryAwareLearningof').submit();\">Jinwei Gu</a>,\n</form>\n<form id=\"form-KihwanKimGeometryAwareLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kihwan Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-KihwanKimGeometryAwareLearningof').submit();\">Kihwan Kim</a>,\n</form>\n<form id=\"form-JamesHaysGeometryAwareLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"James Hays\">\n<a href=\"#\" onclick=\"document.getElementById('form-JamesHaysGeometryAwareLearningof').submit();\">James Hays</a>,\n</form>\n<form id=\"form-JanKautzGeometryAwareLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jan Kautz\">\n<a href=\"#\" onclick=\"document.getElementById('form-JanKautzGeometryAwareLearningof').submit();\">Jan Kautz</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Brahmbhatt_Geometry-Aware_Learning_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0168-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.03342\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Brahmbhatt_2018_CVPR,<br>\nauthor = {Brahmbhatt, Samarth and Gu, Jinwei and Kim, Kihwan and Hays, James and Kautz, Jan},<br>\ntitle = {Geometry-Aware Learning of Maps for Camera Localization},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Huang_Recurrent_Slice_Networks_CVPR_2018_paper.html\">Recurrent Slice Networks for 3D Segmentation of Point Clouds</a></dt>\n<dd>\n<form id=\"form-QianguiHuangRecurrentSliceNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qiangui Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-QianguiHuangRecurrentSliceNetworks').submit();\">Qiangui Huang</a>,\n</form>\n<form id=\"form-WeiyueWangRecurrentSliceNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weiyue Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiyueWangRecurrentSliceNetworks').submit();\">Weiyue Wang</a>,\n</form>\n<form id=\"form-UlrichNeumannRecurrentSliceNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ulrich Neumann\">\n<a href=\"#\" onclick=\"document.getElementById('form-UlrichNeumannRecurrentSliceNetworks').submit();\">Ulrich Neumann</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Huang_Recurrent_Slice_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2058-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.04402\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Huang_2018_CVPR,<br>\nauthor = {Huang, Qiangui and Wang, Weiyue and Neumann, Ulrich},<br>\ntitle = {Recurrent Slice Networks for 3D Segmentation of Point Clouds},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yuan_Depth-Based_3D_Hand_CVPR_2018_paper.html\">Depth-Based 3D Hand Pose Estimation: From Current Achievements to Future Goals</a></dt>\n<dd>\n<form id=\"form-ShanxinYuanDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shanxin Yuan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShanxinYuanDepthBased3DHand').submit();\">Shanxin Yuan</a>,\n</form>\n<form id=\"form-GuillermoGarcia-HernandoDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guillermo Garcia-Hernando\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuillermoGarcia-HernandoDepthBased3DHand').submit();\">Guillermo Garcia-Hernando</a>,\n</form>\n<form id=\"form-Bj\u00c3\u00b6rnStengerDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bj\u00c3\u00b6rn Stenger\">\n<a href=\"#\" onclick=\"document.getElementById('form-Bj\u00c3\u00b6rnStengerDepthBased3DHand').submit();\">Bj\u00c3\u00b6rn Stenger</a>,\n</form>\n<form id=\"form-GyeongsikMoonDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gyeongsik Moon\">\n<a href=\"#\" onclick=\"document.getElementById('form-GyeongsikMoonDepthBased3DHand').submit();\">Gyeongsik Moon</a>,\n</form>\n<form id=\"form-JuYongDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ju Yong Chang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JuYongDepthBased3DHand').submit();\">Ju Yong Chang</a>,\n</form>\n<form id=\"form-KyoungMuDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kyoung Mu Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-KyoungMuDepthBased3DHand').submit();\">Kyoung Mu Lee</a>,\n</form>\n<form id=\"form-PavloMolchanovDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pavlo Molchanov\">\n<a href=\"#\" onclick=\"document.getElementById('form-PavloMolchanovDepthBased3DHand').submit();\">Pavlo Molchanov</a>,\n</form>\n<form id=\"form-JanKautzDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jan Kautz\">\n<a href=\"#\" onclick=\"document.getElementById('form-JanKautzDepthBased3DHand').submit();\">Jan Kautz</a>,\n</form>\n<form id=\"form-SinaHonariDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sina Honari\">\n<a href=\"#\" onclick=\"document.getElementById('form-SinaHonariDepthBased3DHand').submit();\">Sina Honari</a>,\n</form>\n<form id=\"form-LiuhaoGeDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liuhao Ge\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiuhaoGeDepthBased3DHand').submit();\">Liuhao Ge</a>,\n</form>\n<form id=\"form-JunsongYuanDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junsong Yuan\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunsongYuanDepthBased3DHand').submit();\">Junsong Yuan</a>,\n</form>\n<form id=\"form-XinghaoChenDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xinghao Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinghaoChenDepthBased3DHand').submit();\">Xinghao Chen</a>,\n</form>\n<form id=\"form-GuijinWangDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guijin Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuijinWangDepthBased3DHand').submit();\">Guijin Wang</a>,\n</form>\n<form id=\"form-FanYangDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fan Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-FanYangDepthBased3DHand').submit();\">Fan Yang</a>,\n</form>\n<form id=\"form-KaiAkiyamaDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kai Akiyama\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaiAkiyamaDepthBased3DHand').submit();\">Kai Akiyama</a>,\n</form>\n<form id=\"form-YangWuDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yang Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YangWuDepthBased3DHand').submit();\">Yang Wu</a>,\n</form>\n<form id=\"form-QingfuWanDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qingfu Wan\">\n<a href=\"#\" onclick=\"document.getElementById('form-QingfuWanDepthBased3DHand').submit();\">Qingfu Wan</a>,\n</form>\n<form id=\"form-MeysamMadadiDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Meysam Madadi\">\n<a href=\"#\" onclick=\"document.getElementById('form-MeysamMadadiDepthBased3DHand').submit();\">Meysam Madadi</a>,\n</form>\n<form id=\"form-SergioEscaleraDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sergio Escalera\">\n<a href=\"#\" onclick=\"document.getElementById('form-SergioEscaleraDepthBased3DHand').submit();\">Sergio Escalera</a>,\n</form>\n<form id=\"form-ShileLiDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shile Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShileLiDepthBased3DHand').submit();\">Shile Li</a>,\n</form>\n<form id=\"form-DongheuiLeeDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dongheui Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-DongheuiLeeDepthBased3DHand').submit();\">Dongheui Lee</a>,\n</form>\n<form id=\"form-IasonOikonomidisDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Iason Oikonomidis\">\n<a href=\"#\" onclick=\"document.getElementById('form-IasonOikonomidisDepthBased3DHand').submit();\">Iason Oikonomidis</a>,\n</form>\n<form id=\"form-AntonisArgyrosDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Antonis Argyros\">\n<a href=\"#\" onclick=\"document.getElementById('form-AntonisArgyrosDepthBased3DHand').submit();\">Antonis Argyros</a>,\n</form>\n<form id=\"form-Tae-KyunKimDepthBased3DHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tae-Kyun Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-Tae-KyunKimDepthBased3DHand').submit();\">Tae-Kyun Kim</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yuan_Depth-Based_3D_Hand_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.03917\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yuan_2018_CVPR,<br>\nauthor = {Yuan, Shanxin and Garcia-Hernando, Guillermo and Stenger, Bj\u00c3\u00b6rn and Moon, Gyeongsik and Yong Chang, Ju and Mu Lee, Kyoung and Molchanov, Pavlo and Kautz, Jan and Honari, Sina and Ge, Liuhao and Yuan, Junsong and Chen, Xinghao and Wang, Guijin and Yang, Fan and Akiyama, Kai and Wu, Yang and Wan, Qingfu and Madadi, Meysam and Escalera, Sergio and Li, Shile and Lee, Dongheui and Oikonomidis, Iason and Argyros, Antonis and Kim, Tae-Kyun},<br>\ntitle = {Depth-Based 3D Hand Pose Estimation: From Current Achievements to Future Goals},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Slavcheva_SobolevFusion_3D_Reconstruction_CVPR_2018_paper.html\">SobolevFusion: 3D Reconstruction of Scenes Undergoing Free Non-Rigid Motion</a></dt>\n<dd>\n<form id=\"form-MiroslavaSlavchevaSobolevFusion3DReconstruction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Miroslava Slavcheva\">\n<a href=\"#\" onclick=\"document.getElementById('form-MiroslavaSlavchevaSobolevFusion3DReconstruction').submit();\">Miroslava Slavcheva</a>,\n</form>\n<form id=\"form-MaximilianBaustSobolevFusion3DReconstruction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Maximilian Baust\">\n<a href=\"#\" onclick=\"document.getElementById('form-MaximilianBaustSobolevFusion3DReconstruction').submit();\">Maximilian Baust</a>,\n</form>\n<form id=\"form-SlobodanIlicSobolevFusion3DReconstruction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Slobodan Ilic\">\n<a href=\"#\" onclick=\"document.getElementById('form-SlobodanIlicSobolevFusion3DReconstruction').submit();\">Slobodan Ilic</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Slavcheva_SobolevFusion_3D_Reconstruction_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1101-supp.zip\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Slavcheva_2018_CVPR,<br>\nauthor = {Slavcheva, Miroslava and Baust, Maximilian and Ilic, Slobodan},<br>\ntitle = {SobolevFusion: 3D Reconstruction of Scenes Undergoing Free Non-Rigid Motion},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kundu_AdaDepth_Unsupervised_content_cvpr_2018_paper.html\">AdaDepth: Unsupervised Content Congruent Adaptation for Depth Estimation</a></dt>\n<dd>\n<form id=\"form-JogendraNathAdaDepthUnsupervisedContent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jogendra Nath Kundu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JogendraNathAdaDepthUnsupervisedContent').submit();\">Jogendra Nath Kundu</a>,\n</form>\n<form id=\"form-PhaniKrishnaAdaDepthUnsupervisedContent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Phani Krishna Uppala\">\n<a href=\"#\" onclick=\"document.getElementById('form-PhaniKrishnaAdaDepthUnsupervisedContent').submit();\">Phani Krishna Uppala</a>,\n</form>\n<form id=\"form-AnujPahujaAdaDepthUnsupervisedContent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anuj Pahuja\">\n<a href=\"#\" onclick=\"document.getElementById('form-AnujPahujaAdaDepthUnsupervisedContent').submit();\">Anuj Pahuja</a>,\n</form>\n<form id=\"form-R.VenkateshAdaDepthUnsupervisedContent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"R. Venkatesh Babu\">\n<a href=\"#\" onclick=\"document.getElementById('form-R.VenkateshAdaDepthUnsupervisedContent').submit();\">R. Venkatesh Babu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kundu_AdaDepth_Unsupervised_content_cvpr_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2583-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.01599\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kundu_2018_CVPR,<br>\nauthor = {Nath Kundu, Jogendra and Krishna Uppala, Phani and Pahuja, Anuj and Venkatesh Babu, R.},<br>\ntitle = {AdaDepth: Unsupervised Content Congruent Adaptation for Depth Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yi_Learning_to_Find_CVPR_2018_paper.html\">Learning to Find Good Correspondences</a></dt>\n<dd>\n<form id=\"form-KwangMooLearningtoFind\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kwang Moo Yi\">\n<a href=\"#\" onclick=\"document.getElementById('form-KwangMooLearningtoFind').submit();\">Kwang Moo Yi</a>,\n</form>\n<form id=\"form-EduardTrullsLearningtoFind\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Eduard Trulls\">\n<a href=\"#\" onclick=\"document.getElementById('form-EduardTrullsLearningtoFind').submit();\">Eduard Trulls</a>,\n</form>\n<form id=\"form-YukiOnoLearningtoFind\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuki Ono\">\n<a href=\"#\" onclick=\"document.getElementById('form-YukiOnoLearningtoFind').submit();\">Yuki Ono</a>,\n</form>\n<form id=\"form-VincentLepetitLearningtoFind\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vincent Lepetit\">\n<a href=\"#\" onclick=\"document.getElementById('form-VincentLepetitLearningtoFind').submit();\">Vincent Lepetit</a>,\n</form>\n<form id=\"form-MathieuSalzmannLearningtoFind\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mathieu Salzmann\">\n<a href=\"#\" onclick=\"document.getElementById('form-MathieuSalzmannLearningtoFind').submit();\">Mathieu Salzmann</a>,\n</form>\n<form id=\"form-PascalFuaLearningtoFind\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pascal Fua\">\n<a href=\"#\" onclick=\"document.getElementById('form-PascalFuaLearningtoFind').submit();\">Pascal Fua</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yi_Learning_to_Find_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1453-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.05971\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yi_2018_CVPR,<br>\nauthor = {Moo Yi, Kwang and Trulls, Eduard and Ono, Yuki and Lepetit, Vincent and Salzmann, Mathieu and Fua, Pascal},<br>\ntitle = {Learning to Find Good Correspondences},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Korman_OATM_Occlusion_Aware_CVPR_2018_paper.html\">OATM: Occlusion Aware Template Matching by Consensus Set Maximization</a></dt>\n<dd>\n<form id=\"form-SimonKormanOATMOcclusionAware\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Simon Korman\">\n<a href=\"#\" onclick=\"document.getElementById('form-SimonKormanOATMOcclusionAware').submit();\">Simon Korman</a>,\n</form>\n<form id=\"form-MarkMilamOATMOcclusionAware\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mark Milam\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarkMilamOATMOcclusionAware').submit();\">Mark Milam</a>,\n</form>\n<form id=\"form-StefanoSoattoOATMOcclusionAware\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stefano Soatto\">\n<a href=\"#\" onclick=\"document.getElementById('form-StefanoSoattoOATMOcclusionAware').submit();\">Stefano Soatto</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Korman_OATM_Occlusion_Aware_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.02638\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Korman_2018_CVPR,<br>\nauthor = {Korman, Simon and Milam, Mark and Soatto, Stefano},<br>\ntitle = {OATM: Occlusion Aware Template Matching by Consensus Set Maximization},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zanfir_Deep_Learning_of_CVPR_2018_paper.html\">Deep Learning of Graph Matching</a></dt>\n<dd>\n<form id=\"form-AndreiZanfirDeepLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrei Zanfir\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndreiZanfirDeepLearningof').submit();\">Andrei Zanfir</a>,\n</form>\n<form id=\"form-CristianSminchisescuDeepLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cristian Sminchisescu\">\n<a href=\"#\" onclick=\"document.getElementById('form-CristianSminchisescuDeepLearningof').submit();\">Cristian Sminchisescu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zanfir_Deep_Learning_of_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zanfir_2018_CVPR,<br>\nauthor = {Zanfir, Andrei and Sminchisescu, Cristian},<br>\ntitle = {Deep Learning of Graph Matching},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Unsupervised_Discovery_of_CVPR_2018_paper.html\">Unsupervised Discovery of Object Landmarks as Structural Representations</a></dt>\n<dd>\n<form id=\"form-YutingZhangUnsupervisedDiscoveryof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuting Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YutingZhangUnsupervisedDiscoveryof').submit();\">Yuting Zhang</a>,\n</form>\n<form id=\"form-YijieGuoUnsupervisedDiscoveryof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yijie Guo\">\n<a href=\"#\" onclick=\"document.getElementById('form-YijieGuoUnsupervisedDiscoveryof').submit();\">Yijie Guo</a>,\n</form>\n<form id=\"form-YixinJinUnsupervisedDiscoveryof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yixin Jin\">\n<a href=\"#\" onclick=\"document.getElementById('form-YixinJinUnsupervisedDiscoveryof').submit();\">Yixin Jin</a>,\n</form>\n<form id=\"form-YijunLuoUnsupervisedDiscoveryof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yijun Luo\">\n<a href=\"#\" onclick=\"document.getElementById('form-YijunLuoUnsupervisedDiscoveryof').submit();\">Yijun Luo</a>,\n</form>\n<form id=\"form-ZhiyuanHeUnsupervisedDiscoveryof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhiyuan He\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhiyuanHeUnsupervisedDiscoveryof').submit();\">Zhiyuan He</a>,\n</form>\n<form id=\"form-HonglakLeeUnsupervisedDiscoveryof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Honglak Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-HonglakLeeUnsupervisedDiscoveryof').submit();\">Honglak Lee</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Unsupervised_Discovery_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0932-supp.zip\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.04412\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Yuting and Guo, Yijie and Jin, Yixin and Luo, Yijun and He, Zhiyuan and Lee, Honglak},<br>\ntitle = {Unsupervised Discovery of Object Landmarks as Structural Representations},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Jacob_Quantization_and_Training_CVPR_2018_paper.html\">Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference</a></dt>\n<dd>\n<form id=\"form-BenoitJacobQuantizationandTraining\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Benoit Jacob\">\n<a href=\"#\" onclick=\"document.getElementById('form-BenoitJacobQuantizationandTraining').submit();\">Benoit Jacob</a>,\n</form>\n<form id=\"form-SkirmantasKligysQuantizationandTraining\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Skirmantas Kligys\">\n<a href=\"#\" onclick=\"document.getElementById('form-SkirmantasKligysQuantizationandTraining').submit();\">Skirmantas Kligys</a>,\n</form>\n<form id=\"form-BoChenQuantizationandTraining\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bo Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoChenQuantizationandTraining').submit();\">Bo Chen</a>,\n</form>\n<form id=\"form-MenglongZhuQuantizationandTraining\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Menglong Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-MenglongZhuQuantizationandTraining').submit();\">Menglong Zhu</a>,\n</form>\n<form id=\"form-MatthewTangQuantizationandTraining\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Matthew Tang\">\n<a href=\"#\" onclick=\"document.getElementById('form-MatthewTangQuantizationandTraining').submit();\">Matthew Tang</a>,\n</form>\n<form id=\"form-AndrewHowardQuantizationandTraining\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrew Howard\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndrewHowardQuantizationandTraining').submit();\">Andrew Howard</a>,\n</form>\n<form id=\"form-HartwigAdamQuantizationandTraining\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hartwig Adam\">\n<a href=\"#\" onclick=\"document.getElementById('form-HartwigAdamQuantizationandTraining').submit();\">Hartwig Adam</a>,\n</form>\n<form id=\"form-DmitryKalenichenkoQuantizationandTraining\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dmitry Kalenichenko\">\n<a href=\"#\" onclick=\"document.getElementById('form-DmitryKalenichenkoQuantizationandTraining').submit();\">Dmitry Kalenichenko</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Jacob_Quantization_and_Training_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0777-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.05877\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Jacob_2018_CVPR,<br>\nauthor = {Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},<br>\ntitle = {Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Van_Horn_Lean_Multiclass_Crowdsourcing_CVPR_2018_paper.html\">Lean Multiclass Crowdsourcing</a></dt>\n<dd>\n<form id=\"form-GrantVanLeanMulticlassCrowdsourcing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Grant Van Horn\">\n<a href=\"#\" onclick=\"document.getElementById('form-GrantVanLeanMulticlassCrowdsourcing').submit();\">Grant Van Horn</a>,\n</form>\n<form id=\"form-SteveBransonLeanMulticlassCrowdsourcing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Steve Branson\">\n<a href=\"#\" onclick=\"document.getElementById('form-SteveBransonLeanMulticlassCrowdsourcing').submit();\">Steve Branson</a>,\n</form>\n<form id=\"form-ScottLoarieLeanMulticlassCrowdsourcing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Scott Loarie\">\n<a href=\"#\" onclick=\"document.getElementById('form-ScottLoarieLeanMulticlassCrowdsourcing').submit();\">Scott Loarie</a>,\n</form>\n<form id=\"form-SergeBelongieLeanMulticlassCrowdsourcing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Serge Belongie\">\n<a href=\"#\" onclick=\"document.getElementById('form-SergeBelongieLeanMulticlassCrowdsourcing').submit();\">Serge Belongie</a>,\n</form>\n<form id=\"form-PietroPeronaLeanMulticlassCrowdsourcing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pietro Perona\">\n<a href=\"#\" onclick=\"document.getElementById('form-PietroPeronaLeanMulticlassCrowdsourcing').submit();\">Pietro Perona</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Van_Horn_Lean_Multiclass_Crowdsourcing_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Horn_2018_CVPR,<br>\nauthor = {Van Horn, Grant and Branson, Steve and Loarie, Scott and Belongie, Serge and Perona, Pietro},<br>\ntitle = {Lean Multiclass Crowdsourcing},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Cao_Partial_Transfer_Learning_CVPR_2018_paper.html\">Partial Transfer Learning With Selective Adversarial Networks</a></dt>\n<dd>\n<form id=\"form-ZhangjieCaoPartialTransferLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhangjie Cao\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhangjieCaoPartialTransferLearning').submit();\">Zhangjie Cao</a>,\n</form>\n<form id=\"form-MingshengLongPartialTransferLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mingsheng Long\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingshengLongPartialTransferLearning').submit();\">Mingsheng Long</a>,\n</form>\n<form id=\"form-JianminWangPartialTransferLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianmin Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianminWangPartialTransferLearning').submit();\">Jianmin Wang</a>,\n</form>\n<form id=\"form-MichaelI.PartialTransferLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michael I. Jordan\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichaelI.PartialTransferLearning').submit();\">Michael I. Jordan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Cao_Partial_Transfer_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1707.07901\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Cao_2018_CVPR,<br>\nauthor = {Cao, Zhangjie and Long, Mingsheng and Wang, Jianmin and Jordan, Michael I.},<br>\ntitle = {Partial Transfer Learning With Selective Adversarial Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Jenni_Self-Supervised_Feature_Learning_CVPR_2018_paper.html\">Self-Supervised Feature Learning by Learning to Spot Artifacts</a></dt>\n<dd>\n<form id=\"form-SimonJenniSelfSupervisedFeatureLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Simon Jenni\">\n<a href=\"#\" onclick=\"document.getElementById('form-SimonJenniSelfSupervisedFeatureLearning').submit();\">Simon Jenni</a>,\n</form>\n<form id=\"form-PaoloFavaroSelfSupervisedFeatureLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Paolo Favaro\">\n<a href=\"#\" onclick=\"document.getElementById('form-PaoloFavaroSelfSupervisedFeatureLearning').submit();\">Paolo Favaro</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Jenni_Self-Supervised_Feature_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1806.05024\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Jenni_2018_CVPR,<br>\nauthor = {Jenni, Simon and Favaro, Paolo},<br>\ntitle = {Self-Supervised Feature Learning by Learning to Spot Artifacts},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhu_LDMNet_Low_Dimensional_CVPR_2018_paper.html\">LDMNet: Low Dimensional Manifold Regularized Neural Networks</a></dt>\n<dd>\n<form id=\"form-WeiZhuLDMNetLowDimensional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiZhuLDMNetLowDimensional').submit();\">Wei Zhu</a>,\n</form>\n<form id=\"form-QiangQiuLDMNetLowDimensional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qiang Qiu\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiangQiuLDMNetLowDimensional').submit();\">Qiang Qiu</a>,\n</form>\n<form id=\"form-JiajiHuangLDMNetLowDimensional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiaji Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiajiHuangLDMNetLowDimensional').submit();\">Jiaji Huang</a>,\n</form>\n<form id=\"form-RobertCalderbankLDMNetLowDimensional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Robert Calderbank\">\n<a href=\"#\" onclick=\"document.getElementById('form-RobertCalderbankLDMNetLowDimensional').submit();\">Robert Calderbank</a>,\n</form>\n<form id=\"form-GuillermoSapiroLDMNetLowDimensional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guillermo Sapiro\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuillermoSapiroLDMNetLowDimensional').submit();\">Guillermo Sapiro</a>,\n</form>\n<form id=\"form-IngridDaubechiesLDMNetLowDimensional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ingrid Daubechies\">\n<a href=\"#\" onclick=\"document.getElementById('form-IngridDaubechiesLDMNetLowDimensional').submit();\">Ingrid Daubechies</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhu_LDMNet_Low_Dimensional_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.06246\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhu_2018_CVPR,<br>\nauthor = {Zhu, Wei and Qiu, Qiang and Huang, Jiaji and Calderbank, Robert and Sapiro, Guillermo and Daubechies, Ingrid},<br>\ntitle = {LDMNet: Low Dimensional Manifold Regularized Neural Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Huang_CondenseNet_An_Efficient_CVPR_2018_paper.html\">CondenseNet: An Efficient DenseNet Using Learned Group Convolutions</a></dt>\n<dd>\n<form id=\"form-GaoHuangCondenseNetAnEfficient\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gao Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-GaoHuangCondenseNetAnEfficient').submit();\">Gao Huang</a>,\n</form>\n<form id=\"form-ShichenLiuCondenseNetAnEfficient\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shichen Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShichenLiuCondenseNetAnEfficient').submit();\">Shichen Liu</a>,\n</form>\n<form id=\"form-LaurensvanCondenseNetAnEfficient\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Laurens van der Maaten\">\n<a href=\"#\" onclick=\"document.getElementById('form-LaurensvanCondenseNetAnEfficient').submit();\">Laurens van der Maaten</a>,\n</form>\n<form id=\"form-KilianQ.CondenseNetAnEfficient\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kilian Q. Weinberger\">\n<a href=\"#\" onclick=\"document.getElementById('form-KilianQ.CondenseNetAnEfficient').submit();\">Kilian Q. Weinberger</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Huang_CondenseNet_An_Efficient_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.09224\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Huang_2018_CVPR,<br>\nauthor = {Huang, Gao and Liu, Shichen and van der Maaten, Laurens and Weinberger, Kilian Q.},<br>\ntitle = {CondenseNet: An Efficient DenseNet Using Learned Group Convolutions},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Keller_Learning_Deep_Descriptors_CVPR_2018_paper.html\">Learning Deep Descriptors With Scale-Aware Triplet Networks</a></dt>\n<dd>\n<form id=\"form-MichelKellerLearningDeepDescriptors\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michel Keller\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichelKellerLearningDeepDescriptors').submit();\">Michel Keller</a>,\n</form>\n<form id=\"form-ZetaoChenLearningDeepDescriptors\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zetao Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZetaoChenLearningDeepDescriptors').submit();\">Zetao Chen</a>,\n</form>\n<form id=\"form-FabiolaMaffraLearningDeepDescriptors\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fabiola Maffra\">\n<a href=\"#\" onclick=\"document.getElementById('form-FabiolaMaffraLearningDeepDescriptors').submit();\">Fabiola Maffra</a>,\n</form>\n<form id=\"form-PatrikSchmuckLearningDeepDescriptors\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Patrik Schmuck\">\n<a href=\"#\" onclick=\"document.getElementById('form-PatrikSchmuckLearningDeepDescriptors').submit();\">Patrik Schmuck</a>,\n</form>\n<form id=\"form-MargaritaChliLearningDeepDescriptors\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Margarita Chli\">\n<a href=\"#\" onclick=\"document.getElementById('form-MargaritaChliLearningDeepDescriptors').submit();\">Margarita Chli</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Keller_Learning_Deep_Descriptors_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3673-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Keller_2018_CVPR,<br>\nauthor = {Keller, Michel and Chen, Zetao and Maffra, Fabiola and Schmuck, Patrik and Chli, Margarita},<br>\ntitle = {Learning Deep Descriptors With Scale-Aware Triplet Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_Decoupled_Networks_CVPR_2018_paper.html\">Decoupled Networks</a></dt>\n<dd>\n<form id=\"form-WeiyangLiuDecoupledNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weiyang Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiyangLiuDecoupledNetworks').submit();\">Weiyang Liu</a>,\n</form>\n<form id=\"form-ZhenLiuDecoupledNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhen Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhenLiuDecoupledNetworks').submit();\">Zhen Liu</a>,\n</form>\n<form id=\"form-ZhidingYuDecoupledNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhiding Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhidingYuDecoupledNetworks').submit();\">Zhiding Yu</a>,\n</form>\n<form id=\"form-BoDaiDecoupledNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bo Dai\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoDaiDecoupledNetworks').submit();\">Bo Dai</a>,\n</form>\n<form id=\"form-RongmeiLinDecoupledNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rongmei Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-RongmeiLinDecoupledNetworks').submit();\">Rongmei Lin</a>,\n</form>\n<form id=\"form-YisenWangDecoupledNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yisen Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YisenWangDecoupledNetworks').submit();\">Yisen Wang</a>,\n</form>\n<form id=\"form-JamesM.DecoupledNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"James M. Rehg\">\n<a href=\"#\" onclick=\"document.getElementById('form-JamesM.DecoupledNetworks').submit();\">James M. Rehg</a>,\n</form>\n<form id=\"form-LeSongDecoupledNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Le Song\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeSongDecoupledNetworks').submit();\">Le Song</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_Decoupled_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/4133-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.01246\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Weiyang and Liu, Zhen and Yu, Zhiding and Dai, Bo and Lin, Rongmei and Wang, Yisen and Rehg, James M. and Song, Le},<br>\ntitle = {Decoupled Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Duan_Deep_Adversarial_Metric_CVPR_2018_paper.html\">Deep Adversarial Metric Learning</a></dt>\n<dd>\n<form id=\"form-YueqiDuanDeepAdversarialMetric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yueqi Duan\">\n<a href=\"#\" onclick=\"document.getElementById('form-YueqiDuanDeepAdversarialMetric').submit();\">Yueqi Duan</a>,\n</form>\n<form id=\"form-WenzhaoZhengDeepAdversarialMetric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenzhao Zheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenzhaoZhengDeepAdversarialMetric').submit();\">Wenzhao Zheng</a>,\n</form>\n<form id=\"form-XudongLinDeepAdversarialMetric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xudong Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-XudongLinDeepAdversarialMetric').submit();\">Xudong Lin</a>,\n</form>\n<form id=\"form-JiwenLuDeepAdversarialMetric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiwen Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiwenLuDeepAdversarialMetric').submit();\">Jiwen Lu</a>,\n</form>\n<form id=\"form-JieZhouDeepAdversarialMetric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jie Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-JieZhouDeepAdversarialMetric').submit();\">Jie Zhou</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Duan_Deep_Adversarial_Metric_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1806.01477\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Duan_2018_CVPR,<br>\nauthor = {Duan, Yueqi and Zheng, Wenzhao and Lin, Xudong and Lu, Jiwen and Zhou, Jie},<br>\ntitle = {Deep Adversarial Metric Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yu_PU-Net_Point_Cloud_CVPR_2018_paper.html\">PU-Net: Point Cloud Upsampling Network</a></dt>\n<dd>\n<form id=\"form-LequanYuPUNetPointCloud\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lequan Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-LequanYuPUNetPointCloud').submit();\">Lequan Yu</a>,\n</form>\n<form id=\"form-XianzhiLiPUNetPointCloud\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xianzhi Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-XianzhiLiPUNetPointCloud').submit();\">Xianzhi Li</a>,\n</form>\n<form id=\"form-Chi-WingFuPUNetPointCloud\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chi-Wing Fu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Chi-WingFuPUNetPointCloud').submit();\">Chi-Wing Fu</a>,\n</form>\n<form id=\"form-DanielCohen-OrPUNetPointCloud\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daniel Cohen-Or\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanielCohen-OrPUNetPointCloud').submit();\">Daniel Cohen-Or</a>,\n</form>\n<form id=\"form-Pheng-AnnHengPUNetPointCloud\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pheng-Ann Heng\">\n<a href=\"#\" onclick=\"document.getElementById('form-Pheng-AnnHengPUNetPointCloud').submit();\">Pheng-Ann Heng</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yu_PU-Net_Point_Cloud_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1248-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.06761\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yu_2018_CVPR,<br>\nauthor = {Yu, Lequan and Li, Xianzhi and Fu, Chi-Wing and Cohen-Or, Daniel and Heng, Pheng-Ann},<br>\ntitle = {PU-Net: Point Cloud Upsampling Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Atapour-Abarghouei_Real-Time_Monocular_Depth_CVPR_2018_paper.html\">Real-Time Monocular Depth Estimation Using Synthetic Data With Domain Adaptation via Image Style Transfer</a></dt>\n<dd>\n<form id=\"form-AmirAtapour-AbarghoueiRealTimeMonocularDepth\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Amir Atapour-Abarghouei\">\n<a href=\"#\" onclick=\"document.getElementById('form-AmirAtapour-AbarghoueiRealTimeMonocularDepth').submit();\">Amir Atapour-Abarghouei</a>,\n</form>\n<form id=\"form-TobyP.RealTimeMonocularDepth\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Toby P. Breckon\">\n<a href=\"#\" onclick=\"document.getElementById('form-TobyP.RealTimeMonocularDepth').submit();\">Toby P. Breckon</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Atapour-Abarghouei_Real-Time_Monocular_Depth_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Atapour-Abarghouei_2018_CVPR,<br>\nauthor = {Atapour-Abarghouei, Amir and Breckon, Toby P.},<br>\ntitle = {Real-Time Monocular Depth Estimation Using Synthetic Data With Domain Adaptation via Image Style Transfer},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liang_Learning_for_Disparity_CVPR_2018_paper.html\">Learning for Disparity Estimation Through Feature Constancy</a></dt>\n<dd>\n<form id=\"form-ZhengfaLiangLearningforDisparity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhengfa Liang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhengfaLiangLearningforDisparity').submit();\">Zhengfa Liang</a>,\n</form>\n<form id=\"form-YiliuFengLearningforDisparity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yiliu Feng\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiliuFengLearningforDisparity').submit();\">Yiliu Feng</a>,\n</form>\n<form id=\"form-YulanGuoLearningforDisparity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yulan Guo\">\n<a href=\"#\" onclick=\"document.getElementById('form-YulanGuoLearningforDisparity').submit();\">Yulan Guo</a>,\n</form>\n<form id=\"form-HengzhuLiuLearningforDisparity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hengzhu Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HengzhuLiuLearningforDisparity').submit();\">Hengzhu Liu</a>,\n</form>\n<form id=\"form-WeiChenLearningforDisparity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiChenLearningforDisparity').submit();\">Wei Chen</a>,\n</form>\n<form id=\"form-LinboQiaoLearningforDisparity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Linbo Qiao\">\n<a href=\"#\" onclick=\"document.getElementById('form-LinboQiaoLearningforDisparity').submit();\">Linbo Qiao</a>,\n</form>\n<form id=\"form-LiZhouLearningforDisparity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Li Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiZhouLearningforDisparity').submit();\">Li Zhou</a>,\n</form>\n<form id=\"form-JianfengZhangLearningforDisparity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianfeng Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianfengZhangLearningforDisparity').submit();\">Jianfeng Zhang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liang_Learning_for_Disparity_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.01039\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liang_2018_CVPR,<br>\nauthor = {Liang, Zhengfa and Feng, Yiliu and Guo, Yulan and Liu, Hengzhu and Chen, Wei and Qiao, Linbo and Zhou, Li and Zhang, Jianfeng},<br>\ntitle = {Learning for Disparity Estimation Through Feature Constancy},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Huang_DeepMVS_Learning_Multi-View_CVPR_2018_paper.html\">DeepMVS: Learning Multi-View Stereopsis</a></dt>\n<dd>\n<form id=\"form-Po-HanHuangDeepMVSLearningMultiView\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Po-Han Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Po-HanHuangDeepMVSLearningMultiView').submit();\">Po-Han Huang</a>,\n</form>\n<form id=\"form-KevinMatzenDeepMVSLearningMultiView\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kevin Matzen\">\n<a href=\"#\" onclick=\"document.getElementById('form-KevinMatzenDeepMVSLearningMultiView').submit();\">Kevin Matzen</a>,\n</form>\n<form id=\"form-JohannesKopfDeepMVSLearningMultiView\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Johannes Kopf\">\n<a href=\"#\" onclick=\"document.getElementById('form-JohannesKopfDeepMVSLearningMultiView').submit();\">Johannes Kopf</a>,\n</form>\n<form id=\"form-NarendraAhujaDeepMVSLearningMultiView\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Narendra Ahuja\">\n<a href=\"#\" onclick=\"document.getElementById('form-NarendraAhujaDeepMVSLearningMultiView').submit();\">Narendra Ahuja</a>,\n</form>\n<form id=\"form-Jia-BinHuangDeepMVSLearningMultiView\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jia-Bin Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jia-BinHuangDeepMVSLearningMultiView').submit();\">Jia-Bin Huang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Huang_DeepMVS_Learning_Multi-View_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2703-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00650\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Huang_2018_CVPR,<br>\nauthor = {Huang, Po-Han and Matzen, Kevin and Kopf, Johannes and Ahuja, Narendra and Huang, Jia-Bin},<br>\ntitle = {DeepMVS: Learning Multi-View Stereopsis},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Teo_Self-Calibrating_Polarising_Radiometric_CVPR_2018_paper.html\">Self-Calibrating Polarising Radiometric Calibration</a></dt>\n<dd>\n<form id=\"form-DanielTeoSelfCalibratingPolarisingRadiometric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daniel Teo\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanielTeoSelfCalibratingPolarisingRadiometric').submit();\">Daniel Teo</a>,\n</form>\n<form id=\"form-BoxinShiSelfCalibratingPolarisingRadiometric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Boxin Shi\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoxinShiSelfCalibratingPolarisingRadiometric').submit();\">Boxin Shi</a>,\n</form>\n<form id=\"form-YinqiangZhengSelfCalibratingPolarisingRadiometric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yinqiang Zheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-YinqiangZhengSelfCalibratingPolarisingRadiometric').submit();\">Yinqiang Zheng</a>,\n</form>\n<form id=\"form-Sai-KitYeungSelfCalibratingPolarisingRadiometric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sai-Kit Yeung\">\n<a href=\"#\" onclick=\"document.getElementById('form-Sai-KitYeungSelfCalibratingPolarisingRadiometric').submit();\">Sai-Kit Yeung</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Teo_Self-Calibrating_Polarising_Radiometric_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3446-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Teo_2018_CVPR,<br>\nauthor = {Teo, Daniel and Shi, Boxin and Zheng, Yinqiang and Yeung, Sai-Kit},<br>\ntitle = {Self-Calibrating Polarising Radiometric Calibration},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tanfous_Coding_Kendalls_Shape_CVPR_2018_paper.html\">Coding Kendall's Shape Trajectories for 3D Action Recognition</a></dt>\n<dd>\n<form id=\"form-AmorBenCodingKendallsShape\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Amor Ben Tanfous\">\n<a href=\"#\" onclick=\"document.getElementById('form-AmorBenCodingKendallsShape').submit();\">Amor Ben Tanfous</a>,\n</form>\n<form id=\"form-HassenDriraCodingKendallsShape\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hassen Drira\">\n<a href=\"#\" onclick=\"document.getElementById('form-HassenDriraCodingKendallsShape').submit();\">Hassen Drira</a>,\n</form>\n<form id=\"form-BoulbabaBenCodingKendallsShape\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Boulbaba Ben Amor\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoulbabaBenCodingKendallsShape').submit();\">Boulbaba Ben Amor</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tanfous_Coding_Kendalls_Shape_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tanfous_2018_CVPR,<br>\nauthor = {Ben Tanfous, Amor and Drira, Hassen and Ben Amor, Boulbaba},<br>\ntitle = {Coding Kendall's Shape Trajectories for 3D Action Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Turek_Efficient_Sparse_Representation_CVPR_2018_paper.html\">Efficient, Sparse Representation of Manifold Distance Matrices for Classical Scaling</a></dt>\n<dd>\n<form id=\"form-JavierS.EfficientSparseRepresentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Javier S. Turek\">\n<a href=\"#\" onclick=\"document.getElementById('form-JavierS.EfficientSparseRepresentation').submit();\">Javier S. Turek</a>,\n</form>\n<form id=\"form-AlexanderG.EfficientSparseRepresentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexander G. Huth\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexanderG.EfficientSparseRepresentation').submit();\">Alexander G. Huth</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Turek_Efficient_Sparse_Representation_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Turek_2018_CVPR,<br>\nauthor = {Turek, Javier S. and Huth, Alexander G.},<br>\ntitle = {Efficient, Sparse Representation of Manifold Distance Matrices for Classical Scaling},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xu_Motion_Segmentation_by_CVPR_2018_paper.html\">Motion Segmentation by Exploiting Complementary Geometric Models</a></dt>\n<dd>\n<form id=\"form-XunXuMotionSegmentationby\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xun Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XunXuMotionSegmentationby').submit();\">Xun Xu</a>,\n</form>\n<form id=\"form-LoongFahMotionSegmentationby\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Loong Fah Cheong\">\n<a href=\"#\" onclick=\"document.getElementById('form-LoongFahMotionSegmentationby').submit();\">Loong Fah Cheong</a>,\n</form>\n<form id=\"form-ZhuwenLiMotionSegmentationby\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhuwen Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhuwenLiMotionSegmentationby').submit();\">Zhuwen Li</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xu_Motion_Segmentation_by_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.02142\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xu_2018_CVPR,<br>\nauthor = {Xu, Xun and Fah Cheong, Loong and Li, Zhuwen},<br>\ntitle = {Motion Segmentation by Exploiting Complementary Geometric Models},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Shi_Estimation_of_Camera_CVPR_2018_paper.html\">Estimation of Camera Locations in Highly Corrupted Scenarios: All About That Base, No Shape Trouble</a></dt>\n<dd>\n<form id=\"form-YunpengShiEstimationofCamera\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yunpeng Shi\">\n<a href=\"#\" onclick=\"document.getElementById('form-YunpengShiEstimationofCamera').submit();\">Yunpeng Shi</a>,\n</form>\n<form id=\"form-GiladLermanEstimationofCamera\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gilad Lerman\">\n<a href=\"#\" onclick=\"document.getElementById('form-GiladLermanEstimationofCamera').submit();\">Gilad Lerman</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Shi_Estimation_of_Camera_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/4239-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Shi_2018_CVPR,<br>\nauthor = {Shi, Yunpeng and Lerman, Gilad},<br>\ntitle = {Estimation of Camera Locations in Highly Corrupted Scenarios: All About That Base, No Shape Trouble},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_4D_Human_Body_CVPR_2018_paper.html\">4D Human Body Correspondences From Panoramic Depth Maps</a></dt>\n<dd>\n<form id=\"form-ZhongLi4DHumanBody\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhong Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhongLi4DHumanBody').submit();\">Zhong Li</a>,\n</form>\n<form id=\"form-MinyeWu4DHumanBody\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Minye Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-MinyeWu4DHumanBody').submit();\">Minye Wu</a>,\n</form>\n<form id=\"form-WangyitengZhou4DHumanBody\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wangyiteng Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-WangyitengZhou4DHumanBody').submit();\">Wangyiteng Zhou</a>,\n</form>\n<form id=\"form-JingyiYu4DHumanBody\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jingyi Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingyiYu4DHumanBody').submit();\">Jingyi Yu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_4D_Human_Body_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0345-supp.zip\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Zhong and Wu, Minye and Zhou, Wangyiteng and Yu, Jingyi},<br>\ntitle = {4D Human Body Correspondences From Panoramic Depth Maps},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Reconstructing_Thin_Structures_CVPR_2018_paper.html\">Reconstructing Thin Structures of Manifold Surfaces by Integrating Spatial Curves</a></dt>\n<dd>\n<form id=\"form-ShiweiLiReconstructingThinStructures\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shiwei Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShiweiLiReconstructingThinStructures').submit();\">Shiwei Li</a>,\n</form>\n<form id=\"form-YaoYaoReconstructingThinStructures\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yao Yao\">\n<a href=\"#\" onclick=\"document.getElementById('form-YaoYaoReconstructingThinStructures').submit();\">Yao Yao</a>,\n</form>\n<form id=\"form-TianFangReconstructingThinStructures\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tian Fang\">\n<a href=\"#\" onclick=\"document.getElementById('form-TianFangReconstructingThinStructures').submit();\">Tian Fang</a>,\n</form>\n<form id=\"form-LongQuanReconstructingThinStructures\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Long Quan\">\n<a href=\"#\" onclick=\"document.getElementById('form-LongQuanReconstructingThinStructures').submit();\">Long Quan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Reconstructing_Thin_Structures_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Shiwei and Yao, Yao and Fang, Tian and Quan, Long},<br>\ntitle = {Reconstructing Thin Structures of Manifold Surfaces by Integrating Spatial Curves},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tulsiani_Multi-View_Consistency_as_CVPR_2018_paper.html\">Multi-View Consistency as Supervisory Signal for Learning Shape and Pose Prediction</a></dt>\n<dd>\n<form id=\"form-ShubhamTulsianiMultiViewConsistencyas\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shubham Tulsiani\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShubhamTulsianiMultiViewConsistencyas').submit();\">Shubham Tulsiani</a>,\n</form>\n<form id=\"form-AlexeiA.MultiViewConsistencyas\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexei A. Efros\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexeiA.MultiViewConsistencyas').submit();\">Alexei A. Efros</a>,\n</form>\n<form id=\"form-JitendraMalikMultiViewConsistencyas\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jitendra Malik\">\n<a href=\"#\" onclick=\"document.getElementById('form-JitendraMalikMultiViewConsistencyas').submit();\">Jitendra Malik</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tulsiani_Multi-View_Consistency_as_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0759-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.03910\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tulsiani_2018_CVPR,<br>\nauthor = {Tulsiani, Shubham and Efros, Alexei A. and Malik, Jitendra},<br>\ntitle = {Multi-View Consistency as Supervisory Signal for Learning Shape and Pose Prediction},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Isokane_Probabilistic_Plant_Modeling_CVPR_2018_paper.html\">Probabilistic Plant Modeling via Multi-View Image-to-Image Translation</a></dt>\n<dd>\n<form id=\"form-TakahiroIsokaneProbabilisticPlantModeling\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Takahiro Isokane\">\n<a href=\"#\" onclick=\"document.getElementById('form-TakahiroIsokaneProbabilisticPlantModeling').submit();\">Takahiro Isokane</a>,\n</form>\n<form id=\"form-FumioOkuraProbabilisticPlantModeling\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fumio Okura\">\n<a href=\"#\" onclick=\"document.getElementById('form-FumioOkuraProbabilisticPlantModeling').submit();\">Fumio Okura</a>,\n</form>\n<form id=\"form-AyakaIdeProbabilisticPlantModeling\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ayaka Ide\">\n<a href=\"#\" onclick=\"document.getElementById('form-AyakaIdeProbabilisticPlantModeling').submit();\">Ayaka Ide</a>,\n</form>\n<form id=\"form-YasuyukiMatsushitaProbabilisticPlantModeling\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yasuyuki Matsushita\">\n<a href=\"#\" onclick=\"document.getElementById('form-YasuyukiMatsushitaProbabilisticPlantModeling').submit();\">Yasuyuki Matsushita</a>,\n</form>\n<form id=\"form-YasushiYagiProbabilisticPlantModeling\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yasushi Yagi\">\n<a href=\"#\" onclick=\"document.getElementById('form-YasushiYagiProbabilisticPlantModeling').submit();\">Yasushi Yagi</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Isokane_Probabilistic_Plant_Modeling_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1443-supp.zip\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.09404\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Isokane_2018_CVPR,<br>\nauthor = {Isokane, Takahiro and Okura, Fumio and Ide, Ayaka and Matsushita, Yasuyuki and Yagi, Yasushi},<br>\ntitle = {Probabilistic Plant Modeling via Multi-View Image-to-Image Translation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liao_Deep_Marching_Cubes_CVPR_2018_paper.html\">Deep Marching Cubes: Learning Explicit Surface Representations</a></dt>\n<dd>\n<form id=\"form-YiyiLiaoDeepMarchingCubes\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yiyi Liao\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiyiLiaoDeepMarchingCubes').submit();\">Yiyi Liao</a>,\n</form>\n<form id=\"form-SimonDonn\u00c3\u00a9DeepMarchingCubes\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Simon Donn\u00c3\u00a9\">\n<a href=\"#\" onclick=\"document.getElementById('form-SimonDonn\u00c3\u00a9DeepMarchingCubes').submit();\">Simon Donn\u00c3\u00a9</a>,\n</form>\n<form id=\"form-AndreasGeigerDeepMarchingCubes\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andreas Geiger\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndreasGeigerDeepMarchingCubes').submit();\">Andreas Geiger</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liao_Deep_Marching_Cubes_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liao_2018_CVPR,<br>\nauthor = {Liao, Yiyi and Donn\u00c3\u00a9, Simon and Geiger, Andreas},<br>\ntitle = {Deep Marching Cubes: Learning Explicit Surface Representations},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Muralikrishnan_Tags2Parts_Discovering_Semantic_CVPR_2018_paper.html\">Tags2Parts: Discovering Semantic Regions From Shape Tags</a></dt>\n<dd>\n<form id=\"form-SanjeevMuralikrishnanTags2PartsDiscoveringSemantic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sanjeev Muralikrishnan\">\n<a href=\"#\" onclick=\"document.getElementById('form-SanjeevMuralikrishnanTags2PartsDiscoveringSemantic').submit();\">Sanjeev Muralikrishnan</a>,\n</form>\n<form id=\"form-VladimirG.Tags2PartsDiscoveringSemantic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vladimir G. Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-VladimirG.Tags2PartsDiscoveringSemantic').submit();\">Vladimir G. Kim</a>,\n</form>\n<form id=\"form-SiddharthaChaudhuriTags2PartsDiscoveringSemantic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Siddhartha Chaudhuri\">\n<a href=\"#\" onclick=\"document.getElementById('form-SiddharthaChaudhuriTags2PartsDiscoveringSemantic').submit();\">Siddhartha Chaudhuri</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Muralikrishnan_Tags2Parts_Discovering_Semantic_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1893-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1708.06673\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Muralikrishnan_2018_CVPR,<br>\nauthor = {Muralikrishnan, Sanjeev and Kim, Vladimir G. and Chaudhuri, Siddhartha},<br>\ntitle = {Tags2Parts: Discovering Semantic Regions From Shape Tags},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Mo_Uncalibrated_Photometric_Stereo_CVPR_2018_paper.html\">Uncalibrated Photometric Stereo Under Natural Illumination</a></dt>\n<dd>\n<form id=\"form-ZhipengMoUncalibratedPhotometricStereo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhipeng Mo\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhipengMoUncalibratedPhotometricStereo').submit();\">Zhipeng Mo</a>,\n</form>\n<form id=\"form-BoxinShiUncalibratedPhotometricStereo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Boxin Shi\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoxinShiUncalibratedPhotometricStereo').submit();\">Boxin Shi</a>,\n</form>\n<form id=\"form-FengLuUncalibratedPhotometricStereo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Feng Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-FengLuUncalibratedPhotometricStereo').submit();\">Feng Lu</a>,\n</form>\n<form id=\"form-Sai-KitYeungUncalibratedPhotometricStereo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sai-Kit Yeung\">\n<a href=\"#\" onclick=\"document.getElementById('form-Sai-KitYeungUncalibratedPhotometricStereo').submit();\">Sai-Kit Yeung</a>,\n</form>\n<form id=\"form-YasuyukiMatsushitaUncalibratedPhotometricStereo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yasuyuki Matsushita\">\n<a href=\"#\" onclick=\"document.getElementById('form-YasuyukiMatsushitaUncalibratedPhotometricStereo').submit();\">Yasuyuki Matsushita</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Mo_Uncalibrated_Photometric_Stereo_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Mo_2018_CVPR,<br>\nauthor = {Mo, Zhipeng and Shi, Boxin and Lu, Feng and Yeung, Sai-Kit and Matsushita, Yasuyuki},<br>\ntitle = {Uncalibrated Photometric Stereo Under Natural Illumination},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Im_Robust_Depth_Estimation_CVPR_2018_paper.html\">Robust Depth Estimation From Auto Bracketed Images</a></dt>\n<dd>\n<form id=\"form-SunghoonImRobustDepthEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sunghoon Im\">\n<a href=\"#\" onclick=\"document.getElementById('form-SunghoonImRobustDepthEstimation').submit();\">Sunghoon Im</a>,\n</form>\n<form id=\"form-Hae-GonJeonRobustDepthEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hae-Gon Jeon\">\n<a href=\"#\" onclick=\"document.getElementById('form-Hae-GonJeonRobustDepthEstimation').submit();\">Hae-Gon Jeon</a>,\n</form>\n<form id=\"form-InSoRobustDepthEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"In So Kweon\">\n<a href=\"#\" onclick=\"document.getElementById('form-InSoRobustDepthEstimation').submit();\">In So Kweon</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Im_Robust_Depth_Estimation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.07702\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Im_2018_CVPR,<br>\nauthor = {Im, Sunghoon and Jeon, Hae-Gon and So Kweon, In},<br>\ntitle = {Robust Depth Estimation From Auto Bracketed Images},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Krahenbuhl_Free_Supervision_From_CVPR_2018_paper.html\">Free Supervision From Video Games</a></dt>\n<dd>\n<form id=\"form-PhilippKr\u00c3\u00a4henb\u00c3\u00bchlFreeSupervisionFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Philipp Kr\u00c3\u00a4henb\u00c3\u00bchl\">\n<a href=\"#\" onclick=\"document.getElementById('form-PhilippKr\u00c3\u00a4henb\u00c3\u00bchlFreeSupervisionFrom').submit();\">Philipp Kr\u00c3\u00a4henb\u00c3\u00bchl</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Krahenbuhl_Free_Supervision_From_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kr\u00c3\u00a4henb\u00c3\u00bchl_2018_CVPR,<br>\nauthor = {Kr\u00c3\u00a4henb\u00c3\u00bchl, Philipp},<br>\ntitle = {Free Supervision From Video Games},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Fang_Planar_Shape_Detection_CVPR_2018_paper.html\">Planar Shape Detection at Structural Scales</a></dt>\n<dd>\n<form id=\"form-HaoFangPlanarShapeDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hao Fang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaoFangPlanarShapeDetection').submit();\">Hao Fang</a>,\n</form>\n<form id=\"form-FlorentLafargePlanarShapeDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Florent Lafarge\">\n<a href=\"#\" onclick=\"document.getElementById('form-FlorentLafargePlanarShapeDetection').submit();\">Florent Lafarge</a>,\n</form>\n<form id=\"form-MathieuDesbrunPlanarShapeDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mathieu Desbrun\">\n<a href=\"#\" onclick=\"document.getElementById('form-MathieuDesbrunPlanarShapeDetection').submit();\">Mathieu Desbrun</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Fang_Planar_Shape_Detection_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Fang_2018_CVPR,<br>\nauthor = {Fang, Hao and Lafarge, Florent and Desbrun, Mathieu},<br>\ntitle = {Planar Shape Detection at Structural Scales},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sun_Pix3D_Dataset_and_CVPR_2018_paper.html\">Pix3D: Dataset and Methods for Single-Image 3D Shape Modeling</a></dt>\n<dd>\n<form id=\"form-XingyuanSunPix3DDatasetand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xingyuan Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-XingyuanSunPix3DDatasetand').submit();\">Xingyuan Sun</a>,\n</form>\n<form id=\"form-JiajunWuPix3DDatasetand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiajun Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiajunWuPix3DDatasetand').submit();\">Jiajun Wu</a>,\n</form>\n<form id=\"form-XiumingZhangPix3DDatasetand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiuming Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiumingZhangPix3DDatasetand').submit();\">Xiuming Zhang</a>,\n</form>\n<form id=\"form-ZhoutongZhangPix3DDatasetand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhoutong Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhoutongZhangPix3DDatasetand').submit();\">Zhoutong Zhang</a>,\n</form>\n<form id=\"form-ChengkaiZhangPix3DDatasetand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chengkai Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChengkaiZhangPix3DDatasetand').submit();\">Chengkai Zhang</a>,\n</form>\n<form id=\"form-TianfanXuePix3DDatasetand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tianfan Xue\">\n<a href=\"#\" onclick=\"document.getElementById('form-TianfanXuePix3DDatasetand').submit();\">Tianfan Xue</a>,\n</form>\n<form id=\"form-JoshuaB.Pix3DDatasetand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Joshua B. Tenenbaum\">\n<a href=\"#\" onclick=\"document.getElementById('form-JoshuaB.Pix3DDatasetand').submit();\">Joshua B. Tenenbaum</a>,\n</form>\n<form id=\"form-WilliamT.Pix3DDatasetand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"William T. Freeman\">\n<a href=\"#\" onclick=\"document.getElementById('form-WilliamT.Pix3DDatasetand').submit();\">William T. Freeman</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sun_Pix3D_Dataset_and_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.04610\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sun_2018_CVPR,<br>\nauthor = {Sun, Xingyuan and Wu, Jiajun and Zhang, Xiuming and Zhang, Zhoutong and Zhang, Chengkai and Xue, Tianfan and Tenenbaum, Joshua B. and Freeman, William T.},<br>\ntitle = {Pix3D: Dataset and Methods for Single-Image 3D Shape Modeling},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Larsson_Camera_Pose_Estimation_CVPR_2018_paper.html\">Camera Pose Estimation With Unknown Principal Point</a></dt>\n<dd>\n<form id=\"form-ViktorLarssonCameraPoseEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Viktor Larsson\">\n<a href=\"#\" onclick=\"document.getElementById('form-ViktorLarssonCameraPoseEstimation').submit();\">Viktor Larsson</a>,\n</form>\n<form id=\"form-ZuzanaKukelovaCameraPoseEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zuzana Kukelova\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZuzanaKukelovaCameraPoseEstimation').submit();\">Zuzana Kukelova</a>,\n</form>\n<form id=\"form-YinqiangZhengCameraPoseEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yinqiang Zheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-YinqiangZhengCameraPoseEstimation').submit();\">Yinqiang Zheng</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Larsson_Camera_Pose_Estimation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2936-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Larsson_2018_CVPR,<br>\nauthor = {Larsson, Viktor and Kukelova, Zuzana and Zheng, Yinqiang},<br>\ntitle = {Camera Pose Estimation With Unknown Principal Point},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Vongkulbhisal_Inverse_Composition_Discriminative_CVPR_2018_paper.html\">Inverse Composition Discriminative Optimization for Point Cloud Registration</a></dt>\n<dd>\n<form id=\"form-JayakornVongkulbhisalInverseCompositionDiscriminative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jayakorn Vongkulbhisal\">\n<a href=\"#\" onclick=\"document.getElementById('form-JayakornVongkulbhisalInverseCompositionDiscriminative').submit();\">Jayakorn Vongkulbhisal</a>,\n</form>\n<form id=\"form-Be\u00c3\u00b1atIrastorzaInverseCompositionDiscriminative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Be\u00c3\u00b1at Irastorza Ugalde\">\n<a href=\"#\" onclick=\"document.getElementById('form-Be\u00c3\u00b1atIrastorzaInverseCompositionDiscriminative').submit();\">Be\u00c3\u00b1at Irastorza Ugalde</a>,\n</form>\n<form id=\"form-FernandoDeInverseCompositionDiscriminative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fernando De la Torre\">\n<a href=\"#\" onclick=\"document.getElementById('form-FernandoDeInverseCompositionDiscriminative').submit();\">Fernando De la Torre</a>,\n</form>\n<form id=\"form-Jo\u00c3\u00a3oP.InverseCompositionDiscriminative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jo\u00c3\u00a3o P. Costeira\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jo\u00c3\u00a3oP.InverseCompositionDiscriminative').submit();\">Jo\u00c3\u00a3o P. Costeira</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Vongkulbhisal_Inverse_Composition_Discriminative_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2988-supp.zip\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Vongkulbhisal_2018_CVPR,<br>\nauthor = {Vongkulbhisal, Jayakorn and Irastorza Ugalde, Be\u00c3\u00b1at and De la Torre, Fernando and Costeira, Jo\u00c3\u00a3o P.},<br>\ntitle = {Inverse Composition Discriminative Optimization for Point Cloud Registration},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chu_SurfConv_Bridging_3D_CVPR_2018_paper.html\">SurfConv: Bridging 3D and 2D Convolution for RGBD Images</a></dt>\n<dd>\n<form id=\"form-HangChuSurfConvBridging3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hang Chu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HangChuSurfConvBridging3D').submit();\">Hang Chu</a>,\n</form>\n<form id=\"form-Wei-ChiuMaSurfConvBridging3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei-Chiu Ma\">\n<a href=\"#\" onclick=\"document.getElementById('form-Wei-ChiuMaSurfConvBridging3D').submit();\">Wei-Chiu Ma</a>,\n</form>\n<form id=\"form-KaustavKunduSurfConvBridging3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kaustav Kundu\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaustavKunduSurfConvBridging3D').submit();\">Kaustav Kundu</a>,\n</form>\n<form id=\"form-RaquelUrtasunSurfConvBridging3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Raquel Urtasun\">\n<a href=\"#\" onclick=\"document.getElementById('form-RaquelUrtasunSurfConvBridging3D').submit();\">Raquel Urtasun</a>,\n</form>\n<form id=\"form-SanjaFidlerSurfConvBridging3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sanja Fidler\">\n<a href=\"#\" onclick=\"document.getElementById('form-SanjaFidlerSurfConvBridging3D').submit();\">Sanja Fidler</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chu_SurfConv_Bridging_3D_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chu_2018_CVPR,<br>\nauthor = {Chu, Hang and Ma, Wei-Chiu and Kundu, Kaustav and Urtasun, Raquel and Fidler, Sanja},<br>\ntitle = {SurfConv: Bridging 3D and 2D Convolution for RGBD Images},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_A_Fast_Resection-Intersection_CVPR_2018_paper.html\">A Fast Resection-Intersection Method for the Known Rotation Problem</a></dt>\n<dd>\n<form id=\"form-QianggongZhangAFastResectionIntersection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qianggong Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-QianggongZhangAFastResectionIntersection').submit();\">Qianggong Zhang</a>,\n</form>\n<form id=\"form-Tat-JunChinAFastResectionIntersection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tat-Jun Chin\">\n<a href=\"#\" onclick=\"document.getElementById('form-Tat-JunChinAFastResectionIntersection').submit();\">Tat-Jun Chin</a>,\n</form>\n<form id=\"form-HuuMinhAFastResectionIntersection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huu Minh Le\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuuMinhAFastResectionIntersection').submit();\">Huu Minh Le</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_A_Fast_Resection-Intersection_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0762-supp.zip\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Qianggong and Chin, Tat-Jun and Minh Le, Huu},<br>\ntitle = {A Fast Resection-Intersection Method for the Known Rotation Problem},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Grabner_3D_Pose_Estimation_CVPR_2018_paper.html\">3D Pose Estimation and 3D Model Retrieval for Objects in the Wild</a></dt>\n<dd>\n<form id=\"form-AlexanderGrabner3DPoseEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexander Grabner\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexanderGrabner3DPoseEstimation').submit();\">Alexander Grabner</a>,\n</form>\n<form id=\"form-PeterM.3DPoseEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peter M. Roth\">\n<a href=\"#\" onclick=\"document.getElementById('form-PeterM.3DPoseEstimation').submit();\">Peter M. Roth</a>,\n</form>\n<form id=\"form-VincentLepetit3DPoseEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vincent Lepetit\">\n<a href=\"#\" onclick=\"document.getElementById('form-VincentLepetit3DPoseEstimation').submit();\">Vincent Lepetit</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Grabner_3D_Pose_Estimation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1914-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.11493\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Grabner_2018_CVPR,<br>\nauthor = {Grabner, Alexander and Roth, Peter M. and Lepetit, Vincent},<br>\ntitle = {3D Pose Estimation and 3D Model Retrieval for Objects in the Wild},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Structure_From_Recurrent_CVPR_2018_paper.html\">Structure From Recurrent Motion: From Rigidity to Recurrency</a></dt>\n<dd>\n<form id=\"form-XiuLiStructureFromRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiu Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiuLiStructureFromRecurrent').submit();\">Xiu Li</a>,\n</form>\n<form id=\"form-HongdongLiStructureFromRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hongdong Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-HongdongLiStructureFromRecurrent').submit();\">Hongdong Li</a>,\n</form>\n<form id=\"form-HanbyulJooStructureFromRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hanbyul Joo\">\n<a href=\"#\" onclick=\"document.getElementById('form-HanbyulJooStructureFromRecurrent').submit();\">Hanbyul Joo</a>,\n</form>\n<form id=\"form-YebinLiuStructureFromRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yebin Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YebinLiuStructureFromRecurrent').submit();\">Yebin Liu</a>,\n</form>\n<form id=\"form-YaserSheikhStructureFromRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yaser Sheikh\">\n<a href=\"#\" onclick=\"document.getElementById('form-YaserSheikhStructureFromRecurrent').submit();\">Yaser Sheikh</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Structure_From_Recurrent_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.06510\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Xiu and Li, Hongdong and Joo, Hanbyul and Liu, Yebin and Sheikh, Yaser},<br>\ntitle = {Structure From Recurrent Motion: From Rigidity to Recurrency},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Poms_Learning_Patch_Reconstructability_CVPR_2018_paper.html\">Learning Patch Reconstructability for Accelerating Multi-View Stereo</a></dt>\n<dd>\n<form id=\"form-AlexPomsLearningPatchReconstructability\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alex Poms\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexPomsLearningPatchReconstructability').submit();\">Alex Poms</a>,\n</form>\n<form id=\"form-ChengleiWuLearningPatchReconstructability\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chenglei Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChengleiWuLearningPatchReconstructability').submit();\">Chenglei Wu</a>,\n</form>\n<form id=\"form-Shoou-IYuLearningPatchReconstructability\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shoou-I Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Shoou-IYuLearningPatchReconstructability').submit();\">Shoou-I Yu</a>,\n</form>\n<form id=\"form-YaserSheikhLearningPatchReconstructability\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yaser Sheikh\">\n<a href=\"#\" onclick=\"document.getElementById('form-YaserSheikhLearningPatchReconstructability').submit();\">Yaser Sheikh</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Poms_Learning_Patch_Reconstructability_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Poms_2018_CVPR,<br>\nauthor = {Poms, Alex and Wu, Chenglei and Yu, Shoou-I and Sheikh, Yaser},<br>\ntitle = {Learning Patch Reconstructability for Accelerating Multi-View Stereo},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_Progressively_Complementarity-Aware_Fusion_CVPR_2018_paper.html\">Progressively Complementarity-Aware Fusion Network for RGB-D Salient Object Detection</a></dt>\n<dd>\n<form id=\"form-HaoChenProgressivelyComplementarityAwareFusion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hao Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaoChenProgressivelyComplementarityAwareFusion').submit();\">Hao Chen</a>,\n</form>\n<form id=\"form-YoufuLiProgressivelyComplementarityAwareFusion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Youfu Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-YoufuLiProgressivelyComplementarityAwareFusion').submit();\">Youfu Li</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_Progressively_Complementarity-Aware_Fusion_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Hao and Li, Youfu},<br>\ntitle = {Progressively Complementarity-Aware Fusion Network for RGB-D Salient Object Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Shin_Pixels_Voxels_and_CVPR_2018_paper.html\">Pixels, Voxels, and Views: A Study of Shape Representations for Single View 3D Object Shape Prediction</a></dt>\n<dd>\n<form id=\"form-DaeyunShinPixelsVoxelsand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daeyun Shin\">\n<a href=\"#\" onclick=\"document.getElementById('form-DaeyunShinPixelsVoxelsand').submit();\">Daeyun Shin</a>,\n</form>\n<form id=\"form-CharlessC.PixelsVoxelsand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Charless C. Fowlkes\">\n<a href=\"#\" onclick=\"document.getElementById('form-CharlessC.PixelsVoxelsand').submit();\">Charless C. Fowlkes</a>,\n</form>\n<form id=\"form-DerekHoiemPixelsVoxelsand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Derek Hoiem\">\n<a href=\"#\" onclick=\"document.getElementById('form-DerekHoiemPixelsVoxelsand').submit();\">Derek Hoiem</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Shin_Pixels_Voxels_and_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3826-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Shin_2018_CVPR,<br>\nauthor = {Shin, Daeyun and Fowlkes, Charless C. and Hoiem, Derek},<br>\ntitle = {Pixels, Voxels, and Views: A Study of Shape Representations for Single View 3D Object Shape Prediction},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Pan_Learning_Dual_Convolutional_CVPR_2018_paper.html\">Learning Dual Convolutional Neural Networks for Low-Level Vision</a></dt>\n<dd>\n<form id=\"form-JinshanPanLearningDualConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jinshan Pan\">\n<a href=\"#\" onclick=\"document.getElementById('form-JinshanPanLearningDualConvolutional').submit();\">Jinshan Pan</a>,\n</form>\n<form id=\"form-SifeiLiuLearningDualConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sifei Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-SifeiLiuLearningDualConvolutional').submit();\">Sifei Liu</a>,\n</form>\n<form id=\"form-DeqingSunLearningDualConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Deqing Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-DeqingSunLearningDualConvolutional').submit();\">Deqing Sun</a>,\n</form>\n<form id=\"form-JiaweiZhangLearningDualConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiawei Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiaweiZhangLearningDualConvolutional').submit();\">Jiawei Zhang</a>,\n</form>\n<form id=\"form-YangLiuLearningDualConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yang Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YangLiuLearningDualConvolutional').submit();\">Yang Liu</a>,\n</form>\n<form id=\"form-JimmyRenLearningDualConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jimmy Ren\">\n<a href=\"#\" onclick=\"document.getElementById('form-JimmyRenLearningDualConvolutional').submit();\">Jimmy Ren</a>,\n</form>\n<form id=\"form-ZechaoLiLearningDualConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zechao Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZechaoLiLearningDualConvolutional').submit();\">Zechao Li</a>,\n</form>\n<form id=\"form-JinhuiTangLearningDualConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jinhui Tang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JinhuiTangLearningDualConvolutional').submit();\">Jinhui Tang</a>,\n</form>\n<form id=\"form-HuchuanLuLearningDualConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huchuan Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuchuanLuLearningDualConvolutional').submit();\">Huchuan Lu</a>,\n</form>\n<form id=\"form-Yu-WingTaiLearningDualConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu-Wing Tai\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yu-WingTaiLearningDualConvolutional').submit();\">Yu-Wing Tai</a>,\n</form>\n<form id=\"form-Ming-HsuanYangLearningDualConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming-Hsuan Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ming-HsuanYangLearningDualConvolutional').submit();\">Ming-Hsuan Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Pan_Learning_Dual_Convolutional_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0816-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.05020\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Pan_2018_CVPR,<br>\nauthor = {Pan, Jinshan and Liu, Sifei and Sun, Deqing and Zhang, Jiawei and Liu, Yang and Ren, Jimmy and Li, Zechao and Tang, Jinhui and Lu, Huchuan and Tai, Yu-Wing and Yang, Ming-Hsuan},<br>\ntitle = {Learning Dual Convolutional Neural Networks for Low-Level Vision},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhao_Defocus_Blur_Detection_CVPR_2018_paper.html\">Defocus Blur Detection via Multi-Stream Bottom-Top-Bottom Fully Convolutional Network</a></dt>\n<dd>\n<form id=\"form-WendaZhaoDefocusBlurDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenda Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-WendaZhaoDefocusBlurDetection').submit();\">Wenda Zhao</a>,\n</form>\n<form id=\"form-FanZhaoDefocusBlurDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fan Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-FanZhaoDefocusBlurDetection').submit();\">Fan Zhao</a>,\n</form>\n<form id=\"form-DongWangDefocusBlurDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dong Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-DongWangDefocusBlurDetection').submit();\">Dong Wang</a>,\n</form>\n<form id=\"form-HuchuanLuDefocusBlurDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huchuan Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuchuanLuDefocusBlurDetection').submit();\">Huchuan Lu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhao_Defocus_Blur_Detection_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhao_2018_CVPR,<br>\nauthor = {Zhao, Wenda and Zhao, Fan and Wang, Dong and Lu, Huchuan},<br>\ntitle = {Defocus Blur Detection via Multi-Stream Bottom-Top-Bottom Fully Convolutional Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_PiCANet_Learning_Pixel-Wise_CVPR_2018_paper.html\">PiCANet: Learning Pixel-Wise Contextual Attention for Saliency Detection</a></dt>\n<dd>\n<form id=\"form-NianLiuPiCANetLearningPixelWise\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nian Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-NianLiuPiCANetLearningPixelWise').submit();\">Nian Liu</a>,\n</form>\n<form id=\"form-JunweiHanPiCANetLearningPixelWise\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junwei Han\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunweiHanPiCANetLearningPixelWise').submit();\">Junwei Han</a>,\n</form>\n<form id=\"form-Ming-HsuanYangPiCANetLearningPixelWise\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming-Hsuan Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ming-HsuanYangPiCANetLearningPixelWise').submit();\">Ming-Hsuan Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_PiCANet_Learning_Pixel-Wise_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1251-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1708.06433\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Nian and Han, Junwei and Yang, Ming-Hsuan},<br>\ntitle = {PiCANet: Learning Pixel-Wise Contextual Attention for Saliency Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Barnea_Curve_Reconstruction_via_CVPR_2018_paper.html\">Curve Reconstruction via the Global Statistics of Natural Curves</a></dt>\n<dd>\n<form id=\"form-EhudBarneaCurveReconstructionvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ehud Barnea\">\n<a href=\"#\" onclick=\"document.getElementById('form-EhudBarneaCurveReconstructionvia').submit();\">Ehud Barnea</a>,\n</form>\n<form id=\"form-OhadBen-ShaharCurveReconstructionvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ohad Ben-Shahar\">\n<a href=\"#\" onclick=\"document.getElementById('form-OhadBen-ShaharCurveReconstructionvia').submit();\">Ohad Ben-Shahar</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Barnea_Curve_Reconstruction_via_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1508-supp.zip\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.03172\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Barnea_2018_CVPR,<br>\nauthor = {Barnea, Ehud and Ben-Shahar, Ohad},<br>\ntitle = {Curve Reconstruction via the Global Statistics of Natural Curves},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Palacio_What_Do_Deep_CVPR_2018_paper.html\">What Do Deep Networks Like to See?</a></dt>\n<dd>\n<form id=\"form-SebastianPalacioWhatDoDeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sebastian Palacio\">\n<a href=\"#\" onclick=\"document.getElementById('form-SebastianPalacioWhatDoDeep').submit();\">Sebastian Palacio</a>,\n</form>\n<form id=\"form-JoachimFolzWhatDoDeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Joachim Folz\">\n<a href=\"#\" onclick=\"document.getElementById('form-JoachimFolzWhatDoDeep').submit();\">Joachim Folz</a>,\n</form>\n<form id=\"form-J\u00c3\u00b6rnHeesWhatDoDeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"J\u00c3\u00b6rn Hees\">\n<a href=\"#\" onclick=\"document.getElementById('form-J\u00c3\u00b6rnHeesWhatDoDeep').submit();\">J\u00c3\u00b6rn Hees</a>,\n</form>\n<form id=\"form-FedericoRaueWhatDoDeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Federico Raue\">\n<a href=\"#\" onclick=\"document.getElementById('form-FedericoRaueWhatDoDeep').submit();\">Federico Raue</a>,\n</form>\n<form id=\"form-DamianBorthWhatDoDeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Damian Borth\">\n<a href=\"#\" onclick=\"document.getElementById('form-DamianBorthWhatDoDeep').submit();\">Damian Borth</a>,\n</form>\n<form id=\"form-AndreasDengelWhatDoDeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andreas Dengel\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndreasDengelWhatDoDeep').submit();\">Andreas Dengel</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Palacio_What_Do_Deep_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Palacio_2018_CVPR,<br>\nauthor = {Palacio, Sebastian and Folz, Joachim and Hees, J\u00c3\u00b6rn and Raue, Federico and Borth, Damian and Dengel, Andreas},<br>\ntitle = {What Do Deep Networks Like to See?},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Shocher_Zero-Shot_Super-Resolution_Using_CVPR_2018_paper.html\">\u00e2\u0080\u009cZero-Shot\u00e2\u0080\u009d Super-Resolution Using Deep Internal Learning</a></dt>\n<dd>\n<form id=\"form-AssafShocherZeroShotSuperResolutionUsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Assaf Shocher\">\n<a href=\"#\" onclick=\"document.getElementById('form-AssafShocherZeroShotSuperResolutionUsing').submit();\">Assaf Shocher</a>,\n</form>\n<form id=\"form-NadavCohenZeroShotSuperResolutionUsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nadav Cohen\">\n<a href=\"#\" onclick=\"document.getElementById('form-NadavCohenZeroShotSuperResolutionUsing').submit();\">Nadav Cohen</a>,\n</form>\n<form id=\"form-MichalIraniZeroShotSuperResolutionUsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michal Irani\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichalIraniZeroShotSuperResolutionUsing').submit();\">Michal Irani</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Shocher_Zero-Shot_Super-Resolution_Using_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Shocher_2018_CVPR,<br>\nauthor = {Shocher, Assaf and Cohen, Nadav and Irani, Michal},<br>\ntitle = {\u00e2\u0080\u009cZero-Shot\u00e2\u0080\u009d Super-Resolution Using Deep Internal Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Detect_Globally_Refine_CVPR_2018_paper.html\">Detect Globally, Refine Locally: A Novel Approach to Saliency Detection</a></dt>\n<dd>\n<form id=\"form-TiantianWangDetectGloballyRefine\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tiantian Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-TiantianWangDetectGloballyRefine').submit();\">Tiantian Wang</a>,\n</form>\n<form id=\"form-LiheZhangDetectGloballyRefine\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lihe Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiheZhangDetectGloballyRefine').submit();\">Lihe Zhang</a>,\n</form>\n<form id=\"form-ShuoWangDetectGloballyRefine\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuo Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuoWangDetectGloballyRefine').submit();\">Shuo Wang</a>,\n</form>\n<form id=\"form-HuchuanLuDetectGloballyRefine\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huchuan Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuchuanLuDetectGloballyRefine').submit();\">Huchuan Lu</a>,\n</form>\n<form id=\"form-GangYangDetectGloballyRefine\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gang Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-GangYangDetectGloballyRefine').submit();\">Gang Yang</a>,\n</form>\n<form id=\"form-XiangRuanDetectGloballyRefine\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiang Ruan\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiangRuanDetectGloballyRefine').submit();\">Xiang Ruan</a>,\n</form>\n<form id=\"form-AliBorjiDetectGloballyRefine\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ali Borji\">\n<a href=\"#\" onclick=\"document.getElementById('form-AliBorjiDetectGloballyRefine').submit();\">Ali Borji</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Detect_Globally_Refine_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Tiantian and Zhang, Lihe and Wang, Shuo and Lu, Huchuan and Yang, Gang and Ruan, Xiang and Borji, Ali},<br>\ntitle = {Detect Globally, Refine Locally: A Novel Approach to Saliency Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Mosinska_Beyond_the_Pixel-Wise_CVPR_2018_paper.html\">Beyond the Pixel-Wise Loss for Topology-Aware Delineation</a></dt>\n<dd>\n<form id=\"form-AgataMosinskaBeyondthePixelWise\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Agata Mosinska\">\n<a href=\"#\" onclick=\"document.getElementById('form-AgataMosinskaBeyondthePixelWise').submit();\">Agata Mosinska</a>,\n</form>\n<form id=\"form-PabloM\u00c3\u00a1rquez-NeilaBeyondthePixelWise\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pablo M\u00c3\u00a1rquez-Neila\">\n<a href=\"#\" onclick=\"document.getElementById('form-PabloM\u00c3\u00a1rquez-NeilaBeyondthePixelWise').submit();\">Pablo M\u00c3\u00a1rquez-Neila</a>,\n</form>\n<form id=\"form-MateuszKozi\u00c5\u0084skiBeyondthePixelWise\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mateusz Kozi\u00c5\u0084ski\">\n<a href=\"#\" onclick=\"document.getElementById('form-MateuszKozi\u00c5\u0084skiBeyondthePixelWise').submit();\">Mateusz Kozi\u00c5\u0084ski</a>,\n</form>\n<form id=\"form-PascalFuaBeyondthePixelWise\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pascal Fua\">\n<a href=\"#\" onclick=\"document.getElementById('form-PascalFuaBeyondthePixelWise').submit();\">Pascal Fua</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Mosinska_Beyond_the_Pixel-Wise_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2605-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.02190\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Mosinska_2018_CVPR,<br>\nauthor = {Mosinska, Agata and M\u00c3\u00a1rquez-Neila, Pablo and Kozi\u00c5\u0084ski, Mateusz and Fua, Pascal},<br>\ntitle = {Beyond the Pixel-Wise Loss for Topology-Aware Delineation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Bauchet_KIPPI_KInetic_Polygonal_CVPR_2018_paper.html\">KIPPI: KInetic Polygonal Partitioning of Images</a></dt>\n<dd>\n<form id=\"form-Jean-PhilippeBauchetKIPPIKIneticPolygonal\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jean-Philippe Bauchet\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jean-PhilippeBauchetKIPPIKIneticPolygonal').submit();\">Jean-Philippe Bauchet</a>,\n</form>\n<form id=\"form-FlorentLafargeKIPPIKIneticPolygonal\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Florent Lafarge\">\n<a href=\"#\" onclick=\"document.getElementById('form-FlorentLafargeKIPPIKIneticPolygonal').submit();\">Florent Lafarge</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Bauchet_KIPPI_KInetic_Polygonal_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Bauchet_2018_CVPR,<br>\nauthor = {Bauchet, Jean-Philippe and Lafarge, Florent},<br>\ntitle = {KIPPI: KInetic Polygonal Partitioning of Images},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_Image_Blind_Denoising_CVPR_2018_paper.html\">Image Blind Denoising With Generative Adversarial Network Based Noise Modeling</a></dt>\n<dd>\n<form id=\"form-JingwenChenImageBlindDenoising\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jingwen Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingwenChenImageBlindDenoising').submit();\">Jingwen Chen</a>,\n</form>\n<form id=\"form-JiaweiChenImageBlindDenoising\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiawei Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiaweiChenImageBlindDenoising').submit();\">Jiawei Chen</a>,\n</form>\n<form id=\"form-HongyangChaoImageBlindDenoising\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hongyang Chao\">\n<a href=\"#\" onclick=\"document.getElementById('form-HongyangChaoImageBlindDenoising').submit();\">Hongyang Chao</a>,\n</form>\n<form id=\"form-MingYangImageBlindDenoising\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingYangImageBlindDenoising').submit();\">Ming Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_Image_Blind_Denoising_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2954-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Jingwen and Chen, Jiawei and Chao, Hongyang and Yang, Ming},<br>\ntitle = {Image Blind Denoising With Generative Adversarial Network Based Noise Modeling},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yair_Multi-Scale_Weighted_Nuclear_CVPR_2018_paper.html\">Multi-Scale Weighted Nuclear Norm Image Restoration</a></dt>\n<dd>\n<form id=\"form-NoamYairMultiScaleWeightedNuclear\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Noam Yair\">\n<a href=\"#\" onclick=\"document.getElementById('form-NoamYairMultiScaleWeightedNuclear').submit();\">Noam Yair</a>,\n</form>\n<form id=\"form-TomerMichaeliMultiScaleWeightedNuclear\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tomer Michaeli\">\n<a href=\"#\" onclick=\"document.getElementById('form-TomerMichaeliMultiScaleWeightedNuclear').submit();\">Tomer Michaeli</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yair_Multi-Scale_Weighted_Nuclear_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3269-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yair_2018_CVPR,<br>\nauthor = {Yair, Noam and Michaeli, Tomer},<br>\ntitle = {Multi-Scale Weighted Nuclear Norm Image Restoration},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Gou_MoNet_Moments_Embedding_CVPR_2018_paper.html\">MoNet: Moments Embedding Network</a></dt>\n<dd>\n<form id=\"form-MengranGouMoNetMomentsEmbedding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mengran Gou\">\n<a href=\"#\" onclick=\"document.getElementById('form-MengranGouMoNetMomentsEmbedding').submit();\">Mengran Gou</a>,\n</form>\n<form id=\"form-FeiXiongMoNetMomentsEmbedding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fei Xiong\">\n<a href=\"#\" onclick=\"document.getElementById('form-FeiXiongMoNetMomentsEmbedding').submit();\">Fei Xiong</a>,\n</form>\n<form id=\"form-OctaviaCampsMoNetMomentsEmbedding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Octavia Camps\">\n<a href=\"#\" onclick=\"document.getElementById('form-OctaviaCampsMoNetMomentsEmbedding').submit();\">Octavia Camps</a>,\n</form>\n<form id=\"form-MarioSznaierMoNetMomentsEmbedding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mario Sznaier\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarioSznaierMoNetMomentsEmbedding').submit();\">Mario Sznaier</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Gou_MoNet_Moments_Embedding_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.07303\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Gou_2018_CVPR,<br>\nauthor = {Gou, Mengran and Xiong, Fei and Camps, Octavia and Sznaier, Mario},<br>\ntitle = {MoNet: Moments Embedding Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wloka_Active_Fixation_Control_CVPR_2018_paper.html\">Active Fixation Control to Predict Saccade Sequences</a></dt>\n<dd>\n<form id=\"form-CaldenWlokaActiveFixationControl\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Calden Wloka\">\n<a href=\"#\" onclick=\"document.getElementById('form-CaldenWlokaActiveFixationControl').submit();\">Calden Wloka</a>,\n</form>\n<form id=\"form-IuliiaKotserubaActiveFixationControl\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Iuliia Kotseruba\">\n<a href=\"#\" onclick=\"document.getElementById('form-IuliiaKotserubaActiveFixationControl').submit();\">Iuliia Kotseruba</a>,\n</form>\n<form id=\"form-JohnK.ActiveFixationControl\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"John K. Tsotsos\">\n<a href=\"#\" onclick=\"document.getElementById('form-JohnK.ActiveFixationControl').submit();\">John K. Tsotsos</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wloka_Active_Fixation_Control_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3798-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wloka_2018_CVPR,<br>\nauthor = {Wloka, Calden and Kotseruba, Iuliia and Tsotsos, John K.},<br>\ntitle = {Active Fixation Control to Predict Saccade Sequences},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Densely_Connected_Pyramid_CVPR_2018_paper.html\">Densely Connected Pyramid Dehazing Network</a></dt>\n<dd>\n<form id=\"form-HeZhangDenselyConnectedPyramid\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"He Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HeZhangDenselyConnectedPyramid').submit();\">He Zhang</a>,\n</form>\n<form id=\"form-VishalM.DenselyConnectedPyramid\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vishal M. Patel\">\n<a href=\"#\" onclick=\"document.getElementById('form-VishalM.DenselyConnectedPyramid').submit();\">Vishal M. Patel</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Densely_Connected_Pyramid_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.08396\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, He and Patel, Vishal M.},<br>\ntitle = {Densely Connected Pyramid Dehazing Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lefkimmiatis_Universal_Denoising_Networks_CVPR_2018_paper.html\">Universal Denoising Networks : A Novel CNN Architecture for Image Denoising</a></dt>\n<dd>\n<form id=\"form-StamatiosLefkimmiatisUniversalDenoisingNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stamatios Lefkimmiatis\">\n<a href=\"#\" onclick=\"document.getElementById('form-StamatiosLefkimmiatisUniversalDenoisingNetworks').submit();\">Stamatios Lefkimmiatis</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lefkimmiatis_Universal_Denoising_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0512-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.07807\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lefkimmiatis_2018_CVPR,<br>\nauthor = {Lefkimmiatis, Stamatios},<br>\ntitle = {Universal Denoising Networks : A Novel CNN Architecture for Image Denoising},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Learning_Convolutional_Networks_CVPR_2018_paper.html\">Learning Convolutional Networks for Content-Weighted Image Compression</a></dt>\n<dd>\n<form id=\"form-MuLiLearningConvolutionalNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mu Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-MuLiLearningConvolutionalNetworks').submit();\">Mu Li</a>,\n</form>\n<form id=\"form-WangmengZuoLearningConvolutionalNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wangmeng Zuo\">\n<a href=\"#\" onclick=\"document.getElementById('form-WangmengZuoLearningConvolutionalNetworks').submit();\">Wangmeng Zuo</a>,\n</form>\n<form id=\"form-ShuhangGuLearningConvolutionalNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuhang Gu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuhangGuLearningConvolutionalNetworks').submit();\">Shuhang Gu</a>,\n</form>\n<form id=\"form-DebinZhaoLearningConvolutionalNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Debin Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-DebinZhaoLearningConvolutionalNetworks').submit();\">Debin Zhao</a>,\n</form>\n<form id=\"form-DavidZhangLearningConvolutionalNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"David Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavidZhangLearningConvolutionalNetworks').submit();\">David Zhang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Learning_Convolutional_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1703.10553\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Mu and Zuo, Wangmeng and Gu, Shuhang and Zhao, Debin and Zhang, David},<br>\ntitle = {Learning Convolutional Networks for Content-Weighted Image Compression},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Jo_Deep_Video_Super-Resolution_CVPR_2018_paper.html\">Deep Video Super-Resolution Network Using Dynamic Upsampling Filters Without Explicit Motion Compensation</a></dt>\n<dd>\n<form id=\"form-YounghyunJoDeepVideoSuperResolution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Younghyun Jo\">\n<a href=\"#\" onclick=\"document.getElementById('form-YounghyunJoDeepVideoSuperResolution').submit();\">Younghyun Jo</a>,\n</form>\n<form id=\"form-SeoungWugDeepVideoSuperResolution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Seoung Wug Oh\">\n<a href=\"#\" onclick=\"document.getElementById('form-SeoungWugDeepVideoSuperResolution').submit();\">Seoung Wug Oh</a>,\n</form>\n<form id=\"form-JaeyeonKangDeepVideoSuperResolution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jaeyeon Kang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JaeyeonKangDeepVideoSuperResolution').submit();\">Jaeyeon Kang</a>,\n</form>\n<form id=\"form-SeonJooDeepVideoSuperResolution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Seon Joo Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-SeonJooDeepVideoSuperResolution').submit();\">Seon Joo Kim</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Jo_Deep_Video_Super-Resolution_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0823-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Jo_2018_CVPR,<br>\nauthor = {Jo, Younghyun and Wug Oh, Seoung and Kang, Jaeyeon and Joo Kim, Seon},<br>\ntitle = {Deep Video Super-Resolution Network Using Dynamic Upsampling Filters Without Explicit Motion Compensation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_Erase_or_Fill_CVPR_2018_paper.html\">Erase or Fill? Deep Joint Recurrent Rain Removal and Reconstruction in Videos</a></dt>\n<dd>\n<form id=\"form-JiayingLiuEraseorFill\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiaying Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiayingLiuEraseorFill').submit();\">Jiaying Liu</a>,\n</form>\n<form id=\"form-WenhanYangEraseorFill\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenhan Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenhanYangEraseorFill').submit();\">Wenhan Yang</a>,\n</form>\n<form id=\"form-ShuaiYangEraseorFill\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuai Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuaiYangEraseorFill').submit();\">Shuai Yang</a>,\n</form>\n<form id=\"form-ZongmingGuoEraseorFill\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zongming Guo\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZongmingGuoEraseorFill').submit();\">Zongming Guo</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_Erase_or_Fill_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1118-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Jiaying and Yang, Wenhan and Yang, Shuai and Guo, Zongming},<br>\ntitle = {Erase or Fill? Deep Joint Recurrent Rain Removal and Reconstruction in Videos},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Flow_Guided_Recurrent_CVPR_2018_paper.html\">Flow Guided Recurrent Neural Encoder for Video Salient Object Detection</a></dt>\n<dd>\n<form id=\"form-GuanbinLiFlowGuidedRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guanbin Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuanbinLiFlowGuidedRecurrent').submit();\">Guanbin Li</a>,\n</form>\n<form id=\"form-YuanXieFlowGuidedRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuan Xie\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuanXieFlowGuidedRecurrent').submit();\">Yuan Xie</a>,\n</form>\n<form id=\"form-TianhaoWeiFlowGuidedRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tianhao Wei\">\n<a href=\"#\" onclick=\"document.getElementById('form-TianhaoWeiFlowGuidedRecurrent').submit();\">Tianhao Wei</a>,\n</form>\n<form id=\"form-KezeWangFlowGuidedRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Keze Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-KezeWangFlowGuidedRecurrent').submit();\">Keze Wang</a>,\n</form>\n<form id=\"form-LiangLinFlowGuidedRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liang Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiangLinFlowGuidedRecurrent').submit();\">Liang Lin</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Flow_Guided_Recurrent_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Guanbin and Xie, Yuan and Wei, Tianhao and Wang, Keze and Lin, Liang},<br>\ntitle = {Flow Guided Recurrent Neural Encoder for Video Salient Object Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ren_Gated_Fusion_Network_CVPR_2018_paper.html\">Gated Fusion Network for Single Image Dehazing</a></dt>\n<dd>\n<form id=\"form-WenqiRenGatedFusionNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenqi Ren\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenqiRenGatedFusionNetwork').submit();\">Wenqi Ren</a>,\n</form>\n<form id=\"form-LinMaGatedFusionNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lin Ma\">\n<a href=\"#\" onclick=\"document.getElementById('form-LinMaGatedFusionNetwork').submit();\">Lin Ma</a>,\n</form>\n<form id=\"form-JiaweiZhangGatedFusionNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiawei Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiaweiZhangGatedFusionNetwork').submit();\">Jiawei Zhang</a>,\n</form>\n<form id=\"form-JinshanPanGatedFusionNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jinshan Pan\">\n<a href=\"#\" onclick=\"document.getElementById('form-JinshanPanGatedFusionNetwork').submit();\">Jinshan Pan</a>,\n</form>\n<form id=\"form-XiaochunCaoGatedFusionNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaochun Cao\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaochunCaoGatedFusionNetwork').submit();\">Xiaochun Cao</a>,\n</form>\n<form id=\"form-WeiLiuGatedFusionNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiLiuGatedFusionNetwork').submit();\">Wei Liu</a>,\n</form>\n<form id=\"form-Ming-HsuanYangGatedFusionNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming-Hsuan Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ming-HsuanYangGatedFusionNetwork').submit();\">Ming-Hsuan Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ren_Gated_Fusion_Network_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00213\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ren_2018_CVPR,<br>\nauthor = {Ren, Wenqi and Ma, Lin and Zhang, Jiawei and Pan, Jinshan and Cao, Xiaochun and Liu, Wei and Yang, Ming-Hsuan},<br>\ntitle = {Gated Fusion Network for Single Image Dehazing},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Learning_a_Single_CVPR_2018_paper.html\">Learning a Single Convolutional Super-Resolution Network for Multiple Degradations</a></dt>\n<dd>\n<form id=\"form-KaiZhangLearningaSingle\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kai Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaiZhangLearningaSingle').submit();\">Kai Zhang</a>,\n</form>\n<form id=\"form-WangmengZuoLearningaSingle\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wangmeng Zuo\">\n<a href=\"#\" onclick=\"document.getElementById('form-WangmengZuoLearningaSingle').submit();\">Wangmeng Zuo</a>,\n</form>\n<form id=\"form-LeiZhangLearningaSingle\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lei Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeiZhangLearningaSingle').submit();\">Lei Zhang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Learning_a_Single_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.06116\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Kai and Zuo, Wangmeng and Zhang, Lei},<br>\ntitle = {Learning a Single Convolutional Super-Resolution Network for Multiple Degradations},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Vasu_Non-Blind_Deblurring_Handling_CVPR_2018_paper.html\">Non-Blind Deblurring: Handling Kernel Uncertainty With CNNs</a></dt>\n<dd>\n<form id=\"form-SubeeshVasuNonBlindDeblurringHandling\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Subeesh Vasu\">\n<a href=\"#\" onclick=\"document.getElementById('form-SubeeshVasuNonBlindDeblurringHandling').submit();\">Subeesh Vasu</a>,\n</form>\n<form id=\"form-VenkateshReddyNonBlindDeblurringHandling\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Venkatesh Reddy Maligireddy\">\n<a href=\"#\" onclick=\"document.getElementById('form-VenkateshReddyNonBlindDeblurringHandling').submit();\">Venkatesh Reddy Maligireddy</a>,\n</form>\n<form id=\"form-A.N.NonBlindDeblurringHandling\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"A. N. Rajagopalan\">\n<a href=\"#\" onclick=\"document.getElementById('form-A.N.NonBlindDeblurringHandling').submit();\">A. N. Rajagopalan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Vasu_Non-Blind_Deblurring_Handling_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1792-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Vasu_2018_CVPR,<br>\nauthor = {Vasu, Subeesh and Reddy Maligireddy, Venkatesh and Rajagopalan, A. N.},<br>\ntitle = {Non-Blind Deblurring: Handling Kernel Uncertainty With CNNs},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lei_Boundary_Flow_A_CVPR_2018_paper.html\">Boundary Flow: A Siamese Network That Predicts Boundary Motion Without Training on Motion</a></dt>\n<dd>\n<form id=\"form-PengLeiBoundaryFlowA\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peng Lei\">\n<a href=\"#\" onclick=\"document.getElementById('form-PengLeiBoundaryFlowA').submit();\">Peng Lei</a>,\n</form>\n<form id=\"form-FuxinLiBoundaryFlowA\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fuxin Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-FuxinLiBoundaryFlowA').submit();\">Fuxin Li</a>,\n</form>\n<form id=\"form-SinisaTodorovicBoundaryFlowA\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sinisa Todorovic\">\n<a href=\"#\" onclick=\"document.getElementById('form-SinisaTodorovicBoundaryFlowA').submit();\">Sinisa Todorovic</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lei_Boundary_Flow_A_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1702.08646\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lei_2018_CVPR,<br>\nauthor = {Lei, Peng and Li, Fuxin and Todorovic, Sinisa},<br>\ntitle = {Boundary Flow: A Siamese Network That Predicts Boundary Motion Without Training on Motion},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_Learning_to_See_CVPR_2018_paper.html\">Learning to See in the Dark</a></dt>\n<dd>\n<form id=\"form-ChenChenLearningtoSee\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chen Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenChenLearningtoSee').submit();\">Chen Chen</a>,\n</form>\n<form id=\"form-QifengChenLearningtoSee\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qifeng Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-QifengChenLearningtoSee').submit();\">Qifeng Chen</a>,\n</form>\n<form id=\"form-JiaXuLearningtoSee\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jia Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiaXuLearningtoSee').submit();\">Jia Xu</a>,\n</form>\n<form id=\"form-VladlenKoltunLearningtoSee\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vladlen Koltun\">\n<a href=\"#\" onclick=\"document.getElementById('form-VladlenKoltunLearningtoSee').submit();\">Vladlen Koltun</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_Learning_to_See_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.01934\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Chen and Chen, Qifeng and Xu, Jia and Koltun, Vladlen},<br>\ntitle = {Learning to See in the Dark},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_BPGrad_Towards_Global_CVPR_2018_paper.html\">BPGrad: Towards Global Optimality in Deep Learning via Branch and Pruning</a></dt>\n<dd>\n<form id=\"form-ZimingZhangBPGradTowardsGlobal\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ziming Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZimingZhangBPGradTowardsGlobal').submit();\">Ziming Zhang</a>,\n</form>\n<form id=\"form-YuanweiWuBPGradTowardsGlobal\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuanwei Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuanweiWuBPGradTowardsGlobal').submit();\">Yuanwei Wu</a>,\n</form>\n<form id=\"form-GuanghuiWangBPGradTowardsGlobal\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guanghui Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuanghuiWangBPGradTowardsGlobal').submit();\">Guanghui Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_BPGrad_Towards_Global_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.06959\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Ziming and Wu, Yuanwei and Wang, Guanghui},<br>\ntitle = {BPGrad: Towards Global Optimality in Deep Learning via Branch and Pruning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Juefei-Xu_Perturbative_Neural_Networks_CVPR_2018_paper.html\">Perturbative Neural Networks</a></dt>\n<dd>\n<form id=\"form-FelixJuefei-XuPerturbativeNeuralNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Felix Juefei-Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-FelixJuefei-XuPerturbativeNeuralNetworks').submit();\">Felix Juefei-Xu</a>,\n</form>\n<form id=\"form-VishnuNareshPerturbativeNeuralNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vishnu Naresh Boddeti\">\n<a href=\"#\" onclick=\"document.getElementById('form-VishnuNareshPerturbativeNeuralNetworks').submit();\">Vishnu Naresh Boddeti</a>,\n</form>\n<form id=\"form-MariosSavvidesPerturbativeNeuralNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Marios Savvides\">\n<a href=\"#\" onclick=\"document.getElementById('form-MariosSavvidesPerturbativeNeuralNetworks').submit();\">Marios Savvides</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Juefei-Xu_Perturbative_Neural_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0200-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1806.01817\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Juefei-Xu_2018_CVPR,<br>\nauthor = {Juefei-Xu, Felix and Naresh Boddeti, Vishnu and Savvides, Marios},<br>\ntitle = {Perturbative Neural Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hoshen_Unsupervised_Correlation_Analysis_CVPR_2018_paper.html\">Unsupervised Correlation Analysis</a></dt>\n<dd>\n<form id=\"form-YedidHoshenUnsupervisedCorrelationAnalysis\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yedid Hoshen\">\n<a href=\"#\" onclick=\"document.getElementById('form-YedidHoshenUnsupervisedCorrelationAnalysis').submit();\">Yedid Hoshen</a>,\n</form>\n<form id=\"form-LiorWolfUnsupervisedCorrelationAnalysis\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lior Wolf\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiorWolfUnsupervisedCorrelationAnalysis').submit();\">Lior Wolf</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hoshen_Unsupervised_Correlation_Analysis_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00347\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hoshen_2018_CVPR,<br>\nauthor = {Hoshen, Yedid and Wolf, Lior},<br>\ntitle = {Unsupervised Correlation Analysis},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Mukherjee_A_Biresolution_Spectral_CVPR_2018_paper.html\">A Biresolution Spectral Framework for Product Quantization</a></dt>\n<dd>\n<form id=\"form-LopamudraMukherjeeABiresolutionSpectral\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lopamudra Mukherjee\">\n<a href=\"#\" onclick=\"document.getElementById('form-LopamudraMukherjeeABiresolutionSpectral').submit();\">Lopamudra Mukherjee</a>,\n</form>\n<form id=\"form-SathyaN.ABiresolutionSpectral\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sathya N. Ravi\">\n<a href=\"#\" onclick=\"document.getElementById('form-SathyaN.ABiresolutionSpectral').submit();\">Sathya N. Ravi</a>,\n</form>\n<form id=\"form-JimingPengABiresolutionSpectral\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiming Peng\">\n<a href=\"#\" onclick=\"document.getElementById('form-JimingPengABiresolutionSpectral').submit();\">Jiming Peng</a>,\n</form>\n<form id=\"form-VikasSinghABiresolutionSpectral\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vikas Singh\">\n<a href=\"#\" onclick=\"document.getElementById('form-VikasSinghABiresolutionSpectral').submit();\">Vikas Singh</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Mukherjee_A_Biresolution_Spectral_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Mukherjee_2018_CVPR,<br>\nauthor = {Mukherjee, Lopamudra and Ravi, Sathya N. and Peng, Jiming and Singh, Vikas},<br>\ntitle = {A Biresolution Spectral Framework for Product Quantization},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_Domain_Adaptive_Faster_CVPR_2018_paper.html\">Domain Adaptive Faster R-CNN for Object Detection in the Wild</a></dt>\n<dd>\n<form id=\"form-YuhuaChenDomainAdaptiveFaster\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuhua Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuhuaChenDomainAdaptiveFaster').submit();\">Yuhua Chen</a>,\n</form>\n<form id=\"form-WenLiDomainAdaptiveFaster\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wen Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenLiDomainAdaptiveFaster').submit();\">Wen Li</a>,\n</form>\n<form id=\"form-ChristosSakaridisDomainAdaptiveFaster\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Christos Sakaridis\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChristosSakaridisDomainAdaptiveFaster').submit();\">Christos Sakaridis</a>,\n</form>\n<form id=\"form-DengxinDaiDomainAdaptiveFaster\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dengxin Dai\">\n<a href=\"#\" onclick=\"document.getElementById('form-DengxinDaiDomainAdaptiveFaster').submit();\">Dengxin Dai</a>,\n</form>\n<form id=\"form-LucVanDomainAdaptiveFaster\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Luc Van Gool\">\n<a href=\"#\" onclick=\"document.getElementById('form-LucVanDomainAdaptiveFaster').submit();\">Luc Van Gool</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_Domain_Adaptive_Faster_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.03243\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Yuhua and Li, Wen and Sakaridis, Christos and Dai, Dengxin and Van Gool, Luc},<br>\ntitle = {Domain Adaptive Faster R-CNN for Object Detection in the Wild},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Douze_Low-Shot_Learning_With_CVPR_2018_paper.html\">Low-Shot Learning With Large-Scale Diffusion</a></dt>\n<dd>\n<form id=\"form-MatthijsDouzeLowShotLearningWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Matthijs Douze\">\n<a href=\"#\" onclick=\"document.getElementById('form-MatthijsDouzeLowShotLearningWith').submit();\">Matthijs Douze</a>,\n</form>\n<form id=\"form-ArthurSzlamLowShotLearningWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Arthur Szlam\">\n<a href=\"#\" onclick=\"document.getElementById('form-ArthurSzlamLowShotLearningWith').submit();\">Arthur Szlam</a>,\n</form>\n<form id=\"form-BharathHariharanLowShotLearningWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bharath Hariharan\">\n<a href=\"#\" onclick=\"document.getElementById('form-BharathHariharanLowShotLearningWith').submit();\">Bharath Hariharan</a>,\n</form>\n<form id=\"form-Herv\u00c3\u00a9J\u00c3\u00a9gouLowShotLearningWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Herv\u00c3\u00a9 J\u00c3\u00a9gou\">\n<a href=\"#\" onclick=\"document.getElementById('form-Herv\u00c3\u00a9J\u00c3\u00a9gouLowShotLearningWith').submit();\">Herv\u00c3\u00a9 J\u00c3\u00a9gou</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Douze_Low-Shot_Learning_With_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1706.02332\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Douze_2018_CVPR,<br>\nauthor = {Douze, Matthijs and Szlam, Arthur and Hariharan, Bharath and J\u00c3\u00a9gou, Herv\u00c3\u00a9},<br>\ntitle = {Low-Shot Learning With Large-Scale Diffusion},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Joint_Pose_and_CVPR_2018_paper.html\">Joint Pose and Expression Modeling for Facial Expression Recognition</a></dt>\n<dd>\n<form id=\"form-FeifeiZhangJointPoseand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Feifei Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-FeifeiZhangJointPoseand').submit();\">Feifei Zhang</a>,\n</form>\n<form id=\"form-TianzhuZhangJointPoseand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tianzhu Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-TianzhuZhangJointPoseand').submit();\">Tianzhu Zhang</a>,\n</form>\n<form id=\"form-QirongMaoJointPoseand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qirong Mao\">\n<a href=\"#\" onclick=\"document.getElementById('form-QirongMaoJointPoseand').submit();\">Qirong Mao</a>,\n</form>\n<form id=\"form-ChangshengXuJointPoseand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Changsheng Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChangshengXuJointPoseand').submit();\">Changsheng Xu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Joint_Pose_and_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Feifei and Zhang, Tianzhu and Mao, Qirong and Xu, Changsheng},<br>\ntitle = {Joint Pose and Expression Modeling for Facial Expression Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Gast_Lightweight_Probabilistic_Deep_CVPR_2018_paper.html\">Lightweight Probabilistic Deep Networks</a></dt>\n<dd>\n<form id=\"form-JochenGastLightweightProbabilisticDeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jochen Gast\">\n<a href=\"#\" onclick=\"document.getElementById('form-JochenGastLightweightProbabilisticDeep').submit();\">Jochen Gast</a>,\n</form>\n<form id=\"form-StefanRothLightweightProbabilisticDeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stefan Roth\">\n<a href=\"#\" onclick=\"document.getElementById('form-StefanRothLightweightProbabilisticDeep').submit();\">Stefan Roth</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Gast_Lightweight_Probabilistic_Deep_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1799-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.11327\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Gast_2018_CVPR,<br>\nauthor = {Gast, Jochen and Roth, Stefan},<br>\ntitle = {Lightweight Probabilistic Deep Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sabokrou_Adversarially_Learned_One-Class_CVPR_2018_paper.html\">Adversarially Learned One-Class Classifier for Novelty Detection</a></dt>\n<dd>\n<form id=\"form-MohammadSabokrouAdversariallyLearnedOneClass\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mohammad Sabokrou\">\n<a href=\"#\" onclick=\"document.getElementById('form-MohammadSabokrouAdversariallyLearnedOneClass').submit();\">Mohammad Sabokrou</a>,\n</form>\n<form id=\"form-MohammadKhalooeiAdversariallyLearnedOneClass\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mohammad Khalooei\">\n<a href=\"#\" onclick=\"document.getElementById('form-MohammadKhalooeiAdversariallyLearnedOneClass').submit();\">Mohammad Khalooei</a>,\n</form>\n<form id=\"form-MahmoodFathyAdversariallyLearnedOneClass\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mahmood Fathy\">\n<a href=\"#\" onclick=\"document.getElementById('form-MahmoodFathyAdversariallyLearnedOneClass').submit();\">Mahmood Fathy</a>,\n</form>\n<form id=\"form-EhsanAdeliAdversariallyLearnedOneClass\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ehsan Adeli\">\n<a href=\"#\" onclick=\"document.getElementById('form-EhsanAdeliAdversariallyLearnedOneClass').submit();\">Ehsan Adeli</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sabokrou_Adversarially_Learned_One-Class_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.09088\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sabokrou_2018_CVPR,<br>\nauthor = {Sabokrou, Mohammad and Khalooei, Mohammad and Fathy, Mahmood and Adeli, Ehsan},<br>\ntitle = {Adversarially Learned One-Class Classifier for Novelty Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Akhtar_Defense_Against_Universal_CVPR_2018_paper.html\">Defense Against Universal Adversarial Perturbations</a></dt>\n<dd>\n<form id=\"form-NaveedAkhtarDefenseAgainstUniversal\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Naveed Akhtar\">\n<a href=\"#\" onclick=\"document.getElementById('form-NaveedAkhtarDefenseAgainstUniversal').submit();\">Naveed Akhtar</a>,\n</form>\n<form id=\"form-JianLiuDefenseAgainstUniversal\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jian Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianLiuDefenseAgainstUniversal').submit();\">Jian Liu</a>,\n</form>\n<form id=\"form-AjmalMianDefenseAgainstUniversal\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ajmal Mian\">\n<a href=\"#\" onclick=\"document.getElementById('form-AjmalMianDefenseAgainstUniversal').submit();\">Ajmal Mian</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Akhtar_Defense_Against_Universal_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2722-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.05929\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Akhtar_2018_CVPR,<br>\nauthor = {Akhtar, Naveed and Liu, Jian and Mian, Ajmal},<br>\ntitle = {Defense Against Universal Adversarial Perturbations},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hu_Disentangling_Factors_of_CVPR_2018_paper.html\">Disentangling Factors of Variation by Mixing Them</a></dt>\n<dd>\n<form id=\"form-QiyangHuDisentanglingFactorsof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qiyang Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiyangHuDisentanglingFactorsof').submit();\">Qiyang Hu</a>,\n</form>\n<form id=\"form-AttilaSzab\u00c3\u00b3DisentanglingFactorsof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Attila Szab\u00c3\u00b3\">\n<a href=\"#\" onclick=\"document.getElementById('form-AttilaSzab\u00c3\u00b3DisentanglingFactorsof').submit();\">Attila Szab\u00c3\u00b3</a>,\n</form>\n<form id=\"form-TizianoPortenierDisentanglingFactorsof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tiziano Portenier\">\n<a href=\"#\" onclick=\"document.getElementById('form-TizianoPortenierDisentanglingFactorsof').submit();\">Tiziano Portenier</a>,\n</form>\n<form id=\"form-PaoloFavaroDisentanglingFactorsof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Paolo Favaro\">\n<a href=\"#\" onclick=\"document.getElementById('form-PaoloFavaroDisentanglingFactorsof').submit();\">Paolo Favaro</a>,\n</form>\n<form id=\"form-MatthiasZwickerDisentanglingFactorsof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Matthias Zwicker\">\n<a href=\"#\" onclick=\"document.getElementById('form-MatthiasZwickerDisentanglingFactorsof').submit();\">Matthias Zwicker</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hu_Disentangling_Factors_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.07410\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hu_2018_CVPR,<br>\nauthor = {Hu, Qiyang and Szab\u00c3\u00b3, Attila and Portenier, Tiziano and Favaro, Paolo and Zwicker, Matthias},<br>\ntitle = {Disentangling Factors of Variation by Mixing Them},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Siarohin_Deformable_GANs_for_CVPR_2018_paper.html\">Deformable GANs for Pose-Based Human Image Generation</a></dt>\n<dd>\n<form id=\"form-AliaksandrSiarohinDeformableGANsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Aliaksandr Siarohin\">\n<a href=\"#\" onclick=\"document.getElementById('form-AliaksandrSiarohinDeformableGANsfor').submit();\">Aliaksandr Siarohin</a>,\n</form>\n<form id=\"form-EnverSanginetoDeformableGANsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Enver Sangineto\">\n<a href=\"#\" onclick=\"document.getElementById('form-EnverSanginetoDeformableGANsfor').submit();\">Enver Sangineto</a>,\n</form>\n<form id=\"form-St\u00c3\u00a9phaneLathuili\u00c3\u00a8reDeformableGANsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"St\u00c3\u00a9phane Lathuili\u00c3\u00a8re\">\n<a href=\"#\" onclick=\"document.getElementById('form-St\u00c3\u00a9phaneLathuili\u00c3\u00a8reDeformableGANsfor').submit();\">St\u00c3\u00a9phane Lathuili\u00c3\u00a8re</a>,\n</form>\n<form id=\"form-NicuSebeDeformableGANsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nicu Sebe\">\n<a href=\"#\" onclick=\"document.getElementById('form-NicuSebeDeformableGANsfor').submit();\">Nicu Sebe</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Siarohin_Deformable_GANs_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3247-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.00055\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Siarohin_2018_CVPR,<br>\nauthor = {Siarohin, Aliaksandr and Sangineto, Enver and Lathuili\u00c3\u00a8re, St\u00c3\u00a9phane and Sebe, Nicu},<br>\ntitle = {Deformable GANs for Pose-Based Human Image Generation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Homayounfar_Hierarchical_Recurrent_Attention_CVPR_2018_paper.html\">Hierarchical Recurrent Attention Networks for Structured Online Maps</a></dt>\n<dd>\n<form id=\"form-NamdarHomayounfarHierarchicalRecurrentAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Namdar Homayounfar\">\n<a href=\"#\" onclick=\"document.getElementById('form-NamdarHomayounfarHierarchicalRecurrentAttention').submit();\">Namdar Homayounfar</a>,\n</form>\n<form id=\"form-Wei-ChiuMaHierarchicalRecurrentAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei-Chiu Ma\">\n<a href=\"#\" onclick=\"document.getElementById('form-Wei-ChiuMaHierarchicalRecurrentAttention').submit();\">Wei-Chiu Ma</a>,\n</form>\n<form id=\"form-ShrinidhiKowshikaHierarchicalRecurrentAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shrinidhi Kowshika Lakshmikanth\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShrinidhiKowshikaHierarchicalRecurrentAttention').submit();\">Shrinidhi Kowshika Lakshmikanth</a>,\n</form>\n<form id=\"form-RaquelUrtasunHierarchicalRecurrentAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Raquel Urtasun\">\n<a href=\"#\" onclick=\"document.getElementById('form-RaquelUrtasunHierarchicalRecurrentAttention').submit();\">Raquel Urtasun</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Homayounfar_Hierarchical_Recurrent_Attention_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Homayounfar_2018_CVPR,<br>\nauthor = {Homayounfar, Namdar and Ma, Wei-Chiu and Kowshika Lakshmikanth, Shrinidhi and Urtasun, Raquel},<br>\ntitle = {Hierarchical Recurrent Attention Networks for Structured Online Maps},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kolouri_Sliced_Wasserstein_Distance_CVPR_2018_paper.html\">Sliced Wasserstein Distance for Learning Gaussian Mixture Models</a></dt>\n<dd>\n<form id=\"form-SoheilKolouriSlicedWassersteinDistance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Soheil Kolouri\">\n<a href=\"#\" onclick=\"document.getElementById('form-SoheilKolouriSlicedWassersteinDistance').submit();\">Soheil Kolouri</a>,\n</form>\n<form id=\"form-GustavoK.SlicedWassersteinDistance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gustavo K. Rohde\">\n<a href=\"#\" onclick=\"document.getElementById('form-GustavoK.SlicedWassersteinDistance').submit();\">Gustavo K. Rohde</a>,\n</form>\n<form id=\"form-HeikoHoffmannSlicedWassersteinDistance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Heiko Hoffmann\">\n<a href=\"#\" onclick=\"document.getElementById('form-HeikoHoffmannSlicedWassersteinDistance').submit();\">Heiko Hoffmann</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kolouri_Sliced_Wasserstein_Distance_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3352-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.05376\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kolouri_2018_CVPR,<br>\nauthor = {Kolouri, Soheil and Rohde, Gustavo K. and Hoffmann, Heiko},<br>\ntitle = {Sliced Wasserstein Distance for Learning Gaussian Mixture Models},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Aligning_Infinite-Dimensional_Covariance_CVPR_2018_paper.html\">Aligning Infinite-Dimensional Covariance Matrices in Reproducing Kernel Hilbert Spaces for Domain Adaptation</a></dt>\n<dd>\n<form id=\"form-ZhenZhangAligningInfiniteDimensionalCovariance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhen Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhenZhangAligningInfiniteDimensionalCovariance').submit();\">Zhen Zhang</a>,\n</form>\n<form id=\"form-MianzhiWangAligningInfiniteDimensionalCovariance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mianzhi Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-MianzhiWangAligningInfiniteDimensionalCovariance').submit();\">Mianzhi Wang</a>,\n</form>\n<form id=\"form-YanHuangAligningInfiniteDimensionalCovariance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yan Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanHuangAligningInfiniteDimensionalCovariance').submit();\">Yan Huang</a>,\n</form>\n<form id=\"form-AryeNehoraiAligningInfiniteDimensionalCovariance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Arye Nehorai\">\n<a href=\"#\" onclick=\"document.getElementById('form-AryeNehoraiAligningInfiniteDimensionalCovariance').submit();\">Arye Nehorai</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Aligning_Infinite-Dimensional_Covariance_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3383-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Zhen and Wang, Mianzhi and Huang, Yan and Nehorai, Arye},<br>\ntitle = {Aligning Infinite-Dimensional Covariance Matrices in Reproducing Kernel Hilbert Spaces for Domain Adaptation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kozerawski_CLEAR_Cumulative_LEARning_CVPR_2018_paper.html\">CLEAR: Cumulative LEARning for One-Shot One-Class Image Recognition</a></dt>\n<dd>\n<form id=\"form-JedrzejKozerawskiCLEARCumulativeLEARning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jedrzej Kozerawski\">\n<a href=\"#\" onclick=\"document.getElementById('form-JedrzejKozerawskiCLEARCumulativeLEARning').submit();\">Jedrzej Kozerawski</a>,\n</form>\n<form id=\"form-MatthewTurkCLEARCumulativeLEARning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Matthew Turk\">\n<a href=\"#\" onclick=\"document.getElementById('form-MatthewTurkCLEARCumulativeLEARning').submit();\">Matthew Turk</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kozerawski_CLEAR_Cumulative_LEARning_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kozerawski_2018_CVPR,<br>\nauthor = {Kozerawski, Jedrzej and Turk, Matthew},<br>\ntitle = {CLEAR: Cumulative LEARning for One-Shot One-Class Image Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ikami_Local_and_Global_CVPR_2018_paper.html\">Local and Global Optimization Techniques in Graph-Based Clustering</a></dt>\n<dd>\n<form id=\"form-DaikiIkamiLocalandGlobal\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daiki Ikami\">\n<a href=\"#\" onclick=\"document.getElementById('form-DaikiIkamiLocalandGlobal').submit();\">Daiki Ikami</a>,\n</form>\n<form id=\"form-ToshihikoYamasakiLocalandGlobal\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Toshihiko Yamasaki\">\n<a href=\"#\" onclick=\"document.getElementById('form-ToshihikoYamasakiLocalandGlobal').submit();\">Toshihiko Yamasaki</a>,\n</form>\n<form id=\"form-KiyoharuAizawaLocalandGlobal\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kiyoharu Aizawa\">\n<a href=\"#\" onclick=\"document.getElementById('form-KiyoharuAizawaLocalandGlobal').submit();\">Kiyoharu Aizawa</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ikami_Local_and_Global_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ikami_2018_CVPR,<br>\nauthor = {Ikami, Daiki and Yamasaki, Toshihiko and Aizawa, Kiyoharu},<br>\ntitle = {Local and Global Optimization Techniques in Graph-Based Clustering},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Mejjati_Multi-Task_Learning_by_CVPR_2018_paper.html\">Multi-Task Learning by Maximizing Statistical Dependence</a></dt>\n<dd>\n<form id=\"form-YoussefA.MultiTaskLearningby\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Youssef A. Mejjati\">\n<a href=\"#\" onclick=\"document.getElementById('form-YoussefA.MultiTaskLearningby').submit();\">Youssef A. Mejjati</a>,\n</form>\n<form id=\"form-DarrenCoskerMultiTaskLearningby\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Darren Cosker\">\n<a href=\"#\" onclick=\"document.getElementById('form-DarrenCoskerMultiTaskLearningby').submit();\">Darren Cosker</a>,\n</form>\n<form id=\"form-KwangInMultiTaskLearningby\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kwang In Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-KwangInMultiTaskLearningby').submit();\">Kwang In Kim</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Mejjati_Multi-Task_Learning_by_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3604-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Mejjati_2018_CVPR,<br>\nauthor = {Mejjati, Youssef A. and Cosker, Darren and In Kim, Kwang},<br>\ntitle = {Multi-Task Learning by Maximizing Statistical Dependence},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yang_Robust_Classification_With_CVPR_2018_paper.html\">Robust Classification With Convolutional Prototype Learning</a></dt>\n<dd>\n<form id=\"form-Hong-MingYangRobustClassificationWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hong-Ming Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Hong-MingYangRobustClassificationWith').submit();\">Hong-Ming Yang</a>,\n</form>\n<form id=\"form-Xu-YaoZhangRobustClassificationWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xu-Yao Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Xu-YaoZhangRobustClassificationWith').submit();\">Xu-Yao Zhang</a>,\n</form>\n<form id=\"form-FeiYinRobustClassificationWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fei Yin\">\n<a href=\"#\" onclick=\"document.getElementById('form-FeiYinRobustClassificationWith').submit();\">Fei Yin</a>,\n</form>\n<form id=\"form-Cheng-LinLiuRobustClassificationWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cheng-Lin Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Cheng-LinLiuRobustClassificationWith').submit();\">Cheng-Lin Liu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yang_Robust_Classification_With_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.03438\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yang_2018_CVPR,<br>\nauthor = {Yang, Hong-Ming and Zhang, Xu-Yao and Yin, Fei and Liu, Cheng-Lin},<br>\ntitle = {Robust Classification With Convolutional Prototype Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Deshpande_Generative_Modeling_Using_CVPR_2018_paper.html\">Generative Modeling Using the Sliced Wasserstein Distance</a></dt>\n<dd>\n<form id=\"form-IshanDeshpandeGenerativeModelingUsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ishan Deshpande\">\n<a href=\"#\" onclick=\"document.getElementById('form-IshanDeshpandeGenerativeModelingUsing').submit();\">Ishan Deshpande</a>,\n</form>\n<form id=\"form-ZiyuZhangGenerativeModelingUsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ziyu Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZiyuZhangGenerativeModelingUsing').submit();\">Ziyu Zhang</a>,\n</form>\n<form id=\"form-AlexanderG.GenerativeModelingUsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexander G. Schwing\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexanderG.GenerativeModelingUsing').submit();\">Alexander G. Schwing</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Deshpande_Generative_Modeling_Using_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3722-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.11188\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Deshpande_2018_CVPR,<br>\nauthor = {Deshpande, Ishan and Zhang, Ziyu and Schwing, Alexander G.},<br>\ntitle = {Generative Modeling Using the Sliced Wasserstein Distance},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Veniat_Learning_TimeMemory-Efficient_Deep_CVPR_2018_paper.html\">Learning Time/Memory-Efficient Deep Architectures With Budgeted Super Networks</a></dt>\n<dd>\n<form id=\"form-TomV\u00c3\u00a9niatLearningTimeMemoryEfficientDeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tom V\u00c3\u00a9niat\">\n<a href=\"#\" onclick=\"document.getElementById('form-TomV\u00c3\u00a9niatLearningTimeMemoryEfficientDeep').submit();\">Tom V\u00c3\u00a9niat</a>,\n</form>\n<form id=\"form-LudovicDenoyerLearningTimeMemoryEfficientDeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ludovic Denoyer\">\n<a href=\"#\" onclick=\"document.getElementById('form-LudovicDenoyerLearningTimeMemoryEfficientDeep').submit();\">Ludovic Denoyer</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Veniat_Learning_TimeMemory-Efficient_Deep_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3809-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1706.00046\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{V\u00c3\u00a9niat_2018_CVPR,<br>\nauthor = {V\u00c3\u00a9niat, Tom and Denoyer, Ludovic},<br>\ntitle = {Learning Time/Memory-Efficient Deep Architectures With Budgeted Super Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Regmi_Cross-View_Image_Synthesis_CVPR_2018_paper.html\">Cross-View Image Synthesis Using Conditional GANs</a></dt>\n<dd>\n<form id=\"form-KrishnaRegmiCrossViewImageSynthesis\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Krishna Regmi\">\n<a href=\"#\" onclick=\"document.getElementById('form-KrishnaRegmiCrossViewImageSynthesis').submit();\">Krishna Regmi</a>,\n</form>\n<form id=\"form-AliBorjiCrossViewImageSynthesis\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ali Borji\">\n<a href=\"#\" onclick=\"document.getElementById('form-AliBorjiCrossViewImageSynthesis').submit();\">Ali Borji</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Regmi_Cross-View_Image_Synthesis_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.03396\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Regmi_2018_CVPR,<br>\nauthor = {Regmi, Krishna and Borji, Ali},<br>\ntitle = {Cross-View Image Synthesis Using Conditional GANs},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Dekel_Sparse_Smart_Contours_CVPR_2018_paper.html\">Sparse, Smart Contours to Represent and Edit Images</a></dt>\n<dd>\n<form id=\"form-TaliDekelSparseSmartContours\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tali Dekel\">\n<a href=\"#\" onclick=\"document.getElementById('form-TaliDekelSparseSmartContours').submit();\">Tali Dekel</a>,\n</form>\n<form id=\"form-ChuangGanSparseSmartContours\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chuang Gan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChuangGanSparseSmartContours').submit();\">Chuang Gan</a>,\n</form>\n<form id=\"form-DilipKrishnanSparseSmartContours\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dilip Krishnan\">\n<a href=\"#\" onclick=\"document.getElementById('form-DilipKrishnanSparseSmartContours').submit();\">Dilip Krishnan</a>,\n</form>\n<form id=\"form-CeLiuSparseSmartContours\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ce Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-CeLiuSparseSmartContours').submit();\">Ce Liu</a>,\n</form>\n<form id=\"form-WilliamT.SparseSmartContours\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"William T. Freeman\">\n<a href=\"#\" onclick=\"document.getElementById('form-WilliamT.SparseSmartContours').submit();\">William T. Freeman</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Dekel_Sparse_Smart_Contours_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Dekel_2018_CVPR,<br>\nauthor = {Dekel, Tali and Gan, Chuang and Krishnan, Dilip and Liu, Ce and Freeman, William T.},<br>\ntitle = {Sparse, Smart Contours to Represent and Edit Images},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Suzuki_Anticipating_Traffic_Accidents_CVPR_2018_paper.html\">Anticipating Traffic Accidents With Adaptive Loss and Large-Scale Incident DB</a></dt>\n<dd>\n<form id=\"form-TomoyukiSuzukiAnticipatingTrafficAccidents\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tomoyuki Suzuki\">\n<a href=\"#\" onclick=\"document.getElementById('form-TomoyukiSuzukiAnticipatingTrafficAccidents').submit();\">Tomoyuki Suzuki</a>,\n</form>\n<form id=\"form-HirokatsuKataokaAnticipatingTrafficAccidents\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hirokatsu Kataoka\">\n<a href=\"#\" onclick=\"document.getElementById('form-HirokatsuKataokaAnticipatingTrafficAccidents').submit();\">Hirokatsu Kataoka</a>,\n</form>\n<form id=\"form-YoshimitsuAokiAnticipatingTrafficAccidents\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yoshimitsu Aoki\">\n<a href=\"#\" onclick=\"document.getElementById('form-YoshimitsuAokiAnticipatingTrafficAccidents').submit();\">Yoshimitsu Aoki</a>,\n</form>\n<form id=\"form-YutakaSatohAnticipatingTrafficAccidents\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yutaka Satoh\">\n<a href=\"#\" onclick=\"document.getElementById('form-YutakaSatohAnticipatingTrafficAccidents').submit();\">Yutaka Satoh</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Suzuki_Anticipating_Traffic_Accidents_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.02675\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Suzuki_2018_CVPR,<br>\nauthor = {Suzuki, Tomoyuki and Kataoka, Hirokatsu and Aoki, Yoshimitsu and Satoh, Yutaka},<br>\ntitle = {Anticipating Traffic Accidents With Adaptive Loss and Large-Scale Incident DB},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Birdal_A_Minimalist_Approach_CVPR_2018_paper.html\">A Minimalist Approach to Type-Agnostic Detection of Quadrics in Point Clouds</a></dt>\n<dd>\n<form id=\"form-TolgaBirdalAMinimalistApproach\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tolga Birdal\">\n<a href=\"#\" onclick=\"document.getElementById('form-TolgaBirdalAMinimalistApproach').submit();\">Tolga Birdal</a>,\n</form>\n<form id=\"form-BenjaminBusamAMinimalistApproach\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Benjamin Busam\">\n<a href=\"#\" onclick=\"document.getElementById('form-BenjaminBusamAMinimalistApproach').submit();\">Benjamin Busam</a>,\n</form>\n<form id=\"form-NassirNavabAMinimalistApproach\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nassir Navab\">\n<a href=\"#\" onclick=\"document.getElementById('form-NassirNavabAMinimalistApproach').submit();\">Nassir Navab</a>,\n</form>\n<form id=\"form-SlobodanIlicAMinimalistApproach\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Slobodan Ilic\">\n<a href=\"#\" onclick=\"document.getElementById('form-SlobodanIlicAMinimalistApproach').submit();\">Slobodan Ilic</a>,\n</form>\n<form id=\"form-PeterSturmAMinimalistApproach\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peter Sturm\">\n<a href=\"#\" onclick=\"document.getElementById('form-PeterSturmAMinimalistApproach').submit();\">Peter Sturm</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Birdal_A_Minimalist_Approach_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.07191\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Birdal_2018_CVPR,<br>\nauthor = {Birdal, Tolga and Busam, Benjamin and Navab, Nassir and Ilic, Slobodan and Sturm, Peter},<br>\ntitle = {A Minimalist Approach to Type-Agnostic Detection of Quadrics in Point Clouds},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_Facelet-Bank_for_Fast_CVPR_2018_paper.html\">Facelet-Bank for Fast Portrait Manipulation</a></dt>\n<dd>\n<form id=\"form-Ying-CongChenFaceletBankforFast\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ying-Cong Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ying-CongChenFaceletBankforFast').submit();\">Ying-Cong Chen</a>,\n</form>\n<form id=\"form-HuaijiaLinFaceletBankforFast\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huaijia Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuaijiaLinFaceletBankforFast').submit();\">Huaijia Lin</a>,\n</form>\n<form id=\"form-MichelleShuFaceletBankforFast\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michelle Shu\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichelleShuFaceletBankforFast').submit();\">Michelle Shu</a>,\n</form>\n<form id=\"form-RuiyuLiFaceletBankforFast\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ruiyu Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-RuiyuLiFaceletBankforFast').submit();\">Ruiyu Li</a>,\n</form>\n<form id=\"form-XinTaoFaceletBankforFast\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xin Tao\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinTaoFaceletBankforFast').submit();\">Xin Tao</a>,\n</form>\n<form id=\"form-XiaoyongShenFaceletBankforFast\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaoyong Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaoyongShenFaceletBankforFast').submit();\">Xiaoyong Shen</a>,\n</form>\n<form id=\"form-YangangYeFaceletBankforFast\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yangang Ye\">\n<a href=\"#\" onclick=\"document.getElementById('form-YangangYeFaceletBankforFast').submit();\">Yangang Ye</a>,\n</form>\n<form id=\"form-JiayaJiaFaceletBankforFast\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiaya Jia\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiayaJiaFaceletBankforFast').submit();\">Jiaya Jia</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_Facelet-Bank_for_Fast_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.05576\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Ying-Cong and Lin, Huaijia and Shu, Michelle and Li, Ruiyu and Tao, Xin and Shen, Xiaoyong and Ye, Yangang and Jia, Jiaya},<br>\ntitle = {Facelet-Bank for Fast Portrait Manipulation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhou_Visual_to_Sound_CVPR_2018_paper.html\">Visual to Sound: Generating Natural Sound for Videos in the Wild</a></dt>\n<dd>\n<form id=\"form-YipinZhouVisualtoSound\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yipin Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-YipinZhouVisualtoSound').submit();\">Yipin Zhou</a>,\n</form>\n<form id=\"form-ZhaowenWangVisualtoSound\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhaowen Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhaowenWangVisualtoSound').submit();\">Zhaowen Wang</a>,\n</form>\n<form id=\"form-ChenFangVisualtoSound\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chen Fang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenFangVisualtoSound').submit();\">Chen Fang</a>,\n</form>\n<form id=\"form-TrungBuiVisualtoSound\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Trung Bui\">\n<a href=\"#\" onclick=\"document.getElementById('form-TrungBuiVisualtoSound').submit();\">Trung Bui</a>,\n</form>\n<form id=\"form-TamaraL.VisualtoSound\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tamara L. Berg\">\n<a href=\"#\" onclick=\"document.getElementById('form-TamaraL.VisualtoSound').submit();\">Tamara L. Berg</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhou_Visual_to_Sound_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.01393\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhou_2018_CVPR,<br>\nauthor = {Zhou, Yipin and Wang, Zhaowen and Fang, Chen and Bui, Trung and Berg, Tamara L.},<br>\ntitle = {Visual to Sound: Generating Natural Sound for Videos in the Wild},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kundu_3D-RCNN_Instance-Level_3D_CVPR_2018_paper.html\">3D-RCNN: Instance-Level 3D Object Reconstruction via Render-and-Compare</a></dt>\n<dd>\n<form id=\"form-AbhijitKundu3DRCNNInstanceLevel3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Abhijit Kundu\">\n<a href=\"#\" onclick=\"document.getElementById('form-AbhijitKundu3DRCNNInstanceLevel3D').submit();\">Abhijit Kundu</a>,\n</form>\n<form id=\"form-YinLi3DRCNNInstanceLevel3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yin Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-YinLi3DRCNNInstanceLevel3D').submit();\">Yin Li</a>,\n</form>\n<form id=\"form-JamesM.3DRCNNInstanceLevel3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"James M. Rehg\">\n<a href=\"#\" onclick=\"document.getElementById('form-JamesM.3DRCNNInstanceLevel3D').submit();\">James M. Rehg</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kundu_3D-RCNN_Instance-Level_3D_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kundu_2018_CVPR,<br>\nauthor = {Kundu, Abhijit and Li, Yin and Rehg, James M.},<br>\ntitle = {3D-RCNN: Instance-Level 3D Object Reconstruction via Render-and-Compare},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Luo_Fast_and_Furious_CVPR_2018_paper.html\">Fast and Furious: Real Time End-to-End 3D Detection, Tracking and Motion Forecasting With a Single Convolutional Net</a></dt>\n<dd>\n<form id=\"form-WenjieLuoFastandFurious\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenjie Luo\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenjieLuoFastandFurious').submit();\">Wenjie Luo</a>,\n</form>\n<form id=\"form-BinYangFastandFurious\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bin Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-BinYangFastandFurious').submit();\">Bin Yang</a>,\n</form>\n<form id=\"form-RaquelUrtasunFastandFurious\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Raquel Urtasun\">\n<a href=\"#\" onclick=\"document.getElementById('form-RaquelUrtasunFastandFurious').submit();\">Raquel Urtasun</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Luo_Fast_and_Furious_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Luo_2018_CVPR,<br>\nauthor = {Luo, Wenjie and Yang, Bin and Urtasun, Raquel},<br>\ntitle = {Fast and Furious: Real Time End-to-End 3D Detection, Tracking and Motion Forecasting With a Single Convolutional Net},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Singh_An_Analysis_of_CVPR_2018_paper.html\">An Analysis of Scale Invariance in Object Detection \u00c2\u00ad SNIP</a></dt>\n<dd>\n<form id=\"form-BharatSinghAnAnalysisof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bharat Singh\">\n<a href=\"#\" onclick=\"document.getElementById('form-BharatSinghAnAnalysisof').submit();\">Bharat Singh</a>,\n</form>\n<form id=\"form-LarryS.AnAnalysisof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Larry S. Davis\">\n<a href=\"#\" onclick=\"document.getElementById('form-LarryS.AnAnalysisof').submit();\">Larry S. Davis</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Singh_An_Analysis_of_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Singh_2018_CVPR,<br>\nauthor = {Singh, Bharat and Davis, Larry S.},<br>\ntitle = {An Analysis of Scale Invariance in Object Detection \u00c2\u00ad SNIP},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hu_Relation_Networks_for_CVPR_2018_paper.html\">Relation Networks for Object Detection</a></dt>\n<dd>\n<form id=\"form-HanHuRelationNetworksfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Han Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HanHuRelationNetworksfor').submit();\">Han Hu</a>,\n</form>\n<form id=\"form-JiayuanGuRelationNetworksfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiayuan Gu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiayuanGuRelationNetworksfor').submit();\">Jiayuan Gu</a>,\n</form>\n<form id=\"form-ZhengZhangRelationNetworksfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zheng Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhengZhangRelationNetworksfor').submit();\">Zheng Zhang</a>,\n</form>\n<form id=\"form-JifengDaiRelationNetworksfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jifeng Dai\">\n<a href=\"#\" onclick=\"document.getElementById('form-JifengDaiRelationNetworksfor').submit();\">Jifeng Dai</a>,\n</form>\n<form id=\"form-YichenWeiRelationNetworksfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yichen Wei\">\n<a href=\"#\" onclick=\"document.getElementById('form-YichenWeiRelationNetworksfor').submit();\">Yichen Wei</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hu_Relation_Networks_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.11575\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hu_2018_CVPR,<br>\nauthor = {Hu, Han and Gu, Jiayuan and Zhang, Zheng and Dai, Jifeng and Wei, Yichen},<br>\ntitle = {Relation Networks for Object Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Shen_Zero-Shot_Sketch-Image_Hashing_CVPR_2018_paper.html\">Zero-Shot Sketch-Image Hashing</a></dt>\n<dd>\n<form id=\"form-YumingShenZeroShotSketchImageHashing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuming Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-YumingShenZeroShotSketchImageHashing').submit();\">Yuming Shen</a>,\n</form>\n<form id=\"form-LiLiuZeroShotSketchImageHashing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Li Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiLiuZeroShotSketchImageHashing').submit();\">Li Liu</a>,\n</form>\n<form id=\"form-FuminShenZeroShotSketchImageHashing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fumin Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-FuminShenZeroShotSketchImageHashing').submit();\">Fumin Shen</a>,\n</form>\n<form id=\"form-LingShaoZeroShotSketchImageHashing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ling Shao\">\n<a href=\"#\" onclick=\"document.getElementById('form-LingShaoZeroShotSketchImageHashing').submit();\">Ling Shao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Shen_Zero-Shot_Sketch-Image_Hashing_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.02284\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Shen_2018_CVPR,<br>\nauthor = {Shen, Yuming and Liu, Li and Shen, Fumin and Shao, Ling},<br>\ntitle = {Zero-Shot Sketch-Image Hashing},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Gurari_VizWiz_Grand_Challenge_CVPR_2018_paper.html\">VizWiz Grand Challenge: Answering Visual Questions From Blind People</a></dt>\n<dd>\n<form id=\"form-DannaGurariVizWizGrandChallenge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Danna Gurari\">\n<a href=\"#\" onclick=\"document.getElementById('form-DannaGurariVizWizGrandChallenge').submit();\">Danna Gurari</a>,\n</form>\n<form id=\"form-QingLiVizWizGrandChallenge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qing Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-QingLiVizWizGrandChallenge').submit();\">Qing Li</a>,\n</form>\n<form id=\"form-AbigaleJ.VizWizGrandChallenge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Abigale J. Stangl\">\n<a href=\"#\" onclick=\"document.getElementById('form-AbigaleJ.VizWizGrandChallenge').submit();\">Abigale J. Stangl</a>,\n</form>\n<form id=\"form-AnhongGuoVizWizGrandChallenge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anhong Guo\">\n<a href=\"#\" onclick=\"document.getElementById('form-AnhongGuoVizWizGrandChallenge').submit();\">Anhong Guo</a>,\n</form>\n<form id=\"form-ChiLinVizWizGrandChallenge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chi Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChiLinVizWizGrandChallenge').submit();\">Chi Lin</a>,\n</form>\n<form id=\"form-KristenGraumanVizWizGrandChallenge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kristen Grauman\">\n<a href=\"#\" onclick=\"document.getElementById('form-KristenGraumanVizWizGrandChallenge').submit();\">Kristen Grauman</a>,\n</form>\n<form id=\"form-JieboLuoVizWizGrandChallenge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiebo Luo\">\n<a href=\"#\" onclick=\"document.getElementById('form-JieboLuoVizWizGrandChallenge').submit();\">Jiebo Luo</a>,\n</form>\n<form id=\"form-JeffreyP.VizWizGrandChallenge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jeffrey P. Bigham\">\n<a href=\"#\" onclick=\"document.getElementById('form-JeffreyP.VizWizGrandChallenge').submit();\">Jeffrey P. Bigham</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Gurari_VizWiz_Grand_Challenge_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1597-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.08218\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Gurari_2018_CVPR,<br>\nauthor = {Gurari, Danna and Li, Qing and Stangl, Abigale J. and Guo, Anhong and Lin, Chi and Grauman, Kristen and Luo, Jiebo and Bigham, Jeffrey P.},<br>\ntitle = {VizWiz Grand Challenge: Answering Visual Questions From Blind People},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sam_Divide_and_Grow_CVPR_2018_paper.html\">Divide and Grow: Capturing Huge Diversity in Crowd Images With Incrementally Growing CNN</a></dt>\n<dd>\n<form id=\"form-DeepakBabuDivideandGrow\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Deepak Babu Sam\">\n<a href=\"#\" onclick=\"document.getElementById('form-DeepakBabuDivideandGrow').submit();\">Deepak Babu Sam</a>,\n</form>\n<form id=\"form-NeerajN.DivideandGrow\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Neeraj N. Sajjan\">\n<a href=\"#\" onclick=\"document.getElementById('form-NeerajN.DivideandGrow').submit();\">Neeraj N. Sajjan</a>,\n</form>\n<form id=\"form-R.VenkateshDivideandGrow\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"R. Venkatesh Babu\">\n<a href=\"#\" onclick=\"document.getElementById('form-R.VenkateshDivideandGrow').submit();\">R. Venkatesh Babu</a>,\n</form>\n<form id=\"form-MukundhanSrinivasanDivideandGrow\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mukundhan Srinivasan\">\n<a href=\"#\" onclick=\"document.getElementById('form-MukundhanSrinivasanDivideandGrow').submit();\">Mukundhan Srinivasan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sam_Divide_and_Grow_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1807.09993\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sam_2018_CVPR,<br>\nauthor = {Babu Sam, Deepak and Sajjan, Neeraj N. and Venkatesh Babu, R. and Srinivasan, Mukundhan},<br>\ntitle = {Divide and Grow: Capturing Huge Diversity in Crowd Images With Incrementally Growing CNN},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Choi_Structured_Set_Matching_CVPR_2018_paper.html\">Structured Set Matching Networks for One-Shot Part Labeling</a></dt>\n<dd>\n<form id=\"form-JonghyunChoiStructuredSetMatching\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jonghyun Choi\">\n<a href=\"#\" onclick=\"document.getElementById('form-JonghyunChoiStructuredSetMatching').submit();\">Jonghyun Choi</a>,\n</form>\n<form id=\"form-JayantKrishnamurthyStructuredSetMatching\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jayant Krishnamurthy\">\n<a href=\"#\" onclick=\"document.getElementById('form-JayantKrishnamurthyStructuredSetMatching').submit();\">Jayant Krishnamurthy</a>,\n</form>\n<form id=\"form-AniruddhaKembhaviStructuredSetMatching\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Aniruddha Kembhavi\">\n<a href=\"#\" onclick=\"document.getElementById('form-AniruddhaKembhaviStructuredSetMatching').submit();\">Aniruddha Kembhavi</a>,\n</form>\n<form id=\"form-AliFarhadiStructuredSetMatching\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ali Farhadi\">\n<a href=\"#\" onclick=\"document.getElementById('form-AliFarhadiStructuredSetMatching').submit();\">Ali Farhadi</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Choi_Structured_Set_Matching_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2732-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.01867\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Choi_2018_CVPR,<br>\nauthor = {Choi, Jonghyun and Krishnamurthy, Jayant and Kembhavi, Aniruddha and Farhadi, Ali},<br>\ntitle = {Structured Set Matching Networks for One-Shot Part Labeling},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Novotny_Self-Supervised_Learning_of_CVPR_2018_paper.html\">Self-Supervised Learning of Geometrically Stable Features Through Probabilistic Introspection</a></dt>\n<dd>\n<form id=\"form-DavidNovotnySelfSupervisedLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"David Novotny\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavidNovotnySelfSupervisedLearningof').submit();\">David Novotny</a>,\n</form>\n<form id=\"form-SamuelAlbanieSelfSupervisedLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Samuel Albanie\">\n<a href=\"#\" onclick=\"document.getElementById('form-SamuelAlbanieSelfSupervisedLearningof').submit();\">Samuel Albanie</a>,\n</form>\n<form id=\"form-DianeLarlusSelfSupervisedLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Diane Larlus\">\n<a href=\"#\" onclick=\"document.getElementById('form-DianeLarlusSelfSupervisedLearningof').submit();\">Diane Larlus</a>,\n</form>\n<form id=\"form-AndreaVedaldiSelfSupervisedLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrea Vedaldi\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndreaVedaldiSelfSupervisedLearningof').submit();\">Andrea Vedaldi</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Novotny_Self-Supervised_Learning_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2827-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.01552\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Novotny_2018_CVPR,<br>\nauthor = {Novotny, David and Albanie, Samuel and Larlus, Diane and Vedaldi, Andrea},<br>\ntitle = {Self-Supervised Learning of Geometrically Stable Features Through Probabilistic Introspection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Douze_Link_and_Code_CVPR_2018_paper.html\">Link and Code: Fast Indexing With Graphs and Compact Regression Codes</a></dt>\n<dd>\n<form id=\"form-MatthijsDouzeLinkandCode\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Matthijs Douze\">\n<a href=\"#\" onclick=\"document.getElementById('form-MatthijsDouzeLinkandCode').submit();\">Matthijs Douze</a>,\n</form>\n<form id=\"form-AlexandreSablayrollesLinkandCode\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexandre Sablayrolles\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexandreSablayrollesLinkandCode').submit();\">Alexandre Sablayrolles</a>,\n</form>\n<form id=\"form-Herv\u00c3\u00a9J\u00c3\u00a9gouLinkandCode\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Herv\u00c3\u00a9 J\u00c3\u00a9gou\">\n<a href=\"#\" onclick=\"document.getElementById('form-Herv\u00c3\u00a9J\u00c3\u00a9gouLinkandCode').submit();\">Herv\u00c3\u00a9 J\u00c3\u00a9gou</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Douze_Link_and_Code_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.09996\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Douze_2018_CVPR,<br>\nauthor = {Douze, Matthijs and Sablayrolles, Alexandre and J\u00c3\u00a9gou, Herv\u00c3\u00a9},<br>\ntitle = {Link and Code: Fast Indexing With Graphs and Compact Regression Codes},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Textbook_Question_Answering_CVPR_2018_paper.html\">Textbook Question Answering Under Instructor Guidance With Memory Networks</a></dt>\n<dd>\n<form id=\"form-JuzhengLiTextbookQuestionAnswering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Juzheng Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-JuzhengLiTextbookQuestionAnswering').submit();\">Juzheng Li</a>,\n</form>\n<form id=\"form-HangSuTextbookQuestionAnswering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hang Su\">\n<a href=\"#\" onclick=\"document.getElementById('form-HangSuTextbookQuestionAnswering').submit();\">Hang Su</a>,\n</form>\n<form id=\"form-JunZhuTextbookQuestionAnswering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jun Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunZhuTextbookQuestionAnswering').submit();\">Jun Zhu</a>,\n</form>\n<form id=\"form-SiyuWangTextbookQuestionAnswering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Siyu Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-SiyuWangTextbookQuestionAnswering').submit();\">Siyu Wang</a>,\n</form>\n<form id=\"form-BoZhangTextbookQuestionAnswering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bo Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoZhangTextbookQuestionAnswering').submit();\">Bo Zhang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Textbook_Question_Answering_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Juzheng and Su, Hang and Zhu, Jun and Wang, Siyu and Zhang, Bo},<br>\ntitle = {Textbook Question Answering Under Instructor Guidance With Memory Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Dizaji_Unsupervised_Deep_Generative_CVPR_2018_paper.html\">Unsupervised Deep Generative Adversarial Hashing Network</a></dt>\n<dd>\n<form id=\"form-KamranGhasediUnsupervisedDeepGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kamran Ghasedi Dizaji\">\n<a href=\"#\" onclick=\"document.getElementById('form-KamranGhasediUnsupervisedDeepGenerative').submit();\">Kamran Ghasedi Dizaji</a>,\n</form>\n<form id=\"form-FengZhengUnsupervisedDeepGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Feng Zheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-FengZhengUnsupervisedDeepGenerative').submit();\">Feng Zheng</a>,\n</form>\n<form id=\"form-NajmehSadoughiUnsupervisedDeepGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Najmeh Sadoughi\">\n<a href=\"#\" onclick=\"document.getElementById('form-NajmehSadoughiUnsupervisedDeepGenerative').submit();\">Najmeh Sadoughi</a>,\n</form>\n<form id=\"form-YanhuaYangUnsupervisedDeepGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yanhua Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanhuaYangUnsupervisedDeepGenerative').submit();\">Yanhua Yang</a>,\n</form>\n<form id=\"form-ChengDengUnsupervisedDeepGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cheng Deng\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChengDengUnsupervisedDeepGenerative').submit();\">Cheng Deng</a>,\n</form>\n<form id=\"form-HengHuangUnsupervisedDeepGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Heng Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HengHuangUnsupervisedDeepGenerative').submit();\">Heng Huang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Dizaji_Unsupervised_Deep_Generative_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Dizaji_2018_CVPR,<br>\nauthor = {Ghasedi Dizaji, Kamran and Zheng, Feng and Sadoughi, Najmeh and Yang, Yanhua and Deng, Cheng and Huang, Heng},<br>\ntitle = {Unsupervised Deep Generative Adversarial Hashing Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Anderson_Vision-and-Language_Navigation_Interpreting_CVPR_2018_paper.html\">Vision-and-Language Navigation: Interpreting Visually-Grounded Navigation Instructions in Real Environments</a></dt>\n<dd>\n<form id=\"form-PeterAndersonVisionandLanguageNavigationInterpreting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peter Anderson\">\n<a href=\"#\" onclick=\"document.getElementById('form-PeterAndersonVisionandLanguageNavigationInterpreting').submit();\">Peter Anderson</a>,\n</form>\n<form id=\"form-QiWuVisionandLanguageNavigationInterpreting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qi Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiWuVisionandLanguageNavigationInterpreting').submit();\">Qi Wu</a>,\n</form>\n<form id=\"form-DamienTeneyVisionandLanguageNavigationInterpreting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Damien Teney\">\n<a href=\"#\" onclick=\"document.getElementById('form-DamienTeneyVisionandLanguageNavigationInterpreting').submit();\">Damien Teney</a>,\n</form>\n<form id=\"form-JakeBruceVisionandLanguageNavigationInterpreting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jake Bruce\">\n<a href=\"#\" onclick=\"document.getElementById('form-JakeBruceVisionandLanguageNavigationInterpreting').submit();\">Jake Bruce</a>,\n</form>\n<form id=\"form-MarkJohnsonVisionandLanguageNavigationInterpreting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mark Johnson\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarkJohnsonVisionandLanguageNavigationInterpreting').submit();\">Mark Johnson</a>,\n</form>\n<form id=\"form-NikoS\u00c3\u00bcnderhaufVisionandLanguageNavigationInterpreting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Niko S\u00c3\u00bcnderhauf\">\n<a href=\"#\" onclick=\"document.getElementById('form-NikoS\u00c3\u00bcnderhaufVisionandLanguageNavigationInterpreting').submit();\">Niko S\u00c3\u00bcnderhauf</a>,\n</form>\n<form id=\"form-IanReidVisionandLanguageNavigationInterpreting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ian Reid\">\n<a href=\"#\" onclick=\"document.getElementById('form-IanReidVisionandLanguageNavigationInterpreting').submit();\">Ian Reid</a>,\n</form>\n<form id=\"form-StephenGouldVisionandLanguageNavigationInterpreting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stephen Gould\">\n<a href=\"#\" onclick=\"document.getElementById('form-StephenGouldVisionandLanguageNavigationInterpreting').submit();\">Stephen Gould</a>,\n</form>\n<form id=\"form-AntonvanVisionandLanguageNavigationInterpreting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anton van den Hengel\">\n<a href=\"#\" onclick=\"document.getElementById('form-AntonvanVisionandLanguageNavigationInterpreting').submit();\">Anton van den Hengel</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Anderson_Vision-and-Language_Navigation_Interpreting_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1027-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.07280\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Anderson_2018_CVPR,<br>\nauthor = {Anderson, Peter and Wu, Qi and Teney, Damien and Bruce, Jake and Johnson, Mark and S\u00c3\u00bcnderhauf, Niko and Reid, Ian and Gould, Stephen and van den Hengel, Anton},<br>\ntitle = {Vision-and-Language Navigation: Interpreting Visually-Grounded Navigation Instructions in Real Environments},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yang_DenseASPP_for_Semantic_CVPR_2018_paper.html\">DenseASPP for Semantic Segmentation in Street Scenes</a></dt>\n<dd>\n<form id=\"form-MaokeYangDenseASPPforSemantic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Maoke Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-MaokeYangDenseASPPforSemantic').submit();\">Maoke Yang</a>,\n</form>\n<form id=\"form-KunYuDenseASPPforSemantic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kun Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-KunYuDenseASPPforSemantic').submit();\">Kun Yu</a>,\n</form>\n<form id=\"form-ChiZhangDenseASPPforSemantic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chi Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChiZhangDenseASPPforSemantic').submit();\">Chi Zhang</a>,\n</form>\n<form id=\"form-ZhiweiLiDenseASPPforSemantic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhiwei Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhiweiLiDenseASPPforSemantic').submit();\">Zhiwei Li</a>,\n</form>\n<form id=\"form-KuiyuanYangDenseASPPforSemantic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kuiyuan Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-KuiyuanYangDenseASPPforSemantic').submit();\">Kuiyuan Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yang_DenseASPP_for_Semantic_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yang_2018_CVPR,<br>\nauthor = {Yang, Maoke and Yu, Kun and Zhang, Chi and Li, Zhiwei and Yang, Kuiyuan},<br>\ntitle = {DenseASPP for Semantic Segmentation in Street Scenes},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Mohapatra_Efficient_Optimization_for_CVPR_2018_paper.html\">Efficient Optimization for Rank-Based Loss Functions</a></dt>\n<dd>\n<form id=\"form-PritishMohapatraEfficientOptimizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pritish Mohapatra\">\n<a href=\"#\" onclick=\"document.getElementById('form-PritishMohapatraEfficientOptimizationfor').submit();\">Pritish Mohapatra</a>,\n</form>\n<form id=\"form-MichalRol\u00c3\u00adnekEfficientOptimizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michal Rol\u00c3\u00adnek\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichalRol\u00c3\u00adnekEfficientOptimizationfor').submit();\">Michal Rol\u00c3\u00adnek</a>,\n</form>\n<form id=\"form-C.V.JawaharEfficientOptimizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"C.V. Jawahar\">\n<a href=\"#\" onclick=\"document.getElementById('form-C.V.JawaharEfficientOptimizationfor').submit();\">C.V. Jawahar</a>,\n</form>\n<form id=\"form-VladimirKolmogorovEfficientOptimizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vladimir Kolmogorov\">\n<a href=\"#\" onclick=\"document.getElementById('form-VladimirKolmogorovEfficientOptimizationfor').submit();\">Vladimir Kolmogorov</a>,\n</form>\n<form id=\"form-M.PawanEfficientOptimizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"M. Pawan Kumar\">\n<a href=\"#\" onclick=\"document.getElementById('form-M.PawanEfficientOptimizationfor').submit();\">M. Pawan Kumar</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Mohapatra_Efficient_Optimization_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3595-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1604.08269\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Mohapatra_2018_CVPR,<br>\nauthor = {Mohapatra, Pritish and Rol\u00c3\u00adnek, Michal and Jawahar, C.V. and Kolmogorov, Vladimir and Pawan Kumar, M.},<br>\ntitle = {Efficient Optimization for Rank-Based Loss Functions},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lee_Wasserstein_Introspective_Neural_CVPR_2018_paper.html\">Wasserstein Introspective Neural Networks</a></dt>\n<dd>\n<form id=\"form-KwonjoonLeeWassersteinIntrospectiveNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kwonjoon Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-KwonjoonLeeWassersteinIntrospectiveNeural').submit();\">Kwonjoon Lee</a>,\n</form>\n<form id=\"form-WeijianXuWassersteinIntrospectiveNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weijian Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeijianXuWassersteinIntrospectiveNeural').submit();\">Weijian Xu</a>,\n</form>\n<form id=\"form-FanFanWassersteinIntrospectiveNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fan Fan\">\n<a href=\"#\" onclick=\"document.getElementById('form-FanFanWassersteinIntrospectiveNeural').submit();\">Fan Fan</a>,\n</form>\n<form id=\"form-ZhuowenTuWassersteinIntrospectiveNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhuowen Tu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhuowenTuWassersteinIntrospectiveNeural').submit();\">Zhuowen Tu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lee_Wasserstein_Introspective_Neural_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.08875\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lee_2018_CVPR,<br>\nauthor = {Lee, Kwonjoon and Xu, Weijian and Fan, Fan and Tu, Zhuowen},<br>\ntitle = {Wasserstein Introspective Neural Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zamir_Taskonomy_Disentangling_Task_CVPR_2018_paper.html\">Taskonomy: Disentangling Task Transfer Learning</a></dt>\n<dd>\n<form id=\"form-AmirR.TaskonomyDisentanglingTask\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Amir R. Zamir\">\n<a href=\"#\" onclick=\"document.getElementById('form-AmirR.TaskonomyDisentanglingTask').submit();\">Amir R. Zamir</a>,\n</form>\n<form id=\"form-AlexanderSaxTaskonomyDisentanglingTask\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexander Sax\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexanderSaxTaskonomyDisentanglingTask').submit();\">Alexander Sax</a>,\n</form>\n<form id=\"form-WilliamShenTaskonomyDisentanglingTask\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"William Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-WilliamShenTaskonomyDisentanglingTask').submit();\">William Shen</a>,\n</form>\n<form id=\"form-LeonidasJ.TaskonomyDisentanglingTask\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Leonidas J. Guibas\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeonidasJ.TaskonomyDisentanglingTask').submit();\">Leonidas J. Guibas</a>,\n</form>\n<form id=\"form-JitendraMalikTaskonomyDisentanglingTask\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jitendra Malik\">\n<a href=\"#\" onclick=\"document.getElementById('form-JitendraMalikTaskonomyDisentanglingTask').submit();\">Jitendra Malik</a>,\n</form>\n<form id=\"form-SilvioSavareseTaskonomyDisentanglingTask\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Silvio Savarese\">\n<a href=\"#\" onclick=\"document.getElementById('form-SilvioSavareseTaskonomyDisentanglingTask').submit();\">Silvio Savarese</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zamir_Taskonomy_Disentangling_Task_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.08328\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zamir_2018_CVPR,<br>\nauthor = {Zamir, Amir R. and Sax, Alexander and Shen, William and Guibas, Leonidas J. and Malik, Jitendra and Savarese, Silvio},<br>\ntitle = {Taskonomy: Disentangling Task Transfer Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Saito_Maximum_Classifier_Discrepancy_CVPR_2018_paper.html\">Maximum Classifier Discrepancy for Unsupervised Domain Adaptation</a></dt>\n<dd>\n<form id=\"form-KuniakiSaitoMaximumClassifierDiscrepancy\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kuniaki Saito\">\n<a href=\"#\" onclick=\"document.getElementById('form-KuniakiSaitoMaximumClassifierDiscrepancy').submit();\">Kuniaki Saito</a>,\n</form>\n<form id=\"form-KoheiWatanabeMaximumClassifierDiscrepancy\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kohei Watanabe\">\n<a href=\"#\" onclick=\"document.getElementById('form-KoheiWatanabeMaximumClassifierDiscrepancy').submit();\">Kohei Watanabe</a>,\n</form>\n<form id=\"form-YoshitakaUshikuMaximumClassifierDiscrepancy\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yoshitaka Ushiku\">\n<a href=\"#\" onclick=\"document.getElementById('form-YoshitakaUshikuMaximumClassifierDiscrepancy').submit();\">Yoshitaka Ushiku</a>,\n</form>\n<form id=\"form-TatsuyaHaradaMaximumClassifierDiscrepancy\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tatsuya Harada\">\n<a href=\"#\" onclick=\"document.getElementById('form-TatsuyaHaradaMaximumClassifierDiscrepancy').submit();\">Tatsuya Harada</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Saito_Maximum_Classifier_Discrepancy_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1470-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.02560\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Saito_2018_CVPR,<br>\nauthor = {Saito, Kuniaki and Watanabe, Kohei and Ushiku, Yoshitaka and Harada, Tatsuya},<br>\ntitle = {Maximum Classifier Discrepancy for Unsupervised Domain Adaptation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper.html\">Unsupervised Feature Learning via Non-Parametric Instance Discrimination</a></dt>\n<dd>\n<form id=\"form-ZhirongWuUnsupervisedFeatureLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhirong Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhirongWuUnsupervisedFeatureLearning').submit();\">Zhirong Wu</a>,\n</form>\n<form id=\"form-YuanjunXiongUnsupervisedFeatureLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuanjun Xiong\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuanjunXiongUnsupervisedFeatureLearning').submit();\">Yuanjun Xiong</a>,\n</form>\n<form id=\"form-StellaX.UnsupervisedFeatureLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stella X. Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-StellaX.UnsupervisedFeatureLearning').submit();\">Stella X. Yu</a>,\n</form>\n<form id=\"form-DahuaLinUnsupervisedFeatureLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dahua Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-DahuaLinUnsupervisedFeatureLearning').submit();\">Dahua Lin</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.01978\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wu_2018_CVPR,<br>\nauthor = {Wu, Zhirong and Xiong, Yuanjun and Yu, Stella X. and Lin, Dahua},<br>\ntitle = {Unsupervised Feature Learning via Non-Parametric Instance Discrimination},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_Multi-Task_Adversarial_Network_CVPR_2018_paper.html\">Multi-Task Adversarial Network for Disentangled Feature Learning</a></dt>\n<dd>\n<form id=\"form-YangLiuMultiTaskAdversarialNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yang Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YangLiuMultiTaskAdversarialNetwork').submit();\">Yang Liu</a>,\n</form>\n<form id=\"form-ZhaowenWangMultiTaskAdversarialNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhaowen Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhaowenWangMultiTaskAdversarialNetwork').submit();\">Zhaowen Wang</a>,\n</form>\n<form id=\"form-HailinJinMultiTaskAdversarialNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hailin Jin\">\n<a href=\"#\" onclick=\"document.getElementById('form-HailinJinMultiTaskAdversarialNetwork').submit();\">Hailin Jin</a>,\n</form>\n<form id=\"form-IanWassellMultiTaskAdversarialNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ian Wassell\">\n<a href=\"#\" onclick=\"document.getElementById('form-IanWassellMultiTaskAdversarialNetwork').submit();\">Ian Wassell</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_Multi-Task_Adversarial_Network_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1589-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Yang and Wang, Zhaowen and Jin, Hailin and Wassell, Ian},<br>\ntitle = {Multi-Task Adversarial Network for Disentangled Feature Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sankaranarayanan_Learning_From_Synthetic_CVPR_2018_paper.html\">Learning From Synthetic Data: Addressing Domain Shift for Semantic Segmentation</a></dt>\n<dd>\n<form id=\"form-SwamiSankaranarayananLearningFromSynthetic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Swami Sankaranarayanan\">\n<a href=\"#\" onclick=\"document.getElementById('form-SwamiSankaranarayananLearningFromSynthetic').submit();\">Swami Sankaranarayanan</a>,\n</form>\n<form id=\"form-YogeshBalajiLearningFromSynthetic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yogesh Balaji\">\n<a href=\"#\" onclick=\"document.getElementById('form-YogeshBalajiLearningFromSynthetic').submit();\">Yogesh Balaji</a>,\n</form>\n<form id=\"form-ArpitJainLearningFromSynthetic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Arpit Jain\">\n<a href=\"#\" onclick=\"document.getElementById('form-ArpitJainLearningFromSynthetic').submit();\">Arpit Jain</a>,\n</form>\n<form id=\"form-SerNamLearningFromSynthetic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ser Nam Lim\">\n<a href=\"#\" onclick=\"document.getElementById('form-SerNamLearningFromSynthetic').submit();\">Ser Nam Lim</a>,\n</form>\n<form id=\"form-RamaChellappaLearningFromSynthetic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rama Chellappa\">\n<a href=\"#\" onclick=\"document.getElementById('form-RamaChellappaLearningFromSynthetic').submit();\">Rama Chellappa</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sankaranarayanan_Learning_From_Synthetic_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1593-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.06969\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sankaranarayanan_2018_CVPR,<br>\nauthor = {Sankaranarayanan, Swami and Balaji, Yogesh and Jain, Arpit and Nam Lim, Ser and Chellappa, Rama},<br>\ntitle = {Learning From Synthetic Data: Addressing Domain Shift for Semantic Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Fawzi_Empirical_Study_of_CVPR_2018_paper.html\">Empirical Study of the Topology and Geometry of Deep Networks</a></dt>\n<dd>\n<form id=\"form-AlhusseinFawziEmpiricalStudyof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alhussein Fawzi\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlhusseinFawziEmpiricalStudyof').submit();\">Alhussein Fawzi</a>,\n</form>\n<form id=\"form-Seyed-MohsenMoosavi-DezfooliEmpiricalStudyof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Seyed-Mohsen Moosavi-Dezfooli\">\n<a href=\"#\" onclick=\"document.getElementById('form-Seyed-MohsenMoosavi-DezfooliEmpiricalStudyof').submit();\">Seyed-Mohsen Moosavi-Dezfooli</a>,\n</form>\n<form id=\"form-PascalFrossardEmpiricalStudyof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pascal Frossard\">\n<a href=\"#\" onclick=\"document.getElementById('form-PascalFrossardEmpiricalStudyof').submit();\">Pascal Frossard</a>,\n</form>\n<form id=\"form-StefanoSoattoEmpiricalStudyof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stefano Soatto\">\n<a href=\"#\" onclick=\"document.getElementById('form-StefanoSoattoEmpiricalStudyof').submit();\">Stefano Soatto</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Fawzi_Empirical_Study_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2851-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Fawzi_2018_CVPR,<br>\nauthor = {Fawzi, Alhussein and Moosavi-Dezfooli, Seyed-Mohsen and Frossard, Pascal and Soatto, Stefano},<br>\ntitle = {Empirical Study of the Topology and Geometry of Deep Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Mancini_Boosting_Domain_Adaptation_CVPR_2018_paper.html\">Boosting Domain Adaptation by Discovering Latent Domains</a></dt>\n<dd>\n<form id=\"form-MassimilianoManciniBoostingDomainAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Massimiliano Mancini\">\n<a href=\"#\" onclick=\"document.getElementById('form-MassimilianoManciniBoostingDomainAdaptation').submit();\">Massimiliano Mancini</a>,\n</form>\n<form id=\"form-LorenzoPorziBoostingDomainAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lorenzo Porzi\">\n<a href=\"#\" onclick=\"document.getElementById('form-LorenzoPorziBoostingDomainAdaptation').submit();\">Lorenzo Porzi</a>,\n</form>\n<form id=\"form-SamuelRotaBoostingDomainAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Samuel Rota Bul\u00c3\u00b2\">\n<a href=\"#\" onclick=\"document.getElementById('form-SamuelRotaBoostingDomainAdaptation').submit();\">Samuel Rota Bul\u00c3\u00b2</a>,\n</form>\n<form id=\"form-BarbaraCaputoBoostingDomainAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Barbara Caputo\">\n<a href=\"#\" onclick=\"document.getElementById('form-BarbaraCaputoBoostingDomainAdaptation').submit();\">Barbara Caputo</a>,\n</form>\n<form id=\"form-ElisaRicciBoostingDomainAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Elisa Ricci\">\n<a href=\"#\" onclick=\"document.getElementById('form-ElisaRicciBoostingDomainAdaptation').submit();\">Elisa Ricci</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Mancini_Boosting_Domain_Adaptation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3548-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.01386\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Mancini_2018_CVPR,<br>\nauthor = {Mancini, Massimiliano and Porzi, Lorenzo and Rota Bul\u00c3\u00b2, Samuel and Caputo, Barbara and Ricci, Elisa},<br>\ntitle = {Boosting Domain Adaptation by Discovering Latent Domains},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yang_Shape_From_Shading_CVPR_2018_paper.html\">Shape From Shading Through Shape Evolution</a></dt>\n<dd>\n<form id=\"form-DaweiYangShapeFromShading\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dawei Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-DaweiYangShapeFromShading').submit();\">Dawei Yang</a>,\n</form>\n<form id=\"form-JiaDengShapeFromShading\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jia Deng\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiaDengShapeFromShading').submit();\">Jia Deng</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yang_Shape_From_Shading_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.02961\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yang_2018_CVPR,<br>\nauthor = {Yang, Dawei and Deng, Jia},<br>\ntitle = {Shape From Shading Through Shape Evolution},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhou_Weakly_Supervised_Instance_CVPR_2018_paper.html\">Weakly Supervised Instance Segmentation Using Class Peak Response</a></dt>\n<dd>\n<form id=\"form-YanzhaoZhouWeaklySupervisedInstance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yanzhao Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanzhaoZhouWeaklySupervisedInstance').submit();\">Yanzhao Zhou</a>,\n</form>\n<form id=\"form-YiZhuWeaklySupervisedInstance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiZhuWeaklySupervisedInstance').submit();\">Yi Zhu</a>,\n</form>\n<form id=\"form-QixiangYeWeaklySupervisedInstance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qixiang Ye\">\n<a href=\"#\" onclick=\"document.getElementById('form-QixiangYeWeaklySupervisedInstance').submit();\">Qixiang Ye</a>,\n</form>\n<form id=\"form-QiangQiuWeaklySupervisedInstance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qiang Qiu\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiangQiuWeaklySupervisedInstance').submit();\">Qiang Qiu</a>,\n</form>\n<form id=\"form-JianbinJiaoWeaklySupervisedInstance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianbin Jiao\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianbinJiaoWeaklySupervisedInstance').submit();\">Jianbin Jiao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhou_Weakly_Supervised_Instance_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00880\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhou_2018_CVPR,<br>\nauthor = {Zhou, Yanzhao and Zhu, Yi and Ye, Qixiang and Qiu, Qiang and Jiao, Jianbin},<br>\ntitle = {Weakly Supervised Instance Segmentation Using Class Peak Response},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Collaborative_and_Adversarial_CVPR_2018_paper.html\">Collaborative and Adversarial Network for Unsupervised Domain Adaptation</a></dt>\n<dd>\n<form id=\"form-WeichenZhangCollaborativeandAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weichen Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeichenZhangCollaborativeandAdversarial').submit();\">Weichen Zhang</a>,\n</form>\n<form id=\"form-WanliOuyangCollaborativeandAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wanli Ouyang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WanliOuyangCollaborativeandAdversarial').submit();\">Wanli Ouyang</a>,\n</form>\n<form id=\"form-WenLiCollaborativeandAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wen Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenLiCollaborativeandAdversarial').submit();\">Wen Li</a>,\n</form>\n<form id=\"form-DongXuCollaborativeandAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dong Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-DongXuCollaborativeandAdversarial').submit();\">Dong Xu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Collaborative_and_Adversarial_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Weichen and Ouyang, Wanli and Li, Wen and Xu, Dong},<br>\ntitle = {Collaborative and Adversarial Network for Unsupervised Domain Adaptation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xie_Environment_Upgrade_Reinforcement_CVPR_2018_paper.html\">Environment Upgrade Reinforcement Learning for Non-Differentiable Multi-Stage Pipelines</a></dt>\n<dd>\n<form id=\"form-ShuqinXieEnvironmentUpgradeReinforcement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuqin Xie\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuqinXieEnvironmentUpgradeReinforcement').submit();\">Shuqin Xie</a>,\n</form>\n<form id=\"form-ZitianChenEnvironmentUpgradeReinforcement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zitian Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZitianChenEnvironmentUpgradeReinforcement').submit();\">Zitian Chen</a>,\n</form>\n<form id=\"form-ChaoXuEnvironmentUpgradeReinforcement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chao Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChaoXuEnvironmentUpgradeReinforcement').submit();\">Chao Xu</a>,\n</form>\n<form id=\"form-CewuLuEnvironmentUpgradeReinforcement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cewu Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-CewuLuEnvironmentUpgradeReinforcement').submit();\">Cewu Lu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xie_Environment_Upgrade_Reinforcement_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1643-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xie_2018_CVPR,<br>\nauthor = {Xie, Shuqin and Chen, Zitian and Xu, Chao and Lu, Cewu},<br>\ntitle = {Environment Upgrade Reinforcement Learning for Non-Differentiable Multi-Stage Pipelines},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Aodha_Teaching_Categories_to_CVPR_2018_paper.html\">Teaching Categories to Human Learners With Visual Explanations</a></dt>\n<dd>\n<form id=\"form-OisinMacTeachingCategoriesto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Oisin Mac Aodha\">\n<a href=\"#\" onclick=\"document.getElementById('form-OisinMacTeachingCategoriesto').submit();\">Oisin Mac Aodha</a>,\n</form>\n<form id=\"form-ShihanSuTeachingCategoriesto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shihan Su\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShihanSuTeachingCategoriesto').submit();\">Shihan Su</a>,\n</form>\n<form id=\"form-YuxinChenTeachingCategoriesto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuxin Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuxinChenTeachingCategoriesto').submit();\">Yuxin Chen</a>,\n</form>\n<form id=\"form-PietroPeronaTeachingCategoriesto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pietro Perona\">\n<a href=\"#\" onclick=\"document.getElementById('form-PietroPeronaTeachingCategoriesto').submit();\">Pietro Perona</a>,\n</form>\n<form id=\"form-YisongYueTeachingCategoriesto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yisong Yue\">\n<a href=\"#\" onclick=\"document.getElementById('form-YisongYueTeachingCategoriesto').submit();\">Yisong Yue</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Aodha_Teaching_Categories_to_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.06924\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Aodha_2018_CVPR,<br>\nauthor = {Mac Aodha, Oisin and Su, Shihan and Chen, Yuxin and Perona, Pietro and Yue, Yisong},<br>\ntitle = {Teaching Categories to Human Learners With Visual Explanations},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lawin_Density_Adaptive_Point_CVPR_2018_paper.html\">Density Adaptive Point Set Registration</a></dt>\n<dd>\n<form id=\"form-FelixJ\u00c3\u00a4remoDensityAdaptivePoint\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Felix J\u00c3\u00a4remo Lawin\">\n<a href=\"#\" onclick=\"document.getElementById('form-FelixJ\u00c3\u00a4remoDensityAdaptivePoint').submit();\">Felix J\u00c3\u00a4remo Lawin</a>,\n</form>\n<form id=\"form-MartinDanelljanDensityAdaptivePoint\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Martin Danelljan\">\n<a href=\"#\" onclick=\"document.getElementById('form-MartinDanelljanDensityAdaptivePoint').submit();\">Martin Danelljan</a>,\n</form>\n<form id=\"form-FahadShahbazDensityAdaptivePoint\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fahad Shahbaz Khan\">\n<a href=\"#\" onclick=\"document.getElementById('form-FahadShahbazDensityAdaptivePoint').submit();\">Fahad Shahbaz Khan</a>,\n</form>\n<form id=\"form-Per-ErikForss\u00c3\u00a9nDensityAdaptivePoint\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Per-Erik Forss\u00c3\u00a9n\">\n<a href=\"#\" onclick=\"document.getElementById('form-Per-ErikForss\u00c3\u00a9nDensityAdaptivePoint').submit();\">Per-Erik Forss\u00c3\u00a9n</a>,\n</form>\n<form id=\"form-MichaelFelsbergDensityAdaptivePoint\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michael Felsberg\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichaelFelsbergDensityAdaptivePoint').submit();\">Michael Felsberg</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lawin_Density_Adaptive_Point_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2354-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.01495\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lawin_2018_CVPR,<br>\nauthor = {J\u00c3\u00a4remo Lawin, Felix and Danelljan, Martin and Shahbaz Khan, Fahad and Forss\u00c3\u00a9n, Per-Erik and Felsberg, Michael},<br>\ntitle = {Density Adaptive Point Set Registration},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Jie_Left-Right_Comparative_Recurrent_CVPR_2018_paper.html\">Left-Right Comparative Recurrent Model for Stereo Matching</a></dt>\n<dd>\n<form id=\"form-ZequnJieLeftRightComparativeRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zequn Jie\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZequnJieLeftRightComparativeRecurrent').submit();\">Zequn Jie</a>,\n</form>\n<form id=\"form-PengfeiWangLeftRightComparativeRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pengfei Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-PengfeiWangLeftRightComparativeRecurrent').submit();\">Pengfei Wang</a>,\n</form>\n<form id=\"form-YonggenLingLeftRightComparativeRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yonggen Ling\">\n<a href=\"#\" onclick=\"document.getElementById('form-YonggenLingLeftRightComparativeRecurrent').submit();\">Yonggen Ling</a>,\n</form>\n<form id=\"form-BoZhaoLeftRightComparativeRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bo Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoZhaoLeftRightComparativeRecurrent').submit();\">Bo Zhao</a>,\n</form>\n<form id=\"form-YunchaoWeiLeftRightComparativeRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yunchao Wei\">\n<a href=\"#\" onclick=\"document.getElementById('form-YunchaoWeiLeftRightComparativeRecurrent').submit();\">Yunchao Wei</a>,\n</form>\n<form id=\"form-JiashiFengLeftRightComparativeRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiashi Feng\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiashiFengLeftRightComparativeRecurrent').submit();\">Jiashi Feng</a>,\n</form>\n<form id=\"form-WeiLiuLeftRightComparativeRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiLiuLeftRightComparativeRecurrent').submit();\">Wei Liu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Jie_Left-Right_Comparative_Recurrent_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00796\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Jie_2018_CVPR,<br>\nauthor = {Jie, Zequn and Wang, Pengfei and Ling, Yonggen and Zhao, Bo and Wei, Yunchao and Feng, Jiashi and Liu, Wei},<br>\ntitle = {Left-Right Comparative Recurrent Model for Stereo Matching},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Song_Im2Pano3D_Extrapolating_360deg_CVPR_2018_paper.html\">Im2Pano3D: Extrapolating 360\u00c2\u00b0 Structure and Semantics Beyond the Field of View</a></dt>\n<dd>\n<form id=\"form-ShuranSongIm2Pano3DExtrapolating360\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuran Song\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuranSongIm2Pano3DExtrapolating360').submit();\">Shuran Song</a>,\n</form>\n<form id=\"form-AndyZengIm2Pano3DExtrapolating360\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andy Zeng\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndyZengIm2Pano3DExtrapolating360').submit();\">Andy Zeng</a>,\n</form>\n<form id=\"form-AngelX.Im2Pano3DExtrapolating360\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Angel X. Chang\">\n<a href=\"#\" onclick=\"document.getElementById('form-AngelX.Im2Pano3DExtrapolating360').submit();\">Angel X. Chang</a>,\n</form>\n<form id=\"form-ManolisSavvaIm2Pano3DExtrapolating360\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Manolis Savva\">\n<a href=\"#\" onclick=\"document.getElementById('form-ManolisSavvaIm2Pano3DExtrapolating360').submit();\">Manolis Savva</a>,\n</form>\n<form id=\"form-SilvioSavareseIm2Pano3DExtrapolating360\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Silvio Savarese\">\n<a href=\"#\" onclick=\"document.getElementById('form-SilvioSavareseIm2Pano3DExtrapolating360').submit();\">Silvio Savarese</a>,\n</form>\n<form id=\"form-ThomasFunkhouserIm2Pano3DExtrapolating360\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Thomas Funkhouser\">\n<a href=\"#\" onclick=\"document.getElementById('form-ThomasFunkhouserIm2Pano3DExtrapolating360').submit();\">Thomas Funkhouser</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Song_Im2Pano3D_Extrapolating_360deg_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Song_2018_CVPR,<br>\nauthor = {Song, Shuran and Zeng, Andy and Chang, Angel X. and Savva, Manolis and Savarese, Silvio and Funkhouser, Thomas},<br>\ntitle = {Im2Pano3D: Extrapolating 360\u00c2\u00b0 Structure and Semantics Beyond the Field of View},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yang_Polarimetric_Dense_Monocular_CVPR_2018_paper.html\">Polarimetric Dense Monocular SLAM</a></dt>\n<dd>\n<form id=\"form-LuweiYangPolarimetricDenseMonocular\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Luwei Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LuweiYangPolarimetricDenseMonocular').submit();\">Luwei Yang</a>,\n</form>\n<form id=\"form-FeitongTanPolarimetricDenseMonocular\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Feitong Tan\">\n<a href=\"#\" onclick=\"document.getElementById('form-FeitongTanPolarimetricDenseMonocular').submit();\">Feitong Tan</a>,\n</form>\n<form id=\"form-AoLiPolarimetricDenseMonocular\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ao Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-AoLiPolarimetricDenseMonocular').submit();\">Ao Li</a>,\n</form>\n<form id=\"form-ZhaopengCuiPolarimetricDenseMonocular\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhaopeng Cui\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhaopengCuiPolarimetricDenseMonocular').submit();\">Zhaopeng Cui</a>,\n</form>\n<form id=\"form-YasutakaFurukawaPolarimetricDenseMonocular\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yasutaka Furukawa\">\n<a href=\"#\" onclick=\"document.getElementById('form-YasutakaFurukawaPolarimetricDenseMonocular').submit();\">Yasutaka Furukawa</a>,\n</form>\n<form id=\"form-PingTanPolarimetricDenseMonocular\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ping Tan\">\n<a href=\"#\" onclick=\"document.getElementById('form-PingTanPolarimetricDenseMonocular').submit();\">Ping Tan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yang_Polarimetric_Dense_Monocular_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2612-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yang_2018_CVPR,<br>\nauthor = {Yang, Luwei and Tan, Feitong and Li, Ao and Cui, Zhaopeng and Furukawa, Yasutaka and Tan, Ping},<br>\ntitle = {Polarimetric Dense Monocular SLAM},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Gallego_A_Unifying_Contrast_CVPR_2018_paper.html\">A Unifying Contrast Maximization Framework for Event Cameras, With Applications to Motion, Depth, and Optical Flow Estimation</a></dt>\n<dd>\n<form id=\"form-GuillermoGallegoAUnifyingContrast\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guillermo Gallego\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuillermoGallegoAUnifyingContrast').submit();\">Guillermo Gallego</a>,\n</form>\n<form id=\"form-HenriRebecqAUnifyingContrast\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Henri Rebecq\">\n<a href=\"#\" onclick=\"document.getElementById('form-HenriRebecqAUnifyingContrast').submit();\">Henri Rebecq</a>,\n</form>\n<form id=\"form-DavideScaramuzzaAUnifyingContrast\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Davide Scaramuzza\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavideScaramuzzaAUnifyingContrast').submit();\">Davide Scaramuzza</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Gallego_A_Unifying_Contrast_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2974-supp.zip\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Gallego_2018_CVPR,<br>\nauthor = {Gallego, Guillermo and Rebecq, Henri and Scaramuzza, Davide},<br>\ntitle = {A Unifying Contrast Maximization Framework for Event Cameras, With Applications to Motion, Depth, and Optical Flow Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Bagautdinov_Modeling_Facial_Geometry_CVPR_2018_paper.html\">Modeling Facial Geometry Using Compositional VAEs</a></dt>\n<dd>\n<form id=\"form-TimurBagautdinovModelingFacialGeometry\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Timur Bagautdinov\">\n<a href=\"#\" onclick=\"document.getElementById('form-TimurBagautdinovModelingFacialGeometry').submit();\">Timur Bagautdinov</a>,\n</form>\n<form id=\"form-ChengleiWuModelingFacialGeometry\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chenglei Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChengleiWuModelingFacialGeometry').submit();\">Chenglei Wu</a>,\n</form>\n<form id=\"form-JasonSaragihModelingFacialGeometry\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jason Saragih\">\n<a href=\"#\" onclick=\"document.getElementById('form-JasonSaragihModelingFacialGeometry').submit();\">Jason Saragih</a>,\n</form>\n<form id=\"form-PascalFuaModelingFacialGeometry\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pascal Fua\">\n<a href=\"#\" onclick=\"document.getElementById('form-PascalFuaModelingFacialGeometry').submit();\">Pascal Fua</a>,\n</form>\n<form id=\"form-YaserSheikhModelingFacialGeometry\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yaser Sheikh\">\n<a href=\"#\" onclick=\"document.getElementById('form-YaserSheikhModelingFacialGeometry').submit();\">Yaser Sheikh</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Bagautdinov_Modeling_Facial_Geometry_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3156-supp.zip\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Bagautdinov_2018_CVPR,<br>\nauthor = {Bagautdinov, Timur and Wu, Chenglei and Saragih, Jason and Fua, Pascal and Sheikh, Yaser},<br>\ntitle = {Modeling Facial Geometry Using Compositional VAEs},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper.html\">Tangent Convolutions for Dense Prediction in 3D</a></dt>\n<dd>\n<form id=\"form-MaximTatarchenkoTangentConvolutionsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Maxim Tatarchenko\">\n<a href=\"#\" onclick=\"document.getElementById('form-MaximTatarchenkoTangentConvolutionsfor').submit();\">Maxim Tatarchenko</a>,\n</form>\n<form id=\"form-JaesikParkTangentConvolutionsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jaesik Park\">\n<a href=\"#\" onclick=\"document.getElementById('form-JaesikParkTangentConvolutionsfor').submit();\">Jaesik Park</a>,\n</form>\n<form id=\"form-VladlenKoltunTangentConvolutionsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vladlen Koltun\">\n<a href=\"#\" onclick=\"document.getElementById('form-VladlenKoltunTangentConvolutionsfor').submit();\">Vladlen Koltun</a>,\n</form>\n<form id=\"form-Qian-YiZhouTangentConvolutionsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qian-Yi Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-Qian-YiZhouTangentConvolutionsfor').submit();\">Qian-Yi Zhou</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tatarchenko_Tangent_Convolutions_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1807.02443\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tatarchenko_2018_CVPR,<br>\nauthor = {Tatarchenko, Maxim and Park, Jaesik and Koltun, Vladlen and Zhou, Qian-Yi},<br>\ntitle = {Tangent Convolutions for Dense Prediction in 3D},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Paschalidou_RayNet_Learning_Volumetric_CVPR_2018_paper.html\">RayNet: Learning Volumetric 3D Reconstruction With Ray Potentials</a></dt>\n<dd>\n<form id=\"form-DespoinaPaschalidouRayNetLearningVolumetric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Despoina Paschalidou\">\n<a href=\"#\" onclick=\"document.getElementById('form-DespoinaPaschalidouRayNetLearningVolumetric').submit();\">Despoina Paschalidou</a>,\n</form>\n<form id=\"form-OsmanUlusoyRayNetLearningVolumetric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Osman Ulusoy\">\n<a href=\"#\" onclick=\"document.getElementById('form-OsmanUlusoyRayNetLearningVolumetric').submit();\">Osman Ulusoy</a>,\n</form>\n<form id=\"form-CarolinSchmittRayNetLearningVolumetric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Carolin Schmitt\">\n<a href=\"#\" onclick=\"document.getElementById('form-CarolinSchmittRayNetLearningVolumetric').submit();\">Carolin Schmitt</a>,\n</form>\n<form id=\"form-LucVanRayNetLearningVolumetric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Luc Van Gool\">\n<a href=\"#\" onclick=\"document.getElementById('form-LucVanRayNetLearningVolumetric').submit();\">Luc Van Gool</a>,\n</form>\n<form id=\"form-AndreasGeigerRayNetLearningVolumetric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andreas Geiger\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndreasGeigerRayNetLearningVolumetric').submit();\">Andreas Geiger</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Paschalidou_RayNet_Learning_Volumetric_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Paschalidou_2018_CVPR,<br>\nauthor = {Paschalidou, Despoina and Ulusoy, Osman and Schmitt, Carolin and Van Gool, Luc and Geiger, Andreas},<br>\ntitle = {RayNet: Learning Volumetric 3D Reconstruction With Ray Potentials},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kato_Neural_3D_Mesh_CVPR_2018_paper.html\">Neural 3D Mesh Renderer</a></dt>\n<dd>\n<form id=\"form-HiroharuKatoNeural3DMesh\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hiroharu Kato\">\n<a href=\"#\" onclick=\"document.getElementById('form-HiroharuKatoNeural3DMesh').submit();\">Hiroharu Kato</a>,\n</form>\n<form id=\"form-YoshitakaUshikuNeural3DMesh\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yoshitaka Ushiku\">\n<a href=\"#\" onclick=\"document.getElementById('form-YoshitakaUshikuNeural3DMesh').submit();\">Yoshitaka Ushiku</a>,\n</form>\n<form id=\"form-TatsuyaHaradaNeural3DMesh\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tatsuya Harada\">\n<a href=\"#\" onclick=\"document.getElementById('form-TatsuyaHaradaNeural3DMesh').submit();\">Tatsuya Harada</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kato_Neural_3D_Mesh_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2792-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.07566\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kato_2018_CVPR,<br>\nauthor = {Kato, Hiroharu and Ushiku, Yoshitaka and Harada, Tatsuya},<br>\ntitle = {Neural 3D Mesh Renderer},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xu_Structured_Attention_Guided_CVPR_2018_paper.html\">Structured Attention Guided Convolutional Neural Fields for Monocular Depth Estimation</a></dt>\n<dd>\n<form id=\"form-DanXuStructuredAttentionGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dan Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanXuStructuredAttentionGuided').submit();\">Dan Xu</a>,\n</form>\n<form id=\"form-WeiWangStructuredAttentionGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiWangStructuredAttentionGuided').submit();\">Wei Wang</a>,\n</form>\n<form id=\"form-HaoTangStructuredAttentionGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hao Tang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaoTangStructuredAttentionGuided').submit();\">Hao Tang</a>,\n</form>\n<form id=\"form-HongLiuStructuredAttentionGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hong Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HongLiuStructuredAttentionGuided').submit();\">Hong Liu</a>,\n</form>\n<form id=\"form-NicuSebeStructuredAttentionGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nicu Sebe\">\n<a href=\"#\" onclick=\"document.getElementById('form-NicuSebeStructuredAttentionGuided').submit();\">Nicu Sebe</a>,\n</form>\n<form id=\"form-ElisaRicciStructuredAttentionGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Elisa Ricci\">\n<a href=\"#\" onclick=\"document.getElementById('form-ElisaRicciStructuredAttentionGuided').submit();\">Elisa Ricci</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xu_Structured_Attention_Guided_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.11029\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xu_2018_CVPR,<br>\nauthor = {Xu, Dan and Wang, Wei and Tang, Hao and Liu, Hong and Sebe, Nicu and Ricci, Elisa},<br>\ntitle = {Structured Attention Guided Convolutional Neural Fields for Monocular Depth Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yang_Automatic_3D_Indoor_CVPR_2018_paper.html\">Automatic 3D Indoor Scene Modeling From Single Panorama</a></dt>\n<dd>\n<form id=\"form-YangYangAutomatic3DIndoor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yang Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YangYangAutomatic3DIndoor').submit();\">Yang Yang</a>,\n</form>\n<form id=\"form-ShiJinAutomatic3DIndoor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shi Jin\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShiJinAutomatic3DIndoor').submit();\">Shi Jin</a>,\n</form>\n<form id=\"form-RuiyangLiuAutomatic3DIndoor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ruiyang Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-RuiyangLiuAutomatic3DIndoor').submit();\">Ruiyang Liu</a>,\n</form>\n<form id=\"form-SingBingAutomatic3DIndoor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sing Bing Kang\">\n<a href=\"#\" onclick=\"document.getElementById('form-SingBingAutomatic3DIndoor').submit();\">Sing Bing Kang</a>,\n</form>\n<form id=\"form-JingyiYuAutomatic3DIndoor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jingyi Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingyiYuAutomatic3DIndoor').submit();\">Jingyi Yu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yang_Automatic_3D_Indoor_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yang_2018_CVPR,<br>\nauthor = {Yang, Yang and Jin, Shi and Liu, Ruiyang and Bing Kang, Sing and Yu, Jingyi},<br>\ntitle = {Automatic 3D Indoor Scene Modeling From Single Panorama},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tran_Extreme_3D_Face_CVPR_2018_paper.html\">Extreme 3D Face Reconstruction: Seeing Through Occlusions</a></dt>\n<dd>\n<form id=\"form-AnhTu\u00e1\u00ba\u00a5nExtreme3DFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anh Tu\u00e1\u00ba\u00a5n Tr\u00e1\u00ba\u00a7n\">\n<a href=\"#\" onclick=\"document.getElementById('form-AnhTu\u00e1\u00ba\u00a5nExtreme3DFace').submit();\">Anh Tu\u00e1\u00ba\u00a5n Tr\u00e1\u00ba\u00a7n</a>,\n</form>\n<form id=\"form-TalHassnerExtreme3DFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tal Hassner\">\n<a href=\"#\" onclick=\"document.getElementById('form-TalHassnerExtreme3DFace').submit();\">Tal Hassner</a>,\n</form>\n<form id=\"form-IacopoMasiExtreme3DFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Iacopo Masi\">\n<a href=\"#\" onclick=\"document.getElementById('form-IacopoMasiExtreme3DFace').submit();\">Iacopo Masi</a>,\n</form>\n<form id=\"form-EranPazExtreme3DFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Eran Paz\">\n<a href=\"#\" onclick=\"document.getElementById('form-EranPazExtreme3DFace').submit();\">Eran Paz</a>,\n</form>\n<form id=\"form-YuvalNirkinExtreme3DFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuval Nirkin\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuvalNirkinExtreme3DFace').submit();\">Yuval Nirkin</a>,\n</form>\n<form id=\"form-G\u00c3\u00a9rardMedioniExtreme3DFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"G\u00c3\u00a9rard Medioni\">\n<a href=\"#\" onclick=\"document.getElementById('form-G\u00c3\u00a9rardMedioniExtreme3DFace').submit();\">G\u00c3\u00a9rard Medioni</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tran_Extreme_3D_Face_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.05083\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tr\u00e1\u00ba\u00a7n_2018_CVPR,<br>\nauthor = {Tu\u00e1\u00ba\u00a5n Tr\u00e1\u00ba\u00a7n, Anh and Hassner, Tal and Masi, Iacopo and Paz, Eran and Nirkin, Yuval and Medioni, G\u00c3\u00a9rard},<br>\ntitle = {Extreme 3D Face Reconstruction: Seeing Through Occlusions},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Larsson_Beyond_Grobner_Bases_CVPR_2018_paper.html\">Beyond Grobner Bases: Basis Selection for Minimal Solvers</a></dt>\n<dd>\n<form id=\"form-ViktorLarssonBeyondGrobnerBases\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Viktor Larsson\">\n<a href=\"#\" onclick=\"document.getElementById('form-ViktorLarssonBeyondGrobnerBases').submit();\">Viktor Larsson</a>,\n</form>\n<form id=\"form-MagnusOskarssonBeyondGrobnerBases\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Magnus Oskarsson\">\n<a href=\"#\" onclick=\"document.getElementById('form-MagnusOskarssonBeyondGrobnerBases').submit();\">Magnus Oskarsson</a>,\n</form>\n<form id=\"form-KalleAstromBeyondGrobnerBases\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kalle Astrom\">\n<a href=\"#\" onclick=\"document.getElementById('form-KalleAstromBeyondGrobnerBases').submit();\">Kalle Astrom</a>,\n</form>\n<form id=\"form-AlgeWallisBeyondGrobnerBases\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alge Wallis\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlgeWallisBeyondGrobnerBases').submit();\">Alge Wallis</a>,\n</form>\n<form id=\"form-ZuzanaKukelovaBeyondGrobnerBases\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zuzana Kukelova\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZuzanaKukelovaBeyondGrobnerBases').submit();\">Zuzana Kukelova</a>,\n</form>\n<form id=\"form-TomasPajdlaBeyondGrobnerBases\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tomas Pajdla\">\n<a href=\"#\" onclick=\"document.getElementById('form-TomasPajdlaBeyondGrobnerBases').submit();\">Tomas Pajdla</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Larsson_Beyond_Grobner_Bases_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Larsson_2018_CVPR,<br>\nauthor = {Larsson, Viktor and Oskarsson, Magnus and Astrom, Kalle and Wallis, Alge and Kukelova, Zuzana and Pajdla, Tomas},<br>\ntitle = {Beyond Grobner Bases: Basis Selection for Minimal Solvers},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zuffi_Lions_and_Tigers_CVPR_2018_paper.html\">Lions and Tigers and Bears: Capturing Non-Rigid, 3D, Articulated Shape From Images</a></dt>\n<dd>\n<form id=\"form-SilviaZuffiLionsandTigers\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Silvia Zuffi\">\n<a href=\"#\" onclick=\"document.getElementById('form-SilviaZuffiLionsandTigers').submit();\">Silvia Zuffi</a>,\n</form>\n<form id=\"form-AngjooKanazawaLionsandTigers\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Angjoo Kanazawa\">\n<a href=\"#\" onclick=\"document.getElementById('form-AngjooKanazawaLionsandTigers').submit();\">Angjoo Kanazawa</a>,\n</form>\n<form id=\"form-MichaelJ.LionsandTigers\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michael J. Black\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichaelJ.LionsandTigers').submit();\">Michael J. Black</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zuffi_Lions_and_Tigers_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zuffi_2018_CVPR,<br>\nauthor = {Zuffi, Silvia and Kanazawa, Angjoo and Black, Michael J.},<br>\ntitle = {Lions and Tigers and Bears: Capturing Non-Rigid, 3D, Articulated Shape From Images},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xu_Deep_Cocktail_Network_CVPR_2018_paper.html\">Deep Cocktail Network: Multi-Source Unsupervised Domain Adaptation With Category Shift</a></dt>\n<dd>\n<form id=\"form-RuijiaXuDeepCocktailNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ruijia Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-RuijiaXuDeepCocktailNetwork').submit();\">Ruijia Xu</a>,\n</form>\n<form id=\"form-ZiliangChenDeepCocktailNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ziliang Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZiliangChenDeepCocktailNetwork').submit();\">Ziliang Chen</a>,\n</form>\n<form id=\"form-WangmengZuoDeepCocktailNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wangmeng Zuo\">\n<a href=\"#\" onclick=\"document.getElementById('form-WangmengZuoDeepCocktailNetwork').submit();\">Wangmeng Zuo</a>,\n</form>\n<form id=\"form-JunjieYanDeepCocktailNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junjie Yan\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunjieYanDeepCocktailNetwork').submit();\">Junjie Yan</a>,\n</form>\n<form id=\"form-LiangLinDeepCocktailNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liang Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiangLinDeepCocktailNetwork').submit();\">Liang Lin</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xu_Deep_Cocktail_Network_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1880-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.00830\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xu_2018_CVPR,<br>\nauthor = {Xu, Ruijia and Chen, Ziliang and Zuo, Wangmeng and Yan, Junjie and Lin, Liang},<br>\ntitle = {Deep Cocktail Network: Multi-Source Unsupervised Domain Adaptation With Category Shift},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xia_DOTA_A_Large-Scale_CVPR_2018_paper.html\">DOTA: A Large-Scale Dataset for Object Detection in Aerial Images</a></dt>\n<dd>\n<form id=\"form-Gui-SongXiaDOTAALargeScale\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gui-Song Xia\">\n<a href=\"#\" onclick=\"document.getElementById('form-Gui-SongXiaDOTAALargeScale').submit();\">Gui-Song Xia</a>,\n</form>\n<form id=\"form-XiangBaiDOTAALargeScale\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiang Bai\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiangBaiDOTAALargeScale').submit();\">Xiang Bai</a>,\n</form>\n<form id=\"form-JianDingDOTAALargeScale\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jian Ding\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianDingDOTAALargeScale').submit();\">Jian Ding</a>,\n</form>\n<form id=\"form-ZhenZhuDOTAALargeScale\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhen Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhenZhuDOTAALargeScale').submit();\">Zhen Zhu</a>,\n</form>\n<form id=\"form-SergeBelongieDOTAALargeScale\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Serge Belongie\">\n<a href=\"#\" onclick=\"document.getElementById('form-SergeBelongieDOTAALargeScale').submit();\">Serge Belongie</a>,\n</form>\n<form id=\"form-JieboLuoDOTAALargeScale\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiebo Luo\">\n<a href=\"#\" onclick=\"document.getElementById('form-JieboLuoDOTAALargeScale').submit();\">Jiebo Luo</a>,\n</form>\n<form id=\"form-MihaiDatcuDOTAALargeScale\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mihai Datcu\">\n<a href=\"#\" onclick=\"document.getElementById('form-MihaiDatcuDOTAALargeScale').submit();\">Mihai Datcu</a>,\n</form>\n<form id=\"form-MarcelloPelilloDOTAALargeScale\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Marcello Pelillo\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarcelloPelilloDOTAALargeScale').submit();\">Marcello Pelillo</a>,\n</form>\n<form id=\"form-LiangpeiZhangDOTAALargeScale\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liangpei Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiangpeiZhangDOTAALargeScale').submit();\">Liangpei Zhang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xia_DOTA_A_Large-Scale_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.10398\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xia_2018_CVPR,<br>\nauthor = {Xia, Gui-Song and Bai, Xiang and Ding, Jian and Zhu, Zhen and Belongie, Serge and Luo, Jiebo and Datcu, Mihai and Pelillo, Marcello and Zhang, Liangpei},<br>\ntitle = {DOTA: A Large-Scale Dataset for Object Detection in Aerial Images},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Engilberge_Finding_Beans_in_CVPR_2018_paper.html\">Finding Beans in Burgers: Deep Semantic-Visual Embedding With Localization</a></dt>\n<dd>\n<form id=\"form-MartinEngilbergeFindingBeansin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Martin Engilberge\">\n<a href=\"#\" onclick=\"document.getElementById('form-MartinEngilbergeFindingBeansin').submit();\">Martin Engilberge</a>,\n</form>\n<form id=\"form-LouisChevallierFindingBeansin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Louis Chevallier\">\n<a href=\"#\" onclick=\"document.getElementById('form-LouisChevallierFindingBeansin').submit();\">Louis Chevallier</a>,\n</form>\n<form id=\"form-PatrickP\u00c3\u00a9rezFindingBeansin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Patrick P\u00c3\u00a9rez\">\n<a href=\"#\" onclick=\"document.getElementById('form-PatrickP\u00c3\u00a9rezFindingBeansin').submit();\">Patrick P\u00c3\u00a9rez</a>,\n</form>\n<form id=\"form-MatthieuCordFindingBeansin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Matthieu Cord\">\n<a href=\"#\" onclick=\"document.getElementById('form-MatthieuCordFindingBeansin').submit();\">Matthieu Cord</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Engilberge_Finding_Beans_in_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.01720\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Engilberge_2018_CVPR,<br>\nauthor = {Engilberge, Martin and Chevallier, Louis and P\u00c3\u00a9rez, Patrick and Cord, Matthieu},<br>\ntitle = {Finding Beans in Burgers: Deep Semantic-Visual Embedding With Localization},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tan_Feature_Super-Resolution_Make_CVPR_2018_paper.html\">Feature Super-Resolution: Make Machine See More Clearly</a></dt>\n<dd>\n<form id=\"form-WeiminTanFeatureSuperResolutionMake\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weimin Tan\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiminTanFeatureSuperResolutionMake').submit();\">Weimin Tan</a>,\n</form>\n<form id=\"form-BoYanFeatureSuperResolutionMake\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bo Yan\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoYanFeatureSuperResolutionMake').submit();\">Bo Yan</a>,\n</form>\n<form id=\"form-BahetiyaerBareFeatureSuperResolutionMake\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bahetiyaer Bare\">\n<a href=\"#\" onclick=\"document.getElementById('form-BahetiyaerBareFeatureSuperResolutionMake').submit();\">Bahetiyaer Bare</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tan_Feature_Super-Resolution_Make_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tan_2018_CVPR,<br>\nauthor = {Tan, Weimin and Yan, Bo and Bare, Bahetiyaer},<br>\ntitle = {Feature Super-Resolution: Make Machine See More Clearly},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/LaLonde_ClusterNet_Detecting_Small_CVPR_2018_paper.html\">ClusterNet: Detecting Small Objects in Large Scenes by Exploiting Spatio-Temporal Information</a></dt>\n<dd>\n<form id=\"form-RodneyLaLondeClusterNetDetectingSmall\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rodney LaLonde\">\n<a href=\"#\" onclick=\"document.getElementById('form-RodneyLaLondeClusterNetDetectingSmall').submit();\">Rodney LaLonde</a>,\n</form>\n<form id=\"form-DongZhangClusterNetDetectingSmall\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dong Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-DongZhangClusterNetDetectingSmall').submit();\">Dong Zhang</a>,\n</form>\n<form id=\"form-MubarakShahClusterNetDetectingSmall\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mubarak Shah\">\n<a href=\"#\" onclick=\"document.getElementById('form-MubarakShahClusterNetDetectingSmall').submit();\">Mubarak Shah</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/LaLonde_ClusterNet_Detecting_Small_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3460-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1704.02694\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{LaLonde_2018_CVPR,<br>\nauthor = {LaLonde, Rodney and Zhang, Dong and Shah, Mubarak},<br>\ntitle = {ClusterNet: Detecting Small Objects in Large Scenes by Exploiting Spatio-Temporal Information},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_MaskLab_Instance_Segmentation_CVPR_2018_paper.html\">MaskLab: Instance Segmentation by Refining Object Detection With Semantic and Direction Features</a></dt>\n<dd>\n<form id=\"form-Liang-ChiehChenMaskLabInstanceSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liang-Chieh Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-Liang-ChiehChenMaskLabInstanceSegmentation').submit();\">Liang-Chieh Chen</a>,\n</form>\n<form id=\"form-AlexanderHermansMaskLabInstanceSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexander Hermans\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexanderHermansMaskLabInstanceSegmentation').submit();\">Alexander Hermans</a>,\n</form>\n<form id=\"form-GeorgePapandreouMaskLabInstanceSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"George Papandreou\">\n<a href=\"#\" onclick=\"document.getElementById('form-GeorgePapandreouMaskLabInstanceSegmentation').submit();\">George Papandreou</a>,\n</form>\n<form id=\"form-FlorianSchroffMaskLabInstanceSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Florian Schroff\">\n<a href=\"#\" onclick=\"document.getElementById('form-FlorianSchroffMaskLabInstanceSegmentation').submit();\">Florian Schroff</a>,\n</form>\n<form id=\"form-PengWangMaskLabInstanceSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peng Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-PengWangMaskLabInstanceSegmentation').submit();\">Peng Wang</a>,\n</form>\n<form id=\"form-HartwigAdamMaskLabInstanceSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hartwig Adam\">\n<a href=\"#\" onclick=\"document.getElementById('form-HartwigAdamMaskLabInstanceSegmentation').submit();\">Hartwig Adam</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_MaskLab_Instance_Segmentation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3680-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.04837\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Liang-Chieh and Hermans, Alexander and Papandreou, George and Schroff, Florian and Wang, Peng and Adam, Hartwig},<br>\ntitle = {MaskLab: Instance Segmentation by Refining Object Detection With Semantic and Direction Features},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/He_Hashing_as_Tie-Aware_CVPR_2018_paper.html\">Hashing as Tie-Aware Learning to Rank</a></dt>\n<dd>\n<form id=\"form-KunHeHashingasTieAware\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kun He\">\n<a href=\"#\" onclick=\"document.getElementById('form-KunHeHashingasTieAware').submit();\">Kun He</a>,\n</form>\n<form id=\"form-FatihCakirHashingasTieAware\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fatih Cakir\">\n<a href=\"#\" onclick=\"document.getElementById('form-FatihCakirHashingasTieAware').submit();\">Fatih Cakir</a>,\n</form>\n<form id=\"form-SarahAdelHashingasTieAware\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sarah Adel Bargal\">\n<a href=\"#\" onclick=\"document.getElementById('form-SarahAdelHashingasTieAware').submit();\">Sarah Adel Bargal</a>,\n</form>\n<form id=\"form-StanSclaroffHashingasTieAware\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stan Sclaroff\">\n<a href=\"#\" onclick=\"document.getElementById('form-StanSclaroffHashingasTieAware').submit();\">Stan Sclaroff</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/He_Hashing_as_Tie-Aware_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0367-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1705.08562\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{He_2018_CVPR,<br>\nauthor = {He, Kun and Cakir, Fatih and Adel Bargal, Sarah and Sclaroff, Stan},<br>\ntitle = {Hashing as Tie-Aware Learning to Rank},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sharma_Classification-Driven_Dynamic_Image_CVPR_2018_paper.html\">Classification-Driven Dynamic Image Enhancement</a></dt>\n<dd>\n<form id=\"form-VivekSharmaClassificationDrivenDynamicImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vivek Sharma\">\n<a href=\"#\" onclick=\"document.getElementById('form-VivekSharmaClassificationDrivenDynamicImage').submit();\">Vivek Sharma</a>,\n</form>\n<form id=\"form-AliDibaClassificationDrivenDynamicImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ali Diba\">\n<a href=\"#\" onclick=\"document.getElementById('form-AliDibaClassificationDrivenDynamicImage').submit();\">Ali Diba</a>,\n</form>\n<form id=\"form-DavyNevenClassificationDrivenDynamicImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Davy Neven\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavyNevenClassificationDrivenDynamicImage').submit();\">Davy Neven</a>,\n</form>\n<form id=\"form-MichaelS.ClassificationDrivenDynamicImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michael S. Brown\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichaelS.ClassificationDrivenDynamicImage').submit();\">Michael S. Brown</a>,\n</form>\n<form id=\"form-LucVanClassificationDrivenDynamicImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Luc Van Gool\">\n<a href=\"#\" onclick=\"document.getElementById('form-LucVanClassificationDrivenDynamicImage').submit();\">Luc Van Gool</a>,\n</form>\n<form id=\"form-RainerStiefelhagenClassificationDrivenDynamicImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rainer Stiefelhagen\">\n<a href=\"#\" onclick=\"document.getElementById('form-RainerStiefelhagenClassificationDrivenDynamicImage').submit();\">Rainer Stiefelhagen</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sharma_Classification-Driven_Dynamic_Image_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1710.07558\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sharma_2018_CVPR,<br>\nauthor = {Sharma, Vivek and Diba, Ali and Neven, Davy and Brown, Michael S. and Van Gool, Luc and Stiefelhagen, Rainer},<br>\ntitle = {Classification-Driven Dynamic Image Enhancement},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_Knowledge_Aided_Consistency_CVPR_2018_paper.html\">Knowledge Aided Consistency for Weakly Supervised Phrase Grounding</a></dt>\n<dd>\n<form id=\"form-KanChenKnowledgeAidedConsistency\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kan Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-KanChenKnowledgeAidedConsistency').submit();\">Kan Chen</a>,\n</form>\n<form id=\"form-JiyangGaoKnowledgeAidedConsistency\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiyang Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiyangGaoKnowledgeAidedConsistency').submit();\">Jiyang Gao</a>,\n</form>\n<form id=\"form-RamNevatiaKnowledgeAidedConsistency\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ram Nevatia\">\n<a href=\"#\" onclick=\"document.getElementById('form-RamNevatiaKnowledgeAidedConsistency').submit();\">Ram Nevatia</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_Knowledge_Aided_Consistency_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0589-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.03879\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Kan and Gao, Jiyang and Nevatia, Ram},<br>\ntitle = {Knowledge Aided Consistency for Weakly Supervised Phrase Grounding},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ehsani_Who_Let_the_CVPR_2018_paper.html\">Who Let the Dogs Out? Modeling Dog Behavior From Visual Data</a></dt>\n<dd>\n<form id=\"form-KianaEhsaniWhoLetthe\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kiana Ehsani\">\n<a href=\"#\" onclick=\"document.getElementById('form-KianaEhsaniWhoLetthe').submit();\">Kiana Ehsani</a>,\n</form>\n<form id=\"form-HessamBagherinezhadWhoLetthe\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hessam Bagherinezhad\">\n<a href=\"#\" onclick=\"document.getElementById('form-HessamBagherinezhadWhoLetthe').submit();\">Hessam Bagherinezhad</a>,\n</form>\n<form id=\"form-JosephRedmonWhoLetthe\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Joseph Redmon\">\n<a href=\"#\" onclick=\"document.getElementById('form-JosephRedmonWhoLetthe').submit();\">Joseph Redmon</a>,\n</form>\n<form id=\"form-RoozbehMottaghiWhoLetthe\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Roozbeh Mottaghi\">\n<a href=\"#\" onclick=\"document.getElementById('form-RoozbehMottaghiWhoLetthe').submit();\">Roozbeh Mottaghi</a>,\n</form>\n<form id=\"form-AliFarhadiWhoLetthe\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ali Farhadi\">\n<a href=\"#\" onclick=\"document.getElementById('form-AliFarhadiWhoLetthe').submit();\">Ali Farhadi</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ehsani_Who_Let_the_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ehsani_2018_CVPR,<br>\nauthor = {Ehsani, Kiana and Bagherinezhad, Hessam and Redmon, Joseph and Mottaghi, Roozbeh and Farhadi, Ali},<br>\ntitle = {Who Let the Dogs Out? Modeling Dog Behavior From Visual Data},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhao_Pseudo_Mask_Augmented_CVPR_2018_paper.html\">Pseudo Mask Augmented Object Detection</a></dt>\n<dd>\n<form id=\"form-XiangyunZhaoPseudoMaskAugmented\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiangyun Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiangyunZhaoPseudoMaskAugmented').submit();\">Xiangyun Zhao</a>,\n</form>\n<form id=\"form-ShuangLiangPseudoMaskAugmented\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuang Liang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuangLiangPseudoMaskAugmented').submit();\">Shuang Liang</a>,\n</form>\n<form id=\"form-YichenWeiPseudoMaskAugmented\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yichen Wei\">\n<a href=\"#\" onclick=\"document.getElementById('form-YichenWeiPseudoMaskAugmented').submit();\">Yichen Wei</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhao_Pseudo_Mask_Augmented_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.05858\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhao_2018_CVPR,<br>\nauthor = {Zhao, Xiangyun and Liang, Shuang and Wei, Yichen},<br>\ntitle = {Pseudo Mask Augmented Object Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Cheng_Dual_Skipping_Networks_CVPR_2018_paper.html\">Dual Skipping Networks</a></dt>\n<dd>\n<form id=\"form-ChangmaoChengDualSkippingNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Changmao Cheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChangmaoChengDualSkippingNetworks').submit();\">Changmao Cheng</a>,\n</form>\n<form id=\"form-YanweiFuDualSkippingNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yanwei Fu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanweiFuDualSkippingNetworks').submit();\">Yanwei Fu</a>,\n</form>\n<form id=\"form-Yu-GangJiangDualSkippingNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu-Gang Jiang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yu-GangJiangDualSkippingNetworks').submit();\">Yu-Gang Jiang</a>,\n</form>\n<form id=\"form-WeiLiuDualSkippingNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiLiuDualSkippingNetworks').submit();\">Wei Liu</a>,\n</form>\n<form id=\"form-WenlianLuDualSkippingNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenlian Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenlianLuDualSkippingNetworks').submit();\">Wenlian Lu</a>,\n</form>\n<form id=\"form-JianfengFengDualSkippingNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianfeng Feng\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianfengFengDualSkippingNetworks').submit();\">Jianfeng Feng</a>,\n</form>\n<form id=\"form-XiangyangXueDualSkippingNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiangyang Xue\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiangyangXueDualSkippingNetworks').submit();\">Xiangyang Xue</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Cheng_Dual_Skipping_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1710.10386\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Cheng_2018_CVPR,<br>\nauthor = {Cheng, Changmao and Fu, Yanwei and Jiang, Yu-Gang and Liu, Wei and Lu, Wenlian and Feng, Jianfeng and Xue, Xiangyang},<br>\ntitle = {Dual Skipping Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Cai_Memory_Matching_Networks_CVPR_2018_paper.html\">Memory Matching Networks for One-Shot Image Recognition</a></dt>\n<dd>\n<form id=\"form-QiCaiMemoryMatchingNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qi Cai\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiCaiMemoryMatchingNetworks').submit();\">Qi Cai</a>,\n</form>\n<form id=\"form-YingweiPanMemoryMatchingNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yingwei Pan\">\n<a href=\"#\" onclick=\"document.getElementById('form-YingweiPanMemoryMatchingNetworks').submit();\">Yingwei Pan</a>,\n</form>\n<form id=\"form-TingYaoMemoryMatchingNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ting Yao\">\n<a href=\"#\" onclick=\"document.getElementById('form-TingYaoMemoryMatchingNetworks').submit();\">Ting Yao</a>,\n</form>\n<form id=\"form-ChenggangYanMemoryMatchingNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chenggang Yan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenggangYanMemoryMatchingNetworks').submit();\">Chenggang Yan</a>,\n</form>\n<form id=\"form-TaoMeiMemoryMatchingNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tao Mei\">\n<a href=\"#\" onclick=\"document.getElementById('form-TaoMeiMemoryMatchingNetworks').submit();\">Tao Mei</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Cai_Memory_Matching_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.08281\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Cai_2018_CVPR,<br>\nauthor = {Cai, Qi and Pan, Yingwei and Yao, Ting and Yan, Chenggang and Mei, Tao},<br>\ntitle = {Memory Matching Networks for One-Shot Image Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Gordon_IQA_Visual_Question_CVPR_2018_paper.html\">IQA: Visual Question Answering in Interactive Environments</a></dt>\n<dd>\n<form id=\"form-DanielGordonIQAVisualQuestion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daniel Gordon\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanielGordonIQAVisualQuestion').submit();\">Daniel Gordon</a>,\n</form>\n<form id=\"form-AniruddhaKembhaviIQAVisualQuestion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Aniruddha Kembhavi\">\n<a href=\"#\" onclick=\"document.getElementById('form-AniruddhaKembhaviIQAVisualQuestion').submit();\">Aniruddha Kembhavi</a>,\n</form>\n<form id=\"form-MohammadRastegariIQAVisualQuestion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mohammad Rastegari\">\n<a href=\"#\" onclick=\"document.getElementById('form-MohammadRastegariIQAVisualQuestion').submit();\">Mohammad Rastegari</a>,\n</form>\n<form id=\"form-JosephRedmonIQAVisualQuestion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Joseph Redmon\">\n<a href=\"#\" onclick=\"document.getElementById('form-JosephRedmonIQAVisualQuestion').submit();\">Joseph Redmon</a>,\n</form>\n<form id=\"form-DieterFoxIQAVisualQuestion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dieter Fox\">\n<a href=\"#\" onclick=\"document.getElementById('form-DieterFoxIQAVisualQuestion').submit();\">Dieter Fox</a>,\n</form>\n<form id=\"form-AliFarhadiIQAVisualQuestion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ali Farhadi\">\n<a href=\"#\" onclick=\"document.getElementById('form-AliFarhadiIQAVisualQuestion').submit();\">Ali Farhadi</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Gordon_IQA_Visual_Question_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.03316\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Gordon_2018_CVPR,<br>\nauthor = {Gordon, Daniel and Kembhavi, Aniruddha and Rastegari, Mohammad and Redmon, Joseph and Fox, Dieter and Farhadi, Ali},<br>\ntitle = {IQA: Visual Question Answering in Interactive Environments},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_Pose_Transferrable_Person_CVPR_2018_paper.html\">Pose Transferrable Person Re-Identification</a></dt>\n<dd>\n<form id=\"form-JinxianLiuPoseTransferrablePerson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jinxian Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JinxianLiuPoseTransferrablePerson').submit();\">Jinxian Liu</a>,\n</form>\n<form id=\"form-BingbingNiPoseTransferrablePerson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bingbing Ni\">\n<a href=\"#\" onclick=\"document.getElementById('form-BingbingNiPoseTransferrablePerson').submit();\">Bingbing Ni</a>,\n</form>\n<form id=\"form-YichaoYanPoseTransferrablePerson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yichao Yan\">\n<a href=\"#\" onclick=\"document.getElementById('form-YichaoYanPoseTransferrablePerson').submit();\">Yichao Yan</a>,\n</form>\n<form id=\"form-PengZhouPoseTransferrablePerson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peng Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-PengZhouPoseTransferrablePerson').submit();\">Peng Zhou</a>,\n</form>\n<form id=\"form-ShuoChengPoseTransferrablePerson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuo Cheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuoChengPoseTransferrablePerson').submit();\">Shuo Cheng</a>,\n</form>\n<form id=\"form-JianguoHuPoseTransferrablePerson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianguo Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianguoHuPoseTransferrablePerson').submit();\">Jianguo Hu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_Pose_Transferrable_Person_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Jinxian and Ni, Bingbing and Yan, Yichao and Zhou, Peng and Cheng, Shuo and Hu, Jianguo},<br>\ntitle = {Pose Transferrable Person Re-Identification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Cui_Large_Scale_Fine-Grained_CVPR_2018_paper.html\">Large Scale Fine-Grained Categorization and Domain-Specific Transfer Learning</a></dt>\n<dd>\n<form id=\"form-YinCuiLargeScaleFineGrained\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yin Cui\">\n<a href=\"#\" onclick=\"document.getElementById('form-YinCuiLargeScaleFineGrained').submit();\">Yin Cui</a>,\n</form>\n<form id=\"form-YangSongLargeScaleFineGrained\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yang Song\">\n<a href=\"#\" onclick=\"document.getElementById('form-YangSongLargeScaleFineGrained').submit();\">Yang Song</a>,\n</form>\n<form id=\"form-ChenSunLargeScaleFineGrained\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chen Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenSunLargeScaleFineGrained').submit();\">Chen Sun</a>,\n</form>\n<form id=\"form-AndrewHowardLargeScaleFineGrained\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrew Howard\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndrewHowardLargeScaleFineGrained').submit();\">Andrew Howard</a>,\n</form>\n<form id=\"form-SergeBelongieLargeScaleFineGrained\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Serge Belongie\">\n<a href=\"#\" onclick=\"document.getElementById('form-SergeBelongieLargeScaleFineGrained').submit();\">Serge Belongie</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Cui_Large_Scale_Fine-Grained_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1806.06193\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Cui_2018_CVPR,<br>\nauthor = {Cui, Yin and Song, Yang and Sun, Chen and Howard, Andrew and Belongie, Serge},<br>\ntitle = {Large Scale Fine-Grained Categorization and Domain-Specific Transfer Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Radosavovic_Data_Distillation_Towards_CVPR_2018_paper.html\">Data Distillation: Towards Omni-Supervised Learning</a></dt>\n<dd>\n<form id=\"form-IlijaRadosavovicDataDistillationTowards\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ilija Radosavovic\">\n<a href=\"#\" onclick=\"document.getElementById('form-IlijaRadosavovicDataDistillationTowards').submit();\">Ilija Radosavovic</a>,\n</form>\n<form id=\"form-PiotrDoll\u00c3\u00a1rDataDistillationTowards\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Piotr Doll\u00c3\u00a1r\">\n<a href=\"#\" onclick=\"document.getElementById('form-PiotrDoll\u00c3\u00a1rDataDistillationTowards').submit();\">Piotr Doll\u00c3\u00a1r</a>,\n</form>\n<form id=\"form-RossGirshickDataDistillationTowards\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ross Girshick\">\n<a href=\"#\" onclick=\"document.getElementById('form-RossGirshickDataDistillationTowards').submit();\">Ross Girshick</a>,\n</form>\n<form id=\"form-GeorgiaGkioxariDataDistillationTowards\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Georgia Gkioxari\">\n<a href=\"#\" onclick=\"document.getElementById('form-GeorgiaGkioxariDataDistillationTowards').submit();\">Georgia Gkioxari</a>,\n</form>\n<form id=\"form-KaimingHeDataDistillationTowards\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kaiming He\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaimingHeDataDistillationTowards').submit();\">Kaiming He</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Radosavovic_Data_Distillation_Towards_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.04440\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Radosavovic_2018_CVPR,<br>\nauthor = {Radosavovic, Ilija and Doll\u00c3\u00a1r, Piotr and Girshick, Ross and Gkioxari, Georgia and He, Kaiming},<br>\ntitle = {Data Distillation: Towards Omni-Supervised Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Vasudevan_Object_Referring_in_CVPR_2018_paper.html\">Object Referring in Videos With Language and Human Gaze</a></dt>\n<dd>\n<form id=\"form-ArunBalajeeObjectReferringin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Arun Balajee Vasudevan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ArunBalajeeObjectReferringin').submit();\">Arun Balajee Vasudevan</a>,\n</form>\n<form id=\"form-DengxinDaiObjectReferringin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dengxin Dai\">\n<a href=\"#\" onclick=\"document.getElementById('form-DengxinDaiObjectReferringin').submit();\">Dengxin Dai</a>,\n</form>\n<form id=\"form-LucVanObjectReferringin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Luc Van Gool\">\n<a href=\"#\" onclick=\"document.getElementById('form-LucVanObjectReferringin').submit();\">Luc Van Gool</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Vasudevan_Object_Referring_in_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.01582\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Vasudevan_2018_CVPR,<br>\nauthor = {Balajee Vasudevan, Arun and Dai, Dengxin and Van Gool, Luc},<br>\ntitle = {Object Referring in Videos With Language and Human Gaze},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhai_Feature_Selective_Networks_CVPR_2018_paper.html\">Feature Selective Networks for Object Detection</a></dt>\n<dd>\n<form id=\"form-YaoZhaiFeatureSelectiveNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yao Zhai\">\n<a href=\"#\" onclick=\"document.getElementById('form-YaoZhaiFeatureSelectiveNetworks').submit();\">Yao Zhai</a>,\n</form>\n<form id=\"form-JingjingFuFeatureSelectiveNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jingjing Fu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingjingFuFeatureSelectiveNetworks').submit();\">Jingjing Fu</a>,\n</form>\n<form id=\"form-YanLuFeatureSelectiveNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yan Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanLuFeatureSelectiveNetworks').submit();\">Yan Lu</a>,\n</form>\n<form id=\"form-HouqiangLiFeatureSelectiveNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Houqiang Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-HouqiangLiFeatureSelectiveNetworks').submit();\">Houqiang Li</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhai_Feature_Selective_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.08879\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhai_2018_CVPR,<br>\nauthor = {Zhai, Yao and Fu, Jingjing and Lu, Yan and Li, Houqiang},<br>\ntitle = {Feature Selective Networks for Object Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Learning_a_Discriminative_CVPR_2018_paper.html\">Learning a Discriminative Filter Bank Within a CNN for Fine-Grained Recognition</a></dt>\n<dd>\n<form id=\"form-YamingWangLearningaDiscriminative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yaming Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YamingWangLearningaDiscriminative').submit();\">Yaming Wang</a>,\n</form>\n<form id=\"form-VladI.LearningaDiscriminative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vlad I. Morariu\">\n<a href=\"#\" onclick=\"document.getElementById('form-VladI.LearningaDiscriminative').submit();\">Vlad I. Morariu</a>,\n</form>\n<form id=\"form-LarryS.LearningaDiscriminative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Larry S. Davis\">\n<a href=\"#\" onclick=\"document.getElementById('form-LarryS.LearningaDiscriminative').submit();\">Larry S. Davis</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Learning_a_Discriminative_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1611.09932\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Yaming and Morariu, Vlad I. and Davis, Larry S.},<br>\ntitle = {Learning a Discriminative Filter Bank Within a CNN for Fine-Grained Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Grounding_Referring_Expressions_CVPR_2018_paper.html\">Grounding Referring Expressions in Images by Variational Context</a></dt>\n<dd>\n<form id=\"form-HanwangZhangGroundingReferringExpressions\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hanwang Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HanwangZhangGroundingReferringExpressions').submit();\">Hanwang Zhang</a>,\n</form>\n<form id=\"form-YuleiNiuGroundingReferringExpressions\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yulei Niu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuleiNiuGroundingReferringExpressions').submit();\">Yulei Niu</a>,\n</form>\n<form id=\"form-Shih-FuChangGroundingReferringExpressions\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shih-Fu Chang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Shih-FuChangGroundingReferringExpressions').submit();\">Shih-Fu Chang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Grounding_Referring_Expressions_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.01892\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Hanwang and Niu, Yulei and Chang, Shih-Fu},<br>\ntitle = {Grounding Referring Expressions in Images by Variational Context},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kim_Dynamic_Graph_Generation_CVPR_2018_paper.html\">Dynamic Graph Generation Network: Generating Relational Knowledge From Diagrams</a></dt>\n<dd>\n<form id=\"form-DaesikKimDynamicGraphGeneration\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daesik Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-DaesikKimDynamicGraphGeneration').submit();\">Daesik Kim</a>,\n</form>\n<form id=\"form-YoungJoonYooDynamicGraphGeneration\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"YoungJoon Yoo\">\n<a href=\"#\" onclick=\"document.getElementById('form-YoungJoonYooDynamicGraphGeneration').submit();\">YoungJoon Yoo</a>,\n</form>\n<form id=\"form-Jee-SooKimDynamicGraphGeneration\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jee-Soo Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jee-SooKimDynamicGraphGeneration').submit();\">Jee-Soo Kim</a>,\n</form>\n<form id=\"form-SangKukLeeDynamicGraphGeneration\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"SangKuk Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-SangKukLeeDynamicGraphGeneration').submit();\">SangKuk Lee</a>,\n</form>\n<form id=\"form-NojunKwakDynamicGraphGeneration\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nojun Kwak\">\n<a href=\"#\" onclick=\"document.getElementById('form-NojunKwakDynamicGraphGeneration').submit();\">Nojun Kwak</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kim_Dynamic_Graph_Generation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2764-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.09528\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kim_2018_CVPR,<br>\nauthor = {Kim, Daesik and Yoo, YoungJoon and Kim, Jee-Soo and Lee, SangKuk and Kwak, Nojun},<br>\ntitle = {Dynamic Graph Generation Network: Generating Relational Knowledge From Diagrams},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Roveri_A_Network_Architecture_CVPR_2018_paper.html\">A Network Architecture for Point Cloud Classification via Automatic Depth Images Generation</a></dt>\n<dd>\n<form id=\"form-RiccardoRoveriANetworkArchitecture\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Riccardo Roveri\">\n<a href=\"#\" onclick=\"document.getElementById('form-RiccardoRoveriANetworkArchitecture').submit();\">Riccardo Roveri</a>,\n</form>\n<form id=\"form-LukasRahmannANetworkArchitecture\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lukas Rahmann\">\n<a href=\"#\" onclick=\"document.getElementById('form-LukasRahmannANetworkArchitecture').submit();\">Lukas Rahmann</a>,\n</form>\n<form id=\"form-CengizOztireliANetworkArchitecture\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cengiz Oztireli\">\n<a href=\"#\" onclick=\"document.getElementById('form-CengizOztireliANetworkArchitecture').submit();\">Cengiz Oztireli</a>,\n</form>\n<form id=\"form-MarkusGrossANetworkArchitecture\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Markus Gross\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarkusGrossANetworkArchitecture').submit();\">Markus Gross</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Roveri_A_Network_Architecture_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3120-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Roveri_2018_CVPR,<br>\nauthor = {Roveri, Riccardo and Rahmann, Lukas and Oztireli, Cengiz and Gross, Markus},<br>\ntitle = {A Network Architecture for Point Cloud Classification via Automatic Depth Images Generation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Bozek_Towards_Dense_Object_CVPR_2018_paper.html\">Towards Dense Object Tracking in a 2D Honeybee Hive</a></dt>\n<dd>\n<form id=\"form-KatarzynaBozekTowardsDenseObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Katarzyna Bozek\">\n<a href=\"#\" onclick=\"document.getElementById('form-KatarzynaBozekTowardsDenseObject').submit();\">Katarzyna Bozek</a>,\n</form>\n<form id=\"form-LaetitiaHebertTowardsDenseObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Laetitia Hebert\">\n<a href=\"#\" onclick=\"document.getElementById('form-LaetitiaHebertTowardsDenseObject').submit();\">Laetitia Hebert</a>,\n</form>\n<form id=\"form-AlexanderS.TowardsDenseObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexander S. Mikheyev\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexanderS.TowardsDenseObject').submit();\">Alexander S. Mikheyev</a>,\n</form>\n<form id=\"form-GregJ.TowardsDenseObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Greg J. Stephens\">\n<a href=\"#\" onclick=\"document.getElementById('form-GregJ.TowardsDenseObject').submit();\">Greg J. Stephens</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Bozek_Towards_Dense_Object_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3583-supp.zip\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.08324\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Bozek_2018_CVPR,<br>\nauthor = {Bozek, Katarzyna and Hebert, Laetitia and Mikheyev, Alexander S. and Stephens, Greg J.},<br>\ntitle = {Towards Dense Object Tracking in a 2D Honeybee Hive},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Bhattacharyya_Long-Term_On-Board_Prediction_CVPR_2018_paper.html\">Long-Term On-Board Prediction of People in Traffic Scenes Under Uncertainty</a></dt>\n<dd>\n<form id=\"form-ApratimBhattacharyyaLongTermOnBoardPrediction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Apratim Bhattacharyya\">\n<a href=\"#\" onclick=\"document.getElementById('form-ApratimBhattacharyyaLongTermOnBoardPrediction').submit();\">Apratim Bhattacharyya</a>,\n</form>\n<form id=\"form-MarioFritzLongTermOnBoardPrediction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mario Fritz\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarioFritzLongTermOnBoardPrediction').submit();\">Mario Fritz</a>,\n</form>\n<form id=\"form-BerntSchieleLongTermOnBoardPrediction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bernt Schiele\">\n<a href=\"#\" onclick=\"document.getElementById('form-BerntSchieleLongTermOnBoardPrediction').submit();\">Bernt Schiele</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Bhattacharyya_Long-Term_On-Board_Prediction_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3887-supp.zip\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.09026\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Bhattacharyya_2018_CVPR,<br>\nauthor = {Bhattacharyya, Apratim and Fritz, Mario and Schiele, Bernt},<br>\ntitle = {Long-Term On-Board Prediction of People in Traffic Scenes Under Uncertainty},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Single-Shot_Refinement_Neural_CVPR_2018_paper.html\">Single-Shot Refinement Neural Network for Object Detection</a></dt>\n<dd>\n<form id=\"form-ShifengZhangSingleShotRefinementNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shifeng Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShifengZhangSingleShotRefinementNeural').submit();\">Shifeng Zhang</a>,\n</form>\n<form id=\"form-LongyinWenSingleShotRefinementNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Longyin Wen\">\n<a href=\"#\" onclick=\"document.getElementById('form-LongyinWenSingleShotRefinementNeural').submit();\">Longyin Wen</a>,\n</form>\n<form id=\"form-XiaoBianSingleShotRefinementNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiao Bian\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaoBianSingleShotRefinementNeural').submit();\">Xiao Bian</a>,\n</form>\n<form id=\"form-ZhenLeiSingleShotRefinementNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhen Lei\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhenLeiSingleShotRefinementNeural').submit();\">Zhen Lei</a>,\n</form>\n<form id=\"form-StanZ.SingleShotRefinementNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stan Z. Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-StanZ.SingleShotRefinementNeural').submit();\">Stan Z. Li</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Single-Shot_Refinement_Neural_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0005-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.06897\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Shifeng and Wen, Longyin and Bian, Xiao and Lei, Zhen and Li, Stan Z.},<br>\ntitle = {Single-Shot Refinement Neural Network for Object Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Video_Captioning_via_CVPR_2018_paper.html\">Video Captioning via Hierarchical Reinforcement Learning</a></dt>\n<dd>\n<form id=\"form-XinWangVideoCaptioningvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xin Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinWangVideoCaptioningvia').submit();\">Xin Wang</a>,\n</form>\n<form id=\"form-WenhuChenVideoCaptioningvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenhu Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenhuChenVideoCaptioningvia').submit();\">Wenhu Chen</a>,\n</form>\n<form id=\"form-JiaweiWuVideoCaptioningvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiawei Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiaweiWuVideoCaptioningvia').submit();\">Jiawei Wu</a>,\n</form>\n<form id=\"form-Yuan-FangWangVideoCaptioningvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuan-Fang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yuan-FangWangVideoCaptioningvia').submit();\">Yuan-Fang Wang</a>,\n</form>\n<form id=\"form-WilliamYangVideoCaptioningvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"William Yang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WilliamYangVideoCaptioningvia').submit();\">William Yang Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Video_Captioning_via_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0007-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.11135\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Xin and Chen, Wenhu and Wu, Jiawei and Wang, Yuan-Fang and Yang Wang, William},<br>\ntitle = {Video Captioning via Hierarchical Reinforcement Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Teney_Tips_and_Tricks_CVPR_2018_paper.html\">Tips and Tricks for Visual Question Answering: Learnings From the 2017 Challenge</a></dt>\n<dd>\n<form id=\"form-DamienTeneyTipsandTricks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Damien Teney\">\n<a href=\"#\" onclick=\"document.getElementById('form-DamienTeneyTipsandTricks').submit();\">Damien Teney</a>,\n</form>\n<form id=\"form-PeterAndersonTipsandTricks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peter Anderson\">\n<a href=\"#\" onclick=\"document.getElementById('form-PeterAndersonTipsandTricks').submit();\">Peter Anderson</a>,\n</form>\n<form id=\"form-XiaodongHeTipsandTricks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaodong He\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaodongHeTipsandTricks').submit();\">Xiaodong He</a>,\n</form>\n<form id=\"form-AntonvanTipsandTricks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anton van den Hengel\">\n<a href=\"#\" onclick=\"document.getElementById('form-AntonvanTipsandTricks').submit();\">Anton van den Hengel</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Teney_Tips_and_Tricks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0021-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1708.02711\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Teney_2018_CVPR,<br>\nauthor = {Teney, Damien and Anderson, Peter and He, Xiaodong and van den Hengel, Anton},<br>\ntitle = {Tips and Tricks for Visual Question Answering: Learnings From the 2017 Challenge},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hu_Learning_to_Segment_CVPR_2018_paper.html\">Learning to Segment Every Thing</a></dt>\n<dd>\n<form id=\"form-RonghangHuLearningtoSegment\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ronghang Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-RonghangHuLearningtoSegment').submit();\">Ronghang Hu</a>,\n</form>\n<form id=\"form-PiotrDoll\u00c3\u00a1rLearningtoSegment\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Piotr Doll\u00c3\u00a1r\">\n<a href=\"#\" onclick=\"document.getElementById('form-PiotrDoll\u00c3\u00a1rLearningtoSegment').submit();\">Piotr Doll\u00c3\u00a1r</a>,\n</form>\n<form id=\"form-KaimingHeLearningtoSegment\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kaiming He\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaimingHeLearningtoSegment').submit();\">Kaiming He</a>,\n</form>\n<form id=\"form-TrevorDarrellLearningtoSegment\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Trevor Darrell\">\n<a href=\"#\" onclick=\"document.getElementById('form-TrevorDarrellLearningtoSegment').submit();\">Trevor Darrell</a>,\n</form>\n<form id=\"form-RossGirshickLearningtoSegment\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ross Girshick\">\n<a href=\"#\" onclick=\"document.getElementById('form-RossGirshickLearningtoSegment').submit();\">Ross Girshick</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hu_Learning_to_Segment_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0047-supp.zip\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.10370\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hu_2018_CVPR,<br>\nauthor = {Hu, Ronghang and Doll\u00c3\u00a1r, Piotr and He, Kaiming and Darrell, Trevor and Girshick, Ross},<br>\ntitle = {Learning to Segment Every Thing},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Self-Supervised_Adversarial_Hashing_CVPR_2018_paper.html\">Self-Supervised Adversarial Hashing Networks for Cross-Modal Retrieval</a></dt>\n<dd>\n<form id=\"form-ChaoLiSelfSupervisedAdversarialHashing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chao Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChaoLiSelfSupervisedAdversarialHashing').submit();\">Chao Li</a>,\n</form>\n<form id=\"form-ChengDengSelfSupervisedAdversarialHashing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cheng Deng\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChengDengSelfSupervisedAdversarialHashing').submit();\">Cheng Deng</a>,\n</form>\n<form id=\"form-NingLiSelfSupervisedAdversarialHashing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ning Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-NingLiSelfSupervisedAdversarialHashing').submit();\">Ning Li</a>,\n</form>\n<form id=\"form-WeiLiuSelfSupervisedAdversarialHashing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiLiuSelfSupervisedAdversarialHashing').submit();\">Wei Liu</a>,\n</form>\n<form id=\"form-XinboGaoSelfSupervisedAdversarialHashing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xinbo Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinboGaoSelfSupervisedAdversarialHashing').submit();\">Xinbo Gao</a>,\n</form>\n<form id=\"form-DachengTaoSelfSupervisedAdversarialHashing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dacheng Tao\">\n<a href=\"#\" onclick=\"document.getElementById('form-DachengTaoSelfSupervisedAdversarialHashing').submit();\">Dacheng Tao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Self-Supervised_Adversarial_Hashing_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.01223\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Chao and Deng, Cheng and Li, Ning and Liu, Wei and Gao, Xinbo and Tao, Dacheng},<br>\ntitle = {Self-Supervised Adversarial Hashing Networks for Cross-Modal Retrieval},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhuang_Parallel_Attention_A_CVPR_2018_paper.html\">Parallel Attention: A Unified Framework for Visual Object Discovery Through Dialogs and Queries</a></dt>\n<dd>\n<form id=\"form-BohanZhuangParallelAttentionA\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bohan Zhuang\">\n<a href=\"#\" onclick=\"document.getElementById('form-BohanZhuangParallelAttentionA').submit();\">Bohan Zhuang</a>,\n</form>\n<form id=\"form-QiWuParallelAttentionA\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qi Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiWuParallelAttentionA').submit();\">Qi Wu</a>,\n</form>\n<form id=\"form-ChunhuaShenParallelAttentionA\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chunhua Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChunhuaShenParallelAttentionA').submit();\">Chunhua Shen</a>,\n</form>\n<form id=\"form-IanReidParallelAttentionA\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ian Reid\">\n<a href=\"#\" onclick=\"document.getElementById('form-IanReidParallelAttentionA').submit();\">Ian Reid</a>,\n</form>\n<form id=\"form-AntonvanParallelAttentionA\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anton van den Hengel\">\n<a href=\"#\" onclick=\"document.getElementById('form-AntonvanParallelAttentionA').submit();\">Anton van den Hengel</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhuang_Parallel_Attention_A_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.06370\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhuang_2018_CVPR,<br>\nauthor = {Zhuang, Bohan and Wu, Qi and Shen, Chunhua and Reid, Ian and van den Hengel, Anton},<br>\ntitle = {Parallel Attention: A Unified Framework for Visual Object Discovery Through Dialogs and Queries},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Zigzag_Learning_for_CVPR_2018_paper.html\">Zigzag Learning for Weakly Supervised Object Detection</a></dt>\n<dd>\n<form id=\"form-XiaopengZhangZigzagLearningfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaopeng Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaopengZhangZigzagLearningfor').submit();\">Xiaopeng Zhang</a>,\n</form>\n<form id=\"form-JiashiFengZigzagLearningfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiashi Feng\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiashiFengZigzagLearningfor').submit();\">Jiashi Feng</a>,\n</form>\n<form id=\"form-HongkaiXiongZigzagLearningfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hongkai Xiong\">\n<a href=\"#\" onclick=\"document.getElementById('form-HongkaiXiongZigzagLearningfor').submit();\">Hongkai Xiong</a>,\n</form>\n<form id=\"form-QiTianZigzagLearningfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qi Tian\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiTianZigzagLearningfor').submit();\">Qi Tian</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Zigzag_Learning_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.09466\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Xiaopeng and Feng, Jiashi and Xiong, Hongkai and Tian, Qi},<br>\ntitle = {Zigzag Learning for Weakly Supervised Object Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Attentive_Fashion_Grammar_CVPR_2018_paper.html\">Attentive Fashion Grammar Network for Fashion Landmark Detection and Clothing Category Classification</a></dt>\n<dd>\n<form id=\"form-WenguanWangAttentiveFashionGrammar\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenguan Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenguanWangAttentiveFashionGrammar').submit();\">Wenguan Wang</a>,\n</form>\n<form id=\"form-YuanluXuAttentiveFashionGrammar\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuanlu Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuanluXuAttentiveFashionGrammar').submit();\">Yuanlu Xu</a>,\n</form>\n<form id=\"form-JianbingShenAttentiveFashionGrammar\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianbing Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianbingShenAttentiveFashionGrammar').submit();\">Jianbing Shen</a>,\n</form>\n<form id=\"form-Song-ChunZhuAttentiveFashionGrammar\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Song-Chun Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Song-ChunZhuAttentiveFashionGrammar').submit();\">Song-Chun Zhu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Attentive_Fashion_Grammar_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Wenguan and Xu, Yuanlu and Shen, Jianbing and Zhu, Song-Chun},<br>\ntitle = {Attentive Fashion Grammar Network for Fashion Landmark Detection and Clothing Category Classification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Verma_Generalized_Zero-Shot_Learning_CVPR_2018_paper.html\">Generalized Zero-Shot Learning via Synthesized Examples</a></dt>\n<dd>\n<form id=\"form-VinayKumarGeneralizedZeroShotLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vinay Kumar Verma\">\n<a href=\"#\" onclick=\"document.getElementById('form-VinayKumarGeneralizedZeroShotLearning').submit();\">Vinay Kumar Verma</a>,\n</form>\n<form id=\"form-GundeepAroraGeneralizedZeroShotLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gundeep Arora\">\n<a href=\"#\" onclick=\"document.getElementById('form-GundeepAroraGeneralizedZeroShotLearning').submit();\">Gundeep Arora</a>,\n</form>\n<form id=\"form-AshishMishraGeneralizedZeroShotLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ashish Mishra\">\n<a href=\"#\" onclick=\"document.getElementById('form-AshishMishraGeneralizedZeroShotLearning').submit();\">Ashish Mishra</a>,\n</form>\n<form id=\"form-PiyushRaiGeneralizedZeroShotLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Piyush Rai\">\n<a href=\"#\" onclick=\"document.getElementById('form-PiyushRaiGeneralizedZeroShotLearning').submit();\">Piyush Rai</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Verma_Generalized_Zero-Shot_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.03878\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Verma_2018_CVPR,<br>\nauthor = {Kumar Verma, Vinay and Arora, Gundeep and Mishra, Ashish and Rai, Piyush},<br>\ntitle = {Generalized Zero-Shot Learning via Synthesized Examples},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Cao_Partially_Shared_Multi-Task_CVPR_2018_paper.html\">Partially Shared Multi-Task Convolutional Neural Network With Local Constraint for Face Attribute Learning</a></dt>\n<dd>\n<form id=\"form-JiajiongCaoPartiallySharedMultiTask\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiajiong Cao\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiajiongCaoPartiallySharedMultiTask').submit();\">Jiajiong Cao</a>,\n</form>\n<form id=\"form-YingmingLiPartiallySharedMultiTask\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yingming Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-YingmingLiPartiallySharedMultiTask').submit();\">Yingming Li</a>,\n</form>\n<form id=\"form-ZhongfeiZhangPartiallySharedMultiTask\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhongfei Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhongfeiZhangPartiallySharedMultiTask').submit();\">Zhongfei Zhang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Cao_Partially_Shared_Multi-Task_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Cao_2018_CVPR,<br>\nauthor = {Cao, Jiajiong and Li, Yingming and Zhang, Zhongfei},<br>\ntitle = {Partially Shared Multi-Task Convolutional Neural Network With Local Constraint for Face Attribute Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Faraone_SYQ_Learning_Symmetric_CVPR_2018_paper.html\">SYQ: Learning Symmetric Quantization for Efficient Deep Neural Networks</a></dt>\n<dd>\n<form id=\"form-JulianFaraoneSYQLearningSymmetric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Julian Faraone\">\n<a href=\"#\" onclick=\"document.getElementById('form-JulianFaraoneSYQLearningSymmetric').submit();\">Julian Faraone</a>,\n</form>\n<form id=\"form-NicholasFraserSYQLearningSymmetric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nicholas Fraser\">\n<a href=\"#\" onclick=\"document.getElementById('form-NicholasFraserSYQLearningSymmetric').submit();\">Nicholas Fraser</a>,\n</form>\n<form id=\"form-MichaelaBlottSYQLearningSymmetric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michaela Blott\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichaelaBlottSYQLearningSymmetric').submit();\">Michaela Blott</a>,\n</form>\n<form id=\"form-PhilipH.W.SYQLearningSymmetric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Philip H.W. Leong\">\n<a href=\"#\" onclick=\"document.getElementById('form-PhilipH.W.SYQLearningSymmetric').submit();\">Philip H.W. Leong</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Faraone_SYQ_Learning_Symmetric_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1807.00301\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Faraone_2018_CVPR,<br>\nauthor = {Faraone, Julian and Fraser, Nicholas and Blott, Michaela and Leong, Philip H.W.},<br>\ntitle = {SYQ: Learning Symmetric Quantization for Efficient Deep Neural Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Bernard_DS_Tighter_Lifting-Free_CVPR_2018_paper.html\">DS*: Tighter Lifting-Free Convex Relaxations for Quadratic Matching Problems</a></dt>\n<dd>\n<form id=\"form-FlorianBernardDSTighterLiftingFree\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Florian Bernard\">\n<a href=\"#\" onclick=\"document.getElementById('form-FlorianBernardDSTighterLiftingFree').submit();\">Florian Bernard</a>,\n</form>\n<form id=\"form-ChristianTheobaltDSTighterLiftingFree\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Christian Theobalt\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChristianTheobaltDSTighterLiftingFree').submit();\">Christian Theobalt</a>,\n</form>\n<form id=\"form-MichaelMoellerDSTighterLiftingFree\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michael Moeller\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichaelMoellerDSTighterLiftingFree').submit();\">Michael Moeller</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Bernard_DS_Tighter_Lifting-Free_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0083-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Bernard_2018_CVPR,<br>\nauthor = {Bernard, Florian and Theobalt, Christian and Moeller, Michael},<br>\ntitle = {DS*: Tighter Lifting-Free Convex Relaxations for Quadratic Matching Problems},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Deep_Mutual_Learning_CVPR_2018_paper.html\">Deep Mutual Learning</a></dt>\n<dd>\n<form id=\"form-YingZhangDeepMutualLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ying Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YingZhangDeepMutualLearning').submit();\">Ying Zhang</a>,\n</form>\n<form id=\"form-TaoXiangDeepMutualLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tao Xiang\">\n<a href=\"#\" onclick=\"document.getElementById('form-TaoXiangDeepMutualLearning').submit();\">Tao Xiang</a>,\n</form>\n<form id=\"form-TimothyM.DeepMutualLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Timothy M. Hospedales\">\n<a href=\"#\" onclick=\"document.getElementById('form-TimothyM.DeepMutualLearning').submit();\">Timothy M. Hospedales</a>,\n</form>\n<form id=\"form-HuchuanLuDeepMutualLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huchuan Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuchuanLuDeepMutualLearning').submit();\">Huchuan Lu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Deep_Mutual_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1706.00384\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Ying and Xiang, Tao and Hospedales, Timothy M. and Lu, Huchuan},<br>\ntitle = {Deep Mutual Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_Coupled_End-to-End_Transfer_CVPR_2018_paper.html\">Coupled End-to-End Transfer Learning With Generalized Fisher Information</a></dt>\n<dd>\n<form id=\"form-ShixingChenCoupledEndtoEndTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shixing Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShixingChenCoupledEndtoEndTransfer').submit();\">Shixing Chen</a>,\n</form>\n<form id=\"form-CaojinZhangCoupledEndtoEndTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Caojin Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-CaojinZhangCoupledEndtoEndTransfer').submit();\">Caojin Zhang</a>,\n</form>\n<form id=\"form-MingDongCoupledEndtoEndTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming Dong\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingDongCoupledEndtoEndTransfer').submit();\">Ming Dong</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_Coupled_End-to-End_Transfer_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0588-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Shixing and Zhang, Caojin and Dong, Ming},<br>\ntitle = {Coupled End-to-End Transfer Learning With Generalized Fisher Information},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Rozantsev_Residual_Parameter_Transfer_CVPR_2018_paper.html\">Residual Parameter Transfer for Deep Domain Adaptation</a></dt>\n<dd>\n<form id=\"form-ArtemRozantsevResidualParameterTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Artem Rozantsev\">\n<a href=\"#\" onclick=\"document.getElementById('form-ArtemRozantsevResidualParameterTransfer').submit();\">Artem Rozantsev</a>,\n</form>\n<form id=\"form-MathieuSalzmannResidualParameterTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mathieu Salzmann\">\n<a href=\"#\" onclick=\"document.getElementById('form-MathieuSalzmannResidualParameterTransfer').submit();\">Mathieu Salzmann</a>,\n</form>\n<form id=\"form-PascalFuaResidualParameterTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pascal Fua\">\n<a href=\"#\" onclick=\"document.getElementById('form-PascalFuaResidualParameterTransfer').submit();\">Pascal Fua</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Rozantsev_Residual_Parameter_Transfer_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0963-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.07714\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Rozantsev_2018_CVPR,<br>\nauthor = {Rozantsev, Artem and Salzmann, Mathieu and Fua, Pascal},<br>\ntitle = {Residual Parameter Transfer for Deep Domain Adaptation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kim_High-Order_Tensor_Regularization_CVPR_2018_paper.html\">High-Order Tensor Regularization With Application to Attribute Ranking</a></dt>\n<dd>\n<form id=\"form-KwangInHighOrderTensorRegularization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kwang In Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-KwangInHighOrderTensorRegularization').submit();\">Kwang In Kim</a>,\n</form>\n<form id=\"form-JuhyunParkHighOrderTensorRegularization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Juhyun Park\">\n<a href=\"#\" onclick=\"document.getElementById('form-JuhyunParkHighOrderTensorRegularization').submit();\">Juhyun Park</a>,\n</form>\n<form id=\"form-JamesTompkinHighOrderTensorRegularization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"James Tompkin\">\n<a href=\"#\" onclick=\"document.getElementById('form-JamesTompkinHighOrderTensorRegularization').submit();\">James Tompkin</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kim_High-Order_Tensor_Regularization_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1126-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kim_2018_CVPR,<br>\nauthor = {In Kim, Kwang and Park, Juhyun and Tompkin, James},<br>\ntitle = {High-Order Tensor Regularization With Application to Attribute Ranking},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Senocak_Learning_to_Localize_CVPR_2018_paper.html\">Learning to Localize Sound Source in Visual Scenes</a></dt>\n<dd>\n<form id=\"form-ArdaSenocakLearningtoLocalize\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Arda Senocak\">\n<a href=\"#\" onclick=\"document.getElementById('form-ArdaSenocakLearningtoLocalize').submit();\">Arda Senocak</a>,\n</form>\n<form id=\"form-Tae-HyunOhLearningtoLocalize\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tae-Hyun Oh\">\n<a href=\"#\" onclick=\"document.getElementById('form-Tae-HyunOhLearningtoLocalize').submit();\">Tae-Hyun Oh</a>,\n</form>\n<form id=\"form-JunsikKimLearningtoLocalize\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junsik Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunsikKimLearningtoLocalize').submit();\">Junsik Kim</a>,\n</form>\n<form id=\"form-Ming-HsuanYangLearningtoLocalize\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming-Hsuan Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ming-HsuanYangLearningtoLocalize').submit();\">Ming-Hsuan Yang</a>,\n</form>\n<form id=\"form-InSoLearningtoLocalize\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"In So Kweon\">\n<a href=\"#\" onclick=\"document.getElementById('form-InSoLearningtoLocalize').submit();\">In So Kweon</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Senocak_Learning_to_Localize_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1294-supp.zip\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.03849\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Senocak_2018_CVPR,<br>\nauthor = {Senocak, Arda and Oh, Tae-Hyun and Kim, Junsik and Yang, Ming-Hsuan and So Kweon, In},<br>\ntitle = {Learning to Localize Sound Source in Visual Scenes},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Gidaris_Dynamic_Few-Shot_Visual_CVPR_2018_paper.html\">Dynamic Few-Shot Visual Learning Without Forgetting</a></dt>\n<dd>\n<form id=\"form-SpyrosGidarisDynamicFewShotVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Spyros Gidaris\">\n<a href=\"#\" onclick=\"document.getElementById('form-SpyrosGidarisDynamicFewShotVisual').submit();\">Spyros Gidaris</a>,\n</form>\n<form id=\"form-NikosKomodakisDynamicFewShotVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nikos Komodakis\">\n<a href=\"#\" onclick=\"document.getElementById('form-NikosKomodakisDynamicFewShotVisual').submit();\">Nikos Komodakis</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Gidaris_Dynamic_Few-Shot_Visual_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1296-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.09458\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Gidaris_2018_CVPR,<br>\nauthor = {Gidaris, Spyros and Komodakis, Nikos},<br>\ntitle = {Dynamic Few-Shot Visual Learning Without Forgetting},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Two-Step_Quantization_for_CVPR_2018_paper.html\">Two-Step Quantization for Low-Bit Neural Networks</a></dt>\n<dd>\n<form id=\"form-PeisongWangTwoStepQuantizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peisong Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-PeisongWangTwoStepQuantizationfor').submit();\">Peisong Wang</a>,\n</form>\n<form id=\"form-QinghaoHuTwoStepQuantizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qinghao Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-QinghaoHuTwoStepQuantizationfor').submit();\">Qinghao Hu</a>,\n</form>\n<form id=\"form-YifanZhangTwoStepQuantizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yifan Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YifanZhangTwoStepQuantizationfor').submit();\">Yifan Zhang</a>,\n</form>\n<form id=\"form-ChunjieZhangTwoStepQuantizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chunjie Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChunjieZhangTwoStepQuantizationfor').submit();\">Chunjie Zhang</a>,\n</form>\n<form id=\"form-YangLiuTwoStepQuantizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yang Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YangLiuTwoStepQuantizationfor').submit();\">Yang Liu</a>,\n</form>\n<form id=\"form-JianChengTwoStepQuantizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jian Cheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianChengTwoStepQuantizationfor').submit();\">Jian Cheng</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Two-Step_Quantization_for_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Peisong and Hu, Qinghao and Zhang, Yifan and Zhang, Chunjie and Liu, Yang and Cheng, Jian},<br>\ntitle = {Two-Step Quantization for Low-Bit Neural Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Johnston_Improved_Lossy_Image_CVPR_2018_paper.html\">Improved Lossy Image Compression With Priming and Spatially Adaptive Bit Rates for Recurrent Networks</a></dt>\n<dd>\n<form id=\"form-NickJohnstonImprovedLossyImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nick Johnston\">\n<a href=\"#\" onclick=\"document.getElementById('form-NickJohnstonImprovedLossyImage').submit();\">Nick Johnston</a>,\n</form>\n<form id=\"form-DamienVincentImprovedLossyImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Damien Vincent\">\n<a href=\"#\" onclick=\"document.getElementById('form-DamienVincentImprovedLossyImage').submit();\">Damien Vincent</a>,\n</form>\n<form id=\"form-DavidMinnenImprovedLossyImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"David Minnen\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavidMinnenImprovedLossyImage').submit();\">David Minnen</a>,\n</form>\n<form id=\"form-MicheleCovellImprovedLossyImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michele Covell\">\n<a href=\"#\" onclick=\"document.getElementById('form-MicheleCovellImprovedLossyImage').submit();\">Michele Covell</a>,\n</form>\n<form id=\"form-SaurabhSinghImprovedLossyImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Saurabh Singh\">\n<a href=\"#\" onclick=\"document.getElementById('form-SaurabhSinghImprovedLossyImage').submit();\">Saurabh Singh</a>,\n</form>\n<form id=\"form-TroyChinenImprovedLossyImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Troy Chinen\">\n<a href=\"#\" onclick=\"document.getElementById('form-TroyChinenImprovedLossyImage').submit();\">Troy Chinen</a>,\n</form>\n<form id=\"form-SungJinImprovedLossyImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sung Jin Hwang\">\n<a href=\"#\" onclick=\"document.getElementById('form-SungJinImprovedLossyImage').submit();\">Sung Jin Hwang</a>,\n</form>\n<form id=\"form-JoelShorImprovedLossyImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Joel Shor\">\n<a href=\"#\" onclick=\"document.getElementById('form-JoelShorImprovedLossyImage').submit();\">Joel Shor</a>,\n</form>\n<form id=\"form-GeorgeTodericiImprovedLossyImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"George Toderici\">\n<a href=\"#\" onclick=\"document.getElementById('form-GeorgeTodericiImprovedLossyImage').submit();\">George Toderici</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Johnston_Improved_Lossy_Image_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1904-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1703.10114\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Johnston_2018_CVPR,<br>\nauthor = {Johnston, Nick and Vincent, Damien and Minnen, David and Covell, Michele and Singh, Saurabh and Chinen, Troy and Jin Hwang, Sung and Shor, Joel and Toderici, George},<br>\ntitle = {Improved Lossy Image Compression With Priming and Spatially Adaptive Bit Rates for Recurrent Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Mentzer_Conditional_Probability_Models_CVPR_2018_paper.html\">Conditional Probability Models for Deep Image Compression</a></dt>\n<dd>\n<form id=\"form-FabianMentzerConditionalProbabilityModels\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fabian Mentzer\">\n<a href=\"#\" onclick=\"document.getElementById('form-FabianMentzerConditionalProbabilityModels').submit();\">Fabian Mentzer</a>,\n</form>\n<form id=\"form-EirikurAgustssonConditionalProbabilityModels\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Eirikur Agustsson\">\n<a href=\"#\" onclick=\"document.getElementById('form-EirikurAgustssonConditionalProbabilityModels').submit();\">Eirikur Agustsson</a>,\n</form>\n<form id=\"form-MichaelTschannenConditionalProbabilityModels\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michael Tschannen\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichaelTschannenConditionalProbabilityModels').submit();\">Michael Tschannen</a>,\n</form>\n<form id=\"form-RaduTimofteConditionalProbabilityModels\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Radu Timofte\">\n<a href=\"#\" onclick=\"document.getElementById('form-RaduTimofteConditionalProbabilityModels').submit();\">Radu Timofte</a>,\n</form>\n<form id=\"form-LucVanConditionalProbabilityModels\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Luc Van Gool\">\n<a href=\"#\" onclick=\"document.getElementById('form-LucVanConditionalProbabilityModels').submit();\">Luc Van Gool</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Mentzer_Conditional_Probability_Models_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2172-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.04260\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Mentzer_2018_CVPR,<br>\nauthor = {Mentzer, Fabian and Agustsson, Eirikur and Tschannen, Michael and Timofte, Radu and Van Gool, Luc},<br>\ntitle = {Conditional Probability Models for Deep Image Compression},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Detlefsen_Deep_Diffeomorphic_Transformer_CVPR_2018_paper.html\">Deep Diffeomorphic Transformer Networks</a></dt>\n<dd>\n<form id=\"form-NickiSkafteDeepDiffeomorphicTransformer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nicki Skafte Detlefsen\">\n<a href=\"#\" onclick=\"document.getElementById('form-NickiSkafteDeepDiffeomorphicTransformer').submit();\">Nicki Skafte Detlefsen</a>,\n</form>\n<form id=\"form-OrenFreifeldDeepDiffeomorphicTransformer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Oren Freifeld\">\n<a href=\"#\" onclick=\"document.getElementById('form-OrenFreifeldDeepDiffeomorphicTransformer').submit();\">Oren Freifeld</a>,\n</form>\n<form id=\"form-S\u00c3\u00b8renHaubergDeepDiffeomorphicTransformer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"S\u00c3\u00b8ren Hauberg\">\n<a href=\"#\" onclick=\"document.getElementById('form-S\u00c3\u00b8renHaubergDeepDiffeomorphicTransformer').submit();\">S\u00c3\u00b8ren Hauberg</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Detlefsen_Deep_Diffeomorphic_Transformer_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2257-supp.zip\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Detlefsen_2018_CVPR,<br>\nauthor = {Skafte Detlefsen, Nicki and Freifeld, Oren and Hauberg, S\u00c3\u00b8ren},<br>\ntitle = {Deep Diffeomorphic Transformer Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Berman_The_LovaSz-Softmax_Loss_CVPR_2018_paper.html\">The Lov\u00c3\u00a1sz-Softmax Loss: A Tractable Surrogate for the Optimization of the Intersection-Over-Union Measure in Neural Networks</a></dt>\n<dd>\n<form id=\"form-MaximBermanTheLovszSoftmaxLoss\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Maxim Berman\">\n<a href=\"#\" onclick=\"document.getElementById('form-MaximBermanTheLovszSoftmaxLoss').submit();\">Maxim Berman</a>,\n</form>\n<form id=\"form-AmalRannenTheLovszSoftmaxLoss\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Amal Rannen Triki\">\n<a href=\"#\" onclick=\"document.getElementById('form-AmalRannenTheLovszSoftmaxLoss').submit();\">Amal Rannen Triki</a>,\n</form>\n<form id=\"form-MatthewB.TheLovszSoftmaxLoss\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Matthew B. Blaschko\">\n<a href=\"#\" onclick=\"document.getElementById('form-MatthewB.TheLovszSoftmaxLoss').submit();\">Matthew B. Blaschko</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Berman_The_LovaSz-Softmax_Loss_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2291-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Berman_2018_CVPR,<br>\nauthor = {Berman, Maxim and Rannen Triki, Amal and Blaschko, Matthew B.},<br>\ntitle = {The Lov\u00c3\u00a1sz-Softmax Loss: A Tractable Surrogate for the Optimization of the Intersection-Over-Union Measure in Neural Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Poursaeed_Generative_Adversarial_Perturbations_CVPR_2018_paper.html\">Generative Adversarial Perturbations</a></dt>\n<dd>\n<form id=\"form-OmidPoursaeedGenerativeAdversarialPerturbations\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Omid Poursaeed\">\n<a href=\"#\" onclick=\"document.getElementById('form-OmidPoursaeedGenerativeAdversarialPerturbations').submit();\">Omid Poursaeed</a>,\n</form>\n<form id=\"form-IsayKatsmanGenerativeAdversarialPerturbations\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Isay Katsman\">\n<a href=\"#\" onclick=\"document.getElementById('form-IsayKatsmanGenerativeAdversarialPerturbations').submit();\">Isay Katsman</a>,\n</form>\n<form id=\"form-BichengGaoGenerativeAdversarialPerturbations\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bicheng Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-BichengGaoGenerativeAdversarialPerturbations').submit();\">Bicheng Gao</a>,\n</form>\n<form id=\"form-SergeBelongieGenerativeAdversarialPerturbations\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Serge Belongie\">\n<a href=\"#\" onclick=\"document.getElementById('form-SergeBelongieGenerativeAdversarialPerturbations').submit();\">Serge Belongie</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Poursaeed_Generative_Adversarial_Perturbations_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2387-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.02328\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Poursaeed_2018_CVPR,<br>\nauthor = {Poursaeed, Omid and Katsman, Isay and Gao, Bicheng and Belongie, Serge},<br>\ntitle = {Generative Adversarial Perturbations},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yu_Learning_Strict_Identity_CVPR_2018_paper.html\">Learning Strict Identity Mappings in Deep Residual Networks</a></dt>\n<dd>\n<form id=\"form-XinYuLearningStrictIdentity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xin Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinYuLearningStrictIdentity').submit();\">Xin Yu</a>,\n</form>\n<form id=\"form-ZhidingYuLearningStrictIdentity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhiding Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhidingYuLearningStrictIdentity').submit();\">Zhiding Yu</a>,\n</form>\n<form id=\"form-SrikumarRamalingamLearningStrictIdentity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Srikumar Ramalingam\">\n<a href=\"#\" onclick=\"document.getElementById('form-SrikumarRamalingamLearningStrictIdentity').submit();\">Srikumar Ramalingam</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yu_Learning_Strict_Identity_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.01661\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yu_2018_CVPR,<br>\nauthor = {Yu, Xin and Yu, Zhiding and Ramalingam, Srikumar},<br>\ntitle = {Learning Strict Identity Mappings in Deep Residual Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kanbak_Geometric_Robustness_of_CVPR_2018_paper.html\">Geometric Robustness of Deep Networks: Analysis and Improvement</a></dt>\n<dd>\n<form id=\"form-CanKanbakGeometricRobustnessof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Can Kanbak\">\n<a href=\"#\" onclick=\"document.getElementById('form-CanKanbakGeometricRobustnessof').submit();\">Can Kanbak</a>,\n</form>\n<form id=\"form-Seyed-MohsenMoosavi-DezfooliGeometricRobustnessof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Seyed-Mohsen Moosavi-Dezfooli\">\n<a href=\"#\" onclick=\"document.getElementById('form-Seyed-MohsenMoosavi-DezfooliGeometricRobustnessof').submit();\">Seyed-Mohsen Moosavi-Dezfooli</a>,\n</form>\n<form id=\"form-PascalFrossardGeometricRobustnessof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pascal Frossard\">\n<a href=\"#\" onclick=\"document.getElementById('form-PascalFrossardGeometricRobustnessof').submit();\">Pascal Frossard</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kanbak_Geometric_Robustness_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2844-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.09115\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kanbak_2018_CVPR,<br>\nauthor = {Kanbak, Can and Moosavi-Dezfooli, Seyed-Mohsen and Frossard, Pascal},<br>\ntitle = {Geometric Robustness of Deep Networks: Analysis and Improvement},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhu_View_Extrapolation_of_CVPR_2018_paper.html\">View Extrapolation of Human Body From a Single Image</a></dt>\n<dd>\n<form id=\"form-HaoZhuViewExtrapolationof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hao Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaoZhuViewExtrapolationof').submit();\">Hao Zhu</a>,\n</form>\n<form id=\"form-HaoSuViewExtrapolationof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hao Su\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaoSuViewExtrapolationof').submit();\">Hao Su</a>,\n</form>\n<form id=\"form-PengWangViewExtrapolationof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peng Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-PengWangViewExtrapolationof').submit();\">Peng Wang</a>,\n</form>\n<form id=\"form-XunCaoViewExtrapolationof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xun Cao\">\n<a href=\"#\" onclick=\"document.getElementById('form-XunCaoViewExtrapolationof').submit();\">Xun Cao</a>,\n</form>\n<form id=\"form-RuigangYangViewExtrapolationof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ruigang Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-RuigangYangViewExtrapolationof').submit();\">Ruigang Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhu_View_Extrapolation_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.04213\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhu_2018_CVPR,<br>\nauthor = {Zhu, Hao and Su, Hao and Wang, Peng and Cao, Xun and Yang, Ruigang},<br>\ntitle = {View Extrapolation of Human Body From a Single Image},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Roy_Geometry_Aware_Constrained_CVPR_2018_paper.html\">Geometry Aware Constrained Optimization Techniques for Deep Learning</a></dt>\n<dd>\n<form id=\"form-SoumavaKumarGeometryAwareConstrained\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Soumava Kumar Roy\">\n<a href=\"#\" onclick=\"document.getElementById('form-SoumavaKumarGeometryAwareConstrained').submit();\">Soumava Kumar Roy</a>,\n</form>\n<form id=\"form-ZakariaMhammediGeometryAwareConstrained\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zakaria Mhammedi\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZakariaMhammediGeometryAwareConstrained').submit();\">Zakaria Mhammedi</a>,\n</form>\n<form id=\"form-MehrtashHarandiGeometryAwareConstrained\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mehrtash Harandi\">\n<a href=\"#\" onclick=\"document.getElementById('form-MehrtashHarandiGeometryAwareConstrained').submit();\">Mehrtash Harandi</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Roy_Geometry_Aware_Constrained_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Roy_2018_CVPR,<br>\nauthor = {Kumar Roy, Soumava and Mhammedi, Zakaria and Harandi, Mehrtash},<br>\ntitle = {Geometry Aware Constrained Optimization Techniques for Deep Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Uy_PointNetVLAD_Deep_Point_CVPR_2018_paper.html\">PointNetVLAD: Deep Point Cloud Based Retrieval for Large-Scale Place Recognition</a></dt>\n<dd>\n<form id=\"form-MikaelaAngelinaPointNetVLADDeepPoint\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mikaela Angelina Uy\">\n<a href=\"#\" onclick=\"document.getElementById('form-MikaelaAngelinaPointNetVLADDeepPoint').submit();\">Mikaela Angelina Uy</a>,\n</form>\n<form id=\"form-GimHeePointNetVLADDeepPoint\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gim Hee Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-GimHeePointNetVLADDeepPoint').submit();\">Gim Hee Lee</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Uy_PointNetVLAD_Deep_Point_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3164-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.03492\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Uy_2018_CVPR,<br>\nauthor = {Angelina Uy, Mikaela and Hee Lee, Gim},<br>\ntitle = {PointNetVLAD: Deep Point Cloud Based Retrieval for Large-Scale Place Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yu_An_Efficient_and_CVPR_2018_paper.html\">An Efficient and Provable Approach for Mixture Proportion Estimation Using Linear Independence Assumption</a></dt>\n<dd>\n<form id=\"form-XiyuYuAnEfficientand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiyu Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiyuYuAnEfficientand').submit();\">Xiyu Yu</a>,\n</form>\n<form id=\"form-TongliangLiuAnEfficientand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tongliang Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-TongliangLiuAnEfficientand').submit();\">Tongliang Liu</a>,\n</form>\n<form id=\"form-MingmingGongAnEfficientand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mingming Gong\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingmingGongAnEfficientand').submit();\">Mingming Gong</a>,\n</form>\n<form id=\"form-KayhanBatmanghelichAnEfficientand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kayhan Batmanghelich\">\n<a href=\"#\" onclick=\"document.getElementById('form-KayhanBatmanghelichAnEfficientand').submit();\">Kayhan Batmanghelich</a>,\n</form>\n<form id=\"form-DachengTaoAnEfficientand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dacheng Tao\">\n<a href=\"#\" onclick=\"document.getElementById('form-DachengTaoAnEfficientand').submit();\">Dacheng Tao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yu_An_Efficient_and_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3303-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yu_2018_CVPR,<br>\nauthor = {Yu, Xiyu and Liu, Tongliang and Gong, Mingming and Batmanghelich, Kayhan and Tao, Dacheng},<br>\ntitle = {An Efficient and Provable Approach for Mixture Proportion Estimation Using Linear Independence Assumption},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhou_VoxelNet_End-to-End_Learning_CVPR_2018_paper.html\">VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection</a></dt>\n<dd>\n<form id=\"form-YinZhouVoxelNetEndtoEndLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yin Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-YinZhouVoxelNetEndtoEndLearning').submit();\">Yin Zhou</a>,\n</form>\n<form id=\"form-OncelTuzelVoxelNetEndtoEndLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Oncel Tuzel\">\n<a href=\"#\" onclick=\"document.getElementById('form-OncelTuzelVoxelNetEndtoEndLearning').submit();\">Oncel Tuzel</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhou_VoxelNet_End-to-End_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3333-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.06396\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhou_2018_CVPR,<br>\nauthor = {Zhou, Yin and Tuzel, Oncel},<br>\ntitle = {VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Murez_Image_to_Image_CVPR_2018_paper.html\">Image to Image Translation for Domain Adaptation</a></dt>\n<dd>\n<form id=\"form-ZakMurezImagetoImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zak Murez\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZakMurezImagetoImage').submit();\">Zak Murez</a>,\n</form>\n<form id=\"form-SoheilKolouriImagetoImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Soheil Kolouri\">\n<a href=\"#\" onclick=\"document.getElementById('form-SoheilKolouriImagetoImage').submit();\">Soheil Kolouri</a>,\n</form>\n<form id=\"form-DavidKriegmanImagetoImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"David Kriegman\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavidKriegmanImagetoImage').submit();\">David Kriegman</a>,\n</form>\n<form id=\"form-RaviRamamoorthiImagetoImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ravi Ramamoorthi\">\n<a href=\"#\" onclick=\"document.getElementById('form-RaviRamamoorthiImagetoImage').submit();\">Ravi Ramamoorthi</a>,\n</form>\n<form id=\"form-KyungnamKimImagetoImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kyungnam Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-KyungnamKimImagetoImage').submit();\">Kyungnam Kim</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Murez_Image_to_Image_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.00479\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Murez_2018_CVPR,<br>\nauthor = {Murez, Zak and Kolouri, Soheil and Kriegman, David and Ramamoorthi, Ravi and Kim, Kyungnam},<br>\ntitle = {Image to Image Translation for Domain Adaptation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sandler_MobileNetV2_Inverted_Residuals_CVPR_2018_paper.html\">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a></dt>\n<dd>\n<form id=\"form-MarkSandlerMobileNetV2InvertedResiduals\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mark Sandler\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarkSandlerMobileNetV2InvertedResiduals').submit();\">Mark Sandler</a>,\n</form>\n<form id=\"form-AndrewHowardMobileNetV2InvertedResiduals\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrew Howard\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndrewHowardMobileNetV2InvertedResiduals').submit();\">Andrew Howard</a>,\n</form>\n<form id=\"form-MenglongZhuMobileNetV2InvertedResiduals\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Menglong Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-MenglongZhuMobileNetV2InvertedResiduals').submit();\">Menglong Zhu</a>,\n</form>\n<form id=\"form-AndreyZhmoginovMobileNetV2InvertedResiduals\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrey Zhmoginov\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndreyZhmoginovMobileNetV2InvertedResiduals').submit();\">Andrey Zhmoginov</a>,\n</form>\n<form id=\"form-Liang-ChiehChenMobileNetV2InvertedResiduals\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liang-Chieh Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-Liang-ChiehChenMobileNetV2InvertedResiduals').submit();\">Liang-Chieh Chen</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sandler_MobileNetV2_Inverted_Residuals_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.04381\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sandler_2018_CVPR,<br>\nauthor = {Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},<br>\ntitle = {MobileNetV2: Inverted Residuals and Linear Bottlenecks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Niu_Im2Struct_Recovering_3D_CVPR_2018_paper.html\">Im2Struct: Recovering 3D Shape Structure From a Single RGB Image</a></dt>\n<dd>\n<form id=\"form-ChengjieNiuIm2StructRecovering3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chengjie Niu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChengjieNiuIm2StructRecovering3D').submit();\">Chengjie Niu</a>,\n</form>\n<form id=\"form-JunLiIm2StructRecovering3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jun Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunLiIm2StructRecovering3D').submit();\">Jun Li</a>,\n</form>\n<form id=\"form-KaiXuIm2StructRecovering3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kai Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaiXuIm2StructRecovering3D').submit();\">Kai Xu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Niu_Im2Struct_Recovering_3D_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.05469\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Niu_2018_CVPR,<br>\nauthor = {Niu, Chengjie and Li, Jun and Xu, Kai},<br>\ntitle = {Im2Struct: Recovering 3D Shape Structure From a Single RGB Image},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Schilling_Trust_Your_Model_CVPR_2018_paper.html\">Trust Your Model: Light Field Depth Estimation With Inline Occlusion Handling</a></dt>\n<dd>\n<form id=\"form-HendrikSchillingTrustYourModel\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hendrik Schilling\">\n<a href=\"#\" onclick=\"document.getElementById('form-HendrikSchillingTrustYourModel').submit();\">Hendrik Schilling</a>,\n</form>\n<form id=\"form-MaximilianDieboldTrustYourModel\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Maximilian Diebold\">\n<a href=\"#\" onclick=\"document.getElementById('form-MaximilianDieboldTrustYourModel').submit();\">Maximilian Diebold</a>,\n</form>\n<form id=\"form-CarstenRotherTrustYourModel\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Carsten Rother\">\n<a href=\"#\" onclick=\"document.getElementById('form-CarstenRotherTrustYourModel').submit();\">Carsten Rother</a>,\n</form>\n<form id=\"form-BerndJ\u00c3\u00a4hneTrustYourModel\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bernd J\u00c3\u00a4hne\">\n<a href=\"#\" onclick=\"document.getElementById('form-BerndJ\u00c3\u00a4hneTrustYourModel').submit();\">Bernd J\u00c3\u00a4hne</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Schilling_Trust_Your_Model_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Schilling_2018_CVPR,<br>\nauthor = {Schilling, Hendrik and Diebold, Maximilian and Rother, Carsten and J\u00c3\u00a4hne, Bernd},<br>\ntitle = {Trust Your Model: Light Field Depth Estimation With Inline Occlusion Handling},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhuang_Baseline_Desensitizing_in_CVPR_2018_paper.html\">Baseline Desensitizing in Translation Averaging</a></dt>\n<dd>\n<form id=\"form-BingbingZhuangBaselineDesensitizingin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bingbing Zhuang\">\n<a href=\"#\" onclick=\"document.getElementById('form-BingbingZhuangBaselineDesensitizingin').submit();\">Bingbing Zhuang</a>,\n</form>\n<form id=\"form-Loong-FahCheongBaselineDesensitizingin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Loong-Fah Cheong\">\n<a href=\"#\" onclick=\"document.getElementById('form-Loong-FahCheongBaselineDesensitizingin').submit();\">Loong-Fah Cheong</a>,\n</form>\n<form id=\"form-GimHeeBaselineDesensitizingin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gim Hee Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-GimHeeBaselineDesensitizingin').submit();\">Gim Hee Lee</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhuang_Baseline_Desensitizing_in_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0067-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhuang_2018_CVPR,<br>\nauthor = {Zhuang, Bingbing and Cheong, Loong-Fah and Hee Lee, Gim},<br>\ntitle = {Baseline Desensitizing in Translation Averaging},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Shen_Mining_Point_Cloud_CVPR_2018_paper.html\">Mining Point Cloud Local Structures by Kernel Correlation and Graph Pooling</a></dt>\n<dd>\n<form id=\"form-YiruShenMiningPointCloud\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yiru Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiruShenMiningPointCloud').submit();\">Yiru Shen</a>,\n</form>\n<form id=\"form-ChenFengMiningPointCloud\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chen Feng\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenFengMiningPointCloud').submit();\">Chen Feng</a>,\n</form>\n<form id=\"form-YaoqingYangMiningPointCloud\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yaoqing Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YaoqingYangMiningPointCloud').submit();\">Yaoqing Yang</a>,\n</form>\n<form id=\"form-DongTianMiningPointCloud\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dong Tian\">\n<a href=\"#\" onclick=\"document.getElementById('form-DongTianMiningPointCloud').submit();\">Dong Tian</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Shen_Mining_Point_Cloud_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.06760\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Shen_2018_CVPR,<br>\nauthor = {Shen, Yiru and Feng, Chen and Yang, Yaoqing and Tian, Dong},<br>\ntitle = {Mining Point Cloud Local Structures by Kernel Correlation and Graph Pooling},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Landrieu_Large-Scale_Point_Cloud_CVPR_2018_paper.html\">Large-Scale Point Cloud Semantic Segmentation With Superpoint Graphs</a></dt>\n<dd>\n<form id=\"form-LoicLandrieuLargeScalePointCloud\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Loic Landrieu\">\n<a href=\"#\" onclick=\"document.getElementById('form-LoicLandrieuLargeScalePointCloud').submit();\">Loic Landrieu</a>,\n</form>\n<form id=\"form-MartinSimonovskyLargeScalePointCloud\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Martin Simonovsky\">\n<a href=\"#\" onclick=\"document.getElementById('form-MartinSimonovskyLargeScalePointCloud').submit();\">Martin Simonovsky</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Landrieu_Large-Scale_Point_Cloud_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1915-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.09869\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Landrieu_2018_CVPR,<br>\nauthor = {Landrieu, Loic and Simonovsky, Martin},<br>\ntitle = {Large-Scale Point Cloud Semantic Segmentation With Superpoint Graphs},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhu_Very_Large-Scale_Global_CVPR_2018_paper.html\">Very Large-Scale Global SfM by Distributed Motion Averaging</a></dt>\n<dd>\n<form id=\"form-SiyuZhuVeryLargeScaleGlobal\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Siyu Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-SiyuZhuVeryLargeScaleGlobal').submit();\">Siyu Zhu</a>,\n</form>\n<form id=\"form-RunzeZhangVeryLargeScaleGlobal\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Runze Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-RunzeZhangVeryLargeScaleGlobal').submit();\">Runze Zhang</a>,\n</form>\n<form id=\"form-LeiZhouVeryLargeScaleGlobal\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lei Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeiZhouVeryLargeScaleGlobal').submit();\">Lei Zhou</a>,\n</form>\n<form id=\"form-TianweiShenVeryLargeScaleGlobal\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tianwei Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-TianweiShenVeryLargeScaleGlobal').submit();\">Tianwei Shen</a>,\n</form>\n<form id=\"form-TianFangVeryLargeScaleGlobal\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tian Fang\">\n<a href=\"#\" onclick=\"document.getElementById('form-TianFangVeryLargeScaleGlobal').submit();\">Tian Fang</a>,\n</form>\n<form id=\"form-PingTanVeryLargeScaleGlobal\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ping Tan\">\n<a href=\"#\" onclick=\"document.getElementById('form-PingTanVeryLargeScaleGlobal').submit();\">Ping Tan</a>,\n</form>\n<form id=\"form-LongQuanVeryLargeScaleGlobal\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Long Quan\">\n<a href=\"#\" onclick=\"document.getElementById('form-LongQuanVeryLargeScaleGlobal').submit();\">Long Quan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhu_Very_Large-Scale_Global_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhu_2018_CVPR,<br>\nauthor = {Zhu, Siyu and Zhang, Runze and Zhou, Lei and Shen, Tianwei and Fang, Tian and Tan, Ping and Quan, Long},<br>\ntitle = {Very Large-Scale Global SfM by Distributed Motion Averaging},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Dai_ScanComplete_Large-Scale_Scene_CVPR_2018_paper.html\">ScanComplete: Large-Scale Scene Completion and Semantic Segmentation for 3D Scans</a></dt>\n<dd>\n<form id=\"form-AngelaDaiScanCompleteLargeScaleScene\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Angela Dai\">\n<a href=\"#\" onclick=\"document.getElementById('form-AngelaDaiScanCompleteLargeScaleScene').submit();\">Angela Dai</a>,\n</form>\n<form id=\"form-DanielRitchieScanCompleteLargeScaleScene\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daniel Ritchie\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanielRitchieScanCompleteLargeScaleScene').submit();\">Daniel Ritchie</a>,\n</form>\n<form id=\"form-MartinBokelohScanCompleteLargeScaleScene\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Martin Bokeloh\">\n<a href=\"#\" onclick=\"document.getElementById('form-MartinBokelohScanCompleteLargeScaleScene').submit();\">Martin Bokeloh</a>,\n</form>\n<form id=\"form-ScottReedScanCompleteLargeScaleScene\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Scott Reed\">\n<a href=\"#\" onclick=\"document.getElementById('form-ScottReedScanCompleteLargeScaleScene').submit();\">Scott Reed</a>,\n</form>\n<form id=\"form-J\u00c3\u00bcrgenSturmScanCompleteLargeScaleScene\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"J\u00c3\u00bcrgen Sturm\">\n<a href=\"#\" onclick=\"document.getElementById('form-J\u00c3\u00bcrgenSturmScanCompleteLargeScaleScene').submit();\">J\u00c3\u00bcrgen Sturm</a>,\n</form>\n<form id=\"form-MatthiasNie\u00c3\u009fnerScanCompleteLargeScaleScene\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Matthias Nie\u00c3\u009fner\">\n<a href=\"#\" onclick=\"document.getElementById('form-MatthiasNie\u00c3\u009fnerScanCompleteLargeScaleScene').submit();\">Matthias Nie\u00c3\u009fner</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Dai_ScanComplete_Large-Scale_Scene_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2835-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.10215\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Dai_2018_CVPR,<br>\nauthor = {Dai, Angela and Ritchie, Daniel and Bokeloh, Martin and Reed, Scott and Sturm, J\u00c3\u00bcrgen and Nie\u00c3\u009fner, Matthias},<br>\ntitle = {ScanComplete: Large-Scale Scene Completion and Semantic Segmentation for 3D Scans},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lan_Solving_the_Perspective-2-Point_CVPR_2018_paper.html\">Solving the Perspective-2-Point Problem for Flying-Camera Photo Composition</a></dt>\n<dd>\n<form id=\"form-ZiquanLanSolvingthePerspective2Point\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ziquan Lan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZiquanLanSolvingthePerspective2Point').submit();\">Ziquan Lan</a>,\n</form>\n<form id=\"form-DavidHsuSolvingthePerspective2Point\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"David Hsu\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavidHsuSolvingthePerspective2Point').submit();\">David Hsu</a>,\n</form>\n<form id=\"form-GimHeeSolvingthePerspective2Point\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gim Hee Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-GimHeeSolvingthePerspective2Point').submit();\">Gim Hee Lee</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lan_Solving_the_Perspective-2-Point_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lan_2018_CVPR,<br>\nauthor = {Lan, Ziquan and Hsu, David and Hee Lee, Gim},<br>\ntitle = {Solving the Perspective-2-Point Problem for Flying-Camera Photo Composition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yun_Reflection_Removal_for_CVPR_2018_paper.html\">Reflection Removal for Large-Scale 3D Point Clouds</a></dt>\n<dd>\n<form id=\"form-Jae-SeongYunReflectionRemovalfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jae-Seong Yun\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jae-SeongYunReflectionRemovalfor').submit();\">Jae-Seong Yun</a>,\n</form>\n<form id=\"form-Jae-YoungSimReflectionRemovalfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jae-Young Sim\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jae-YoungSimReflectionRemovalfor').submit();\">Jae-Young Sim</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yun_Reflection_Removal_for_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yun_2018_CVPR,<br>\nauthor = {Yun, Jae-Seong and Sim, Jae-Young},<br>\ntitle = {Reflection Removal for Large-Scale 3D Point Clouds},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xie_Attentional_ShapeContextNet_for_CVPR_2018_paper.html\">Attentional ShapeContextNet for Point Cloud Recognition</a></dt>\n<dd>\n<form id=\"form-SainingXieAttentionalShapeContextNetfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Saining Xie\">\n<a href=\"#\" onclick=\"document.getElementById('form-SainingXieAttentionalShapeContextNetfor').submit();\">Saining Xie</a>,\n</form>\n<form id=\"form-SainanLiuAttentionalShapeContextNetfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sainan Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-SainanLiuAttentionalShapeContextNetfor').submit();\">Sainan Liu</a>,\n</form>\n<form id=\"form-ZeyuChenAttentionalShapeContextNetfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zeyu Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZeyuChenAttentionalShapeContextNetfor').submit();\">Zeyu Chen</a>,\n</form>\n<form id=\"form-ZhuowenTuAttentionalShapeContextNetfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhuowen Tu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhuowenTuAttentionalShapeContextNetfor').submit();\">Zhuowen Tu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xie_Attentional_ShapeContextNet_for_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xie_2018_CVPR,<br>\nauthor = {Xie, Saining and Liu, Sainan and Chen, Zeyu and Tu, Zhuowen},<br>\ntitle = {Attentional ShapeContextNet for Point Cloud Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_Geometry-Aware_Deep_Network_CVPR_2018_paper.html\">Geometry-Aware Deep Network for Single-Image Novel View Synthesis</a></dt>\n<dd>\n<form id=\"form-MiaomiaoLiuGeometryAwareDeepNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Miaomiao Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-MiaomiaoLiuGeometryAwareDeepNetwork').submit();\">Miaomiao Liu</a>,\n</form>\n<form id=\"form-XumingHeGeometryAwareDeepNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xuming He\">\n<a href=\"#\" onclick=\"document.getElementById('form-XumingHeGeometryAwareDeepNetwork').submit();\">Xuming He</a>,\n</form>\n<form id=\"form-MathieuSalzmannGeometryAwareDeepNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mathieu Salzmann\">\n<a href=\"#\" onclick=\"document.getElementById('form-MathieuSalzmannGeometryAwareDeepNetwork').submit();\">Mathieu Salzmann</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_Geometry-Aware_Deep_Network_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2437-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.06008\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Miaomiao and He, Xuming and Salzmann, Mathieu},<br>\ntitle = {Geometry-Aware Deep Network for Single-Image Novel View Synthesis},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kim_InverseFaceNet_Deep_Monocular_CVPR_2018_paper.html\">InverseFaceNet: Deep Monocular Inverse Face Rendering</a></dt>\n<dd>\n<form id=\"form-HyeongwooKimInverseFaceNetDeepMonocular\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hyeongwoo Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-HyeongwooKimInverseFaceNetDeepMonocular').submit();\">Hyeongwoo Kim</a>,\n</form>\n<form id=\"form-MichaelZollh\u00c3\u00b6ferInverseFaceNetDeepMonocular\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michael Zollh\u00c3\u00b6fer\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichaelZollh\u00c3\u00b6ferInverseFaceNetDeepMonocular').submit();\">Michael Zollh\u00c3\u00b6fer</a>,\n</form>\n<form id=\"form-AyushTewariInverseFaceNetDeepMonocular\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ayush Tewari\">\n<a href=\"#\" onclick=\"document.getElementById('form-AyushTewariInverseFaceNetDeepMonocular').submit();\">Ayush Tewari</a>,\n</form>\n<form id=\"form-JustusThiesInverseFaceNetDeepMonocular\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Justus Thies\">\n<a href=\"#\" onclick=\"document.getElementById('form-JustusThiesInverseFaceNetDeepMonocular').submit();\">Justus Thies</a>,\n</form>\n<form id=\"form-ChristianRichardtInverseFaceNetDeepMonocular\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Christian Richardt\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChristianRichardtInverseFaceNetDeepMonocular').submit();\">Christian Richardt</a>,\n</form>\n<form id=\"form-ChristianTheobaltInverseFaceNetDeepMonocular\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Christian Theobalt\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChristianTheobaltInverseFaceNetDeepMonocular').submit();\">Christian Theobalt</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kim_InverseFaceNet_Deep_Monocular_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2599-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1703.10956\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kim_2018_CVPR,<br>\nauthor = {Kim, Hyeongwoo and Zollh\u00c3\u00b6fer, Michael and Tewari, Ayush and Thies, Justus and Richardt, Christian and Theobalt, Christian},<br>\ntitle = {InverseFaceNet: Deep Monocular Inverse Face Rendering},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Cao_Sparse_Photometric_3D_CVPR_2018_paper.html\">Sparse Photometric 3D Face Reconstruction Guided by Morphable Models</a></dt>\n<dd>\n<form id=\"form-XuanCaoSparsePhotometric3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xuan Cao\">\n<a href=\"#\" onclick=\"document.getElementById('form-XuanCaoSparsePhotometric3D').submit();\">Xuan Cao</a>,\n</form>\n<form id=\"form-ZhangChenSparsePhotometric3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhang Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhangChenSparsePhotometric3D').submit();\">Zhang Chen</a>,\n</form>\n<form id=\"form-AnpeiChenSparsePhotometric3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anpei Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-AnpeiChenSparsePhotometric3D').submit();\">Anpei Chen</a>,\n</form>\n<form id=\"form-XinChenSparsePhotometric3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xin Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinChenSparsePhotometric3D').submit();\">Xin Chen</a>,\n</form>\n<form id=\"form-ShiyingLiSparsePhotometric3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shiying Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShiyingLiSparsePhotometric3D').submit();\">Shiying Li</a>,\n</form>\n<form id=\"form-JingyiYuSparsePhotometric3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jingyi Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingyiYuSparsePhotometric3D').submit();\">Jingyi Yu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Cao_Sparse_Photometric_3D_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.10870\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Cao_2018_CVPR,<br>\nauthor = {Cao, Xuan and Chen, Zhang and Chen, Anpei and Chen, Xin and Li, Shiying and Yu, Jingyi},<br>\ntitle = {Sparse Photometric 3D Face Reconstruction Guided by Morphable Models},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Fu_Texture_Mapping_for_CVPR_2018_paper.html\">Texture Mapping for 3D Reconstruction With RGB-D Sensor</a></dt>\n<dd>\n<form id=\"form-YanpingFuTextureMappingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yanping Fu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanpingFuTextureMappingfor').submit();\">Yanping Fu</a>,\n</form>\n<form id=\"form-QinganYanTextureMappingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qingan Yan\">\n<a href=\"#\" onclick=\"document.getElementById('form-QinganYanTextureMappingfor').submit();\">Qingan Yan</a>,\n</form>\n<form id=\"form-LongYangTextureMappingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Long Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LongYangTextureMappingfor').submit();\">Long Yang</a>,\n</form>\n<form id=\"form-JieLiaoTextureMappingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jie Liao\">\n<a href=\"#\" onclick=\"document.getElementById('form-JieLiaoTextureMappingfor').submit();\">Jie Liao</a>,\n</form>\n<form id=\"form-ChunxiaXiaoTextureMappingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chunxia Xiao\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChunxiaXiaoTextureMappingfor').submit();\">Chunxia Xiao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Fu_Texture_Mapping_for_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Fu_2018_CVPR,<br>\nauthor = {Fu, Yanping and Yan, Qingan and Yang, Long and Liao, Jie and Xiao, Chunxia},<br>\ntitle = {Texture Mapping for 3D Reconstruction With RGB-D Sensor},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Brachmann_Learning_Less_Is_CVPR_2018_paper.html\">Learning Less Is More - 6D Camera Localization via 3D Surface Regression</a></dt>\n<dd>\n<form id=\"form-EricBrachmannLearningLessIs\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Eric Brachmann\">\n<a href=\"#\" onclick=\"document.getElementById('form-EricBrachmannLearningLessIs').submit();\">Eric Brachmann</a>,\n</form>\n<form id=\"form-CarstenRotherLearningLessIs\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Carsten Rother\">\n<a href=\"#\" onclick=\"document.getElementById('form-CarstenRotherLearningLessIs').submit();\">Carsten Rother</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Brachmann_Learning_Less_Is_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3599-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.10228\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Brachmann_2018_CVPR,<br>\nauthor = {Brachmann, Eric and Rother, Carsten},<br>\ntitle = {Learning Less Is More - 6D Camera Localization via 3D Surface Regression},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Rad_Feature_Mapping_for_CVPR_2018_paper.html\">Feature Mapping for Learning Fast and Accurate 3D Pose Inference From Synthetic Images</a></dt>\n<dd>\n<form id=\"form-MahdiRadFeatureMappingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mahdi Rad\">\n<a href=\"#\" onclick=\"document.getElementById('form-MahdiRadFeatureMappingfor').submit();\">Mahdi Rad</a>,\n</form>\n<form id=\"form-MarkusOberwegerFeatureMappingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Markus Oberweger\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarkusOberwegerFeatureMappingfor').submit();\">Markus Oberweger</a>,\n</form>\n<form id=\"form-VincentLepetitFeatureMappingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vincent Lepetit\">\n<a href=\"#\" onclick=\"document.getElementById('form-VincentLepetitFeatureMappingfor').submit();\">Vincent Lepetit</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Rad_Feature_Mapping_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.03904\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Rad_2018_CVPR,<br>\nauthor = {Rad, Mahdi and Oberweger, Markus and Lepetit, Vincent},<br>\ntitle = {Feature Mapping for Learning Fast and Accurate 3D Pose Inference From Synthetic Images},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kim_Indoor_RGB-D_Compass_CVPR_2018_paper.html\">Indoor RGB-D Compass From a Single Line and Plane</a></dt>\n<dd>\n<form id=\"form-PyojinKimIndoorRGBDCompass\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pyojin Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-PyojinKimIndoorRGBDCompass').submit();\">Pyojin Kim</a>,\n</form>\n<form id=\"form-BrianColtinIndoorRGBDCompass\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Brian Coltin\">\n<a href=\"#\" onclick=\"document.getElementById('form-BrianColtinIndoorRGBDCompass').submit();\">Brian Coltin</a>,\n</form>\n<form id=\"form-H.JinIndoorRGBDCompass\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"H. Jin Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-H.JinIndoorRGBDCompass').submit();\">H. Jin Kim</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kim_Indoor_RGB-D_Compass_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3630-supp.zip\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kim_2018_CVPR,<br>\nauthor = {Kim, Pyojin and Coltin, Brian and Jin Kim, H.},<br>\ntitle = {Indoor RGB-D Compass From a Single Line and Plane},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Pumarola_Geometry-Aware_Network_for_CVPR_2018_paper.html\">Geometry-Aware Network for Non-Rigid Shape Prediction From a Single View</a></dt>\n<dd>\n<form id=\"form-AlbertPumarolaGeometryAwareNetworkfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Albert Pumarola\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlbertPumarolaGeometryAwareNetworkfor').submit();\">Albert Pumarola</a>,\n</form>\n<form id=\"form-AntonioAgudoGeometryAwareNetworkfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Antonio Agudo\">\n<a href=\"#\" onclick=\"document.getElementById('form-AntonioAgudoGeometryAwareNetworkfor').submit();\">Antonio Agudo</a>,\n</form>\n<form id=\"form-LorenzoPorziGeometryAwareNetworkfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lorenzo Porzi\">\n<a href=\"#\" onclick=\"document.getElementById('form-LorenzoPorziGeometryAwareNetworkfor').submit();\">Lorenzo Porzi</a>,\n</form>\n<form id=\"form-AlbertoSanfeliuGeometryAwareNetworkfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alberto Sanfeliu\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlbertoSanfeliuGeometryAwareNetworkfor').submit();\">Alberto Sanfeliu</a>,\n</form>\n<form id=\"form-VincentLepetitGeometryAwareNetworkfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vincent Lepetit\">\n<a href=\"#\" onclick=\"document.getElementById('form-VincentLepetitGeometryAwareNetworkfor').submit();\">Vincent Lepetit</a>,\n</form>\n<form id=\"form-FrancescMoreno-NoguerGeometryAwareNetworkfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Francesc Moreno-Noguer\">\n<a href=\"#\" onclick=\"document.getElementById('form-FrancescMoreno-NoguerGeometryAwareNetworkfor').submit();\">Francesc Moreno-Noguer</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Pumarola_Geometry-Aware_Network_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2967-supp.zip\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Pumarola_2018_CVPR,<br>\nauthor = {Pumarola, Albert and Agudo, Antonio and Porzi, Lorenzo and Sanfeliu, Alberto and Lepetit, Vincent and Moreno-Noguer, Francesc},<br>\ntitle = {Geometry-Aware Network for Non-Rigid Shape Prediction From a Single View},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sadeghi_Sim2Real_Viewpoint_Invariant_CVPR_2018_paper.html\">Sim2Real Viewpoint Invariant Visual Servoing by Recurrent Control</a></dt>\n<dd>\n<form id=\"form-FereshtehSadeghiSim2RealViewpointInvariant\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fereshteh Sadeghi\">\n<a href=\"#\" onclick=\"document.getElementById('form-FereshtehSadeghiSim2RealViewpointInvariant').submit();\">Fereshteh Sadeghi</a>,\n</form>\n<form id=\"form-AlexanderToshevSim2RealViewpointInvariant\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexander Toshev\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexanderToshevSim2RealViewpointInvariant').submit();\">Alexander Toshev</a>,\n</form>\n<form id=\"form-EricJangSim2RealViewpointInvariant\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Eric Jang\">\n<a href=\"#\" onclick=\"document.getElementById('form-EricJangSim2RealViewpointInvariant').submit();\">Eric Jang</a>,\n</form>\n<form id=\"form-SergeyLevineSim2RealViewpointInvariant\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sergey Levine\">\n<a href=\"#\" onclick=\"document.getElementById('form-SergeyLevineSim2RealViewpointInvariant').submit();\">Sergey Levine</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sadeghi_Sim2Real_Viewpoint_Invariant_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sadeghi_2018_CVPR,<br>\nauthor = {Sadeghi, Fereshteh and Toshev, Alexander and Jang, Eric and Levine, Sergey},<br>\ntitle = {Sim2Real Viewpoint Invariant Visual Servoing by Recurrent Control},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ma_DocUNet_Document_Image_CVPR_2018_paper.html\">DocUNet: Document Image Unwarping via a Stacked U-Net</a></dt>\n<dd>\n<form id=\"form-KeMaDocUNetDocumentImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ke Ma\">\n<a href=\"#\" onclick=\"document.getElementById('form-KeMaDocUNetDocumentImage').submit();\">Ke Ma</a>,\n</form>\n<form id=\"form-ZhixinShuDocUNetDocumentImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhixin Shu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhixinShuDocUNetDocumentImage').submit();\">Zhixin Shu</a>,\n</form>\n<form id=\"form-XueBaiDocUNetDocumentImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xue Bai\">\n<a href=\"#\" onclick=\"document.getElementById('form-XueBaiDocUNetDocumentImage').submit();\">Xue Bai</a>,\n</form>\n<form id=\"form-JueWangDocUNetDocumentImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jue Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JueWangDocUNetDocumentImage').submit();\">Jue Wang</a>,\n</form>\n<form id=\"form-DimitrisSamarasDocUNetDocumentImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dimitris Samaras\">\n<a href=\"#\" onclick=\"document.getElementById('form-DimitrisSamarasDocUNetDocumentImage').submit();\">Dimitris Samaras</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ma_DocUNet_Document_Image_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ma_2018_CVPR,<br>\nauthor = {Ma, Ke and Shu, Zhixin and Bai, Xue and Wang, Jue and Samaras, Dimitris},<br>\ntitle = {DocUNet: Document Image Unwarping via a Stacked U-Net},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Urooj_Analysis_of_Hand_CVPR_2018_paper.html\">Analysis of Hand Segmentation in the Wild</a></dt>\n<dd>\n<form id=\"form-AishaUroojAnalysisofHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Aisha Urooj\">\n<a href=\"#\" onclick=\"document.getElementById('form-AishaUroojAnalysisofHand').submit();\">Aisha Urooj</a>,\n</form>\n<form id=\"form-AliBorjiAnalysisofHand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ali Borji\">\n<a href=\"#\" onclick=\"document.getElementById('form-AliBorjiAnalysisofHand').submit();\">Ali Borji</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Urooj_Analysis_of_Hand_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.03317\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Urooj_2018_CVPR,<br>\nauthor = {Urooj, Aisha and Borji, Ali},<br>\ntitle = {Analysis of Hand Segmentation in the Wild},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Bastani_RoadTracer_Automatic_Extraction_CVPR_2018_paper.html\">RoadTracer: Automatic Extraction of Road Networks From Aerial Images</a></dt>\n<dd>\n<form id=\"form-FavyenBastaniRoadTracerAutomaticExtraction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Favyen Bastani\">\n<a href=\"#\" onclick=\"document.getElementById('form-FavyenBastaniRoadTracerAutomaticExtraction').submit();\">Favyen Bastani</a>,\n</form>\n<form id=\"form-SongtaoHeRoadTracerAutomaticExtraction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Songtao He\">\n<a href=\"#\" onclick=\"document.getElementById('form-SongtaoHeRoadTracerAutomaticExtraction').submit();\">Songtao He</a>,\n</form>\n<form id=\"form-SofianeAbbarRoadTracerAutomaticExtraction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sofiane Abbar\">\n<a href=\"#\" onclick=\"document.getElementById('form-SofianeAbbarRoadTracerAutomaticExtraction').submit();\">Sofiane Abbar</a>,\n</form>\n<form id=\"form-MohammadAlizadehRoadTracerAutomaticExtraction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mohammad Alizadeh\">\n<a href=\"#\" onclick=\"document.getElementById('form-MohammadAlizadehRoadTracerAutomaticExtraction').submit();\">Mohammad Alizadeh</a>,\n</form>\n<form id=\"form-HariBalakrishnanRoadTracerAutomaticExtraction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hari Balakrishnan\">\n<a href=\"#\" onclick=\"document.getElementById('form-HariBalakrishnanRoadTracerAutomaticExtraction').submit();\">Hari Balakrishnan</a>,\n</form>\n<form id=\"form-SanjayChawlaRoadTracerAutomaticExtraction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sanjay Chawla\">\n<a href=\"#\" onclick=\"document.getElementById('form-SanjayChawlaRoadTracerAutomaticExtraction').submit();\">Sanjay Chawla</a>,\n</form>\n<form id=\"form-SamMaddenRoadTracerAutomaticExtraction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sam Madden\">\n<a href=\"#\" onclick=\"document.getElementById('form-SamMaddenRoadTracerAutomaticExtraction').submit();\">Sam Madden</a>,\n</form>\n<form id=\"form-DavidDeWittRoadTracerAutomaticExtraction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"David DeWitt\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavidDeWittRoadTracerAutomaticExtraction').submit();\">David DeWitt</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Bastani_RoadTracer_Automatic_Extraction_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/4023-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.03680\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Bastani_2018_CVPR,<br>\nauthor = {Bastani, Favyen and He, Songtao and Abbar, Sofiane and Alizadeh, Mohammad and Balakrishnan, Hari and Chawla, Sanjay and Madden, Sam and DeWitt, David},<br>\ntitle = {RoadTracer: Automatic Extraction of Road Networks From Aerial Images},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Paul_Alternating-Stereo_VINS_Observability_CVPR_2018_paper.html\">Alternating-Stereo VINS: Observability Analysis and Performance Evaluation</a></dt>\n<dd>\n<form id=\"form-MrinalK.AlternatingStereoVINSObservability\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mrinal K. Paul\">\n<a href=\"#\" onclick=\"document.getElementById('form-MrinalK.AlternatingStereoVINSObservability').submit();\">Mrinal K. Paul</a>,\n</form>\n<form id=\"form-StergiosI.AlternatingStereoVINSObservability\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stergios I. Roumeliotis\">\n<a href=\"#\" onclick=\"document.getElementById('form-StergiosI.AlternatingStereoVINSObservability').submit();\">Stergios I. Roumeliotis</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Paul_Alternating-Stereo_VINS_Observability_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Paul_2018_CVPR,<br>\nauthor = {Paul, Mrinal K. and Roumeliotis, Stergios I.},<br>\ntitle = {Alternating-Stereo VINS: Observability Analysis and Performance Evaluation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Rematas_Soccer_on_Your_CVPR_2018_paper.html\">Soccer on Your Tabletop</a></dt>\n<dd>\n<form id=\"form-KonstantinosRematasSocceronYour\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Konstantinos Rematas\">\n<a href=\"#\" onclick=\"document.getElementById('form-KonstantinosRematasSocceronYour').submit();\">Konstantinos Rematas</a>,\n</form>\n<form id=\"form-IraKemelmacher-ShlizermanSocceronYour\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ira Kemelmacher-Shlizerman\">\n<a href=\"#\" onclick=\"document.getElementById('form-IraKemelmacher-ShlizermanSocceronYour').submit();\">Ira Kemelmacher-Shlizerman</a>,\n</form>\n<form id=\"form-BrianCurlessSocceronYour\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Brian Curless\">\n<a href=\"#\" onclick=\"document.getElementById('form-BrianCurlessSocceronYour').submit();\">Brian Curless</a>,\n</form>\n<form id=\"form-SteveSeitzSocceronYour\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Steve Seitz\">\n<a href=\"#\" onclick=\"document.getElementById('form-SteveSeitzSocceronYour').submit();\">Steve Seitz</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Rematas_Soccer_on_Your_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1806.00890\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Rematas_2018_CVPR,<br>\nauthor = {Rematas, Konstantinos and Kemelmacher-Shlizerman, Ira and Curless, Brian and Seitz, Steve},<br>\ntitle = {Soccer on Your Tabletop},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Shin_EPINET_A_Fully-Convolutional_CVPR_2018_paper.html\">EPINET: A Fully-Convolutional Neural Network Using Epipolar Geometry for Depth From Light Field Images</a></dt>\n<dd>\n<form id=\"form-ChanghaShinEPINETAFullyConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Changha Shin\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChanghaShinEPINETAFullyConvolutional').submit();\">Changha Shin</a>,\n</form>\n<form id=\"form-Hae-GonJeonEPINETAFullyConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hae-Gon Jeon\">\n<a href=\"#\" onclick=\"document.getElementById('form-Hae-GonJeonEPINETAFullyConvolutional').submit();\">Hae-Gon Jeon</a>,\n</form>\n<form id=\"form-YoungjinYoonEPINETAFullyConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Youngjin Yoon\">\n<a href=\"#\" onclick=\"document.getElementById('form-YoungjinYoonEPINETAFullyConvolutional').submit();\">Youngjin Yoon</a>,\n</form>\n<form id=\"form-InSoEPINETAFullyConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"In So Kweon\">\n<a href=\"#\" onclick=\"document.getElementById('form-InSoEPINETAFullyConvolutional').submit();\">In So Kweon</a>,\n</form>\n<form id=\"form-SeonJooEPINETAFullyConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Seon Joo Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-SeonJooEPINETAFullyConvolutional').submit();\">Seon Joo Kim</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Shin_EPINET_A_Fully-Convolutional_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.02379\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Shin_2018_CVPR,<br>\nauthor = {Shin, Changha and Jeon, Hae-Gon and Yoon, Youngjin and So Kweon, In and Joo Kim, Seon},<br>\ntitle = {EPINET: A Fully-Convolutional Neural Network Using Epipolar Geometry for Depth From Light Field Images},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liang_A_Hybrid_l1-l0_CVPR_2018_paper.html\">A Hybrid l1-l0 Layer Decomposition Model for Tone Mapping</a></dt>\n<dd>\n<form id=\"form-ZhetongLiangAHybridl1l0\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhetong Liang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhetongLiangAHybridl1l0').submit();\">Zhetong Liang</a>,\n</form>\n<form id=\"form-JunXuAHybridl1l0\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jun Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunXuAHybridl1l0').submit();\">Jun Xu</a>,\n</form>\n<form id=\"form-DavidZhangAHybridl1l0\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"David Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavidZhangAHybridl1l0').submit();\">David Zhang</a>,\n</form>\n<form id=\"form-ZishengCaoAHybridl1l0\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zisheng Cao\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZishengCaoAHybridl1l0').submit();\">Zisheng Cao</a>,\n</form>\n<form id=\"form-LeiZhangAHybridl1l0\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lei Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeiZhangAHybridl1l0').submit();\">Lei Zhang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liang_A_Hybrid_l1-l0_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2391-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liang_2018_CVPR,<br>\nauthor = {Liang, Zhetong and Xu, Jun and Zhang, David and Cao, Zisheng and Zhang, Lei},<br>\ntitle = {A Hybrid l1-l0 Layer Decomposition Model for Tone Mapping},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Nie_Deeply_Learned_Filter_CVPR_2018_paper.html\">Deeply Learned Filter Response Functions for Hyperspectral Reconstruction</a></dt>\n<dd>\n<form id=\"form-ShijieNieDeeplyLearnedFilter\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shijie Nie\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShijieNieDeeplyLearnedFilter').submit();\">Shijie Nie</a>,\n</form>\n<form id=\"form-LinGuDeeplyLearnedFilter\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lin Gu\">\n<a href=\"#\" onclick=\"document.getElementById('form-LinGuDeeplyLearnedFilter').submit();\">Lin Gu</a>,\n</form>\n<form id=\"form-YinqiangZhengDeeplyLearnedFilter\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yinqiang Zheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-YinqiangZhengDeeplyLearnedFilter').submit();\">Yinqiang Zheng</a>,\n</form>\n<form id=\"form-AntonyLamDeeplyLearnedFilter\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Antony Lam\">\n<a href=\"#\" onclick=\"document.getElementById('form-AntonyLamDeeplyLearnedFilter').submit();\">Antony Lam</a>,\n</form>\n<form id=\"form-NobutakaOnoDeeplyLearnedFilter\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nobutaka Ono\">\n<a href=\"#\" onclick=\"document.getElementById('form-NobutakaOnoDeeplyLearnedFilter').submit();\">Nobutaka Ono</a>,\n</form>\n<form id=\"form-ImariSatoDeeplyLearnedFilter\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Imari Sato\">\n<a href=\"#\" onclick=\"document.getElementById('form-ImariSatoDeeplyLearnedFilter').submit();\">Imari Sato</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Nie_Deeply_Learned_Filter_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Nie_2018_CVPR,<br>\nauthor = {Nie, Shijie and Gu, Lin and Zheng, Yinqiang and Lam, Antony and Ono, Nobutaka and Sato, Imari},<br>\ntitle = {Deeply Learned Filter Response Functions for Hyperspectral Reconstruction},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wan_CRRN_Multi-Scale_Guided_CVPR_2018_paper.html\">CRRN: Multi-Scale Guided Concurrent Reflection Removal Network</a></dt>\n<dd>\n<form id=\"form-RenjieWanCRRNMultiScaleGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Renjie Wan\">\n<a href=\"#\" onclick=\"document.getElementById('form-RenjieWanCRRNMultiScaleGuided').submit();\">Renjie Wan</a>,\n</form>\n<form id=\"form-BoxinShiCRRNMultiScaleGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Boxin Shi\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoxinShiCRRNMultiScaleGuided').submit();\">Boxin Shi</a>,\n</form>\n<form id=\"form-Ling-YuDuanCRRNMultiScaleGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ling-Yu Duan\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ling-YuDuanCRRNMultiScaleGuided').submit();\">Ling-Yu Duan</a>,\n</form>\n<form id=\"form-Ah-HweeTanCRRNMultiScaleGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ah-Hwee Tan\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ah-HweeTanCRRNMultiScaleGuided').submit();\">Ah-Hwee Tan</a>,\n</form>\n<form id=\"form-AlexC.CRRNMultiScaleGuided\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alex C. Kot\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexC.CRRNMultiScaleGuided').submit();\">Alex C. Kot</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wan_CRRN_Multi-Scale_Guided_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.11802\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wan_2018_CVPR,<br>\nauthor = {Wan, Renjie and Shi, Boxin and Duan, Ling-Yu and Tan, Ah-Hwee and Kot, Alex C.},<br>\ntitle = {CRRN: Multi-Scale Guided Concurrent Reflection Removal Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Single_Image_Reflection_CVPR_2018_paper.html\">Single Image Reflection Separation With Perceptual Losses</a></dt>\n<dd>\n<form id=\"form-XuanerZhangSingleImageReflection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xuaner Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XuanerZhangSingleImageReflection').submit();\">Xuaner Zhang</a>,\n</form>\n<form id=\"form-RenNgSingleImageReflection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ren Ng\">\n<a href=\"#\" onclick=\"document.getElementById('form-RenNgSingleImageReflection').submit();\">Ren Ng</a>,\n</form>\n<form id=\"form-QifengChenSingleImageReflection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qifeng Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-QifengChenSingleImageReflection').submit();\">Qifeng Chen</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Single_Image_Reflection_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1806.05376\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Xuaner and Ng, Ren and Chen, Qifeng},<br>\ntitle = {Single Image Reflection Separation With Perceptual Losses},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lao_A_Robust_Method_CVPR_2018_paper.html\">A Robust Method for Strong Rolling Shutter Effects Correction Using Lines With Automatic Feature Selection</a></dt>\n<dd>\n<form id=\"form-YizhenLaoARobustMethod\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yizhen Lao\">\n<a href=\"#\" onclick=\"document.getElementById('form-YizhenLaoARobustMethod').submit();\">Yizhen Lao</a>,\n</form>\n<form id=\"form-OmarAit-AiderARobustMethod\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Omar Ait-Aider\">\n<a href=\"#\" onclick=\"document.getElementById('form-OmarAit-AiderARobustMethod').submit();\">Omar Ait-Aider</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lao_A_Robust_Method_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3871-supp.zip\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lao_2018_CVPR,<br>\nauthor = {Lao, Yizhen and Ait-Aider, Omar},<br>\ntitle = {A Robust Method for Strong Rolling Shutter Effects Correction Using Lines With Automatic Feature Selection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tanaka_Time-Resolved_Light_Transport_CVPR_2018_paper.html\">Time-Resolved Light Transport Decomposition for Thermal Photometric Stereo</a></dt>\n<dd>\n<form id=\"form-KenichiroTanakaTimeResolvedLightTransport\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kenichiro Tanaka\">\n<a href=\"#\" onclick=\"document.getElementById('form-KenichiroTanakaTimeResolvedLightTransport').submit();\">Kenichiro Tanaka</a>,\n</form>\n<form id=\"form-NobuhiroIkeyaTimeResolvedLightTransport\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nobuhiro Ikeya\">\n<a href=\"#\" onclick=\"document.getElementById('form-NobuhiroIkeyaTimeResolvedLightTransport').submit();\">Nobuhiro Ikeya</a>,\n</form>\n<form id=\"form-TsuyoshiTakataniTimeResolvedLightTransport\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tsuyoshi Takatani\">\n<a href=\"#\" onclick=\"document.getElementById('form-TsuyoshiTakataniTimeResolvedLightTransport').submit();\">Tsuyoshi Takatani</a>,\n</form>\n<form id=\"form-HiroyukiKuboTimeResolvedLightTransport\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hiroyuki Kubo\">\n<a href=\"#\" onclick=\"document.getElementById('form-HiroyukiKuboTimeResolvedLightTransport').submit();\">Hiroyuki Kubo</a>,\n</form>\n<form id=\"form-TakuyaFunatomiTimeResolvedLightTransport\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Takuya Funatomi\">\n<a href=\"#\" onclick=\"document.getElementById('form-TakuyaFunatomiTimeResolvedLightTransport').submit();\">Takuya Funatomi</a>,\n</form>\n<form id=\"form-YasuhiroMukaigawaTimeResolvedLightTransport\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yasuhiro Mukaigawa\">\n<a href=\"#\" onclick=\"document.getElementById('form-YasuhiroMukaigawaTimeResolvedLightTransport').submit();\">Yasuhiro Mukaigawa</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tanaka_Time-Resolved_Light_Transport_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tanaka_2018_CVPR,<br>\nauthor = {Tanaka, Kenichiro and Ikeya, Nobuhiro and Takatani, Tsuyoshi and Kubo, Hiroyuki and Funatomi, Takuya and Mukaigawa, Yasuhiro},<br>\ntitle = {Time-Resolved Light Transport Decomposition for Thermal Photometric Stereo},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Meshgi_Efficient_Diverse_Ensemble_CVPR_2018_paper.html\">Efficient Diverse Ensemble for Discriminative Co-Tracking</a></dt>\n<dd>\n<form id=\"form-KouroshMeshgiEfficientDiverseEnsemble\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kourosh Meshgi\">\n<a href=\"#\" onclick=\"document.getElementById('form-KouroshMeshgiEfficientDiverseEnsemble').submit();\">Kourosh Meshgi</a>,\n</form>\n<form id=\"form-ShigeyukiObaEfficientDiverseEnsemble\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shigeyuki Oba\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShigeyukiObaEfficientDiverseEnsemble').submit();\">Shigeyuki Oba</a>,\n</form>\n<form id=\"form-ShinIshiiEfficientDiverseEnsemble\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shin Ishii\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShinIshiiEfficientDiverseEnsemble').submit();\">Shin Ishii</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Meshgi_Efficient_Diverse_Ensemble_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.06564\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Meshgi_2018_CVPR,<br>\nauthor = {Meshgi, Kourosh and Oba, Shigeyuki and Ishii, Shin},<br>\ntitle = {Efficient Diverse Ensemble for Discriminative Co-Tracking},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Bapat_Rolling_Shutter_and_CVPR_2018_paper.html\">Rolling Shutter and Radial Distortion Are Features for High Frame Rate Multi-Camera Tracking</a></dt>\n<dd>\n<form id=\"form-AkashBapatRollingShutterand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Akash Bapat\">\n<a href=\"#\" onclick=\"document.getElementById('form-AkashBapatRollingShutterand').submit();\">Akash Bapat</a>,\n</form>\n<form id=\"form-TruePriceRollingShutterand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"True Price\">\n<a href=\"#\" onclick=\"document.getElementById('form-TruePriceRollingShutterand').submit();\">True Price</a>,\n</form>\n<form id=\"form-Jan-MichaelFrahmRollingShutterand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jan-Michael Frahm\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jan-MichaelFrahmRollingShutterand').submit();\">Jan-Michael Frahm</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Bapat_Rolling_Shutter_and_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1949-supp.zip\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Bapat_2018_CVPR,<br>\nauthor = {Bapat, Akash and Price, True and Frahm, Jan-Michael},<br>\ntitle = {Rolling Shutter and Radial Distortion Are Features for High Frame Rate Multi-Camera Tracking},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/He_A_Twofold_Siamese_CVPR_2018_paper.html\">A Twofold Siamese Network for Real-Time Object Tracking</a></dt>\n<dd>\n<form id=\"form-AnfengHeATwofoldSiamese\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anfeng He\">\n<a href=\"#\" onclick=\"document.getElementById('form-AnfengHeATwofoldSiamese').submit();\">Anfeng He</a>,\n</form>\n<form id=\"form-ChongLuoATwofoldSiamese\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chong Luo\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChongLuoATwofoldSiamese').submit();\">Chong Luo</a>,\n</form>\n<form id=\"form-XinmeiTianATwofoldSiamese\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xinmei Tian\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinmeiTianATwofoldSiamese').submit();\">Xinmei Tian</a>,\n</form>\n<form id=\"form-WenjunZengATwofoldSiamese\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenjun Zeng\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenjunZengATwofoldSiamese').submit();\">Wenjun Zeng</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/He_A_Twofold_Siamese_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.08817\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{He_2018_CVPR,<br>\nauthor = {He, Anfeng and Luo, Chong and Tian, Xinmei and Zeng, Wenjun},<br>\ntitle = {A Twofold Siamese Network for Real-Time Object Tracking},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Multi-Cue_Correlation_Filters_CVPR_2018_paper.html\">Multi-Cue Correlation Filters for Robust Visual Tracking</a></dt>\n<dd>\n<form id=\"form-NingWangMultiCueCorrelationFilters\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ning Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-NingWangMultiCueCorrelationFilters').submit();\">Ning Wang</a>,\n</form>\n<form id=\"form-WengangZhouMultiCueCorrelationFilters\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wengang Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-WengangZhouMultiCueCorrelationFilters').submit();\">Wengang Zhou</a>,\n</form>\n<form id=\"form-QiTianMultiCueCorrelationFilters\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qi Tian\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiTianMultiCueCorrelationFilters').submit();\">Qi Tian</a>,\n</form>\n<form id=\"form-RichangHongMultiCueCorrelationFilters\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Richang Hong\">\n<a href=\"#\" onclick=\"document.getElementById('form-RichangHongMultiCueCorrelationFilters').submit();\">Richang Hong</a>,\n</form>\n<form id=\"form-MengWangMultiCueCorrelationFilters\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Meng Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-MengWangMultiCueCorrelationFilters').submit();\">Meng Wang</a>,\n</form>\n<form id=\"form-HouqiangLiMultiCueCorrelationFilters\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Houqiang Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-HouqiangLiMultiCueCorrelationFilters').submit();\">Houqiang Li</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Multi-Cue_Correlation_Filters_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Ning and Zhou, Wengang and Tian, Qi and Hong, Richang and Wang, Meng and Li, Houqiang},<br>\ntitle = {Multi-Cue Correlation Filters for Robust Visual Tracking},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Learning_Attentions_Residual_CVPR_2018_paper.html\">Learning Attentions: Residual Attentional Siamese Network for High Performance Online Visual Tracking</a></dt>\n<dd>\n<form id=\"form-QiangWangLearningAttentionsResidual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qiang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiangWangLearningAttentionsResidual').submit();\">Qiang Wang</a>,\n</form>\n<form id=\"form-ZhuTengLearningAttentionsResidual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhu Teng\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhuTengLearningAttentionsResidual').submit();\">Zhu Teng</a>,\n</form>\n<form id=\"form-JunliangXingLearningAttentionsResidual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junliang Xing\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunliangXingLearningAttentionsResidual').submit();\">Junliang Xing</a>,\n</form>\n<form id=\"form-JinGaoLearningAttentionsResidual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jin Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-JinGaoLearningAttentionsResidual').submit();\">Jin Gao</a>,\n</form>\n<form id=\"form-WeimingHuLearningAttentionsResidual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weiming Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeimingHuLearningAttentionsResidual').submit();\">Weiming Hu</a>,\n</form>\n<form id=\"form-StephenMaybankLearningAttentionsResidual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stephen Maybank\">\n<a href=\"#\" onclick=\"document.getElementById('form-StephenMaybankLearningAttentionsResidual').submit();\">Stephen Maybank</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Learning_Attentions_Residual_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0678-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Qiang and Teng, Zhu and Xing, Junliang and Gao, Jin and Hu, Weiming and Maybank, Stephen},<br>\ntitle = {Learning Attentions: Residual Attentional Siamese Network for High Performance Online Visual Tracking},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_SINT_Robust_Visual_CVPR_2018_paper.html\">SINT++: Robust Visual Tracking via Adversarial Positive Instance Generation</a></dt>\n<dd>\n<form id=\"form-XiaoWangSINTRobustVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiao Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaoWangSINTRobustVisual').submit();\">Xiao Wang</a>,\n</form>\n<form id=\"form-ChenglongLiSINTRobustVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chenglong Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenglongLiSINTRobustVisual').submit();\">Chenglong Li</a>,\n</form>\n<form id=\"form-BinLuoSINTRobustVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bin Luo\">\n<a href=\"#\" onclick=\"document.getElementById('form-BinLuoSINTRobustVisual').submit();\">Bin Luo</a>,\n</form>\n<form id=\"form-JinTangSINTRobustVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jin Tang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JinTangSINTRobustVisual').submit();\">Jin Tang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_SINT_Robust_Visual_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Xiao and Li, Chenglong and Luo, Bin and Tang, Jin},<br>\ntitle = {SINT++: Robust Visual Tracking via Adversarial Positive Instance Generation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tang_High-Speed_Tracking_With_CVPR_2018_paper.html\">High-Speed Tracking With Multi-Kernel Correlation Filters</a></dt>\n<dd>\n<form id=\"form-MingTangHighSpeedTrackingWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming Tang\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingTangHighSpeedTrackingWith').submit();\">Ming Tang</a>,\n</form>\n<form id=\"form-BinYuHighSpeedTrackingWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bin Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-BinYuHighSpeedTrackingWith').submit();\">Bin Yu</a>,\n</form>\n<form id=\"form-FanZhangHighSpeedTrackingWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fan Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-FanZhangHighSpeedTrackingWith').submit();\">Fan Zhang</a>,\n</form>\n<form id=\"form-JinqiaoWangHighSpeedTrackingWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jinqiao Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JinqiaoWangHighSpeedTrackingWith').submit();\">Jinqiao Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tang_High-Speed_Tracking_With_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2129-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1806.06418\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tang_2018_CVPR,<br>\nauthor = {Tang, Ming and Yu, Bin and Zhang, Fan and Wang, Jinqiao},<br>\ntitle = {High-Speed Tracking With Multi-Kernel Correlation Filters},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Occlusion_Aware_Unsupervised_CVPR_2018_paper.html\">Occlusion Aware Unsupervised Learning of Optical Flow</a></dt>\n<dd>\n<form id=\"form-YangWangOcclusionAwareUnsupervised\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YangWangOcclusionAwareUnsupervised').submit();\">Yang Wang</a>,\n</form>\n<form id=\"form-YiYangOcclusionAwareUnsupervised\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiYangOcclusionAwareUnsupervised').submit();\">Yi Yang</a>,\n</form>\n<form id=\"form-ZhenhengYangOcclusionAwareUnsupervised\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhenheng Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhenhengYangOcclusionAwareUnsupervised').submit();\">Zhenheng Yang</a>,\n</form>\n<form id=\"form-LiangZhaoOcclusionAwareUnsupervised\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liang Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiangZhaoOcclusionAwareUnsupervised').submit();\">Liang Zhao</a>,\n</form>\n<form id=\"form-PengWangOcclusionAwareUnsupervised\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peng Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-PengWangOcclusionAwareUnsupervised').submit();\">Peng Wang</a>,\n</form>\n<form id=\"form-WeiXuOcclusionAwareUnsupervised\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiXuOcclusionAwareUnsupervised').submit();\">Wei Xu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Occlusion_Aware_Unsupervised_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3285-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.05890\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Yang and Yang, Yi and Yang, Zhenheng and Zhao, Liang and Wang, Peng and Xu, Wei},<br>\ntitle = {Occlusion Aware Unsupervised Learning of Optical Flow},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Revisiting_Video_Saliency_CVPR_2018_paper.html\">Revisiting Video Saliency: A Large-Scale Benchmark and a New Model</a></dt>\n<dd>\n<form id=\"form-WenguanWangRevisitingVideoSaliency\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenguan Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenguanWangRevisitingVideoSaliency').submit();\">Wenguan Wang</a>,\n</form>\n<form id=\"form-JianbingShenRevisitingVideoSaliency\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianbing Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianbingShenRevisitingVideoSaliency').submit();\">Jianbing Shen</a>,\n</form>\n<form id=\"form-FangGuoRevisitingVideoSaliency\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fang Guo\">\n<a href=\"#\" onclick=\"document.getElementById('form-FangGuoRevisitingVideoSaliency').submit();\">Fang Guo</a>,\n</form>\n<form id=\"form-Ming-MingChengRevisitingVideoSaliency\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming-Ming Cheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ming-MingChengRevisitingVideoSaliency').submit();\">Ming-Ming Cheng</a>,\n</form>\n<form id=\"form-AliBorjiRevisitingVideoSaliency\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ali Borji\">\n<a href=\"#\" onclick=\"document.getElementById('form-AliBorjiRevisitingVideoSaliency').submit();\">Ali Borji</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Revisiting_Video_Saliency_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.07424\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Wenguan and Shen, Jianbing and Guo, Fang and Cheng, Ming-Ming and Borji, Ali},<br>\ntitle = {Revisiting Video Saliency: A Large-Scale Benchmark and a New Model},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Learning_Spatial-Temporal_Regularized_CVPR_2018_paper.html\">Learning Spatial-Temporal Regularized Correlation Filters for Visual Tracking</a></dt>\n<dd>\n<form id=\"form-FengLiLearningSpatialTemporalRegularized\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Feng Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-FengLiLearningSpatialTemporalRegularized').submit();\">Feng Li</a>,\n</form>\n<form id=\"form-ChengTianLearningSpatialTemporalRegularized\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cheng Tian\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChengTianLearningSpatialTemporalRegularized').submit();\">Cheng Tian</a>,\n</form>\n<form id=\"form-WangmengZuoLearningSpatialTemporalRegularized\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wangmeng Zuo\">\n<a href=\"#\" onclick=\"document.getElementById('form-WangmengZuoLearningSpatialTemporalRegularized').submit();\">Wangmeng Zuo</a>,\n</form>\n<form id=\"form-LeiZhangLearningSpatialTemporalRegularized\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lei Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeiZhangLearningSpatialTemporalRegularized').submit();\">Lei Zhang</a>,\n</form>\n<form id=\"form-Ming-HsuanYangLearningSpatialTemporalRegularized\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming-Hsuan Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ming-HsuanYangLearningSpatialTemporalRegularized').submit();\">Ming-Hsuan Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Learning_Spatial-Temporal_Regularized_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1353-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.08679\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Feng and Tian, Cheng and Zuo, Wangmeng and Zhang, Lei and Yang, Ming-Hsuan},<br>\ntitle = {Learning Spatial-Temporal Regularized Correlation Filters for Visual Tracking},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Bouritsas_Multimodal_Visual_Concept_CVPR_2018_paper.html\">Multimodal Visual Concept Learning With Weakly Supervised Techniques</a></dt>\n<dd>\n<form id=\"form-GiorgosBouritsasMultimodalVisualConcept\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Giorgos Bouritsas\">\n<a href=\"#\" onclick=\"document.getElementById('form-GiorgosBouritsasMultimodalVisualConcept').submit();\">Giorgos Bouritsas</a>,\n</form>\n<form id=\"form-PetrosKoutrasMultimodalVisualConcept\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Petros Koutras\">\n<a href=\"#\" onclick=\"document.getElementById('form-PetrosKoutrasMultimodalVisualConcept').submit();\">Petros Koutras</a>,\n</form>\n<form id=\"form-AthanasiaZlatintsiMultimodalVisualConcept\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Athanasia Zlatintsi\">\n<a href=\"#\" onclick=\"document.getElementById('form-AthanasiaZlatintsiMultimodalVisualConcept').submit();\">Athanasia Zlatintsi</a>,\n</form>\n<form id=\"form-PetrosMaragosMultimodalVisualConcept\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Petros Maragos\">\n<a href=\"#\" onclick=\"document.getElementById('form-PetrosMaragosMultimodalVisualConcept').submit();\">Petros Maragos</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Bouritsas_Multimodal_Visual_Concept_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.00796\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Bouritsas_2018_CVPR,<br>\nauthor = {Bouritsas, Giorgos and Koutras, Petros and Zlatintsi, Athanasia and Maragos, Petros},<br>\ntitle = {Multimodal Visual Concept Learning With Weakly Supervised Techniques},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Efficient_Large-Scale_Approximate_CVPR_2018_paper.html\">Efficient Large-Scale Approximate Nearest Neighbor Search on OpenCL FPGA</a></dt>\n<dd>\n<form id=\"form-JialiangZhangEfficientLargeScaleApproximate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jialiang Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JialiangZhangEfficientLargeScaleApproximate').submit();\">Jialiang Zhang</a>,\n</form>\n<form id=\"form-SorooshKhoramEfficientLargeScaleApproximate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Soroosh Khoram\">\n<a href=\"#\" onclick=\"document.getElementById('form-SorooshKhoramEfficientLargeScaleApproximate').submit();\">Soroosh Khoram</a>,\n</form>\n<form id=\"form-JingLiEfficientLargeScaleApproximate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jing Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingLiEfficientLargeScaleApproximate').submit();\">Jing Li</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Efficient_Large-Scale_Approximate_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Jialiang and Khoram, Soroosh and Li, Jing},<br>\ntitle = {Efficient Large-Scale Approximate Nearest Neighbor Search on OpenCL FPGA},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Jain_Learning_a_Complete_CVPR_2018_paper.html\">Learning a Complete Image Indexing Pipeline</a></dt>\n<dd>\n<form id=\"form-HimalayaJainLearningaComplete\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Himalaya Jain\">\n<a href=\"#\" onclick=\"document.getElementById('form-HimalayaJainLearningaComplete').submit();\">Himalaya Jain</a>,\n</form>\n<form id=\"form-JoaquinZepedaLearningaComplete\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Joaquin Zepeda\">\n<a href=\"#\" onclick=\"document.getElementById('form-JoaquinZepedaLearningaComplete').submit();\">Joaquin Zepeda</a>,\n</form>\n<form id=\"form-PatrickP\u00c3\u00a9rezLearningaComplete\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Patrick P\u00c3\u00a9rez\">\n<a href=\"#\" onclick=\"document.getElementById('form-PatrickP\u00c3\u00a9rezLearningaComplete').submit();\">Patrick P\u00c3\u00a9rez</a>,\n</form>\n<form id=\"form-R\u00c3\u00a9miGribonvalLearningaComplete\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"R\u00c3\u00a9mi Gribonval\">\n<a href=\"#\" onclick=\"document.getElementById('form-R\u00c3\u00a9miGribonvalLearningaComplete').submit();\">R\u00c3\u00a9mi Gribonval</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Jain_Learning_a_Complete_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.04480\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Jain_2018_CVPR,<br>\nauthor = {Jain, Himalaya and Zepeda, Joaquin and P\u00c3\u00a9rez, Patrick and Gribonval, R\u00c3\u00a9mi},<br>\ntitle = {Learning a Complete Image Indexing Pipeline},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Mascharka_Transparency_by_Design_CVPR_2018_paper.html\">Transparency by Design: Closing the Gap Between Performance and Interpretability in Visual Reasoning</a></dt>\n<dd>\n<form id=\"form-DavidMascharkaTransparencybyDesign\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"David Mascharka\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavidMascharkaTransparencybyDesign').submit();\">David Mascharka</a>,\n</form>\n<form id=\"form-PhilipTranTransparencybyDesign\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Philip Tran\">\n<a href=\"#\" onclick=\"document.getElementById('form-PhilipTranTransparencybyDesign').submit();\">Philip Tran</a>,\n</form>\n<form id=\"form-RyanSoklaskiTransparencybyDesign\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ryan Soklaski\">\n<a href=\"#\" onclick=\"document.getElementById('form-RyanSoklaskiTransparencybyDesign').submit();\">Ryan Soklaski</a>,\n</form>\n<form id=\"form-ArjunMajumdarTransparencybyDesign\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Arjun Majumdar\">\n<a href=\"#\" onclick=\"document.getElementById('form-ArjunMajumdarTransparencybyDesign').submit();\">Arjun Majumdar</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Mascharka_Transparency_by_Design_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3279-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.05268\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Mascharka_2018_CVPR,<br>\nauthor = {Mascharka, David and Tran, Philip and Soklaski, Ryan and Majumdar, Arjun},<br>\ntitle = {Transparency by Design: Closing the Gap Between Performance and Interpretability in Visual Reasoning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xu_Fooling_Vision_and_CVPR_2018_paper.html\">Fooling Vision and Language Models Despite Localization and Attention Mechanism</a></dt>\n<dd>\n<form id=\"form-XiaojunXuFoolingVisionand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaojun Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaojunXuFoolingVisionand').submit();\">Xiaojun Xu</a>,\n</form>\n<form id=\"form-XinyunChenFoolingVisionand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xinyun Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinyunChenFoolingVisionand').submit();\">Xinyun Chen</a>,\n</form>\n<form id=\"form-ChangLiuFoolingVisionand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chang Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChangLiuFoolingVisionand').submit();\">Chang Liu</a>,\n</form>\n<form id=\"form-AnnaRohrbachFoolingVisionand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anna Rohrbach\">\n<a href=\"#\" onclick=\"document.getElementById('form-AnnaRohrbachFoolingVisionand').submit();\">Anna Rohrbach</a>,\n</form>\n<form id=\"form-TrevorDarrellFoolingVisionand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Trevor Darrell\">\n<a href=\"#\" onclick=\"document.getElementById('form-TrevorDarrellFoolingVisionand').submit();\">Trevor Darrell</a>,\n</form>\n<form id=\"form-DawnSongFoolingVisionand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dawn Song\">\n<a href=\"#\" onclick=\"document.getElementById('form-DawnSongFoolingVisionand').submit();\">Dawn Song</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xu_Fooling_Vision_and_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3295-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1709.08693\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xu_2018_CVPR,<br>\nauthor = {Xu, Xiaojun and Chen, Xinyun and Liu, Chang and Rohrbach, Anna and Darrell, Trevor and Song, Dawn},<br>\ntitle = {Fooling Vision and Language Models Despite Localization and Attention Mechanism},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Categorizing_Concepts_With_CVPR_2018_paper.html\">Categorizing Concepts With Basic Level for Vision-to-Language</a></dt>\n<dd>\n<form id=\"form-HanzhangWangCategorizingConceptsWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hanzhang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HanzhangWangCategorizingConceptsWith').submit();\">Hanzhang Wang</a>,\n</form>\n<form id=\"form-HanliWangCategorizingConceptsWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hanli Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HanliWangCategorizingConceptsWith').submit();\">Hanli Wang</a>,\n</form>\n<form id=\"form-KaishengXuCategorizingConceptsWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kaisheng Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaishengXuCategorizingConceptsWith').submit();\">Kaisheng Xu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Categorizing_Concepts_With_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Hanzhang and Wang, Hanli and Xu, Kaisheng},<br>\ntitle = {Categorizing Concepts With Basic Level for Vision-to-Language},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Agrawal_Dont_Just_Assume_CVPR_2018_paper.html\">Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering</a></dt>\n<dd>\n<form id=\"form-AishwaryaAgrawalDontJustAssume\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Aishwarya Agrawal\">\n<a href=\"#\" onclick=\"document.getElementById('form-AishwaryaAgrawalDontJustAssume').submit();\">Aishwarya Agrawal</a>,\n</form>\n<form id=\"form-DhruvBatraDontJustAssume\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dhruv Batra\">\n<a href=\"#\" onclick=\"document.getElementById('form-DhruvBatraDontJustAssume').submit();\">Dhruv Batra</a>,\n</form>\n<form id=\"form-DeviParikhDontJustAssume\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Devi Parikh\">\n<a href=\"#\" onclick=\"document.getElementById('form-DeviParikhDontJustAssume').submit();\">Devi Parikh</a>,\n</form>\n<form id=\"form-AniruddhaKembhaviDontJustAssume\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Aniruddha Kembhavi\">\n<a href=\"#\" onclick=\"document.getElementById('form-AniruddhaKembhaviDontJustAssume').submit();\">Aniruddha Kembhavi</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Agrawal_Dont_Just_Assume_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.00377\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Agrawal_2018_CVPR,<br>\nauthor = {Agrawal, Aishwarya and Batra, Dhruv and Parikh, Devi and Kembhavi, Aniruddha},<br>\ntitle = {Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ahn_Learning_Pixel-Level_Semantic_CVPR_2018_paper.html\">Learning Pixel-Level Semantic Affinity With Image-Level Supervision for Weakly Supervised Semantic Segmentation</a></dt>\n<dd>\n<form id=\"form-JiwoonAhnLearningPixelLevelSemantic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiwoon Ahn\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiwoonAhnLearningPixelLevelSemantic').submit();\">Jiwoon Ahn</a>,\n</form>\n<form id=\"form-SuhaKwakLearningPixelLevelSemantic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Suha Kwak\">\n<a href=\"#\" onclick=\"document.getElementById('form-SuhaKwakLearningPixelLevelSemantic').submit();\">Suha Kwak</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ahn_Learning_Pixel-Level_Semantic_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.10464\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ahn_2018_CVPR,<br>\nauthor = {Ahn, Jiwoon and Kwak, Suha},<br>\ntitle = {Learning Pixel-Level Semantic Affinity With Image-Level Supervision for Weakly Supervised Semantic Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Fouhey_From_Lifestyle_Vlogs_CVPR_2018_paper.html\">From Lifestyle Vlogs to Everyday Interactions</a></dt>\n<dd>\n<form id=\"form-DavidF.FromLifestyleVlogs\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"David F. Fouhey\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavidF.FromLifestyleVlogs').submit();\">David F. Fouhey</a>,\n</form>\n<form id=\"form-Wei-chengKuoFromLifestyleVlogs\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei-cheng Kuo\">\n<a href=\"#\" onclick=\"document.getElementById('form-Wei-chengKuoFromLifestyleVlogs').submit();\">Wei-cheng Kuo</a>,\n</form>\n<form id=\"form-AlexeiA.FromLifestyleVlogs\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexei A. Efros\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexeiA.FromLifestyleVlogs').submit();\">Alexei A. Efros</a>,\n</form>\n<form id=\"form-JitendraMalikFromLifestyleVlogs\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jitendra Malik\">\n<a href=\"#\" onclick=\"document.getElementById('form-JitendraMalikFromLifestyleVlogs').submit();\">Jitendra Malik</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Fouhey_From_Lifestyle_Vlogs_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.02310\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Fouhey_2018_CVPR,<br>\nauthor = {Fouhey, David F. and Kuo, Wei-cheng and Efros, Alexei A. and Malik, Jitendra},<br>\ntitle = {From Lifestyle Vlogs to Everyday Interactions},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Inoue_Cross-Domain_Weakly-Supervised_Object_CVPR_2018_paper.html\">Cross-Domain Weakly-Supervised Object Detection Through Progressive Domain Adaptation</a></dt>\n<dd>\n<form id=\"form-NaotoInoueCrossDomainWeaklySupervisedObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Naoto Inoue\">\n<a href=\"#\" onclick=\"document.getElementById('form-NaotoInoueCrossDomainWeaklySupervisedObject').submit();\">Naoto Inoue</a>,\n</form>\n<form id=\"form-RyosukeFurutaCrossDomainWeaklySupervisedObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ryosuke Furuta\">\n<a href=\"#\" onclick=\"document.getElementById('form-RyosukeFurutaCrossDomainWeaklySupervisedObject').submit();\">Ryosuke Furuta</a>,\n</form>\n<form id=\"form-ToshihikoYamasakiCrossDomainWeaklySupervisedObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Toshihiko Yamasaki\">\n<a href=\"#\" onclick=\"document.getElementById('form-ToshihikoYamasakiCrossDomainWeaklySupervisedObject').submit();\">Toshihiko Yamasaki</a>,\n</form>\n<form id=\"form-KiyoharuAizawaCrossDomainWeaklySupervisedObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kiyoharu Aizawa\">\n<a href=\"#\" onclick=\"document.getElementById('form-KiyoharuAizawaCrossDomainWeaklySupervisedObject').submit();\">Kiyoharu Aizawa</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Inoue_Cross-Domain_Weakly-Supervised_Object_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1164-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.11365\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Inoue_2018_CVPR,<br>\nauthor = {Inoue, Naoto and Furuta, Ryosuke and Yamasaki, Toshihiko and Aizawa, Kiyoharu},<br>\ntitle = {Cross-Domain Weakly-Supervised Object Detection Through Progressive Domain Adaptation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kanezaki_RotationNet_Joint_Object_CVPR_2018_paper.html\">RotationNet: Joint Object Categorization and Pose Estimation Using Multiviews From Unsupervised Viewpoints</a></dt>\n<dd>\n<form id=\"form-AsakoKanezakiRotationNetJointObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Asako Kanezaki\">\n<a href=\"#\" onclick=\"document.getElementById('form-AsakoKanezakiRotationNetJointObject').submit();\">Asako Kanezaki</a>,\n</form>\n<form id=\"form-YasuyukiMatsushitaRotationNetJointObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yasuyuki Matsushita\">\n<a href=\"#\" onclick=\"document.getElementById('form-YasuyukiMatsushitaRotationNetJointObject').submit();\">Yasuyuki Matsushita</a>,\n</form>\n<form id=\"form-YoshifumiNishidaRotationNetJointObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yoshifumi Nishida\">\n<a href=\"#\" onclick=\"document.getElementById('form-YoshifumiNishidaRotationNetJointObject').submit();\">Yoshifumi Nishida</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kanezaki_RotationNet_Joint_Object_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1282-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1603.06208\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kanezaki_2018_CVPR,<br>\nauthor = {Kanezaki, Asako and Matsushita, Yasuyuki and Nishida, Yoshifumi},<br>\ntitle = {RotationNet: Joint Object Categorization and Pose Estimation Using Multiviews From Unsupervised Viewpoints},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/He_An_End-to-End_TextSpotter_CVPR_2018_paper.html\">An End-to-End TextSpotter With Explicit Alignment and Attention</a></dt>\n<dd>\n<form id=\"form-TongHeAnEndtoEndTextSpotter\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tong He\">\n<a href=\"#\" onclick=\"document.getElementById('form-TongHeAnEndtoEndTextSpotter').submit();\">Tong He</a>,\n</form>\n<form id=\"form-ZhiTianAnEndtoEndTextSpotter\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhi Tian\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhiTianAnEndtoEndTextSpotter').submit();\">Zhi Tian</a>,\n</form>\n<form id=\"form-WeilinHuangAnEndtoEndTextSpotter\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weilin Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeilinHuangAnEndtoEndTextSpotter').submit();\">Weilin Huang</a>,\n</form>\n<form id=\"form-ChunhuaShenAnEndtoEndTextSpotter\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chunhua Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChunhuaShenAnEndtoEndTextSpotter').submit();\">Chunhua Shen</a>,\n</form>\n<form id=\"form-YuQiaoAnEndtoEndTextSpotter\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu Qiao\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuQiaoAnEndtoEndTextSpotter').submit();\">Yu Qiao</a>,\n</form>\n<form id=\"form-ChangmingSunAnEndtoEndTextSpotter\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Changming Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChangmingSunAnEndtoEndTextSpotter').submit();\">Changming Sun</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/He_An_End-to-End_TextSpotter_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.03474\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{He_2018_CVPR,<br>\nauthor = {He, Tong and Tian, Zhi and Huang, Weilin and Shen, Chunhua and Qiao, Yu and Sun, Changming},<br>\ntitle = {An End-to-End TextSpotter With Explicit Alignment and Attention},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chavdarova_WILDTRACK_A_Multi-Camera_CVPR_2018_paper.html\">WILDTRACK: A Multi-Camera HD Dataset for Dense Unscripted Pedestrian Detection</a></dt>\n<dd>\n<form id=\"form-TatjanaChavdarovaWILDTRACKAMultiCamera\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tatjana Chavdarova\">\n<a href=\"#\" onclick=\"document.getElementById('form-TatjanaChavdarovaWILDTRACKAMultiCamera').submit();\">Tatjana Chavdarova</a>,\n</form>\n<form id=\"form-PierreBaqu\u00c3\u00a9WILDTRACKAMultiCamera\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pierre Baqu\u00c3\u00a9\">\n<a href=\"#\" onclick=\"document.getElementById('form-PierreBaqu\u00c3\u00a9WILDTRACKAMultiCamera').submit();\">Pierre Baqu\u00c3\u00a9</a>,\n</form>\n<form id=\"form-St\u00c3\u00a9phaneBouquetWILDTRACKAMultiCamera\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"St\u00c3\u00a9phane Bouquet\">\n<a href=\"#\" onclick=\"document.getElementById('form-St\u00c3\u00a9phaneBouquetWILDTRACKAMultiCamera').submit();\">St\u00c3\u00a9phane Bouquet</a>,\n</form>\n<form id=\"form-AndriiMaksaiWILDTRACKAMultiCamera\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrii Maksai\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndriiMaksaiWILDTRACKAMultiCamera').submit();\">Andrii Maksai</a>,\n</form>\n<form id=\"form-CijoJoseWILDTRACKAMultiCamera\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cijo Jose\">\n<a href=\"#\" onclick=\"document.getElementById('form-CijoJoseWILDTRACKAMultiCamera').submit();\">Cijo Jose</a>,\n</form>\n<form id=\"form-TimurBagautdinovWILDTRACKAMultiCamera\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Timur Bagautdinov\">\n<a href=\"#\" onclick=\"document.getElementById('form-TimurBagautdinovWILDTRACKAMultiCamera').submit();\">Timur Bagautdinov</a>,\n</form>\n<form id=\"form-LouisLettryWILDTRACKAMultiCamera\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Louis Lettry\">\n<a href=\"#\" onclick=\"document.getElementById('form-LouisLettryWILDTRACKAMultiCamera').submit();\">Louis Lettry</a>,\n</form>\n<form id=\"form-PascalFuaWILDTRACKAMultiCamera\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pascal Fua\">\n<a href=\"#\" onclick=\"document.getElementById('form-PascalFuaWILDTRACKAMultiCamera').submit();\">Pascal Fua</a>,\n</form>\n<form id=\"form-LucVanWILDTRACKAMultiCamera\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Luc Van Gool\">\n<a href=\"#\" onclick=\"document.getElementById('form-LucVanWILDTRACKAMultiCamera').submit();\">Luc Van Gool</a>,\n</form>\n<form id=\"form-Fran\u00c3\u00a7oisFleuretWILDTRACKAMultiCamera\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fran\u00c3\u00a7ois Fleuret\">\n<a href=\"#\" onclick=\"document.getElementById('form-Fran\u00c3\u00a7oisFleuretWILDTRACKAMultiCamera').submit();\">Fran\u00c3\u00a7ois Fleuret</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chavdarova_WILDTRACK_A_Multi-Camera_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1562-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chavdarova_2018_CVPR,<br>\nauthor = {Chavdarova, Tatjana and Baqu\u00c3\u00a9, Pierre and Bouquet, St\u00c3\u00a9phane and Maksai, Andrii and Jose, Cijo and Bagautdinov, Timur and Lettry, Louis and Fua, Pascal and Van Gool, Luc and Fleuret, Fran\u00c3\u00a7ois},<br>\ntitle = {WILDTRACK: A Multi-Camera HD Dataset for Dense Unscripted Pedestrian Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Miao_Direct_Shape_Regression_CVPR_2018_paper.html\">Direct Shape Regression Networks for End-to-End Face Alignment</a></dt>\n<dd>\n<form id=\"form-XinMiaoDirectShapeRegression\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xin Miao\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinMiaoDirectShapeRegression').submit();\">Xin Miao</a>,\n</form>\n<form id=\"form-XiantongZhenDirectShapeRegression\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiantong Zhen\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiantongZhenDirectShapeRegression').submit();\">Xiantong Zhen</a>,\n</form>\n<form id=\"form-XianglongLiuDirectShapeRegression\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xianglong Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XianglongLiuDirectShapeRegression').submit();\">Xianglong Liu</a>,\n</form>\n<form id=\"form-ChengDengDirectShapeRegression\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cheng Deng\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChengDengDirectShapeRegression').submit();\">Cheng Deng</a>,\n</form>\n<form id=\"form-VassilisAthitsosDirectShapeRegression\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vassilis Athitsos\">\n<a href=\"#\" onclick=\"document.getElementById('form-VassilisAthitsosDirectShapeRegression').submit();\">Vassilis Athitsos</a>,\n</form>\n<form id=\"form-HengHuangDirectShapeRegression\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Heng Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HengHuangDirectShapeRegression').submit();\">Heng Huang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Miao_Direct_Shape_Regression_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Miao_2018_CVPR,<br>\nauthor = {Miao, Xin and Zhen, Xiantong and Liu, Xianglong and Deng, Cheng and Athitsos, Vassilis and Huang, Heng},<br>\ntitle = {Direct Shape Regression Networks for End-to-End Face Alignment},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sun_Natural_and_Effective_CVPR_2018_paper.html\">Natural and Effective Obfuscation by Head Inpainting</a></dt>\n<dd>\n<form id=\"form-QianruSunNaturalandEffective\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qianru Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-QianruSunNaturalandEffective').submit();\">Qianru Sun</a>,\n</form>\n<form id=\"form-LiqianMaNaturalandEffective\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liqian Ma\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiqianMaNaturalandEffective').submit();\">Liqian Ma</a>,\n</form>\n<form id=\"form-SeongJoonNaturalandEffective\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Seong Joon Oh\">\n<a href=\"#\" onclick=\"document.getElementById('form-SeongJoonNaturalandEffective').submit();\">Seong Joon Oh</a>,\n</form>\n<form id=\"form-LucVanNaturalandEffective\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Luc Van Gool\">\n<a href=\"#\" onclick=\"document.getElementById('form-LucVanNaturalandEffective').submit();\">Luc Van Gool</a>,\n</form>\n<form id=\"form-BerntSchieleNaturalandEffective\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bernt Schiele\">\n<a href=\"#\" onclick=\"document.getElementById('form-BerntSchieleNaturalandEffective').submit();\">Bernt Schiele</a>,\n</form>\n<form id=\"form-MarioFritzNaturalandEffective\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mario Fritz\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarioFritzNaturalandEffective').submit();\">Mario Fritz</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sun_Natural_and_Effective_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1817-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.09001\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sun_2018_CVPR,<br>\nauthor = {Sun, Qianru and Ma, Liqian and Joon Oh, Seong and Van Gool, Luc and Schiele, Bernt and Fritz, Mario},<br>\ntitle = {Natural and Effective Obfuscation by Head Inpainting},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yoon_3D_Semantic_Trajectory_CVPR_2018_paper.html\">3D Semantic Trajectory Reconstruction From 3D Pixel Continuum</a></dt>\n<dd>\n<form id=\"form-JaeShin3DSemanticTrajectory\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jae Shin Yoon\">\n<a href=\"#\" onclick=\"document.getElementById('form-JaeShin3DSemanticTrajectory').submit();\">Jae Shin Yoon</a>,\n</form>\n<form id=\"form-ZiweiLi3DSemanticTrajectory\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ziwei Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZiweiLi3DSemanticTrajectory').submit();\">Ziwei Li</a>,\n</form>\n<form id=\"form-HyunSoo3DSemanticTrajectory\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hyun Soo Park\">\n<a href=\"#\" onclick=\"document.getElementById('form-HyunSoo3DSemanticTrajectory').submit();\">Hyun Soo Park</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yoon_3D_Semantic_Trajectory_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.01359\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yoon_2018_CVPR,<br>\nauthor = {Shin Yoon, Jae and Li, Ziwei and Soo Park, Hyun},<br>\ntitle = {3D Semantic Trajectory Reconstruction From 3D Pixel Continuum},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Han_Optimizing_Filter_Size_CVPR_2018_paper.html\">Optimizing Filter Size in Convolutional Neural Networks for Facial Action Unit Recognition</a></dt>\n<dd>\n<form id=\"form-ShizhongHanOptimizingFilterSize\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shizhong Han\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShizhongHanOptimizingFilterSize').submit();\">Shizhong Han</a>,\n</form>\n<form id=\"form-ZiboMengOptimizingFilterSize\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zibo Meng\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZiboMengOptimizingFilterSize').submit();\">Zibo Meng</a>,\n</form>\n<form id=\"form-ZhiyuanLiOptimizingFilterSize\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhiyuan Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhiyuanLiOptimizingFilterSize').submit();\">Zhiyuan Li</a>,\n</form>\n<form id=\"form-JamesOReillyOptimizingFilterSize\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"James O'Reilly\">\n<a href=\"#\" onclick=\"document.getElementById('form-JamesOReillyOptimizingFilterSize').submit();\">James O'Reilly</a>,\n</form>\n<form id=\"form-JieCaiOptimizingFilterSize\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jie Cai\">\n<a href=\"#\" onclick=\"document.getElementById('form-JieCaiOptimizingFilterSize').submit();\">Jie Cai</a>,\n</form>\n<form id=\"form-XiaofengWangOptimizingFilterSize\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaofeng Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaofengWangOptimizingFilterSize').submit();\">Xiaofeng Wang</a>,\n</form>\n<form id=\"form-YanTongOptimizingFilterSize\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yan Tong\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanTongOptimizingFilterSize').submit();\">Yan Tong</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Han_Optimizing_Filter_Size_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1707.08630\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Han_2018_CVPR,<br>\nauthor = {Han, Shizhong and Meng, Zibo and Li, Zhiyuan and O'Reilly, James and Cai, Jie and Wang, Xiaofeng and Tong, Yan},<br>\ntitle = {Optimizing Filter Size in Convolutional Neural Networks for Facial Action Unit Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Moon_V2V-PoseNet_Voxel-to-Voxel_Prediction_CVPR_2018_paper.html\">V2V-PoseNet: Voxel-to-Voxel Prediction Network for Accurate 3D Hand and Human Pose Estimation From a Single Depth Map</a></dt>\n<dd>\n<form id=\"form-GyeongsikMoonV2VPoseNetVoxeltoVoxelPrediction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gyeongsik Moon\">\n<a href=\"#\" onclick=\"document.getElementById('form-GyeongsikMoonV2VPoseNetVoxeltoVoxelPrediction').submit();\">Gyeongsik Moon</a>,\n</form>\n<form id=\"form-JuYongV2VPoseNetVoxeltoVoxelPrediction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ju Yong Chang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JuYongV2VPoseNetVoxeltoVoxelPrediction').submit();\">Ju Yong Chang</a>,\n</form>\n<form id=\"form-KyoungMuV2VPoseNetVoxeltoVoxelPrediction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kyoung Mu Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-KyoungMuV2VPoseNetVoxeltoVoxelPrediction').submit();\">Kyoung Mu Lee</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Moon_V2V-PoseNet_Voxel-to-Voxel_Prediction_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2548-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.07399\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Moon_2018_CVPR,<br>\nauthor = {Moon, Gyeongsik and Yong Chang, Ju and Mu Lee, Kyoung},<br>\ntitle = {V2V-PoseNet: Voxel-to-Voxel Prediction Network for Accurate 3D Hand and Human Pose Estimation From a Single Depth Map},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zheng_Ring_Loss_Convex_CVPR_2018_paper.html\">Ring Loss: Convex Feature Normalization for Face Recognition</a></dt>\n<dd>\n<form id=\"form-YutongZhengRingLossConvex\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yutong Zheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-YutongZhengRingLossConvex').submit();\">Yutong Zheng</a>,\n</form>\n<form id=\"form-DipanK.RingLossConvex\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dipan K. Pal\">\n<a href=\"#\" onclick=\"document.getElementById('form-DipanK.RingLossConvex').submit();\">Dipan K. Pal</a>,\n</form>\n<form id=\"form-MariosSavvidesRingLossConvex\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Marios Savvides\">\n<a href=\"#\" onclick=\"document.getElementById('form-MariosSavvidesRingLossConvex').submit();\">Marios Savvides</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zheng_Ring_Loss_Convex_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.00130\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zheng_2018_CVPR,<br>\nauthor = {Zheng, Yutong and Pal, Dipan K. and Savvides, Marios},<br>\ntitle = {Ring Loss: Convex Feature Normalization for Face Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Huang_Adversarially_Occluded_Samples_CVPR_2018_paper.html\">Adversarially Occluded Samples for Person Re-Identification</a></dt>\n<dd>\n<form id=\"form-HoujingHuangAdversariallyOccludedSamples\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Houjing Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HoujingHuangAdversariallyOccludedSamples').submit();\">Houjing Huang</a>,\n</form>\n<form id=\"form-DangweiLiAdversariallyOccludedSamples\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dangwei Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-DangweiLiAdversariallyOccludedSamples').submit();\">Dangwei Li</a>,\n</form>\n<form id=\"form-ZhangZhangAdversariallyOccludedSamples\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhang Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhangZhangAdversariallyOccludedSamples').submit();\">Zhang Zhang</a>,\n</form>\n<form id=\"form-XiaotangChenAdversariallyOccludedSamples\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaotang Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaotangChenAdversariallyOccludedSamples').submit();\">Xiaotang Chen</a>,\n</form>\n<form id=\"form-KaiqiHuangAdversariallyOccludedSamples\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kaiqi Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaiqiHuangAdversariallyOccludedSamples').submit();\">Kaiqi Huang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Huang_Adversarially_Occluded_Samples_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2864-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Huang_2018_CVPR,<br>\nauthor = {Huang, Houjing and Li, Dangwei and Zhang, Zhang and Chen, Xiaotang and Huang, Kaiqi},<br>\ntitle = {Adversarially Occluded Samples for Person Re-Identification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Classifier_Learning_With_CVPR_2018_paper.html\">Classifier Learning With Prior Probabilities for Facial Action Unit Recognition</a></dt>\n<dd>\n<form id=\"form-YongZhangClassifierLearningWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yong Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YongZhangClassifierLearningWith').submit();\">Yong Zhang</a>,\n</form>\n<form id=\"form-WeimingDongClassifierLearningWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weiming Dong\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeimingDongClassifierLearningWith').submit();\">Weiming Dong</a>,\n</form>\n<form id=\"form-Bao-GangHuClassifierLearningWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bao-Gang Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Bao-GangHuClassifierLearningWith').submit();\">Bao-Gang Hu</a>,\n</form>\n<form id=\"form-QiangJiClassifierLearningWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qiang Ji\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiangJiClassifierLearningWith').submit();\">Qiang Ji</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Classifier_Learning_With_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Yong and Dong, Weiming and Hu, Bao-Gang and Ji, Qiang},<br>\ntitle = {Classifier Learning With Prior Probabilities for Facial Action Unit Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Cheng_4DFAB_A_Large_CVPR_2018_paper.html\">4DFAB: A Large Scale 4D Database for Facial Expression Analysis and Biometric Applications</a></dt>\n<dd>\n<form id=\"form-ShiyangCheng4DFABALarge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shiyang Cheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShiyangCheng4DFABALarge').submit();\">Shiyang Cheng</a>,\n</form>\n<form id=\"form-IreneKotsia4DFABALarge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Irene Kotsia\">\n<a href=\"#\" onclick=\"document.getElementById('form-IreneKotsia4DFABALarge').submit();\">Irene Kotsia</a>,\n</form>\n<form id=\"form-MajaPantic4DFABALarge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Maja Pantic\">\n<a href=\"#\" onclick=\"document.getElementById('form-MajaPantic4DFABALarge').submit();\">Maja Pantic</a>,\n</form>\n<form id=\"form-StefanosZafeiriou4DFABALarge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stefanos Zafeiriou\">\n<a href=\"#\" onclick=\"document.getElementById('form-StefanosZafeiriou4DFABALarge').submit();\">Stefanos Zafeiriou</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Cheng_4DFAB_A_Large_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Cheng_2018_CVPR,<br>\nauthor = {Cheng, Shiyang and Kotsia, Irene and Pantic, Maja and Zafeiriou, Stefanos},<br>\ntitle = {4DFAB: A Large Scale 4D Database for Facial Expression Analysis and Biometric Applications},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhu_Seeing_Small_Faces_CVPR_2018_paper.html\">Seeing Small Faces From Robust Anchor's Perspective</a></dt>\n<dd>\n<form id=\"form-ChenchenZhuSeeingSmallFaces\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chenchen Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenchenZhuSeeingSmallFaces').submit();\">Chenchen Zhu</a>,\n</form>\n<form id=\"form-RanTaoSeeingSmallFaces\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ran Tao\">\n<a href=\"#\" onclick=\"document.getElementById('form-RanTaoSeeingSmallFaces').submit();\">Ran Tao</a>,\n</form>\n<form id=\"form-KhoaLuuSeeingSmallFaces\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Khoa Luu\">\n<a href=\"#\" onclick=\"document.getElementById('form-KhoaLuuSeeingSmallFaces').submit();\">Khoa Luu</a>,\n</form>\n<form id=\"form-MariosSavvidesSeeingSmallFaces\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Marios Savvides\">\n<a href=\"#\" onclick=\"document.getElementById('form-MariosSavvidesSeeingSmallFaces').submit();\">Marios Savvides</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhu_Seeing_Small_Faces_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.09058\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhu_2018_CVPR,<br>\nauthor = {Zhu, Chenchen and Tao, Ran and Luu, Khoa and Savvides, Marios},<br>\ntitle = {Seeing Small Faces From Robust Anchor's Perspective},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Luvizon_2D3D_Pose_Estimation_CVPR_2018_paper.html\">2D/3D Pose Estimation and Action Recognition Using Multitask Deep Learning</a></dt>\n<dd>\n<form id=\"form-DiogoC.2D3DPoseEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Diogo C. Luvizon\">\n<a href=\"#\" onclick=\"document.getElementById('form-DiogoC.2D3DPoseEstimation').submit();\">Diogo C. Luvizon</a>,\n</form>\n<form id=\"form-DavidPicard2D3DPoseEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"David Picard\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavidPicard2D3DPoseEstimation').submit();\">David Picard</a>,\n</form>\n<form id=\"form-HediTabia2D3DPoseEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hedi Tabia\">\n<a href=\"#\" onclick=\"document.getElementById('form-HediTabia2D3DPoseEstimation').submit();\">Hedi Tabia</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Luvizon_2D3D_Pose_Estimation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0131-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.09232\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Luvizon_2018_CVPR,<br>\nauthor = {Luvizon, Diogo C. and Picard, David and Tabia, Hedi},<br>\ntitle = {2D/3D Pose Estimation and Action Recognition Using Multitask Deep Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wan_Dense_3D_Regression_CVPR_2018_paper.html\">Dense 3D Regression for Hand Pose Estimation</a></dt>\n<dd>\n<form id=\"form-ChengdeWanDense3DRegression\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chengde Wan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChengdeWanDense3DRegression').submit();\">Chengde Wan</a>,\n</form>\n<form id=\"form-ThomasProbstDense3DRegression\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Thomas Probst\">\n<a href=\"#\" onclick=\"document.getElementById('form-ThomasProbstDense3DRegression').submit();\">Thomas Probst</a>,\n</form>\n<form id=\"form-LucVanDense3DRegression\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Luc Van Gool\">\n<a href=\"#\" onclick=\"document.getElementById('form-LucVanDense3DRegression').submit();\">Luc Van Gool</a>,\n</form>\n<form id=\"form-AngelaYaoDense3DRegression\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Angela Yao\">\n<a href=\"#\" onclick=\"document.getElementById('form-AngelaYaoDense3DRegression').submit();\">Angela Yao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wan_Dense_3D_Regression_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.08996\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wan_2018_CVPR,<br>\nauthor = {Wan, Chengde and Probst, Thomas and Van Gool, Luc and Yao, Angela},<br>\ntitle = {Dense 3D Regression for Hand Pose Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhong_Camera_Style_Adaptation_CVPR_2018_paper.html\">Camera Style Adaptation for Person Re-Identification</a></dt>\n<dd>\n<form id=\"form-ZhunZhongCameraStyleAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhun Zhong\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhunZhongCameraStyleAdaptation').submit();\">Zhun Zhong</a>,\n</form>\n<form id=\"form-LiangZhengCameraStyleAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liang Zheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiangZhengCameraStyleAdaptation').submit();\">Liang Zheng</a>,\n</form>\n<form id=\"form-ZhedongZhengCameraStyleAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhedong Zheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhedongZhengCameraStyleAdaptation').submit();\">Zhedong Zheng</a>,\n</form>\n<form id=\"form-ShaoziLiCameraStyleAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shaozi Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShaoziLiCameraStyleAdaptation').submit();\">Shaozi Li</a>,\n</form>\n<form id=\"form-YiYangCameraStyleAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiYangCameraStyleAdaptation').submit();\">Yi Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhong_Camera_Style_Adaptation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.10295\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhong_2018_CVPR,<br>\nauthor = {Zhong, Zhun and Zheng, Liang and Zheng, Zhedong and Li, Shaozi and Yang, Yi},<br>\ntitle = {Camera Style Adaptation for Person Re-Identification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Andriluka_PoseTrack_A_Benchmark_CVPR_2018_paper.html\">PoseTrack: A Benchmark for Human Pose Estimation and Tracking</a></dt>\n<dd>\n<form id=\"form-MykhayloAndrilukaPoseTrackABenchmark\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mykhaylo Andriluka\">\n<a href=\"#\" onclick=\"document.getElementById('form-MykhayloAndrilukaPoseTrackABenchmark').submit();\">Mykhaylo Andriluka</a>,\n</form>\n<form id=\"form-UmarIqbalPoseTrackABenchmark\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Umar Iqbal\">\n<a href=\"#\" onclick=\"document.getElementById('form-UmarIqbalPoseTrackABenchmark').submit();\">Umar Iqbal</a>,\n</form>\n<form id=\"form-EldarInsafutdinovPoseTrackABenchmark\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Eldar Insafutdinov\">\n<a href=\"#\" onclick=\"document.getElementById('form-EldarInsafutdinovPoseTrackABenchmark').submit();\">Eldar Insafutdinov</a>,\n</form>\n<form id=\"form-LeonidPishchulinPoseTrackABenchmark\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Leonid Pishchulin\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeonidPishchulinPoseTrackABenchmark').submit();\">Leonid Pishchulin</a>,\n</form>\n<form id=\"form-AntonMilanPoseTrackABenchmark\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anton Milan\">\n<a href=\"#\" onclick=\"document.getElementById('form-AntonMilanPoseTrackABenchmark').submit();\">Anton Milan</a>,\n</form>\n<form id=\"form-JuergenGallPoseTrackABenchmark\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Juergen Gall\">\n<a href=\"#\" onclick=\"document.getElementById('form-JuergenGallPoseTrackABenchmark').submit();\">Juergen Gall</a>,\n</form>\n<form id=\"form-BerntSchielePoseTrackABenchmark\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bernt Schiele\">\n<a href=\"#\" onclick=\"document.getElementById('form-BerntSchielePoseTrackABenchmark').submit();\">Bernt Schiele</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Andriluka_PoseTrack_A_Benchmark_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1710.10000\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Andriluka_2018_CVPR,<br>\nauthor = {Andriluka, Mykhaylo and Iqbal, Umar and Insafutdinov, Eldar and Pishchulin, Leonid and Milan, Anton and Gall, Juergen and Schiele, Bernt},<br>\ntitle = {PoseTrack: A Benchmark for Human Pose Estimation and Tracking},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wu_Exploit_the_Unknown_CVPR_2018_paper.html\">Exploit the Unknown Gradually: One-Shot Video-Based Person Re-Identification by Stepwise Learning</a></dt>\n<dd>\n<form id=\"form-YuWuExploittheUnknown\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuWuExploittheUnknown').submit();\">Yu Wu</a>,\n</form>\n<form id=\"form-YutianLinExploittheUnknown\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yutian Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-YutianLinExploittheUnknown').submit();\">Yutian Lin</a>,\n</form>\n<form id=\"form-XuanyiDongExploittheUnknown\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xuanyi Dong\">\n<a href=\"#\" onclick=\"document.getElementById('form-XuanyiDongExploittheUnknown').submit();\">Xuanyi Dong</a>,\n</form>\n<form id=\"form-YanYanExploittheUnknown\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yan Yan\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanYanExploittheUnknown').submit();\">Yan Yan</a>,\n</form>\n<form id=\"form-WanliOuyangExploittheUnknown\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wanli Ouyang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WanliOuyangExploittheUnknown').submit();\">Wanli Ouyang</a>,\n</form>\n<form id=\"form-YiYangExploittheUnknown\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiYangExploittheUnknown').submit();\">Yi Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wu_Exploit_the_Unknown_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wu_2018_CVPR,<br>\nauthor = {Wu, Yu and Lin, Yutian and Dong, Xuanyi and Yan, Yan and Ouyang, Wanli and Yang, Yi},<br>\ntitle = {Exploit the Unknown Gradually: One-Shot Video-Based Person Re-Identification by Stepwise Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Cao_Pose-Robust_Face_Recognition_CVPR_2018_paper.html\">Pose-Robust Face Recognition via Deep Residual Equivariant Mapping</a></dt>\n<dd>\n<form id=\"form-KaidiCaoPoseRobustFaceRecognition\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kaidi Cao\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaidiCaoPoseRobustFaceRecognition').submit();\">Kaidi Cao</a>,\n</form>\n<form id=\"form-YuRongPoseRobustFaceRecognition\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu Rong\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuRongPoseRobustFaceRecognition').submit();\">Yu Rong</a>,\n</form>\n<form id=\"form-ChengLiPoseRobustFaceRecognition\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cheng Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChengLiPoseRobustFaceRecognition').submit();\">Cheng Li</a>,\n</form>\n<form id=\"form-XiaoouTangPoseRobustFaceRecognition\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaoou Tang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaoouTangPoseRobustFaceRecognition').submit();\">Xiaoou Tang</a>,\n</form>\n<form id=\"form-ChenChangePoseRobustFaceRecognition\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chen Change Loy\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenChangePoseRobustFaceRecognition').submit();\">Chen Change Loy</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Cao_Pose-Robust_Face_Recognition_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.00839\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Cao_2018_CVPR,<br>\nauthor = {Cao, Kaidi and Rong, Yu and Li, Cheng and Tang, Xiaoou and Change Loy, Chen},<br>\ntitle = {Pose-Robust Face Recognition via Deep Residual Equivariant Mapping},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_DecideNet_Counting_Varying_CVPR_2018_paper.html\">DecideNet: Counting Varying Density Crowds Through Attention Guided Detection and Density Estimation</a></dt>\n<dd>\n<form id=\"form-JiangLiuDecideNetCountingVarying\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiang Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiangLiuDecideNetCountingVarying').submit();\">Jiang Liu</a>,\n</form>\n<form id=\"form-ChenqiangGaoDecideNetCountingVarying\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chenqiang Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenqiangGaoDecideNetCountingVarying').submit();\">Chenqiang Gao</a>,\n</form>\n<form id=\"form-DeyuMengDecideNetCountingVarying\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Deyu Meng\">\n<a href=\"#\" onclick=\"document.getElementById('form-DeyuMengDecideNetCountingVarying').submit();\">Deyu Meng</a>,\n</form>\n<form id=\"form-AlexanderG.DecideNetCountingVarying\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexander G. Hauptmann\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexanderG.DecideNetCountingVarying').submit();\">Alexander G. Hauptmann</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_DecideNet_Counting_Varying_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.06679\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Jiang and Gao, Chenqiang and Meng, Deyu and Hauptmann, Alexander G.},<br>\ntitle = {DecideNet: Counting Varying Density Crowds Through Attention Guided Detection and Density Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Luo_LSTM_Pose_Machines_CVPR_2018_paper.html\">LSTM Pose Machines</a></dt>\n<dd>\n<form id=\"form-YueLuoLSTMPoseMachines\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yue Luo\">\n<a href=\"#\" onclick=\"document.getElementById('form-YueLuoLSTMPoseMachines').submit();\">Yue Luo</a>,\n</form>\n<form id=\"form-JimmyRenLSTMPoseMachines\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jimmy Ren\">\n<a href=\"#\" onclick=\"document.getElementById('form-JimmyRenLSTMPoseMachines').submit();\">Jimmy Ren</a>,\n</form>\n<form id=\"form-ZhouxiaWangLSTMPoseMachines\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhouxia Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhouxiaWangLSTMPoseMachines').submit();\">Zhouxia Wang</a>,\n</form>\n<form id=\"form-WenxiuSunLSTMPoseMachines\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenxiu Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenxiuSunLSTMPoseMachines').submit();\">Wenxiu Sun</a>,\n</form>\n<form id=\"form-JinshanPanLSTMPoseMachines\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jinshan Pan\">\n<a href=\"#\" onclick=\"document.getElementById('form-JinshanPanLSTMPoseMachines').submit();\">Jinshan Pan</a>,\n</form>\n<form id=\"form-JianboLiuLSTMPoseMachines\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianbo Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianboLiuLSTMPoseMachines').submit();\">Jianbo Liu</a>,\n</form>\n<form id=\"form-JiahaoPangLSTMPoseMachines\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiahao Pang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiahaoPangLSTMPoseMachines').submit();\">Jiahao Pang</a>,\n</form>\n<form id=\"form-LiangLinLSTMPoseMachines\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liang Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiangLinLSTMPoseMachines').submit();\">Liang Lin</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Luo_LSTM_Pose_Machines_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.06316\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Luo_2018_CVPR,<br>\nauthor = {Luo, Yue and Ren, Jimmy and Wang, Zhouxia and Sun, Wenxiu and Pan, Jinshan and Liu, Jianbo and Pang, Jiahao and Lin, Liang},<br>\ntitle = {LSTM Pose Machines},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_Disentangling_Features_in_CVPR_2018_paper.html\">Disentangling Features in 3D Face Shapes for Joint Face Reconstruction and Recognition</a></dt>\n<dd>\n<form id=\"form-FengLiuDisentanglingFeaturesin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Feng Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-FengLiuDisentanglingFeaturesin').submit();\">Feng Liu</a>,\n</form>\n<form id=\"form-RonghangZhuDisentanglingFeaturesin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ronghang Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-RonghangZhuDisentanglingFeaturesin').submit();\">Ronghang Zhu</a>,\n</form>\n<form id=\"form-DanZengDisentanglingFeaturesin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dan Zeng\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanZengDisentanglingFeaturesin').submit();\">Dan Zeng</a>,\n</form>\n<form id=\"form-QijunZhaoDisentanglingFeaturesin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qijun Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-QijunZhaoDisentanglingFeaturesin').submit();\">Qijun Zhao</a>,\n</form>\n<form id=\"form-XiaomingLiuDisentanglingFeaturesin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaoming Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaomingLiuDisentanglingFeaturesin').submit();\">Xiaoming Liu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_Disentangling_Features_in_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2852-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.11366\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Feng and Zhu, Ronghang and Zeng, Dan and Zhao, Qijun and Liu, Xiaoming},<br>\ntitle = {Disentangling Features in 3D Face Shapes for Joint Face Reconstruction and Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Convolutional_Sequence_to_CVPR_2018_paper.html\">Convolutional Sequence to Sequence Model for Human Dynamics</a></dt>\n<dd>\n<form id=\"form-ChenLiConvolutionalSequenceto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chen Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenLiConvolutionalSequenceto').submit();\">Chen Li</a>,\n</form>\n<form id=\"form-ZhenZhangConvolutionalSequenceto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhen Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhenZhangConvolutionalSequenceto').submit();\">Zhen Zhang</a>,\n</form>\n<form id=\"form-WeeSunConvolutionalSequenceto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wee Sun Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeeSunConvolutionalSequenceto').submit();\">Wee Sun Lee</a>,\n</form>\n<form id=\"form-GimHeeConvolutionalSequenceto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gim Hee Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-GimHeeConvolutionalSequenceto').submit();\">Gim Hee Lee</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Convolutional_Sequence_to_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.00655\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Chen and Zhang, Zhen and Sun Lee, Wee and Hee Lee, Gim},<br>\ntitle = {Convolutional Sequence to Sequence Model for Human Dynamics},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Narayana_Gesture_Recognition_Focus_CVPR_2018_paper.html\">Gesture Recognition: Focus on the Hands</a></dt>\n<dd>\n<form id=\"form-PradyumnaNarayanaGestureRecognitionFocus\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pradyumna Narayana\">\n<a href=\"#\" onclick=\"document.getElementById('form-PradyumnaNarayanaGestureRecognitionFocus').submit();\">Pradyumna Narayana</a>,\n</form>\n<form id=\"form-RossBeveridgeGestureRecognitionFocus\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ross Beveridge\">\n<a href=\"#\" onclick=\"document.getElementById('form-RossBeveridgeGestureRecognitionFocus').submit();\">Ross Beveridge</a>,\n</form>\n<form id=\"form-BruceA.GestureRecognitionFocus\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bruce A. Draper\">\n<a href=\"#\" onclick=\"document.getElementById('form-BruceA.GestureRecognitionFocus').submit();\">Bruce A. Draper</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Narayana_Gesture_Recognition_Focus_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Narayana_2018_CVPR,<br>\nauthor = {Narayana, Pradyumna and Beveridge, Ross and Draper, Bruce A.},<br>\ntitle = {Gesture Recognition: Focus on the Hands},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Shen_Crowd_Counting_via_CVPR_2018_paper.html\">Crowd Counting via Adversarial Cross-Scale Consistency Pursuit</a></dt>\n<dd>\n<form id=\"form-ZanShenCrowdCountingvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zan Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZanShenCrowdCountingvia').submit();\">Zan Shen</a>,\n</form>\n<form id=\"form-YiXuCrowdCountingvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiXuCrowdCountingvia').submit();\">Yi Xu</a>,\n</form>\n<form id=\"form-BingbingNiCrowdCountingvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bingbing Ni\">\n<a href=\"#\" onclick=\"document.getElementById('form-BingbingNiCrowdCountingvia').submit();\">Bingbing Ni</a>,\n</form>\n<form id=\"form-MinsiWangCrowdCountingvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Minsi Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-MinsiWangCrowdCountingvia').submit();\">Minsi Wang</a>,\n</form>\n<form id=\"form-JianguoHuCrowdCountingvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianguo Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianguoHuCrowdCountingvia').submit();\">Jianguo Hu</a>,\n</form>\n<form id=\"form-XiaokangYangCrowdCountingvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaokang Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaokangYangCrowdCountingvia').submit();\">Xiaokang Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Shen_Crowd_Counting_via_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Shen_2018_CVPR,<br>\nauthor = {Shen, Zan and Xu, Yi and Ni, Bingbing and Wang, Minsi and Hu, Jianguo and Yang, Xiaokang},<br>\ntitle = {Crowd Counting via Adversarial Cross-Scale Consistency Pursuit},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yang_3D_Human_Pose_CVPR_2018_paper.html\">3D Human Pose Estimation in the Wild by Adversarial Learning</a></dt>\n<dd>\n<form id=\"form-WeiYang3DHumanPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiYang3DHumanPose').submit();\">Wei Yang</a>,\n</form>\n<form id=\"form-WanliOuyang3DHumanPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wanli Ouyang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WanliOuyang3DHumanPose').submit();\">Wanli Ouyang</a>,\n</form>\n<form id=\"form-XiaolongWang3DHumanPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaolong Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaolongWang3DHumanPose').submit();\">Xiaolong Wang</a>,\n</form>\n<form id=\"form-JimmyRen3DHumanPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jimmy Ren\">\n<a href=\"#\" onclick=\"document.getElementById('form-JimmyRen3DHumanPose').submit();\">Jimmy Ren</a>,\n</form>\n<form id=\"form-HongshengLi3DHumanPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hongsheng Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-HongshengLi3DHumanPose').submit();\">Hongsheng Li</a>,\n</form>\n<form id=\"form-XiaogangWang3DHumanPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaogang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaogangWang3DHumanPose').submit();\">Xiaogang Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yang_3D_Human_Pose_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.09722\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yang_2018_CVPR,<br>\nauthor = {Yang, Wei and Ouyang, Wanli and Wang, Xiaolong and Ren, Jimmy and Li, Hongsheng and Wang, Xiaogang},<br>\ntitle = {3D Human Pose Estimation in the Wild by Adversarial Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_CosFace_Large_Margin_CVPR_2018_paper.html\">CosFace: Large Margin Cosine Loss for Deep Face Recognition</a></dt>\n<dd>\n<form id=\"form-HaoWangCosFaceLargeMargin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hao Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaoWangCosFaceLargeMargin').submit();\">Hao Wang</a>,\n</form>\n<form id=\"form-YitongWangCosFaceLargeMargin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yitong Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YitongWangCosFaceLargeMargin').submit();\">Yitong Wang</a>,\n</form>\n<form id=\"form-ZhengZhouCosFaceLargeMargin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zheng Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhengZhouCosFaceLargeMargin').submit();\">Zheng Zhou</a>,\n</form>\n<form id=\"form-XingJiCosFaceLargeMargin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xing Ji\">\n<a href=\"#\" onclick=\"document.getElementById('form-XingJiCosFaceLargeMargin').submit();\">Xing Ji</a>,\n</form>\n<form id=\"form-DihongGongCosFaceLargeMargin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dihong Gong\">\n<a href=\"#\" onclick=\"document.getElementById('form-DihongGongCosFaceLargeMargin').submit();\">Dihong Gong</a>,\n</form>\n<form id=\"form-JingchaoZhouCosFaceLargeMargin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jingchao Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingchaoZhouCosFaceLargeMargin').submit();\">Jingchao Zhou</a>,\n</form>\n<form id=\"form-ZhifengLiCosFaceLargeMargin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhifeng Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhifengLiCosFaceLargeMargin').submit();\">Zhifeng Li</a>,\n</form>\n<form id=\"form-WeiLiuCosFaceLargeMargin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiLiuCosFaceLargeMargin').submit();\">Wei Liu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_CosFace_Large_Margin_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1797-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.09414\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Hao and Wang, Yitong and Zhou, Zheng and Ji, Xing and Gong, Dihong and Zhou, Jingchao and Li, Zhifeng and Liu, Wei},<br>\ntitle = {CosFace: Large Margin Cosine Loss for Deep Face Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xu_Encoding_Crowd_Interaction_CVPR_2018_paper.html\">Encoding Crowd Interaction With Deep Neural Network for Pedestrian Trajectory Prediction</a></dt>\n<dd>\n<form id=\"form-YanyuXuEncodingCrowdInteraction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yanyu Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanyuXuEncodingCrowdInteraction').submit();\">Yanyu Xu</a>,\n</form>\n<form id=\"form-ZhixinPiaoEncodingCrowdInteraction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhixin Piao\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhixinPiaoEncodingCrowdInteraction').submit();\">Zhixin Piao</a>,\n</form>\n<form id=\"form-ShenghuaGaoEncodingCrowdInteraction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shenghua Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShenghuaGaoEncodingCrowdInteraction').submit();\">Shenghua Gao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xu_Encoding_Crowd_Interaction_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xu_2018_CVPR,<br>\nauthor = {Xu, Yanyu and Piao, Zhixin and Gao, Shenghua},<br>\ntitle = {Encoding Crowd Interaction With Deep Neural Network for Pedestrian Trajectory Prediction},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Pan_Mean-Variance_Loss_for_CVPR_2018_paper.html\">Mean-Variance Loss for Deep Age Estimation From a Face</a></dt>\n<dd>\n<form id=\"form-HongyuPanMeanVarianceLossfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hongyu Pan\">\n<a href=\"#\" onclick=\"document.getElementById('form-HongyuPanMeanVarianceLossfor').submit();\">Hongyu Pan</a>,\n</form>\n<form id=\"form-HuHanMeanVarianceLossfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hu Han\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuHanMeanVarianceLossfor').submit();\">Hu Han</a>,\n</form>\n<form id=\"form-ShiguangShanMeanVarianceLossfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shiguang Shan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShiguangShanMeanVarianceLossfor').submit();\">Shiguang Shan</a>,\n</form>\n<form id=\"form-XilinChenMeanVarianceLossfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xilin Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-XilinChenMeanVarianceLossfor').submit();\">Xilin Chen</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Pan_Mean-Variance_Loss_for_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Pan_2018_CVPR,<br>\nauthor = {Pan, Hongyu and Han, Hu and Shan, Shiguang and Chen, Xilin},<br>\ntitle = {Mean-Variance Loss for Deep Age Estimation From a Face},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Madsen_Probabilistic_Joint_Face-Skull_CVPR_2018_paper.html\">Probabilistic Joint Face-Skull Modelling for Facial Reconstruction</a></dt>\n<dd>\n<form id=\"form-DennisMadsenProbabilisticJointFaceSkull\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dennis Madsen\">\n<a href=\"#\" onclick=\"document.getElementById('form-DennisMadsenProbabilisticJointFaceSkull').submit();\">Dennis Madsen</a>,\n</form>\n<form id=\"form-MarcelL\u00c3\u00bcthiProbabilisticJointFaceSkull\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Marcel L\u00c3\u00bcthi\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarcelL\u00c3\u00bcthiProbabilisticJointFaceSkull').submit();\">Marcel L\u00c3\u00bcthi</a>,\n</form>\n<form id=\"form-AndreasSchneiderProbabilisticJointFaceSkull\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andreas Schneider\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndreasSchneiderProbabilisticJointFaceSkull').submit();\">Andreas Schneider</a>,\n</form>\n<form id=\"form-ThomasVetterProbabilisticJointFaceSkull\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Thomas Vetter\">\n<a href=\"#\" onclick=\"document.getElementById('form-ThomasVetterProbabilisticJointFaceSkull').submit();\">Thomas Vetter</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Madsen_Probabilistic_Joint_Face-Skull_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Madsen_2018_CVPR,<br>\nauthor = {Madsen, Dennis and L\u00c3\u00bcthi, Marcel and Schneider, Andreas and Vetter, Thomas},<br>\ntitle = {Probabilistic Joint Face-Skull Modelling for Facial Reconstruction},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Piergiovanni_Learning_Latent_Super-Events_CVPR_2018_paper.html\">Learning Latent Super-Events to Detect Multiple Activities in Videos</a></dt>\n<dd>\n<form id=\"form-AJPiergiovanniLearningLatentSuperEvents\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"AJ Piergiovanni\">\n<a href=\"#\" onclick=\"document.getElementById('form-AJPiergiovanniLearningLatentSuperEvents').submit();\">AJ Piergiovanni</a>,\n</form>\n<form id=\"form-MichaelS.LearningLatentSuperEvents\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michael S. Ryoo\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichaelS.LearningLatentSuperEvents').submit();\">Michael S. Ryoo</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Piergiovanni_Learning_Latent_Super-Events_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3795-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.01938\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Piergiovanni_2018_CVPR,<br>\nauthor = {Piergiovanni, AJ and Ryoo, Michael S.},<br>\ntitle = {Learning Latent Super-Events to Detect Multiple Activities in Videos},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Temporal_Hallucinating_for_CVPR_2018_paper.html\">Temporal Hallucinating for Action Recognition With Few Still Images</a></dt>\n<dd>\n<form id=\"form-YaliWangTemporalHallucinatingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yali Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YaliWangTemporalHallucinatingfor').submit();\">Yali Wang</a>,\n</form>\n<form id=\"form-LeiZhouTemporalHallucinatingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lei Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeiZhouTemporalHallucinatingfor').submit();\">Lei Zhou</a>,\n</form>\n<form id=\"form-YuQiaoTemporalHallucinatingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu Qiao\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuQiaoTemporalHallucinatingfor').submit();\">Yu Qiao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Temporal_Hallucinating_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1664-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Yali and Zhou, Lei and Qiao, Yu},<br>\ntitle = {Temporal Hallucinating for Action Recognition With Few Still Images},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tang_Deep_Progressive_Reinforcement_CVPR_2018_paper.html\">Deep Progressive Reinforcement Learning for Skeleton-Based Action Recognition</a></dt>\n<dd>\n<form id=\"form-YansongTangDeepProgressiveReinforcement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yansong Tang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YansongTangDeepProgressiveReinforcement').submit();\">Yansong Tang</a>,\n</form>\n<form id=\"form-YiTianDeepProgressiveReinforcement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi Tian\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiTianDeepProgressiveReinforcement').submit();\">Yi Tian</a>,\n</form>\n<form id=\"form-JiwenLuDeepProgressiveReinforcement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiwen Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiwenLuDeepProgressiveReinforcement').submit();\">Jiwen Lu</a>,\n</form>\n<form id=\"form-PeiyangLiDeepProgressiveReinforcement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peiyang Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-PeiyangLiDeepProgressiveReinforcement').submit();\">Peiyang Li</a>,\n</form>\n<form id=\"form-JieZhouDeepProgressiveReinforcement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jie Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-JieZhouDeepProgressiveReinforcement').submit();\">Jie Zhou</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tang_Deep_Progressive_Reinforcement_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tang_2018_CVPR,<br>\nauthor = {Tang, Yansong and Tian, Yi and Lu, Jiwen and Li, Peiyang and Zhou, Jie},<br>\ntitle = {Deep Progressive Reinforcement Learning for Skeleton-Based Action Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xu_Gaze_Prediction_in_CVPR_2018_paper.html\">Gaze Prediction in Dynamic 360\u00c2\u00b0 Immersive Videos</a></dt>\n<dd>\n<form id=\"form-YanyuXuGazePredictionin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yanyu Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanyuXuGazePredictionin').submit();\">Yanyu Xu</a>,\n</form>\n<form id=\"form-YanbingDongGazePredictionin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yanbing Dong\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanbingDongGazePredictionin').submit();\">Yanbing Dong</a>,\n</form>\n<form id=\"form-JunruWuGazePredictionin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junru Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunruWuGazePredictionin').submit();\">Junru Wu</a>,\n</form>\n<form id=\"form-ZhengzhongSunGazePredictionin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhengzhong Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhengzhongSunGazePredictionin').submit();\">Zhengzhong Sun</a>,\n</form>\n<form id=\"form-ZhiruShiGazePredictionin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhiru Shi\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhiruShiGazePredictionin').submit();\">Zhiru Shi</a>,\n</form>\n<form id=\"form-JingyiYuGazePredictionin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jingyi Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingyiYuGazePredictionin').submit();\">Jingyi Yu</a>,\n</form>\n<form id=\"form-ShenghuaGaoGazePredictionin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shenghua Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShenghuaGaoGazePredictionin').submit();\">Shenghua Gao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xu_Gaze_Prediction_in_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2529-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xu_2018_CVPR,<br>\nauthor = {Xu, Yanyu and Dong, Yanbing and Wu, Junru and Sun, Zhengzhong and Shi, Zhiru and Yu, Jingyi and Gao, Shenghua},<br>\ntitle = {Gaze Prediction in Dynamic 360\u00c2\u00b0 Immersive Videos},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Abu_Farha_When_Will_You_CVPR_2018_paper.html\">When Will You Do What? - Anticipating Temporal Occurrences of Activities</a></dt>\n<dd>\n<form id=\"form-YazanAbuWhenWillYou\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yazan Abu Farha\">\n<a href=\"#\" onclick=\"document.getElementById('form-YazanAbuWhenWillYou').submit();\">Yazan Abu Farha</a>,\n</form>\n<form id=\"form-AlexanderRichardWhenWillYou\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexander Richard\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexanderRichardWhenWillYou').submit();\">Alexander Richard</a>,\n</form>\n<form id=\"form-JuergenGallWhenWillYou\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Juergen Gall\">\n<a href=\"#\" onclick=\"document.getElementById('form-JuergenGallWhenWillYou').submit();\">Juergen Gall</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Abu_Farha_When_Will_You_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Farha_2018_CVPR,<br>\nauthor = {Abu Farha, Yazan and Richard, Alexander and Gall, Juergen},<br>\ntitle = {When Will You Do What? - Anticipating Temporal Occurrences of Activities},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ren_Fusing_Crowd_Density_CVPR_2018_paper.html\">Fusing Crowd Density Maps and Visual Object Trackers for People Tracking in Crowd Scenes</a></dt>\n<dd>\n<form id=\"form-WeihongRenFusingCrowdDensity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weihong Ren\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeihongRenFusingCrowdDensity').submit();\">Weihong Ren</a>,\n</form>\n<form id=\"form-DiKangFusingCrowdDensity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Di Kang\">\n<a href=\"#\" onclick=\"document.getElementById('form-DiKangFusingCrowdDensity').submit();\">Di Kang</a>,\n</form>\n<form id=\"form-YandongTangFusingCrowdDensity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yandong Tang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YandongTangFusingCrowdDensity').submit();\">Yandong Tang</a>,\n</form>\n<form id=\"form-AntoniB.FusingCrowdDensity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Antoni B. Chan\">\n<a href=\"#\" onclick=\"document.getElementById('form-AntoniB.FusingCrowdDensity').submit();\">Antoni B. Chan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ren_Fusing_Crowd_Density_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ren_2018_CVPR,<br>\nauthor = {Ren, Weihong and Kang, Di and Tang, Yandong and Chan, Antoni B.},<br>\ntitle = {Fusing Crowd Density Maps and Visual Object Trackers for People Tracking in Crowd Scenes},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Si_Dual_Attention_Matching_CVPR_2018_paper.html\">Dual Attention Matching Network for Context-Aware Feature Sequence Based Person Re-Identification</a></dt>\n<dd>\n<form id=\"form-JianlouSiDualAttentionMatching\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianlou Si\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianlouSiDualAttentionMatching').submit();\">Jianlou Si</a>,\n</form>\n<form id=\"form-HonggangZhangDualAttentionMatching\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Honggang Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HonggangZhangDualAttentionMatching').submit();\">Honggang Zhang</a>,\n</form>\n<form id=\"form-Chun-GuangLiDualAttentionMatching\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chun-Guang Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-Chun-GuangLiDualAttentionMatching').submit();\">Chun-Guang Li</a>,\n</form>\n<form id=\"form-JasonKuenDualAttentionMatching\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jason Kuen\">\n<a href=\"#\" onclick=\"document.getElementById('form-JasonKuenDualAttentionMatching').submit();\">Jason Kuen</a>,\n</form>\n<form id=\"form-XiangfeiKongDualAttentionMatching\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiangfei Kong\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiangfeiKongDualAttentionMatching').submit();\">Xiangfei Kong</a>,\n</form>\n<form id=\"form-AlexC.DualAttentionMatching\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alex C. Kot\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexC.DualAttentionMatching').submit();\">Alex C. Kot</a>,\n</form>\n<form id=\"form-GangWangDualAttentionMatching\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-GangWangDualAttentionMatching').submit();\">Gang Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Si_Dual_Attention_Matching_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.09937\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Si_2018_CVPR,<br>\nauthor = {Si, Jianlou and Zhang, Honggang and Li, Chun-Guang and Kuen, Jason and Kong, Xiangfei and Kot, Alex C. and Wang, Gang},<br>\ntitle = {Dual Attention Matching Network for Context-Aware Feature Sequence Based Person Re-Identification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhou_Easy_Identification_From_CVPR_2018_paper.html\">Easy Identification From Better Constraints: Multi-Shot Person Re-Identification From Reference Constraints</a></dt>\n<dd>\n<form id=\"form-JiahuanZhouEasyIdentificationFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiahuan Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiahuanZhouEasyIdentificationFrom').submit();\">Jiahuan Zhou</a>,\n</form>\n<form id=\"form-BingSuEasyIdentificationFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bing Su\">\n<a href=\"#\" onclick=\"document.getElementById('form-BingSuEasyIdentificationFrom').submit();\">Bing Su</a>,\n</form>\n<form id=\"form-YingWuEasyIdentificationFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ying Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YingWuEasyIdentificationFrom').submit();\">Ying Wu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhou_Easy_Identification_From_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhou_2018_CVPR,<br>\nauthor = {Zhou, Jiahuan and Su, Bing and Wu, Ying},<br>\ntitle = {Easy Identification From Better Constraints: Multi-Shot Person Re-Identification From Reference Constraints},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Shi_Crowd_Counting_With_CVPR_2018_paper.html\">Crowd Counting With Deep Negative Correlation Learning</a></dt>\n<dd>\n<form id=\"form-ZenglinShiCrowdCountingWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zenglin Shi\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZenglinShiCrowdCountingWith').submit();\">Zenglin Shi</a>,\n</form>\n<form id=\"form-LeZhangCrowdCountingWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Le Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeZhangCrowdCountingWith').submit();\">Le Zhang</a>,\n</form>\n<form id=\"form-YunLiuCrowdCountingWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yun Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YunLiuCrowdCountingWith').submit();\">Yun Liu</a>,\n</form>\n<form id=\"form-XiaofengCaoCrowdCountingWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaofeng Cao\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaofengCaoCrowdCountingWith').submit();\">Xiaofeng Cao</a>,\n</form>\n<form id=\"form-YangdongYeCrowdCountingWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yangdong Ye\">\n<a href=\"#\" onclick=\"document.getElementById('form-YangdongYeCrowdCountingWith').submit();\">Yangdong Ye</a>,\n</form>\n<form id=\"form-Ming-MingChengCrowdCountingWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming-Ming Cheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ming-MingChengCrowdCountingWith').submit();\">Ming-Ming Cheng</a>,\n</form>\n<form id=\"form-GuoyanZhengCrowdCountingWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guoyan Zheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuoyanZhengCrowdCountingWith').submit();\">Guoyan Zheng</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Shi_Crowd_Counting_With_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Shi_2018_CVPR,<br>\nauthor = {Shi, Zenglin and Zhang, Le and Liu, Yun and Cao, Xiaofeng and Ye, Yangdong and Cheng, Ming-Ming and Zheng, Guoyan},<br>\ntitle = {Crowd Counting With Deep Negative Correlation Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zanfir_Human_Appearance_Transfer_CVPR_2018_paper.html\">Human Appearance Transfer</a></dt>\n<dd>\n<form id=\"form-MihaiZanfirHumanAppearanceTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mihai Zanfir\">\n<a href=\"#\" onclick=\"document.getElementById('form-MihaiZanfirHumanAppearanceTransfer').submit();\">Mihai Zanfir</a>,\n</form>\n<form id=\"form-Alin-IonutPopaHumanAppearanceTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alin-Ionut Popa\">\n<a href=\"#\" onclick=\"document.getElementById('form-Alin-IonutPopaHumanAppearanceTransfer').submit();\">Alin-Ionut Popa</a>,\n</form>\n<form id=\"form-AndreiZanfirHumanAppearanceTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrei Zanfir\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndreiZanfirHumanAppearanceTransfer').submit();\">Andrei Zanfir</a>,\n</form>\n<form id=\"form-CristianSminchisescuHumanAppearanceTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cristian Sminchisescu\">\n<a href=\"#\" onclick=\"document.getElementById('form-CristianSminchisescuHumanAppearanceTransfer').submit();\">Cristian Sminchisescu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zanfir_Human_Appearance_Transfer_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zanfir_2018_CVPR,<br>\nauthor = {Zanfir, Mihai and Popa, Alin-Ionut and Zanfir, Andrei and Sminchisescu, Cristian},<br>\ntitle = {Human Appearance Transfer},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Domain_Generalization_With_CVPR_2018_paper.html\">Domain Generalization With Adversarial Feature Learning</a></dt>\n<dd>\n<form id=\"form-HaoliangLiDomainGeneralizationWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Haoliang Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaoliangLiDomainGeneralizationWith').submit();\">Haoliang Li</a>,\n</form>\n<form id=\"form-SinnoJialinDomainGeneralizationWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sinno Jialin Pan\">\n<a href=\"#\" onclick=\"document.getElementById('form-SinnoJialinDomainGeneralizationWith').submit();\">Sinno Jialin Pan</a>,\n</form>\n<form id=\"form-ShiqiWangDomainGeneralizationWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shiqi Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShiqiWangDomainGeneralizationWith').submit();\">Shiqi Wang</a>,\n</form>\n<form id=\"form-AlexC.DomainGeneralizationWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alex C. Kot\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexC.DomainGeneralizationWith').submit();\">Alex C. Kot</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Domain_Generalization_With_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Haoliang and Jialin Pan, Sinno and Wang, Shiqi and Kot, Alex C.},<br>\ntitle = {Domain Generalization With Adversarial Feature Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chang_Pyramid_Stereo_Matching_CVPR_2018_paper.html\">Pyramid Stereo Matching Network</a></dt>\n<dd>\n<form id=\"form-Jia-RenChangPyramidStereoMatching\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jia-Ren Chang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jia-RenChangPyramidStereoMatching').submit();\">Jia-Ren Chang</a>,\n</form>\n<form id=\"form-Yong-ShengChenPyramidStereoMatching\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yong-Sheng Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yong-ShengChenPyramidStereoMatching').submit();\">Yong-Sheng Chen</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chang_Pyramid_Stereo_Matching_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.08669\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chang_2018_CVPR,<br>\nauthor = {Chang, Jia-Ren and Chen, Yong-Sheng},<br>\ntitle = {Pyramid Stereo Matching Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Maqueda_Event-Based_Vision_Meets_CVPR_2018_paper.html\">Event-Based Vision Meets Deep Learning on Steering Prediction for Self-Driving Cars</a></dt>\n<dd>\n<form id=\"form-AnaI.EventBasedVisionMeets\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ana I. Maqueda\">\n<a href=\"#\" onclick=\"document.getElementById('form-AnaI.EventBasedVisionMeets').submit();\">Ana I. Maqueda</a>,\n</form>\n<form id=\"form-AntonioLoquercioEventBasedVisionMeets\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Antonio Loquercio\">\n<a href=\"#\" onclick=\"document.getElementById('form-AntonioLoquercioEventBasedVisionMeets').submit();\">Antonio Loquercio</a>,\n</form>\n<form id=\"form-GuillermoGallegoEventBasedVisionMeets\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guillermo Gallego\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuillermoGallegoEventBasedVisionMeets').submit();\">Guillermo Gallego</a>,\n</form>\n<form id=\"form-NarcisoGarc\u00c3\u00adaEventBasedVisionMeets\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Narciso Garc\u00c3\u00ada\">\n<a href=\"#\" onclick=\"document.getElementById('form-NarcisoGarc\u00c3\u00adaEventBasedVisionMeets').submit();\">Narciso Garc\u00c3\u00ada</a>,\n</form>\n<form id=\"form-DavideScaramuzzaEventBasedVisionMeets\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Davide Scaramuzza\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavideScaramuzzaEventBasedVisionMeets').submit();\">Davide Scaramuzza</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Maqueda_Event-Based_Vision_Meets_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2970-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.01310\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Maqueda_2018_CVPR,<br>\nauthor = {Maqueda, Ana I. and Loquercio, Antonio and Gallego, Guillermo and Garc\u00c3\u00ada, Narciso and Scaramuzza, Davide},<br>\ntitle = {Event-Based Vision Meets Deep Learning on Steering Prediction for Self-Driving Cars},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hu_Learning_Answer_Embeddings_CVPR_2018_paper.html\">Learning Answer Embeddings for Visual Question Answering</a></dt>\n<dd>\n<form id=\"form-HexiangHuLearningAnswerEmbeddings\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hexiang Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HexiangHuLearningAnswerEmbeddings').submit();\">Hexiang Hu</a>,\n</form>\n<form id=\"form-Wei-LunChaoLearningAnswerEmbeddings\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei-Lun Chao\">\n<a href=\"#\" onclick=\"document.getElementById('form-Wei-LunChaoLearningAnswerEmbeddings').submit();\">Wei-Lun Chao</a>,\n</form>\n<form id=\"form-FeiShaLearningAnswerEmbeddings\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fei Sha\">\n<a href=\"#\" onclick=\"document.getElementById('form-FeiShaLearningAnswerEmbeddings').submit();\">Fei Sha</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hu_Learning_Answer_Embeddings_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3010-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1806.03724\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hu_2018_CVPR,<br>\nauthor = {Hu, Hexiang and Chao, Wei-Lun and Sha, Fei},<br>\ntitle = {Learning Answer Embeddings for Visual Question Answering},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wei_Good_View_Hunting_CVPR_2018_paper.html\">Good View Hunting: Learning Photo Composition From Dense View Pairs</a></dt>\n<dd>\n<form id=\"form-ZijunWeiGoodViewHunting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zijun Wei\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZijunWeiGoodViewHunting').submit();\">Zijun Wei</a>,\n</form>\n<form id=\"form-JianmingZhangGoodViewHunting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianming Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianmingZhangGoodViewHunting').submit();\">Jianming Zhang</a>,\n</form>\n<form id=\"form-XiaohuiShenGoodViewHunting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaohui Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaohuiShenGoodViewHunting').submit();\">Xiaohui Shen</a>,\n</form>\n<form id=\"form-ZheLinGoodViewHunting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhe Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZheLinGoodViewHunting').submit();\">Zhe Lin</a>,\n</form>\n<form id=\"form-Radom\u00c3\u00adrMechGoodViewHunting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Radom\u00c3\u00adr Mech\">\n<a href=\"#\" onclick=\"document.getElementById('form-Radom\u00c3\u00adrMechGoodViewHunting').submit();\">Radom\u00c3\u00adr Mech</a>,\n</form>\n<form id=\"form-MinhHoaiGoodViewHunting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Minh Hoai\">\n<a href=\"#\" onclick=\"document.getElementById('form-MinhHoaiGoodViewHunting').submit();\">Minh Hoai</a>,\n</form>\n<form id=\"form-DimitrisSamarasGoodViewHunting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dimitris Samaras\">\n<a href=\"#\" onclick=\"document.getElementById('form-DimitrisSamarasGoodViewHunting').submit();\">Dimitris Samaras</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wei_Good_View_Hunting_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wei_2018_CVPR,<br>\nauthor = {Wei, Zijun and Zhang, Jianming and Shen, Xiaohui and Lin, Zhe and Mech, Radom\u00c3\u00adr and Hoai, Minh and Samaras, Dimitris},<br>\ntitle = {Good View Hunting: Learning Photo Composition From Dense View Pairs},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lee_CleanNet_Transfer_Learning_CVPR_2018_paper.html\">CleanNet: Transfer Learning for Scalable Image Classifier Training With Label Noise</a></dt>\n<dd>\n<form id=\"form-Kuang-HueiLeeCleanNetTransferLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kuang-Huei Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-Kuang-HueiLeeCleanNetTransferLearning').submit();\">Kuang-Huei Lee</a>,\n</form>\n<form id=\"form-XiaodongHeCleanNetTransferLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaodong He\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaodongHeCleanNetTransferLearning').submit();\">Xiaodong He</a>,\n</form>\n<form id=\"form-LeiZhangCleanNetTransferLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lei Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeiZhangCleanNetTransferLearning').submit();\">Lei Zhang</a>,\n</form>\n<form id=\"form-LinjunYangCleanNetTransferLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Linjun Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LinjunYangCleanNetTransferLearning').submit();\">Linjun Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lee_CleanNet_Transfer_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.07131\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lee_2018_CVPR,<br>\nauthor = {Lee, Kuang-Huei and He, Xiaodong and Zhang, Lei and Yang, Linjun},<br>\ntitle = {CleanNet: Transfer Learning for Scalable Image Classifier Training With Label Noise},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Independently_Recurrent_Neural_CVPR_2018_paper.html\">Independently Recurrent Neural Network (IndRNN): Building a Longer and Deeper RNN</a></dt>\n<dd>\n<form id=\"form-ShuaiLiIndependentlyRecurrentNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuai Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuaiLiIndependentlyRecurrentNeural').submit();\">Shuai Li</a>,\n</form>\n<form id=\"form-WanqingLiIndependentlyRecurrentNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wanqing Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-WanqingLiIndependentlyRecurrentNeural').submit();\">Wanqing Li</a>,\n</form>\n<form id=\"form-ChrisCookIndependentlyRecurrentNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chris Cook\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChrisCookIndependentlyRecurrentNeural').submit();\">Chris Cook</a>,\n</form>\n<form id=\"form-CeZhuIndependentlyRecurrentNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ce Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-CeZhuIndependentlyRecurrentNeural').submit();\">Ce Zhu</a>,\n</form>\n<form id=\"form-YanboGaoIndependentlyRecurrentNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yanbo Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanboGaoIndependentlyRecurrentNeural').submit();\">Yanbo Gao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Independently_Recurrent_Neural_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.04831\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Shuai and Li, Wanqing and Cook, Chris and Zhu, Ce and Gao, Yanbo},<br>\ntitle = {Independently Recurrent Neural Network (IndRNN): Building a Longer and Deeper RNN},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Mix_and_Match_CVPR_2018_paper.html\">Mix and Match Networks: Encoder-Decoder Alignment for Zero-Pair Image Translation</a></dt>\n<dd>\n<form id=\"form-YaxingWangMixandMatch\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yaxing Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YaxingWangMixandMatch').submit();\">Yaxing Wang</a>,\n</form>\n<form id=\"form-JoostvanMixandMatch\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Joost van de Weijer\">\n<a href=\"#\" onclick=\"document.getElementById('form-JoostvanMixandMatch').submit();\">Joost van de Weijer</a>,\n</form>\n<form id=\"form-LuisHerranzMixandMatch\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Luis Herranz\">\n<a href=\"#\" onclick=\"document.getElementById('form-LuisHerranzMixandMatch').submit();\">Luis Herranz</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Mix_and_Match_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3617-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.02199\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Yaxing and van de Weijer, Joost and Herranz, Luis},<br>\ntitle = {Mix and Match Networks: Encoder-Decoder Alignment for Zero-Pair Image Translation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Dorta_Structured_Uncertainty_Prediction_CVPR_2018_paper.html\">Structured Uncertainty Prediction Networks</a></dt>\n<dd>\n<form id=\"form-GaroeDortaStructuredUncertaintyPrediction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Garoe Dorta\">\n<a href=\"#\" onclick=\"document.getElementById('form-GaroeDortaStructuredUncertaintyPrediction').submit();\">Garoe Dorta</a>,\n</form>\n<form id=\"form-SaraVicenteStructuredUncertaintyPrediction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sara Vicente\">\n<a href=\"#\" onclick=\"document.getElementById('form-SaraVicenteStructuredUncertaintyPrediction').submit();\">Sara Vicente</a>,\n</form>\n<form id=\"form-LourdesAgapitoStructuredUncertaintyPrediction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lourdes Agapito\">\n<a href=\"#\" onclick=\"document.getElementById('form-LourdesAgapitoStructuredUncertaintyPrediction').submit();\">Lourdes Agapito</a>,\n</form>\n<form id=\"form-NeillD.StructuredUncertaintyPrediction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Neill D. F. Campbell\">\n<a href=\"#\" onclick=\"document.getElementById('form-NeillD.StructuredUncertaintyPrediction').submit();\">Neill D. F. Campbell</a>,\n</form>\n<form id=\"form-IvorSimpsonStructuredUncertaintyPrediction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ivor Simpson\">\n<a href=\"#\" onclick=\"document.getElementById('form-IvorSimpsonStructuredUncertaintyPrediction').submit();\">Ivor Simpson</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Dorta_Structured_Uncertainty_Prediction_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3702-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.07079\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Dorta_2018_CVPR,<br>\nauthor = {Dorta, Garoe and Vicente, Sara and Agapito, Lourdes and Campbell, Neill D. F. and Simpson, Ivor},<br>\ntitle = {Structured Uncertainty Prediction Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tokozume_Between-Class_Learning_for_CVPR_2018_paper.html\">Between-Class Learning for Image Classification</a></dt>\n<dd>\n<form id=\"form-YujiTokozumeBetweenClassLearningfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuji Tokozume\">\n<a href=\"#\" onclick=\"document.getElementById('form-YujiTokozumeBetweenClassLearningfor').submit();\">Yuji Tokozume</a>,\n</form>\n<form id=\"form-YoshitakaUshikuBetweenClassLearningfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yoshitaka Ushiku\">\n<a href=\"#\" onclick=\"document.getElementById('form-YoshitakaUshikuBetweenClassLearningfor').submit();\">Yoshitaka Ushiku</a>,\n</form>\n<form id=\"form-TatsuyaHaradaBetweenClassLearningfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tatsuya Harada\">\n<a href=\"#\" onclick=\"document.getElementById('form-TatsuyaHaradaBetweenClassLearningfor').submit();\">Tatsuya Harada</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tokozume_Between-Class_Learning_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3905-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.10284\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tokozume_2018_CVPR,<br>\nauthor = {Tokozume, Yuji and Ushiku, Yoshitaka and Harada, Tatsuya},<br>\ntitle = {Between-Class Learning for Image Classification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Volpi_Adversarial_Feature_Augmentation_CVPR_2018_paper.html\">Adversarial Feature Augmentation for Unsupervised Domain Adaptation</a></dt>\n<dd>\n<form id=\"form-RiccardoVolpiAdversarialFeatureAugmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Riccardo Volpi\">\n<a href=\"#\" onclick=\"document.getElementById('form-RiccardoVolpiAdversarialFeatureAugmentation').submit();\">Riccardo Volpi</a>,\n</form>\n<form id=\"form-PietroMorerioAdversarialFeatureAugmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pietro Morerio\">\n<a href=\"#\" onclick=\"document.getElementById('form-PietroMorerioAdversarialFeatureAugmentation').submit();\">Pietro Morerio</a>,\n</form>\n<form id=\"form-SilvioSavareseAdversarialFeatureAugmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Silvio Savarese\">\n<a href=\"#\" onclick=\"document.getElementById('form-SilvioSavareseAdversarialFeatureAugmentation').submit();\">Silvio Savarese</a>,\n</form>\n<form id=\"form-VittorioMurinoAdversarialFeatureAugmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vittorio Murino\">\n<a href=\"#\" onclick=\"document.getElementById('form-VittorioMurinoAdversarialFeatureAugmentation').submit();\">Vittorio Murino</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Volpi_Adversarial_Feature_Augmentation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3995-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.08561\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Volpi_2018_CVPR,<br>\nauthor = {Volpi, Riccardo and Morerio, Pietro and Savarese, Silvio and Murino, Vittorio},<br>\ntitle = {Adversarial Feature Augmentation for Unsupervised Domain Adaptation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yu_Generative_Image_Inpainting_CVPR_2018_paper.html\">Generative Image Inpainting With Contextual Attention</a></dt>\n<dd>\n<form id=\"form-JiahuiYuGenerativeImageInpainting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiahui Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiahuiYuGenerativeImageInpainting').submit();\">Jiahui Yu</a>,\n</form>\n<form id=\"form-ZheLinGenerativeImageInpainting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhe Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZheLinGenerativeImageInpainting').submit();\">Zhe Lin</a>,\n</form>\n<form id=\"form-JimeiYangGenerativeImageInpainting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jimei Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JimeiYangGenerativeImageInpainting').submit();\">Jimei Yang</a>,\n</form>\n<form id=\"form-XiaohuiShenGenerativeImageInpainting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaohui Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaohuiShenGenerativeImageInpainting').submit();\">Xiaohui Shen</a>,\n</form>\n<form id=\"form-XinLuGenerativeImageInpainting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xin Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinLuGenerativeImageInpainting').submit();\">Xin Lu</a>,\n</form>\n<form id=\"form-ThomasS.GenerativeImageInpainting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Thomas S. Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ThomasS.GenerativeImageInpainting').submit();\">Thomas S. Huang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yu_Generative_Image_Inpainting_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0456-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.07892\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yu_2018_CVPR,<br>\nauthor = {Yu, Jiahui and Lin, Zhe and Yang, Jimei and Shen, Xiaohui and Lu, Xin and Huang, Thomas S.},<br>\ntitle = {Generative Image Inpainting With Contextual Attention},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sharma_CSGNet_Neural_Shape_CVPR_2018_paper.html\">CSGNet: Neural Shape Parser for Constructive Solid Geometry</a></dt>\n<dd>\n<form id=\"form-GopalSharmaCSGNetNeuralShape\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gopal Sharma\">\n<a href=\"#\" onclick=\"document.getElementById('form-GopalSharmaCSGNetNeuralShape').submit();\">Gopal Sharma</a>,\n</form>\n<form id=\"form-RishabhGoyalCSGNetNeuralShape\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rishabh Goyal\">\n<a href=\"#\" onclick=\"document.getElementById('form-RishabhGoyalCSGNetNeuralShape').submit();\">Rishabh Goyal</a>,\n</form>\n<form id=\"form-DifanLiuCSGNetNeuralShape\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Difan Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-DifanLiuCSGNetNeuralShape').submit();\">Difan Liu</a>,\n</form>\n<form id=\"form-EvangelosKalogerakisCSGNetNeuralShape\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Evangelos Kalogerakis\">\n<a href=\"#\" onclick=\"document.getElementById('form-EvangelosKalogerakisCSGNetNeuralShape').submit();\">Evangelos Kalogerakis</a>,\n</form>\n<form id=\"form-SubhransuMajiCSGNetNeuralShape\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Subhransu Maji\">\n<a href=\"#\" onclick=\"document.getElementById('form-SubhransuMajiCSGNetNeuralShape').submit();\">Subhransu Maji</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sharma_CSGNet_Neural_Shape_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0561-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.08290\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sharma_2018_CVPR,<br>\nauthor = {Sharma, Gopal and Goyal, Rishabh and Liu, Difan and Kalogerakis, Evangelos and Maji, Subhransu},<br>\ntitle = {CSGNet: Neural Shape Parser for Constructive Solid Geometry},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lin_Conditional_Image-to-Image_Translation_CVPR_2018_paper.html\">Conditional Image-to-Image Translation</a></dt>\n<dd>\n<form id=\"form-JianxinLinConditionalImagetoImageTranslation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianxin Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianxinLinConditionalImagetoImageTranslation').submit();\">Jianxin Lin</a>,\n</form>\n<form id=\"form-YingceXiaConditionalImagetoImageTranslation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yingce Xia\">\n<a href=\"#\" onclick=\"document.getElementById('form-YingceXiaConditionalImagetoImageTranslation').submit();\">Yingce Xia</a>,\n</form>\n<form id=\"form-TaoQinConditionalImagetoImageTranslation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tao Qin\">\n<a href=\"#\" onclick=\"document.getElementById('form-TaoQinConditionalImagetoImageTranslation').submit();\">Tao Qin</a>,\n</form>\n<form id=\"form-ZhiboChenConditionalImagetoImageTranslation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhibo Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhiboChenConditionalImagetoImageTranslation').submit();\">Zhibo Chen</a>,\n</form>\n<form id=\"form-Tie-YanLiuConditionalImagetoImageTranslation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tie-Yan Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Tie-YanLiuConditionalImagetoImageTranslation').submit();\">Tie-Yan Liu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lin_Conditional_Image-to-Image_Translation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.00251\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lin_2018_CVPR,<br>\nauthor = {Lin, Jianxin and Xia, Yingce and Qin, Tao and Chen, Zhibo and Liu, Tie-Yan},<br>\ntitle = {Conditional Image-to-Image Translation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Le-Huu_Continuous_Relaxation_of_CVPR_2018_paper.html\">Continuous Relaxation of MAP Inference: A Nonconvex Perspective</a></dt>\n<dd>\n<form id=\"form-D.Khu\u00c3\u00aaContinuousRelaxationof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"D. Khu\u00c3\u00aa L\u00c3\u00aa-Huu\">\n<a href=\"#\" onclick=\"document.getElementById('form-D.Khu\u00c3\u00aaContinuousRelaxationof').submit();\">D. Khu\u00c3\u00aa L\u00c3\u00aa-Huu</a>,\n</form>\n<form id=\"form-NikosParagiosContinuousRelaxationof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nikos Paragios\">\n<a href=\"#\" onclick=\"document.getElementById('form-NikosParagiosContinuousRelaxationof').submit();\">Nikos Paragios</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Le-Huu_Continuous_Relaxation_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2695-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.07796\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{L\u00c3\u00aa-Huu_2018_CVPR,<br>\nauthor = {Khu\u00c3\u00aa L\u00c3\u00aa-Huu, D. and Paragios, Nikos},<br>\ntitle = {Continuous Relaxation of MAP Inference: A Nonconvex Perspective},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xian_Feature_Generating_Networks_CVPR_2018_paper.html\">Feature Generating Networks for Zero-Shot Learning</a></dt>\n<dd>\n<form id=\"form-YongqinXianFeatureGeneratingNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yongqin Xian\">\n<a href=\"#\" onclick=\"document.getElementById('form-YongqinXianFeatureGeneratingNetworks').submit();\">Yongqin Xian</a>,\n</form>\n<form id=\"form-TobiasLorenzFeatureGeneratingNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tobias Lorenz\">\n<a href=\"#\" onclick=\"document.getElementById('form-TobiasLorenzFeatureGeneratingNetworks').submit();\">Tobias Lorenz</a>,\n</form>\n<form id=\"form-BerntSchieleFeatureGeneratingNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bernt Schiele\">\n<a href=\"#\" onclick=\"document.getElementById('form-BerntSchieleFeatureGeneratingNetworks').submit();\">Bernt Schiele</a>,\n</form>\n<form id=\"form-ZeynepAkataFeatureGeneratingNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zeynep Akata\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZeynepAkataFeatureGeneratingNetworks').submit();\">Zeynep Akata</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xian_Feature_Generating_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2709-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.00981\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xian_2018_CVPR,<br>\nauthor = {Xian, Yongqin and Lorenz, Tobias and Schiele, Bernt and Akata, Zeynep},<br>\ntitle = {Feature Generating Networks for Zero-Shot Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tanaka_Joint_Optimization_Framework_CVPR_2018_paper.html\">Joint Optimization Framework for Learning With Noisy Labels</a></dt>\n<dd>\n<form id=\"form-DaikiTanakaJointOptimizationFramework\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daiki Tanaka\">\n<a href=\"#\" onclick=\"document.getElementById('form-DaikiTanakaJointOptimizationFramework').submit();\">Daiki Tanaka</a>,\n</form>\n<form id=\"form-DaikiIkamiJointOptimizationFramework\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daiki Ikami\">\n<a href=\"#\" onclick=\"document.getElementById('form-DaikiIkamiJointOptimizationFramework').submit();\">Daiki Ikami</a>,\n</form>\n<form id=\"form-ToshihikoYamasakiJointOptimizationFramework\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Toshihiko Yamasaki\">\n<a href=\"#\" onclick=\"document.getElementById('form-ToshihikoYamasakiJointOptimizationFramework').submit();\">Toshihiko Yamasaki</a>,\n</form>\n<form id=\"form-KiyoharuAizawaJointOptimizationFramework\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kiyoharu Aizawa\">\n<a href=\"#\" onclick=\"document.getElementById('form-KiyoharuAizawaJointOptimizationFramework').submit();\">Kiyoharu Aizawa</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tanaka_Joint_Optimization_Framework_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3107-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.11364\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tanaka_2018_CVPR,<br>\nauthor = {Tanaka, Daiki and Ikami, Daiki and Yamasaki, Toshihiko and Aizawa, Kiyoharu},<br>\ntitle = {Joint Optimization Framework for Learning With Noisy Labels},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Aneja_Convolutional_Image_Captioning_CVPR_2018_paper.html\">Convolutional Image Captioning</a></dt>\n<dd>\n<form id=\"form-JyotiAnejaConvolutionalImageCaptioning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jyoti Aneja\">\n<a href=\"#\" onclick=\"document.getElementById('form-JyotiAnejaConvolutionalImageCaptioning').submit();\">Jyoti Aneja</a>,\n</form>\n<form id=\"form-AdityaDeshpandeConvolutionalImageCaptioning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Aditya Deshpande\">\n<a href=\"#\" onclick=\"document.getElementById('form-AdityaDeshpandeConvolutionalImageCaptioning').submit();\">Aditya Deshpande</a>,\n</form>\n<form id=\"form-AlexanderG.ConvolutionalImageCaptioning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexander G. Schwing\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexanderG.ConvolutionalImageCaptioning').submit();\">Alexander G. Schwing</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Aneja_Convolutional_Image_Captioning_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3325-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.09019\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Aneja_2018_CVPR,<br>\nauthor = {Aneja, Jyoti and Deshpande, Aditya and Schwing, Alexander G.},<br>\ntitle = {Convolutional Image Captioning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Cheng_AON_Towards_Arbitrarily-Oriented_CVPR_2018_paper.html\">AON: Towards Arbitrarily-Oriented Text Recognition</a></dt>\n<dd>\n<form id=\"form-ZhanzhanChengAONTowardsArbitrarilyOriented\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhanzhan Cheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhanzhanChengAONTowardsArbitrarilyOriented').submit();\">Zhanzhan Cheng</a>,\n</form>\n<form id=\"form-YangliuXuAONTowardsArbitrarilyOriented\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yangliu Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YangliuXuAONTowardsArbitrarilyOriented').submit();\">Yangliu Xu</a>,\n</form>\n<form id=\"form-FanBaiAONTowardsArbitrarilyOriented\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fan Bai\">\n<a href=\"#\" onclick=\"document.getElementById('form-FanBaiAONTowardsArbitrarilyOriented').submit();\">Fan Bai</a>,\n</form>\n<form id=\"form-YiNiuAONTowardsArbitrarilyOriented\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi Niu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiNiuAONTowardsArbitrarilyOriented').submit();\">Yi Niu</a>,\n</form>\n<form id=\"form-ShiliangPuAONTowardsArbitrarilyOriented\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shiliang Pu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShiliangPuAONTowardsArbitrarilyOriented').submit();\">Shiliang Pu</a>,\n</form>\n<form id=\"form-ShuigengZhouAONTowardsArbitrarilyOriented\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuigeng Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuigengZhouAONTowardsArbitrarilyOriented').submit();\">Shuigeng Zhou</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Cheng_AON_Towards_Arbitrarily-Oriented_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.04226\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Cheng_2018_CVPR,<br>\nauthor = {Cheng, Zhanzhan and Xu, Yangliu and Bai, Fan and Niu, Yi and Pu, Shiliang and Zhou, Shuigeng},<br>\ntitle = {AON: Towards Arbitrarily-Oriented Text Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Mallasto_Wrapped_Gaussian_Process_CVPR_2018_paper.html\">Wrapped Gaussian Process Regression on Riemannian Manifolds</a></dt>\n<dd>\n<form id=\"form-AntonMallastoWrappedGaussianProcess\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anton Mallasto\">\n<a href=\"#\" onclick=\"document.getElementById('form-AntonMallastoWrappedGaussianProcess').submit();\">Anton Mallasto</a>,\n</form>\n<form id=\"form-AasaFeragenWrappedGaussianProcess\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Aasa Feragen\">\n<a href=\"#\" onclick=\"document.getElementById('form-AasaFeragenWrappedGaussianProcess').submit();\">Aasa Feragen</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Mallasto_Wrapped_Gaussian_Process_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Mallasto_2018_CVPR,<br>\nauthor = {Mallasto, Anton and Feragen, Aasa},<br>\ntitle = {Wrapped Gaussian Process Regression on Riemannian Manifolds},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Gan_Geometry_Guided_Convolutional_CVPR_2018_paper.html\">Geometry Guided Convolutional Neural Networks for Self-Supervised Video Representation Learning</a></dt>\n<dd>\n<form id=\"form-ChuangGanGeometryGuidedConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chuang Gan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChuangGanGeometryGuidedConvolutional').submit();\">Chuang Gan</a>,\n</form>\n<form id=\"form-BoqingGongGeometryGuidedConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Boqing Gong\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoqingGongGeometryGuidedConvolutional').submit();\">Boqing Gong</a>,\n</form>\n<form id=\"form-KunLiuGeometryGuidedConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kun Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-KunLiuGeometryGuidedConvolutional').submit();\">Kun Liu</a>,\n</form>\n<form id=\"form-HaoSuGeometryGuidedConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hao Su\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaoSuGeometryGuidedConvolutional').submit();\">Hao Su</a>,\n</form>\n<form id=\"form-LeonidasJ.GeometryGuidedConvolutional\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Leonidas J. Guibas\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeonidasJ.GeometryGuidedConvolutional').submit();\">Leonidas J. Guibas</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Gan_Geometry_Guided_Convolutional_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Gan_2018_CVPR,<br>\nauthor = {Gan, Chuang and Gong, Boqing and Liu, Kun and Su, Hao and Guibas, Leonidas J.},<br>\ntitle = {Geometry Guided Convolutional Neural Networks for Self-Supervised Video Representation Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Firman_DiverseNet_When_One_CVPR_2018_paper.html\">DiverseNet: When One Right Answer Is Not Enough</a></dt>\n<dd>\n<form id=\"form-MichaelFirmanDiverseNetWhenOne\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michael Firman\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichaelFirmanDiverseNetWhenOne').submit();\">Michael Firman</a>,\n</form>\n<form id=\"form-NeillD.DiverseNetWhenOne\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Neill D. F. Campbell\">\n<a href=\"#\" onclick=\"document.getElementById('form-NeillD.DiverseNetWhenOne').submit();\">Neill D. F. Campbell</a>,\n</form>\n<form id=\"form-LourdesAgapitoDiverseNetWhenOne\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lourdes Agapito\">\n<a href=\"#\" onclick=\"document.getElementById('form-LourdesAgapitoDiverseNetWhenOne').submit();\">Lourdes Agapito</a>,\n</form>\n<form id=\"form-GabrielJ.DiverseNetWhenOne\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gabriel J. Brostow\">\n<a href=\"#\" onclick=\"document.getElementById('form-GabrielJ.DiverseNetWhenOne').submit();\">Gabriel J. Brostow</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Firman_DiverseNet_When_One_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Firman_2018_CVPR,<br>\nauthor = {Firman, Michael and Campbell, Neill D. F. and Agapito, Lourdes and Brostow, Gabriel J.},<br>\ntitle = {DiverseNet: When One Right Answer Is Not Enough},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Jamal_Deep_Face_Detector_CVPR_2018_paper.html\">Deep Face Detector Adaptation Without Negative Transfer or Catastrophic Forgetting</a></dt>\n<dd>\n<form id=\"form-MuhammadAbdullahDeepFaceDetector\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Muhammad Abdullah Jamal\">\n<a href=\"#\" onclick=\"document.getElementById('form-MuhammadAbdullahDeepFaceDetector').submit();\">Muhammad Abdullah Jamal</a>,\n</form>\n<form id=\"form-HaoxiangLiDeepFaceDetector\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Haoxiang Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaoxiangLiDeepFaceDetector').submit();\">Haoxiang Li</a>,\n</form>\n<form id=\"form-BoqingGongDeepFaceDetector\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Boqing Gong\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoqingGongDeepFaceDetector').submit();\">Boqing Gong</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Jamal_Deep_Face_Detector_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2744-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Jamal_2018_CVPR,<br>\nauthor = {Abdullah Jamal, Muhammad and Li, Haoxiang and Gong, Boqing},<br>\ntitle = {Deep Face Detector Adaptation Without Negative Transfer or Catastrophic Forgetting},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kobayashi_Analyzing_Filters_Toward_CVPR_2018_paper.html\">Analyzing Filters Toward Efficient ConvNet</a></dt>\n<dd>\n<form id=\"form-TakumiKobayashiAnalyzingFiltersToward\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Takumi Kobayashi\">\n<a href=\"#\" onclick=\"document.getElementById('form-TakumiKobayashiAnalyzingFiltersToward').submit();\">Takumi Kobayashi</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kobayashi_Analyzing_Filters_Toward_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3073-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kobayashi_2018_CVPR,<br>\nauthor = {Kobayashi, Takumi},<br>\ntitle = {Analyzing Filters Toward Efficient ConvNet},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Mostajabi_Regularizing_Deep_Networks_CVPR_2018_paper.html\">Regularizing Deep Networks by Modeling and Predicting Label Structure</a></dt>\n<dd>\n<form id=\"form-MohammadrezaMostajabiRegularizingDeepNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mohammadreza Mostajabi\">\n<a href=\"#\" onclick=\"document.getElementById('form-MohammadrezaMostajabiRegularizingDeepNetworks').submit();\">Mohammadreza Mostajabi</a>,\n</form>\n<form id=\"form-MichaelMaireRegularizingDeepNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michael Maire\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichaelMaireRegularizingDeepNetworks').submit();\">Michael Maire</a>,\n</form>\n<form id=\"form-GregoryShakhnarovichRegularizingDeepNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gregory Shakhnarovich\">\n<a href=\"#\" onclick=\"document.getElementById('form-GregoryShakhnarovichRegularizingDeepNetworks').submit();\">Gregory Shakhnarovich</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Mostajabi_Regularizing_Deep_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.02009\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Mostajabi_2018_CVPR,<br>\nauthor = {Mostajabi, Mohammadreza and Maire, Michael and Shakhnarovich, Gregory},<br>\ntitle = {Regularizing Deep Networks by Modeling and Predicting Label Structure},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Bulo_In-Place_Activated_BatchNorm_CVPR_2018_paper.html\">In-Place Activated BatchNorm for Memory-Optimized Training of DNNs</a></dt>\n<dd>\n<form id=\"form-SamuelRotaInPlaceActivatedBatchNorm\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Samuel Rota Bul\u00c3\u00b2\">\n<a href=\"#\" onclick=\"document.getElementById('form-SamuelRotaInPlaceActivatedBatchNorm').submit();\">Samuel Rota Bul\u00c3\u00b2</a>,\n</form>\n<form id=\"form-LorenzoPorziInPlaceActivatedBatchNorm\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lorenzo Porzi\">\n<a href=\"#\" onclick=\"document.getElementById('form-LorenzoPorziInPlaceActivatedBatchNorm').submit();\">Lorenzo Porzi</a>,\n</form>\n<form id=\"form-PeterKontschiederInPlaceActivatedBatchNorm\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peter Kontschieder\">\n<a href=\"#\" onclick=\"document.getElementById('form-PeterKontschiederInPlaceActivatedBatchNorm').submit();\">Peter Kontschieder</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Bulo_In-Place_Activated_BatchNorm_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.02616\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Bul\u00c3\u00b2_2018_CVPR,<br>\nauthor = {Rota Bul\u00c3\u00b2, Samuel and Porzi, Lorenzo and Kontschieder, Peter},<br>\ntitle = {In-Place Activated BatchNorm for Memory-Optimized Training of DNNs},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kafle_DVQA_Understanding_Data_CVPR_2018_paper.html\">DVQA: Understanding Data Visualizations via Question Answering</a></dt>\n<dd>\n<form id=\"form-KushalKafleDVQAUnderstandingData\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kushal Kafle\">\n<a href=\"#\" onclick=\"document.getElementById('form-KushalKafleDVQAUnderstandingData').submit();\">Kushal Kafle</a>,\n</form>\n<form id=\"form-BrianPriceDVQAUnderstandingData\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Brian Price\">\n<a href=\"#\" onclick=\"document.getElementById('form-BrianPriceDVQAUnderstandingData').submit();\">Brian Price</a>,\n</form>\n<form id=\"form-ScottCohenDVQAUnderstandingData\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Scott Cohen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ScottCohenDVQAUnderstandingData').submit();\">Scott Cohen</a>,\n</form>\n<form id=\"form-ChristopherKananDVQAUnderstandingData\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Christopher Kanan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChristopherKananDVQAUnderstandingData').submit();\">Christopher Kanan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kafle_DVQA_Understanding_Data_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2040-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.08163\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kafle_2018_CVPR,<br>\nauthor = {Kafle, Kushal and Price, Brian and Cohen, Scott and Kanan, Christopher},<br>\ntitle = {DVQA: Understanding Data Visualizations via Question Answering},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ma_DA-GAN_Instance-Level_Image_CVPR_2018_paper.html\">DA-GAN: Instance-Level Image Translation by Deep Attention Generative Adversarial Networks</a></dt>\n<dd>\n<form id=\"form-ShuangMaDAGANInstanceLevelImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuang Ma\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuangMaDAGANInstanceLevelImage').submit();\">Shuang Ma</a>,\n</form>\n<form id=\"form-JianlongFuDAGANInstanceLevelImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianlong Fu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianlongFuDAGANInstanceLevelImage').submit();\">Jianlong Fu</a>,\n</form>\n<form id=\"form-ChangWenDAGANInstanceLevelImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chang Wen Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChangWenDAGANInstanceLevelImage').submit();\">Chang Wen Chen</a>,\n</form>\n<form id=\"form-TaoMeiDAGANInstanceLevelImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tao Mei\">\n<a href=\"#\" onclick=\"document.getElementById('form-TaoMeiDAGANInstanceLevelImage').submit();\">Tao Mei</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ma_DA-GAN_Instance-Level_Image_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1877-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.06454\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ma_2018_CVPR,<br>\nauthor = {Ma, Shuang and Fu, Jianlong and Wen Chen, Chang and Mei, Tao},<br>\ntitle = {DA-GAN: Instance-Level Image Translation by Deep Attention Generative Adversarial Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Mahjourian_Unsupervised_Learning_of_CVPR_2018_paper.html\">Unsupervised Learning of Depth and Ego-Motion From Monocular Video Using 3D Geometric Constraints</a></dt>\n<dd>\n<form id=\"form-RezaMahjourianUnsupervisedLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Reza Mahjourian\">\n<a href=\"#\" onclick=\"document.getElementById('form-RezaMahjourianUnsupervisedLearningof').submit();\">Reza Mahjourian</a>,\n</form>\n<form id=\"form-MartinWickeUnsupervisedLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Martin Wicke\">\n<a href=\"#\" onclick=\"document.getElementById('form-MartinWickeUnsupervisedLearningof').submit();\">Martin Wicke</a>,\n</form>\n<form id=\"form-AneliaAngelovaUnsupervisedLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anelia Angelova\">\n<a href=\"#\" onclick=\"document.getElementById('form-AneliaAngelovaUnsupervisedLearningof').submit();\">Anelia Angelova</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Mahjourian_Unsupervised_Learning_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.05522\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Mahjourian_2018_CVPR,<br>\nauthor = {Mahjourian, Reza and Wicke, Martin and Angelova, Anelia},<br>\ntitle = {Unsupervised Learning of Depth and Ego-Motion From Monocular Video Using 3D Geometric Constraints},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_FOTS_Fast_Oriented_CVPR_2018_paper.html\">FOTS: Fast Oriented Text Spotting With a Unified Network</a></dt>\n<dd>\n<form id=\"form-XueboLiuFOTSFastOriented\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xuebo Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XueboLiuFOTSFastOriented').submit();\">Xuebo Liu</a>,\n</form>\n<form id=\"form-DingLiangFOTSFastOriented\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ding Liang\">\n<a href=\"#\" onclick=\"document.getElementById('form-DingLiangFOTSFastOriented').submit();\">Ding Liang</a>,\n</form>\n<form id=\"form-ShiYanFOTSFastOriented\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shi Yan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShiYanFOTSFastOriented').submit();\">Shi Yan</a>,\n</form>\n<form id=\"form-DaguiChenFOTSFastOriented\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dagui Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-DaguiChenFOTSFastOriented').submit();\">Dagui Chen</a>,\n</form>\n<form id=\"form-YuQiaoFOTSFastOriented\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu Qiao\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuQiaoFOTSFastOriented').submit();\">Yu Qiao</a>,\n</form>\n<form id=\"form-JunjieYanFOTSFastOriented\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junjie Yan\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunjieYanFOTSFastOriented').submit();\">Junjie Yan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_FOTS_Fast_Oriented_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.01671\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Xuebo and Liang, Ding and Yan, Shi and Chen, Dagui and Qiao, Yu and Yan, Junjie},<br>\ntitle = {FOTS: Fast Oriented Text Spotting With a Unified Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_Mobile_Video_Object_CVPR_2018_paper.html\">Mobile Video Object Detection With Temporally-Aware Feature Maps</a></dt>\n<dd>\n<form id=\"form-MasonLiuMobileVideoObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mason Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-MasonLiuMobileVideoObject').submit();\">Mason Liu</a>,\n</form>\n<form id=\"form-MenglongZhuMobileVideoObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Menglong Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-MenglongZhuMobileVideoObject').submit();\">Menglong Zhu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_Mobile_Video_Object_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.06368\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Mason and Zhu, Menglong},<br>\ntitle = {Mobile Video Object Detection With Temporally-Aware Feature Maps},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhao_Weakly_Supervised_Phrase_CVPR_2018_paper.html\">Weakly Supervised Phrase Localization With Multi-Scale Anchored Transformer Network</a></dt>\n<dd>\n<form id=\"form-FangZhaoWeaklySupervisedPhrase\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fang Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-FangZhaoWeaklySupervisedPhrase').submit();\">Fang Zhao</a>,\n</form>\n<form id=\"form-JianshuLiWeaklySupervisedPhrase\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianshu Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianshuLiWeaklySupervisedPhrase').submit();\">Jianshu Li</a>,\n</form>\n<form id=\"form-JianZhaoWeaklySupervisedPhrase\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jian Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianZhaoWeaklySupervisedPhrase').submit();\">Jian Zhao</a>,\n</form>\n<form id=\"form-JiashiFengWeaklySupervisedPhrase\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiashi Feng\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiashiFengWeaklySupervisedPhrase').submit();\">Jiashi Feng</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhao_Weakly_Supervised_Phrase_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhao_2018_CVPR,<br>\nauthor = {Zhao, Fang and Li, Jianshu and Zhao, Jian and Feng, Jiashi},<br>\ntitle = {Weakly Supervised Phrase Localization With Multi-Scale Anchored Transformer Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Radenovic_Revisiting_Oxford_and_CVPR_2018_paper.html\">Revisiting Oxford and Paris: Large-Scale Image Retrieval Benchmarking</a></dt>\n<dd>\n<form id=\"form-FilipRadenovi\u00c4\u0087RevisitingOxfordand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Filip Radenovi\u00c4\u0087\">\n<a href=\"#\" onclick=\"document.getElementById('form-FilipRadenovi\u00c4\u0087RevisitingOxfordand').submit();\">Filip Radenovi\u00c4\u0087</a>,\n</form>\n<form id=\"form-AhmetIscenRevisitingOxfordand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ahmet Iscen\">\n<a href=\"#\" onclick=\"document.getElementById('form-AhmetIscenRevisitingOxfordand').submit();\">Ahmet Iscen</a>,\n</form>\n<form id=\"form-GiorgosToliasRevisitingOxfordand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Giorgos Tolias\">\n<a href=\"#\" onclick=\"document.getElementById('form-GiorgosToliasRevisitingOxfordand').submit();\">Giorgos Tolias</a>,\n</form>\n<form id=\"form-YannisAvrithisRevisitingOxfordand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yannis Avrithis\">\n<a href=\"#\" onclick=\"document.getElementById('form-YannisAvrithisRevisitingOxfordand').submit();\">Yannis Avrithis</a>,\n</form>\n<form id=\"form-Ond\u00c5\u0099ejChumRevisitingOxfordand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ond\u00c5\u0099ej Chum\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ond\u00c5\u0099ejChumRevisitingOxfordand').submit();\">Ond\u00c5\u0099ej Chum</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Radenovic_Revisiting_Oxford_and_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.11285\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Radenovi\u00c4\u0087_2018_CVPR,<br>\nauthor = {Radenovi\u00c4\u0087, Filip and Iscen, Ahmet and Tolias, Giorgos and Avrithis, Yannis and Chum, Ond\u00c5\u0099ej},<br>\ntitle = {Revisiting Oxford and Paris: Large-Scale Image Retrieval Benchmarking},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chao_Cross-Dataset_Adaptation_for_CVPR_2018_paper.html\">Cross-Dataset Adaptation for Visual Question Answering</a></dt>\n<dd>\n<form id=\"form-Wei-LunChaoCrossDatasetAdaptationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei-Lun Chao\">\n<a href=\"#\" onclick=\"document.getElementById('form-Wei-LunChaoCrossDatasetAdaptationfor').submit();\">Wei-Lun Chao</a>,\n</form>\n<form id=\"form-HexiangHuCrossDatasetAdaptationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hexiang Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HexiangHuCrossDatasetAdaptationfor').submit();\">Hexiang Hu</a>,\n</form>\n<form id=\"form-FeiShaCrossDatasetAdaptationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fei Sha\">\n<a href=\"#\" onclick=\"document.getElementById('form-FeiShaCrossDatasetAdaptationfor').submit();\">Fei Sha</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chao_Cross-Dataset_Adaptation_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/4249-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1806.03726\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chao_2018_CVPR,<br>\nauthor = {Chao, Wei-Lun and Hu, Hexiang and Sha, Fei},<br>\ntitle = {Cross-Dataset Adaptation for Visual Question Answering},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Joo_Globally_Optimal_Inlier_CVPR_2018_paper.html\">Globally Optimal Inlier Set Maximization for Atlanta Frame Estimation</a></dt>\n<dd>\n<form id=\"form-KyungdonJooGloballyOptimalInlier\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kyungdon Joo\">\n<a href=\"#\" onclick=\"document.getElementById('form-KyungdonJooGloballyOptimalInlier').submit();\">Kyungdon Joo</a>,\n</form>\n<form id=\"form-Tae-HyunOhGloballyOptimalInlier\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tae-Hyun Oh\">\n<a href=\"#\" onclick=\"document.getElementById('form-Tae-HyunOhGloballyOptimalInlier').submit();\">Tae-Hyun Oh</a>,\n</form>\n<form id=\"form-InSoGloballyOptimalInlier\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"In So Kweon\">\n<a href=\"#\" onclick=\"document.getElementById('form-InSoGloballyOptimalInlier').submit();\">In So Kweon</a>,\n</form>\n<form id=\"form-Jean-CharlesBazinGloballyOptimalInlier\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jean-Charles Bazin\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jean-CharlesBazinGloballyOptimalInlier').submit();\">Jean-Charles Bazin</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Joo_Globally_Optimal_Inlier_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2048-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Joo_2018_CVPR,<br>\nauthor = {Joo, Kyungdon and Oh, Tae-Hyun and So Kweon, In and Bazin, Jean-Charles},<br>\ntitle = {Globally Optimal Inlier Set Maximization for Atlanta Frame Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/You_End-to-End_Convolutional_Semantic_CVPR_2018_paper.html\">End-to-End Convolutional Semantic Embeddings</a></dt>\n<dd>\n<form id=\"form-QuanzengYouEndtoEndConvolutionalSemantic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Quanzeng You\">\n<a href=\"#\" onclick=\"document.getElementById('form-QuanzengYouEndtoEndConvolutionalSemantic').submit();\">Quanzeng You</a>,\n</form>\n<form id=\"form-ZhengyouZhangEndtoEndConvolutionalSemantic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhengyou Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhengyouZhangEndtoEndConvolutionalSemantic').submit();\">Zhengyou Zhang</a>,\n</form>\n<form id=\"form-JieboLuoEndtoEndConvolutionalSemantic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiebo Luo\">\n<a href=\"#\" onclick=\"document.getElementById('form-JieboLuoEndtoEndConvolutionalSemantic').submit();\">Jiebo Luo</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/You_End-to-End_Convolutional_Semantic_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{You_2018_CVPR,<br>\nauthor = {You, Quanzeng and Zhang, Zhengyou and Luo, Jiebo},<br>\ntitle = {End-to-End Convolutional Semantic Embeddings},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Referring_Image_Segmentation_CVPR_2018_paper.html\">Referring Image Segmentation via Recurrent Refinement Networks</a></dt>\n<dd>\n<form id=\"form-RuiyuLiReferringImageSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ruiyu Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-RuiyuLiReferringImageSegmentation').submit();\">Ruiyu Li</a>,\n</form>\n<form id=\"form-KaicanLiReferringImageSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kaican Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaicanLiReferringImageSegmentation').submit();\">Kaican Li</a>,\n</form>\n<form id=\"form-Yi-ChunKuoReferringImageSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi-Chun Kuo\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yi-ChunKuoReferringImageSegmentation').submit();\">Yi-Chun Kuo</a>,\n</form>\n<form id=\"form-MichelleShuReferringImageSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michelle Shu\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichelleShuReferringImageSegmentation').submit();\">Michelle Shu</a>,\n</form>\n<form id=\"form-XiaojuanQiReferringImageSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaojuan Qi\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaojuanQiReferringImageSegmentation').submit();\">Xiaojuan Qi</a>,\n</form>\n<form id=\"form-XiaoyongShenReferringImageSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaoyong Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaoyongShenReferringImageSegmentation').submit();\">Xiaoyong Shen</a>,\n</form>\n<form id=\"form-JiayaJiaReferringImageSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiaya Jia\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiayaJiaReferringImageSegmentation').submit();\">Jiaya Jia</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Referring_Image_Segmentation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2788-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Ruiyu and Li, Kaican and Kuo, Yi-Chun and Shu, Michelle and Qi, Xiaojuan and Shen, Xiaoyong and Jia, Jiaya},<br>\ntitle = {Referring Image Segmentation via Recurrent Refinement Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Jain_Two_Can_Play_CVPR_2018_paper.html\">Two Can Play This Game: Visual Dialog With Discriminative Question Generation and Answering</a></dt>\n<dd>\n<form id=\"form-UnnatJainTwoCanPlay\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Unnat Jain\">\n<a href=\"#\" onclick=\"document.getElementById('form-UnnatJainTwoCanPlay').submit();\">Unnat Jain</a>,\n</form>\n<form id=\"form-SvetlanaLazebnikTwoCanPlay\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Svetlana Lazebnik\">\n<a href=\"#\" onclick=\"document.getElementById('form-SvetlanaLazebnikTwoCanPlay').submit();\">Svetlana Lazebnik</a>,\n</form>\n<form id=\"form-AlexanderG.TwoCanPlay\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexander G. Schwing\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexanderG.TwoCanPlay').submit();\">Alexander G. Schwing</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Jain_Two_Can_Play_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3495-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.11186\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Jain_2018_CVPR,<br>\nauthor = {Jain, Unnat and Lazebnik, Svetlana and Schwing, Alexander G.},<br>\ntitle = {Two Can Play This Game: Visual Dialog With Discriminative Question Generation and Answering},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Shen_Generative_Adversarial_Learning_CVPR_2018_paper.html\">Generative Adversarial Learning Towards Fast Weakly Supervised Detection</a></dt>\n<dd>\n<form id=\"form-YunhanShenGenerativeAdversarialLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yunhan Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-YunhanShenGenerativeAdversarialLearning').submit();\">Yunhan Shen</a>,\n</form>\n<form id=\"form-RongrongJiGenerativeAdversarialLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rongrong Ji\">\n<a href=\"#\" onclick=\"document.getElementById('form-RongrongJiGenerativeAdversarialLearning').submit();\">Rongrong Ji</a>,\n</form>\n<form id=\"form-ShengchuanZhangGenerativeAdversarialLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shengchuan Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShengchuanZhangGenerativeAdversarialLearning').submit();\">Shengchuan Zhang</a>,\n</form>\n<form id=\"form-WangmengZuoGenerativeAdversarialLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wangmeng Zuo\">\n<a href=\"#\" onclick=\"document.getElementById('form-WangmengZuoGenerativeAdversarialLearning').submit();\">Wangmeng Zuo</a>,\n</form>\n<form id=\"form-YanWangGenerativeAdversarialLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yan Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanWangGenerativeAdversarialLearning').submit();\">Yan Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Shen_Generative_Adversarial_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Shen_2018_CVPR,<br>\nauthor = {Shen, Yunhan and Ji, Rongrong and Zhang, Shengchuan and Zuo, Wangmeng and Wang, Yan},<br>\ntitle = {Generative Adversarial Learning Towards Fast Weakly Supervised Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Koniusz_A_Deeper_Look_CVPR_2018_paper.html\">A Deeper Look at Power Normalizations</a></dt>\n<dd>\n<form id=\"form-PiotrKoniuszADeeperLook\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Piotr Koniusz\">\n<a href=\"#\" onclick=\"document.getElementById('form-PiotrKoniuszADeeperLook').submit();\">Piotr Koniusz</a>,\n</form>\n<form id=\"form-HongguangZhangADeeperLook\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hongguang Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HongguangZhangADeeperLook').submit();\">Hongguang Zhang</a>,\n</form>\n<form id=\"form-FatihPorikliADeeperLook\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fatih Porikli\">\n<a href=\"#\" onclick=\"document.getElementById('form-FatihPorikliADeeperLook').submit();\">Fatih Porikli</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Koniusz_A_Deeper_Look_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1806.09183\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Koniusz_2018_CVPR,<br>\nauthor = {Koniusz, Piotr and Zhang, Hongguang and Porikli, Fatih},<br>\ntitle = {A Deeper Look at Power Normalizations},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lin_Dimensionalitys_Blessing_Clustering_CVPR_2018_paper.html\">Dimensionality's Blessing: Clustering Images by Underlying Distribution</a></dt>\n<dd>\n<form id=\"form-Wen-YanLinDimensionalitysBlessingClustering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wen-Yan Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-Wen-YanLinDimensionalitysBlessingClustering').submit();\">Wen-Yan Lin</a>,\n</form>\n<form id=\"form-SiyingLiuDimensionalitysBlessingClustering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Siying Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-SiyingLiuDimensionalitysBlessingClustering').submit();\">Siying Liu</a>,\n</form>\n<form id=\"form-Jian-HuangLaiDimensionalitysBlessingClustering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jian-Huang Lai\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jian-HuangLaiDimensionalitysBlessingClustering').submit();\">Jian-Huang Lai</a>,\n</form>\n<form id=\"form-YasuyukiMatsushitaDimensionalitysBlessingClustering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yasuyuki Matsushita\">\n<a href=\"#\" onclick=\"document.getElementById('form-YasuyukiMatsushitaDimensionalitysBlessingClustering').submit();\">Yasuyuki Matsushita</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lin_Dimensionalitys_Blessing_Clustering_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1746-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.02624\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lin_2018_CVPR,<br>\nauthor = {Lin, Wen-Yan and Liu, Siying and Lai, Jian-Huang and Matsushita, Yasuyuki},<br>\ntitle = {Dimensionality's Blessing: Clustering Images by Underlying Distribution},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tian_Eliminating_Background-Bias_for_CVPR_2018_paper.html\">Eliminating Background-Bias for Robust Person Re-Identification</a></dt>\n<dd>\n<form id=\"form-MaoqingTianEliminatingBackgroundBiasfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Maoqing Tian\">\n<a href=\"#\" onclick=\"document.getElementById('form-MaoqingTianEliminatingBackgroundBiasfor').submit();\">Maoqing Tian</a>,\n</form>\n<form id=\"form-ShuaiYiEliminatingBackgroundBiasfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuai Yi\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuaiYiEliminatingBackgroundBiasfor').submit();\">Shuai Yi</a>,\n</form>\n<form id=\"form-HongshengLiEliminatingBackgroundBiasfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hongsheng Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-HongshengLiEliminatingBackgroundBiasfor').submit();\">Hongsheng Li</a>,\n</form>\n<form id=\"form-ShihuaLiEliminatingBackgroundBiasfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shihua Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShihuaLiEliminatingBackgroundBiasfor').submit();\">Shihua Li</a>,\n</form>\n<form id=\"form-XuesenZhangEliminatingBackgroundBiasfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xuesen Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XuesenZhangEliminatingBackgroundBiasfor').submit();\">Xuesen Zhang</a>,\n</form>\n<form id=\"form-JianpingShiEliminatingBackgroundBiasfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianping Shi\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianpingShiEliminatingBackgroundBiasfor').submit();\">Jianping Shi</a>,\n</form>\n<form id=\"form-JunjieYanEliminatingBackgroundBiasfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junjie Yan\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunjieYanEliminatingBackgroundBiasfor').submit();\">Junjie Yan</a>,\n</form>\n<form id=\"form-XiaogangWangEliminatingBackgroundBiasfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaogang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaogangWangEliminatingBackgroundBiasfor').submit();\">Xiaogang Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tian_Eliminating_Background-Bias_for_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tian_2018_CVPR,<br>\nauthor = {Tian, Maoqing and Yi, Shuai and Li, Hongsheng and Li, Shihua and Zhang, Xuesen and Shi, Jianping and Yan, Junjie and Wang, Xiaogang},<br>\ntitle = {Eliminating Background-Bias for Robust Person Re-Identification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Cui_Learning_to_Evaluate_CVPR_2018_paper.html\">Learning to Evaluate Image Captioning</a></dt>\n<dd>\n<form id=\"form-YinCuiLearningtoEvaluate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yin Cui\">\n<a href=\"#\" onclick=\"document.getElementById('form-YinCuiLearningtoEvaluate').submit();\">Yin Cui</a>,\n</form>\n<form id=\"form-GuandaoYangLearningtoEvaluate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guandao Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuandaoYangLearningtoEvaluate').submit();\">Guandao Yang</a>,\n</form>\n<form id=\"form-AndreasVeitLearningtoEvaluate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andreas Veit\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndreasVeitLearningtoEvaluate').submit();\">Andreas Veit</a>,\n</form>\n<form id=\"form-XunHuangLearningtoEvaluate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xun Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XunHuangLearningtoEvaluate').submit();\">Xun Huang</a>,\n</form>\n<form id=\"form-SergeBelongieLearningtoEvaluate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Serge Belongie\">\n<a href=\"#\" onclick=\"document.getElementById('form-SergeBelongieLearningtoEvaluate').submit();\">Serge Belongie</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Cui_Learning_to_Evaluate_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1501-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1806.06422\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Cui_2018_CVPR,<br>\nauthor = {Cui, Yin and Yang, Guandao and Veit, Andreas and Huang, Xun and Belongie, Serge},<br>\ntitle = {Learning to Evaluate Image Captioning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Single-Shot_Object_Detection_CVPR_2018_paper.html\">Single-Shot Object Detection With Enriched Semantics</a></dt>\n<dd>\n<form id=\"form-ZhishuaiZhangSingleShotObjectDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhishuai Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhishuaiZhangSingleShotObjectDetection').submit();\">Zhishuai Zhang</a>,\n</form>\n<form id=\"form-SiyuanQiaoSingleShotObjectDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Siyuan Qiao\">\n<a href=\"#\" onclick=\"document.getElementById('form-SiyuanQiaoSingleShotObjectDetection').submit();\">Siyuan Qiao</a>,\n</form>\n<form id=\"form-CihangXieSingleShotObjectDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cihang Xie\">\n<a href=\"#\" onclick=\"document.getElementById('form-CihangXieSingleShotObjectDetection').submit();\">Cihang Xie</a>,\n</form>\n<form id=\"form-WeiShenSingleShotObjectDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiShenSingleShotObjectDetection').submit();\">Wei Shen</a>,\n</form>\n<form id=\"form-BoWangSingleShotObjectDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bo Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoWangSingleShotObjectDetection').submit();\">Bo Wang</a>,\n</form>\n<form id=\"form-AlanL.SingleShotObjectDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alan L. Yuille\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlanL.SingleShotObjectDetection').submit();\">Alan L. Yuille</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Single-Shot_Object_Detection_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.00433\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Zhishuai and Qiao, Siyuan and Xie, Cihang and Shen, Wei and Wang, Bo and Yuille, Alan L.},<br>\ntitle = {Single-Shot Object Detection With Enriched Semantics},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Qi_Low-Shot_Learning_With_CVPR_2018_paper.html\">Low-Shot Learning With Imprinted Weights</a></dt>\n<dd>\n<form id=\"form-HangQiLowShotLearningWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hang Qi\">\n<a href=\"#\" onclick=\"document.getElementById('form-HangQiLowShotLearningWith').submit();\">Hang Qi</a>,\n</form>\n<form id=\"form-MatthewBrownLowShotLearningWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Matthew Brown\">\n<a href=\"#\" onclick=\"document.getElementById('form-MatthewBrownLowShotLearningWith').submit();\">Matthew Brown</a>,\n</form>\n<form id=\"form-DavidG.LowShotLearningWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"David G. Lowe\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavidG.LowShotLearningWith').submit();\">David G. Lowe</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Qi_Low-Shot_Learning_With_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.07136\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Qi_2018_CVPR,<br>\nauthor = {Qi, Hang and Brown, Matthew and Lowe, David G.},<br>\ntitle = {Low-Shot Learning With Imprinted Weights},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zellers_Neural_Motifs_Scene_CVPR_2018_paper.html\">Neural Motifs: Scene Graph Parsing With Global Context</a></dt>\n<dd>\n<form id=\"form-RowanZellersNeuralMotifsScene\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rowan Zellers\">\n<a href=\"#\" onclick=\"document.getElementById('form-RowanZellersNeuralMotifsScene').submit();\">Rowan Zellers</a>,\n</form>\n<form id=\"form-MarkYatskarNeuralMotifsScene\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mark Yatskar\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarkYatskarNeuralMotifsScene').submit();\">Mark Yatskar</a>,\n</form>\n<form id=\"form-SamThomsonNeuralMotifsScene\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sam Thomson\">\n<a href=\"#\" onclick=\"document.getElementById('form-SamThomsonNeuralMotifsScene').submit();\">Sam Thomson</a>,\n</form>\n<form id=\"form-YejinChoiNeuralMotifsScene\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yejin Choi\">\n<a href=\"#\" onclick=\"document.getElementById('form-YejinChoiNeuralMotifsScene').submit();\">Yejin Choi</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zellers_Neural_Motifs_Scene_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/4272-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.06640\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zellers_2018_CVPR,<br>\nauthor = {Zellers, Rowan and Yatskar, Mark and Thomson, Sam and Choi, Yejin},<br>\ntitle = {Neural Motifs: Scene Graph Parsing With Global Context},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tan_Variational_Autoencoders_for_CVPR_2018_paper.html\">Variational Autoencoders for Deforming 3D Mesh Models</a></dt>\n<dd>\n<form id=\"form-QingyangTanVariationalAutoencodersfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qingyang Tan\">\n<a href=\"#\" onclick=\"document.getElementById('form-QingyangTanVariationalAutoencodersfor').submit();\">Qingyang Tan</a>,\n</form>\n<form id=\"form-LinGaoVariationalAutoencodersfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lin Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-LinGaoVariationalAutoencodersfor').submit();\">Lin Gao</a>,\n</form>\n<form id=\"form-Yu-KunLaiVariationalAutoencodersfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu-Kun Lai\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yu-KunLaiVariationalAutoencodersfor').submit();\">Yu-Kun Lai</a>,\n</form>\n<form id=\"form-ShihongXiaVariationalAutoencodersfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shihong Xia\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShihongXiaVariationalAutoencodersfor').submit();\">Shihong Xia</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tan_Variational_Autoencoders_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1709.04307\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tan_2018_CVPR,<br>\nauthor = {Tan, Qingyang and Gao, Lin and Lai, Yu-Kun and Xia, Shihong},<br>\ntitle = {Variational Autoencoders for Deforming 3D Mesh Models},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Dhawale_Fast_Monte-Carlo_Localization_CVPR_2018_paper.html\">Fast Monte-Carlo Localization on Aerial Vehicles Using Approximate Continuous Belief Representations</a></dt>\n<dd>\n<form id=\"form-AdityaDhawaleFastMonteCarloLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Aditya Dhawale\">\n<a href=\"#\" onclick=\"document.getElementById('form-AdityaDhawaleFastMonteCarloLocalization').submit();\">Aditya Dhawale</a>,\n</form>\n<form id=\"form-KumarShauryaFastMonteCarloLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kumar Shaurya Shankar\">\n<a href=\"#\" onclick=\"document.getElementById('form-KumarShauryaFastMonteCarloLocalization').submit();\">Kumar Shaurya Shankar</a>,\n</form>\n<form id=\"form-NathanMichaelFastMonteCarloLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nathan Michael\">\n<a href=\"#\" onclick=\"document.getElementById('form-NathanMichaelFastMonteCarloLocalization').submit();\">Nathan Michael</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Dhawale_Fast_Monte-Carlo_Localization_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.05507\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Dhawale_2018_CVPR,<br>\nauthor = {Dhawale, Aditya and Shaurya Shankar, Kumar and Michael, Nathan},<br>\ntitle = {Fast Monte-Carlo Localization on Aerial Vehicles Using Approximate Continuous Belief Representations},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_DeLS-3D_Deep_Localization_CVPR_2018_paper.html\">DeLS-3D: Deep Localization and Segmentation With a 3D Semantic Map</a></dt>\n<dd>\n<form id=\"form-PengWangDeLS3DDeepLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peng Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-PengWangDeLS3DDeepLocalization').submit();\">Peng Wang</a>,\n</form>\n<form id=\"form-RuigangYangDeLS3DDeepLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ruigang Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-RuigangYangDeLS3DDeepLocalization').submit();\">Ruigang Yang</a>,\n</form>\n<form id=\"form-BinbinCaoDeLS3DDeepLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Binbin Cao\">\n<a href=\"#\" onclick=\"document.getElementById('form-BinbinCaoDeLS3DDeepLocalization').submit();\">Binbin Cao</a>,\n</form>\n<form id=\"form-WeiXuDeLS3DDeepLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiXuDeLS3DDeepLocalization').submit();\">Wei Xu</a>,\n</form>\n<form id=\"form-YuanqingLinDeLS3DDeepLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuanqing Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuanqingLinDeLS3DDeepLocalization').submit();\">Yuanqing Lin</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_DeLS-3D_Deep_Localization_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0936-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.04949\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Peng and Yang, Ruigang and Cao, Binbin and Xu, Wei and Lin, Yuanqing},<br>\ntitle = {DeLS-3D: Deep Localization and Segmentation With a 3D Semantic Map},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_LiDAR-Video_Driving_Dataset_CVPR_2018_paper.html\">LiDAR-Video Driving Dataset: Learning Driving Policies Effectively</a></dt>\n<dd>\n<form id=\"form-YipingChenLiDARVideoDrivingDataset\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yiping Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-YipingChenLiDARVideoDrivingDataset').submit();\">Yiping Chen</a>,\n</form>\n<form id=\"form-JingkangWangLiDARVideoDrivingDataset\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jingkang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingkangWangLiDARVideoDrivingDataset').submit();\">Jingkang Wang</a>,\n</form>\n<form id=\"form-JonathanLiLiDARVideoDrivingDataset\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jonathan Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-JonathanLiLiDARVideoDrivingDataset').submit();\">Jonathan Li</a>,\n</form>\n<form id=\"form-CewuLuLiDARVideoDrivingDataset\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cewu Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-CewuLuLiDARVideoDrivingDataset').submit();\">Cewu Lu</a>,\n</form>\n<form id=\"form-ZhipengLuoLiDARVideoDrivingDataset\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhipeng Luo\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhipengLuoLiDARVideoDrivingDataset').submit();\">Zhipeng Luo</a>,\n</form>\n<form id=\"form-HanXueLiDARVideoDrivingDataset\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Han Xue\">\n<a href=\"#\" onclick=\"document.getElementById('form-HanXueLiDARVideoDrivingDataset').submit();\">Han Xue</a>,\n</form>\n<form id=\"form-ChengWangLiDARVideoDrivingDataset\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cheng Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChengWangLiDARVideoDrivingDataset').submit();\">Cheng Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_LiDAR-Video_Driving_Dataset_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Yiping and Wang, Jingkang and Li, Jonathan and Lu, Cewu and Luo, Zhipeng and Xue, Han and Wang, Cheng},<br>\ntitle = {LiDAR-Video Driving Dataset: Learning Driving Policies Effectively},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sage_Logo_Synthesis_and_CVPR_2018_paper.html\">Logo Synthesis and Manipulation With Clustered Generative Adversarial Networks</a></dt>\n<dd>\n<form id=\"form-AlexanderSageLogoSynthesisand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexander Sage\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexanderSageLogoSynthesisand').submit();\">Alexander Sage</a>,\n</form>\n<form id=\"form-EirikurAgustssonLogoSynthesisand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Eirikur Agustsson\">\n<a href=\"#\" onclick=\"document.getElementById('form-EirikurAgustssonLogoSynthesisand').submit();\">Eirikur Agustsson</a>,\n</form>\n<form id=\"form-RaduTimofteLogoSynthesisand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Radu Timofte\">\n<a href=\"#\" onclick=\"document.getElementById('form-RaduTimofteLogoSynthesisand').submit();\">Radu Timofte</a>,\n</form>\n<form id=\"form-LucVanLogoSynthesisand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Luc Van Gool\">\n<a href=\"#\" onclick=\"document.getElementById('form-LucVanLogoSynthesisand').submit();\">Luc Van Gool</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sage_Logo_Synthesis_and_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2998-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.04407\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sage_2018_CVPR,<br>\nauthor = {Sage, Alexander and Agustsson, Eirikur and Timofte, Radu and Van Gool, Luc},<br>\ntitle = {Logo Synthesis and Manipulation With Clustered Generative Adversarial Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Bertasius_Egocentric_Basketball_Motion_CVPR_2018_paper.html\">Egocentric Basketball Motion Planning From a Single First-Person Image</a></dt>\n<dd>\n<form id=\"form-GedasBertasiusEgocentricBasketballMotion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gedas Bertasius\">\n<a href=\"#\" onclick=\"document.getElementById('form-GedasBertasiusEgocentricBasketballMotion').submit();\">Gedas Bertasius</a>,\n</form>\n<form id=\"form-AaronChanEgocentricBasketballMotion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Aaron Chan\">\n<a href=\"#\" onclick=\"document.getElementById('form-AaronChanEgocentricBasketballMotion').submit();\">Aaron Chan</a>,\n</form>\n<form id=\"form-JianboShiEgocentricBasketballMotion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianbo Shi\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianboShiEgocentricBasketballMotion').submit();\">Jianbo Shi</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Bertasius_Egocentric_Basketball_Motion_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.01413\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Bertasius_2018_CVPR,<br>\nauthor = {Bertasius, Gedas and Chan, Aaron and Shi, Jianbo},<br>\ntitle = {Egocentric Basketball Motion Planning From a Single First-Person Image},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Qi_Human-Centric_Indoor_Scene_CVPR_2018_paper.html\">Human-Centric Indoor Scene Synthesis Using Stochastic Grammar</a></dt>\n<dd>\n<form id=\"form-SiyuanQiHumanCentricIndoorScene\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Siyuan Qi\">\n<a href=\"#\" onclick=\"document.getElementById('form-SiyuanQiHumanCentricIndoorScene').submit();\">Siyuan Qi</a>,\n</form>\n<form id=\"form-YixinZhuHumanCentricIndoorScene\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yixin Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YixinZhuHumanCentricIndoorScene').submit();\">Yixin Zhu</a>,\n</form>\n<form id=\"form-SiyuanHuangHumanCentricIndoorScene\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Siyuan Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-SiyuanHuangHumanCentricIndoorScene').submit();\">Siyuan Huang</a>,\n</form>\n<form id=\"form-ChenfanfuJiangHumanCentricIndoorScene\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chenfanfu Jiang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenfanfuJiangHumanCentricIndoorScene').submit();\">Chenfanfu Jiang</a>,\n</form>\n<form id=\"form-Song-ChunZhuHumanCentricIndoorScene\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Song-Chun Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Song-ChunZhuHumanCentricIndoorScene').submit();\">Song-Chun Zhu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Qi_Human-Centric_Indoor_Scene_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0116-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Qi_2018_CVPR,<br>\nauthor = {Qi, Siyuan and Zhu, Yixin and Huang, Siyuan and Jiang, Chenfanfu and Zhu, Song-Chun},<br>\ntitle = {Human-Centric Indoor Scene Synthesis Using Stochastic Grammar},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liao_Rotation-Sensitive_Regression_for_CVPR_2018_paper.html\">Rotation-Sensitive Regression for Oriented Scene Text Detection</a></dt>\n<dd>\n<form id=\"form-MinghuiLiaoRotationSensitiveRegressionfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Minghui Liao\">\n<a href=\"#\" onclick=\"document.getElementById('form-MinghuiLiaoRotationSensitiveRegressionfor').submit();\">Minghui Liao</a>,\n</form>\n<form id=\"form-ZhenZhuRotationSensitiveRegressionfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhen Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhenZhuRotationSensitiveRegressionfor').submit();\">Zhen Zhu</a>,\n</form>\n<form id=\"form-BaoguangShiRotationSensitiveRegressionfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Baoguang Shi\">\n<a href=\"#\" onclick=\"document.getElementById('form-BaoguangShiRotationSensitiveRegressionfor').submit();\">Baoguang Shi</a>,\n</form>\n<form id=\"form-Gui-songXiaRotationSensitiveRegressionfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gui-song Xia\">\n<a href=\"#\" onclick=\"document.getElementById('form-Gui-songXiaRotationSensitiveRegressionfor').submit();\">Gui-song Xia</a>,\n</form>\n<form id=\"form-XiangBaiRotationSensitiveRegressionfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiang Bai\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiangBaiRotationSensitiveRegressionfor').submit();\">Xiang Bai</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liao_Rotation-Sensitive_Regression_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.05265\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liao_2018_CVPR,<br>\nauthor = {Liao, Minghui and Zhu, Zhen and Shi, Baoguang and Xia, Gui-song and Bai, Xiang},<br>\ntitle = {Rotation-Sensitive Regression for Oriented Scene Text Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Veit_Separating_Self-Expression_and_CVPR_2018_paper.html\">Separating Self-Expression and Visual Content in Hashtag Supervision</a></dt>\n<dd>\n<form id=\"form-AndreasVeitSeparatingSelfExpressionand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andreas Veit\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndreasVeitSeparatingSelfExpressionand').submit();\">Andreas Veit</a>,\n</form>\n<form id=\"form-MaximilianNickelSeparatingSelfExpressionand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Maximilian Nickel\">\n<a href=\"#\" onclick=\"document.getElementById('form-MaximilianNickelSeparatingSelfExpressionand').submit();\">Maximilian Nickel</a>,\n</form>\n<form id=\"form-SergeBelongieSeparatingSelfExpressionand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Serge Belongie\">\n<a href=\"#\" onclick=\"document.getElementById('form-SergeBelongieSeparatingSelfExpressionand').submit();\">Serge Belongie</a>,\n</form>\n<form id=\"form-LaurensvanSeparatingSelfExpressionand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Laurens van der Maaten\">\n<a href=\"#\" onclick=\"document.getElementById('form-LaurensvanSeparatingSelfExpressionand').submit();\">Laurens van der Maaten</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Veit_Separating_Self-Expression_and_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.09825\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Veit_2018_CVPR,<br>\nauthor = {Veit, Andreas and Nickel, Maximilian and Belongie, Serge and van der Maaten, Laurens},<br>\ntitle = {Separating Self-Expression and Visual Content in Hashtag Supervision},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Park_Distort-and-Recover_Color_Enhancement_CVPR_2018_paper.html\">Distort-and-Recover: Color Enhancement Using Deep Reinforcement Learning</a></dt>\n<dd>\n<form id=\"form-JongchanParkDistortandRecoverColorEnhancement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jongchan Park\">\n<a href=\"#\" onclick=\"document.getElementById('form-JongchanParkDistortandRecoverColorEnhancement').submit();\">Jongchan Park</a>,\n</form>\n<form id=\"form-Joon-YoungLeeDistortandRecoverColorEnhancement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Joon-Young Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-Joon-YoungLeeDistortandRecoverColorEnhancement').submit();\">Joon-Young Lee</a>,\n</form>\n<form id=\"form-DonggeunYooDistortandRecoverColorEnhancement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Donggeun Yoo\">\n<a href=\"#\" onclick=\"document.getElementById('form-DonggeunYooDistortandRecoverColorEnhancement').submit();\">Donggeun Yoo</a>,\n</form>\n<form id=\"form-InSoDistortandRecoverColorEnhancement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"In So Kweon\">\n<a href=\"#\" onclick=\"document.getElementById('form-InSoDistortandRecoverColorEnhancement').submit();\">In So Kweon</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Park_Distort-and-Recover_Color_Enhancement_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.04450\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Park_2018_CVPR,<br>\nauthor = {Park, Jongchan and Lee, Joon-Young and Yoo, Donggeun and So Kweon, In},<br>\ntitle = {Distort-and-Recover: Color Enhancement Using Deep Reinforcement Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Gao_Im2Flow_Motion_Hallucination_CVPR_2018_paper.html\">Im2Flow: Motion Hallucination From Static Images for Action Recognition</a></dt>\n<dd>\n<form id=\"form-RuohanGaoIm2FlowMotionHallucination\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ruohan Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-RuohanGaoIm2FlowMotionHallucination').submit();\">Ruohan Gao</a>,\n</form>\n<form id=\"form-BoXiongIm2FlowMotionHallucination\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bo Xiong\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoXiongIm2FlowMotionHallucination').submit();\">Bo Xiong</a>,\n</form>\n<form id=\"form-KristenGraumanIm2FlowMotionHallucination\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kristen Grauman\">\n<a href=\"#\" onclick=\"document.getElementById('form-KristenGraumanIm2FlowMotionHallucination').submit();\">Kristen Grauman</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Gao_Im2Flow_Motion_Hallucination_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.04109\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Gao_2018_CVPR,<br>\nauthor = {Gao, Ruohan and Xiong, Bo and Grauman, Kristen},<br>\ntitle = {Im2Flow: Motion Hallucination From Static Images for Action Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Huang_Finding_It_Weakly-Supervised_CVPR_2018_paper.html\">Finding \"It\": Weakly-Supervised Reference-Aware Visual Grounding in Instructional Videos</a></dt>\n<dd>\n<form id=\"form-De-AnHuangFindingItWeaklySupervised\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"De-An Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-De-AnHuangFindingItWeaklySupervised').submit();\">De-An Huang</a>,\n</form>\n<form id=\"form-ShyamalBuchFindingItWeaklySupervised\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shyamal Buch\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShyamalBuchFindingItWeaklySupervised').submit();\">Shyamal Buch</a>,\n</form>\n<form id=\"form-LucioDeryFindingItWeaklySupervised\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lucio Dery\">\n<a href=\"#\" onclick=\"document.getElementById('form-LucioDeryFindingItWeaklySupervised').submit();\">Lucio Dery</a>,\n</form>\n<form id=\"form-AnimeshGargFindingItWeaklySupervised\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Animesh Garg\">\n<a href=\"#\" onclick=\"document.getElementById('form-AnimeshGargFindingItWeaklySupervised').submit();\">Animesh Garg</a>,\n</form>\n<form id=\"form-LiFei-FeiFindingItWeaklySupervised\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Li Fei-Fei\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiFei-FeiFindingItWeaklySupervised').submit();\">Li Fei-Fei</a>,\n</form>\n<form id=\"form-JuanCarlosFindingItWeaklySupervised\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Juan Carlos Niebles\">\n<a href=\"#\" onclick=\"document.getElementById('form-JuanCarlosFindingItWeaklySupervised').submit();\">Juan Carlos Niebles</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Huang_Finding_It_Weakly-Supervised_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0778-supp.zip\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Huang_2018_CVPR,<br>\nauthor = {Huang, De-An and Buch, Shyamal and Dery, Lucio and Garg, Animesh and Fei-Fei, Li and Carlos Niebles, Juan},<br>\ntitle = {Finding \"It\": Weakly-Supervised Reference-Aware Visual Grounding in Instructional Videos},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Gavrilyuk_Actor_and_Action_CVPR_2018_paper.html\">Actor and Action Video Segmentation From a Sentence</a></dt>\n<dd>\n<form id=\"form-KirillGavrilyukActorandAction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kirill Gavrilyuk\">\n<a href=\"#\" onclick=\"document.getElementById('form-KirillGavrilyukActorandAction').submit();\">Kirill Gavrilyuk</a>,\n</form>\n<form id=\"form-AmirGhodratiActorandAction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Amir Ghodrati\">\n<a href=\"#\" onclick=\"document.getElementById('form-AmirGhodratiActorandAction').submit();\">Amir Ghodrati</a>,\n</form>\n<form id=\"form-ZhenyangLiActorandAction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhenyang Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhenyangLiActorandAction').submit();\">Zhenyang Li</a>,\n</form>\n<form id=\"form-CeesG.ActorandAction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cees G. M. Snoek\">\n<a href=\"#\" onclick=\"document.getElementById('form-CeesG.ActorandAction').submit();\">Cees G. M. Snoek</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Gavrilyuk_Actor_and_Action_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1458-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.07485\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Gavrilyuk_2018_CVPR,<br>\nauthor = {Gavrilyuk, Kirill and Ghodrati, Amir and Li, Zhenyang and Snoek, Cees G. M.},<br>\ntitle = {Actor and Action Video Segmentation From a Sentence},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Possas_Egocentric_Activity_Recognition_CVPR_2018_paper.html\">Egocentric Activity Recognition on a Budget</a></dt>\n<dd>\n<form id=\"form-RafaelPossasEgocentricActivityRecognition\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rafael Possas\">\n<a href=\"#\" onclick=\"document.getElementById('form-RafaelPossasEgocentricActivityRecognition').submit();\">Rafael Possas</a>,\n</form>\n<form id=\"form-SheilaPintoEgocentricActivityRecognition\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sheila Pinto Caceres\">\n<a href=\"#\" onclick=\"document.getElementById('form-SheilaPintoEgocentricActivityRecognition').submit();\">Sheila Pinto Caceres</a>,\n</form>\n<form id=\"form-FabioRamosEgocentricActivityRecognition\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fabio Ramos\">\n<a href=\"#\" onclick=\"document.getElementById('form-FabioRamosEgocentricActivityRecognition').submit();\">Fabio Ramos</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Possas_Egocentric_Activity_Recognition_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Possas_2018_CVPR,<br>\nauthor = {Possas, Rafael and Pinto Caceres, Sheila and Ramos, Fabio},<br>\ntitle = {Egocentric Activity Recognition on a Budget},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Bao_CNN_in_MRF_CVPR_2018_paper.html\">CNN in MRF: Video Object Segmentation via Inference in a CNN-Based Higher-Order Spatio-Temporal MRF</a></dt>\n<dd>\n<form id=\"form-LinchaoBaoCNNinMRF\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Linchao Bao\">\n<a href=\"#\" onclick=\"document.getElementById('form-LinchaoBaoCNNinMRF').submit();\">Linchao Bao</a>,\n</form>\n<form id=\"form-BaoyuanWuCNNinMRF\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Baoyuan Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-BaoyuanWuCNNinMRF').submit();\">Baoyuan Wu</a>,\n</form>\n<form id=\"form-WeiLiuCNNinMRF\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiLiuCNNinMRF').submit();\">Wei Liu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Bao_CNN_in_MRF_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1249-supp.zip\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.09453\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Bao_2018_CVPR,<br>\nauthor = {Bao, Linchao and Wu, Baoyuan and Liu, Wei},<br>\ntitle = {CNN in MRF: Video Object Segmentation via Inference in a CNN-Based Higher-Order Spatio-Temporal MRF},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Richard_Action_Sets_Weakly_CVPR_2018_paper.html\">Action Sets: Weakly Supervised Action Segmentation Without Ordering Constraints</a></dt>\n<dd>\n<form id=\"form-AlexanderRichardActionSetsWeakly\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexander Richard\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexanderRichardActionSetsWeakly').submit();\">Alexander Richard</a>,\n</form>\n<form id=\"form-HildeKuehneActionSetsWeakly\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hilde Kuehne\">\n<a href=\"#\" onclick=\"document.getElementById('form-HildeKuehneActionSetsWeakly').submit();\">Hilde Kuehne</a>,\n</form>\n<form id=\"form-JuergenGallActionSetsWeakly\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Juergen Gall\">\n<a href=\"#\" onclick=\"document.getElementById('form-JuergenGallActionSetsWeakly').submit();\">Juergen Gall</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Richard_Action_Sets_Weakly_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1706.00699\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Richard_2018_CVPR,<br>\nauthor = {Richard, Alexander and Kuehne, Hilde and Gall, Juergen},<br>\ntitle = {Action Sets: Weakly Supervised Action Segmentation Without Ordering Constraints},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Low-Latency_Video_Semantic_CVPR_2018_paper.html\">Low-Latency Video Semantic Segmentation</a></dt>\n<dd>\n<form id=\"form-YuleLiLowLatencyVideoSemantic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yule Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuleLiLowLatencyVideoSemantic').submit();\">Yule Li</a>,\n</form>\n<form id=\"form-JianpingShiLowLatencyVideoSemantic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianping Shi\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianpingShiLowLatencyVideoSemantic').submit();\">Jianping Shi</a>,\n</form>\n<form id=\"form-DahuaLinLowLatencyVideoSemantic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dahua Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-DahuaLinLowLatencyVideoSemantic').submit();\">Dahua Lin</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Low-Latency_Video_Semantic_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00389\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Yule and Shi, Jianping and Lin, Dahua},<br>\ntitle = {Low-Latency Video Semantic Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yu_Fine-Grained_Video_Captioning_CVPR_2018_paper.html\">Fine-Grained Video Captioning for Sports Narrative</a></dt>\n<dd>\n<form id=\"form-HuanyuYuFineGrainedVideoCaptioning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huanyu Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuanyuYuFineGrainedVideoCaptioning').submit();\">Huanyu Yu</a>,\n</form>\n<form id=\"form-ShuoChengFineGrainedVideoCaptioning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuo Cheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuoChengFineGrainedVideoCaptioning').submit();\">Shuo Cheng</a>,\n</form>\n<form id=\"form-BingbingNiFineGrainedVideoCaptioning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bingbing Ni\">\n<a href=\"#\" onclick=\"document.getElementById('form-BingbingNiFineGrainedVideoCaptioning').submit();\">Bingbing Ni</a>,\n</form>\n<form id=\"form-MinsiWangFineGrainedVideoCaptioning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Minsi Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-MinsiWangFineGrainedVideoCaptioning').submit();\">Minsi Wang</a>,\n</form>\n<form id=\"form-JianZhangFineGrainedVideoCaptioning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jian Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianZhangFineGrainedVideoCaptioning').submit();\">Jian Zhang</a>,\n</form>\n<form id=\"form-XiaokangYangFineGrainedVideoCaptioning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaokang Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaokangYangFineGrainedVideoCaptioning').submit();\">Xiaokang Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yu_Fine-Grained_Video_Captioning_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0668-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yu_2018_CVPR,<br>\nauthor = {Yu, Huanyu and Cheng, Shuo and Ni, Bingbing and Wang, Minsi and Zhang, Jian and Yang, Xiaokang},<br>\ntitle = {Fine-Grained Video Captioning for Sports Narrative},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Fan_End-to-End_Learning_of_CVPR_2018_paper.html\">End-to-End Learning of Motion Representation for Video Understanding</a></dt>\n<dd>\n<form id=\"form-LijieFanEndtoEndLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lijie Fan\">\n<a href=\"#\" onclick=\"document.getElementById('form-LijieFanEndtoEndLearningof').submit();\">Lijie Fan</a>,\n</form>\n<form id=\"form-WenbingHuangEndtoEndLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenbing Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenbingHuangEndtoEndLearningof').submit();\">Wenbing Huang</a>,\n</form>\n<form id=\"form-ChuangGanEndtoEndLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chuang Gan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChuangGanEndtoEndLearningof').submit();\">Chuang Gan</a>,\n</form>\n<form id=\"form-StefanoErmonEndtoEndLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stefano Ermon\">\n<a href=\"#\" onclick=\"document.getElementById('form-StefanoErmonEndtoEndLearningof').submit();\">Stefano Ermon</a>,\n</form>\n<form id=\"form-BoqingGongEndtoEndLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Boqing Gong\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoqingGongEndtoEndLearningof').submit();\">Boqing Gong</a>,\n</form>\n<form id=\"form-JunzhouHuangEndtoEndLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junzhou Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunzhouHuangEndtoEndLearningof').submit();\">Junzhou Huang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Fan_End-to-End_Learning_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2113-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00413\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Fan_2018_CVPR,<br>\nauthor = {Fan, Lijie and Huang, Wenbing and Gan, Chuang and Ermon, Stefano and Gong, Boqing and Huang, Junzhou},<br>\ntitle = {End-to-End Learning of Motion Representation for Video Understanding},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wu_Compressed_Video_Action_CVPR_2018_paper.html\">Compressed Video Action Recognition</a></dt>\n<dd>\n<form id=\"form-Chao-YuanWuCompressedVideoAction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chao-Yuan Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Chao-YuanWuCompressedVideoAction').submit();\">Chao-Yuan Wu</a>,\n</form>\n<form id=\"form-ManzilZaheerCompressedVideoAction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Manzil Zaheer\">\n<a href=\"#\" onclick=\"document.getElementById('form-ManzilZaheerCompressedVideoAction').submit();\">Manzil Zaheer</a>,\n</form>\n<form id=\"form-HexiangHuCompressedVideoAction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hexiang Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HexiangHuCompressedVideoAction').submit();\">Hexiang Hu</a>,\n</form>\n<form id=\"form-R.ManmathaCompressedVideoAction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"R. Manmatha\">\n<a href=\"#\" onclick=\"document.getElementById('form-R.ManmathaCompressedVideoAction').submit();\">R. Manmatha</a>,\n</form>\n<form id=\"form-AlexanderJ.CompressedVideoAction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexander J. Smola\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexanderJ.CompressedVideoAction').submit();\">Alexander J. Smola</a>,\n</form>\n<form id=\"form-PhilippKr\u00c3\u00a4henb\u00c3\u00bchlCompressedVideoAction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Philipp Kr\u00c3\u00a4henb\u00c3\u00bchl\">\n<a href=\"#\" onclick=\"document.getElementById('form-PhilippKr\u00c3\u00a4henb\u00c3\u00bchlCompressedVideoAction').submit();\">Philipp Kr\u00c3\u00a4henb\u00c3\u00bchl</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wu_Compressed_Video_Action_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3006-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.00636\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wu_2018_CVPR,<br>\nauthor = {Wu, Chao-Yuan and Zaheer, Manzil and Hu, Hexiang and Manmatha, R. and Smola, Alexander J. and Kr\u00c3\u00a4henb\u00c3\u00bchl, Philipp},<br>\ntitle = {Compressed Video Action Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ristani_Features_for_Multi-Target_CVPR_2018_paper.html\">Features for Multi-Target Multi-Camera Tracking and Re-Identification</a></dt>\n<dd>\n<form id=\"form-ErgysRistaniFeaturesforMultiTarget\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ergys Ristani\">\n<a href=\"#\" onclick=\"document.getElementById('form-ErgysRistaniFeaturesforMultiTarget').submit();\">Ergys Ristani</a>,\n</form>\n<form id=\"form-CarloTomasiFeaturesforMultiTarget\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Carlo Tomasi\">\n<a href=\"#\" onclick=\"document.getElementById('form-CarloTomasiFeaturesforMultiTarget').submit();\">Carlo Tomasi</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ristani_Features_for_Multi-Target_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.10859\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ristani_2018_CVPR,<br>\nauthor = {Ristani, Ergys and Tomasi, Carlo},<br>\ntitle = {Features for Multi-Target Multi-Camera Tracking and Re-Identification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Gu_AVA_A_Video_CVPR_2018_paper.html\">AVA: A Video Dataset of Spatio-Temporally Localized Atomic Visual Actions</a></dt>\n<dd>\n<form id=\"form-ChunhuiGuAVAAVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chunhui Gu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChunhuiGuAVAAVideo').submit();\">Chunhui Gu</a>,\n</form>\n<form id=\"form-ChenSunAVAAVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chen Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenSunAVAAVideo').submit();\">Chen Sun</a>,\n</form>\n<form id=\"form-DavidA.AVAAVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"David A. Ross\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavidA.AVAAVideo').submit();\">David A. Ross</a>,\n</form>\n<form id=\"form-CarlVondrickAVAAVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Carl Vondrick\">\n<a href=\"#\" onclick=\"document.getElementById('form-CarlVondrickAVAAVideo').submit();\">Carl Vondrick</a>,\n</form>\n<form id=\"form-CarolinePantofaruAVAAVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Caroline Pantofaru\">\n<a href=\"#\" onclick=\"document.getElementById('form-CarolinePantofaruAVAAVideo').submit();\">Caroline Pantofaru</a>,\n</form>\n<form id=\"form-YeqingLiAVAAVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yeqing Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-YeqingLiAVAAVideo').submit();\">Yeqing Li</a>,\n</form>\n<form id=\"form-SudheendraVijayanarasimhanAVAAVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sudheendra Vijayanarasimhan\">\n<a href=\"#\" onclick=\"document.getElementById('form-SudheendraVijayanarasimhanAVAAVideo').submit();\">Sudheendra Vijayanarasimhan</a>,\n</form>\n<form id=\"form-GeorgeTodericiAVAAVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"George Toderici\">\n<a href=\"#\" onclick=\"document.getElementById('form-GeorgeTodericiAVAAVideo').submit();\">George Toderici</a>,\n</form>\n<form id=\"form-SusannaRiccoAVAAVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Susanna Ricco\">\n<a href=\"#\" onclick=\"document.getElementById('form-SusannaRiccoAVAAVideo').submit();\">Susanna Ricco</a>,\n</form>\n<form id=\"form-RahulSukthankarAVAAVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rahul Sukthankar\">\n<a href=\"#\" onclick=\"document.getElementById('form-RahulSukthankarAVAAVideo').submit();\">Rahul Sukthankar</a>,\n</form>\n<form id=\"form-CordeliaSchmidAVAAVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cordelia Schmid\">\n<a href=\"#\" onclick=\"document.getElementById('form-CordeliaSchmidAVAAVideo').submit();\">Cordelia Schmid</a>,\n</form>\n<form id=\"form-JitendraMalikAVAAVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jitendra Malik\">\n<a href=\"#\" onclick=\"document.getElementById('form-JitendraMalikAVAAVideo').submit();\">Jitendra Malik</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Gu_AVA_A_Video_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1705.08421\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Gu_2018_CVPR,<br>\nauthor = {Gu, Chunhui and Sun, Chen and Ross, David A. and Vondrick, Carl and Pantofaru, Caroline and Li, Yeqing and Vijayanarasimhan, Sudheendra and Toderici, George and Ricco, Susanna and Sukthankar, Rahul and Schmid, Cordelia and Malik, Jitendra},<br>\ntitle = {AVA: A Video Dataset of Spatio-Temporally Localized Atomic Visual Actions},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Doughty_Whos_Better_Whos_CVPR_2018_paper.html\">Who's Better? Who's Best? Pairwise Deep Ranking for Skill Determination</a></dt>\n<dd>\n<form id=\"form-HazelDoughtyWhosBetterWhos\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hazel Doughty\">\n<a href=\"#\" onclick=\"document.getElementById('form-HazelDoughtyWhosBetterWhos').submit();\">Hazel Doughty</a>,\n</form>\n<form id=\"form-DimaDamenWhosBetterWhos\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dima Damen\">\n<a href=\"#\" onclick=\"document.getElementById('form-DimaDamenWhosBetterWhos').submit();\">Dima Damen</a>,\n</form>\n<form id=\"form-WalterioMayol-CuevasWhosBetterWhos\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Walterio Mayol-Cuevas\">\n<a href=\"#\" onclick=\"document.getElementById('form-WalterioMayol-CuevasWhosBetterWhos').submit();\">Walterio Mayol-Cuevas</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Doughty_Whos_Better_Whos_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2261-supp.zip\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Doughty_2018_CVPR,<br>\nauthor = {Doughty, Hazel and Damen, Dima and Mayol-Cuevas, Walterio},<br>\ntitle = {Who's Better? Who's Best? Pairwise Deep Ranking for Skill Determination},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hasan_MX-LSTM_Mixing_Tracklets_CVPR_2018_paper.html\">MX-LSTM: Mixing Tracklets and Vislets to Jointly Forecast Trajectories and Head Poses</a></dt>\n<dd>\n<form id=\"form-IrtizaHasanMXLSTMMixingTracklets\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Irtiza Hasan\">\n<a href=\"#\" onclick=\"document.getElementById('form-IrtizaHasanMXLSTMMixingTracklets').submit();\">Irtiza Hasan</a>,\n</form>\n<form id=\"form-FrancescoSettiMXLSTMMixingTracklets\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Francesco Setti\">\n<a href=\"#\" onclick=\"document.getElementById('form-FrancescoSettiMXLSTMMixingTracklets').submit();\">Francesco Setti</a>,\n</form>\n<form id=\"form-TheodoreTsesmelisMXLSTMMixingTracklets\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Theodore Tsesmelis\">\n<a href=\"#\" onclick=\"document.getElementById('form-TheodoreTsesmelisMXLSTMMixingTracklets').submit();\">Theodore Tsesmelis</a>,\n</form>\n<form id=\"form-AlessioDelMXLSTMMixingTracklets\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alessio Del Bue\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlessioDelMXLSTMMixingTracklets').submit();\">Alessio Del Bue</a>,\n</form>\n<form id=\"form-FabioGalassoMXLSTMMixingTracklets\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fabio Galasso\">\n<a href=\"#\" onclick=\"document.getElementById('form-FabioGalassoMXLSTMMixingTracklets').submit();\">Fabio Galasso</a>,\n</form>\n<form id=\"form-MarcoCristaniMXLSTMMixingTracklets\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Marco Cristani\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarcoCristaniMXLSTMMixingTracklets').submit();\">Marco Cristani</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hasan_MX-LSTM_Mixing_Tracklets_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.00652\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hasan_2018_CVPR,<br>\nauthor = {Hasan, Irtiza and Setti, Francesco and Tsesmelis, Theodore and Del Bue, Alessio and Galasso, Fabio and Cristani, Marco},<br>\ntitle = {MX-LSTM: Mixing Tracklets and Vislets to Jointly Forecast Trajectories and Head Poses},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Anderson_Bottom-Up_and_Top-Down_CVPR_2018_paper.html\">Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering</a></dt>\n<dd>\n<form id=\"form-PeterAndersonBottomUpandTopDown\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peter Anderson\">\n<a href=\"#\" onclick=\"document.getElementById('form-PeterAndersonBottomUpandTopDown').submit();\">Peter Anderson</a>,\n</form>\n<form id=\"form-XiaodongHeBottomUpandTopDown\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaodong He\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaodongHeBottomUpandTopDown').submit();\">Xiaodong He</a>,\n</form>\n<form id=\"form-ChrisBuehlerBottomUpandTopDown\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chris Buehler\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChrisBuehlerBottomUpandTopDown').submit();\">Chris Buehler</a>,\n</form>\n<form id=\"form-DamienTeneyBottomUpandTopDown\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Damien Teney\">\n<a href=\"#\" onclick=\"document.getElementById('form-DamienTeneyBottomUpandTopDown').submit();\">Damien Teney</a>,\n</form>\n<form id=\"form-MarkJohnsonBottomUpandTopDown\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mark Johnson\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarkJohnsonBottomUpandTopDown').submit();\">Mark Johnson</a>,\n</form>\n<form id=\"form-StephenGouldBottomUpandTopDown\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stephen Gould\">\n<a href=\"#\" onclick=\"document.getElementById('form-StephenGouldBottomUpandTopDown').submit();\">Stephen Gould</a>,\n</form>\n<form id=\"form-LeiZhangBottomUpandTopDown\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lei Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeiZhangBottomUpandTopDown').submit();\">Lei Zhang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Anderson_Bottom-Up_and_Top-Down_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1163-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1707.07998\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Anderson_2018_CVPR,<br>\nauthor = {Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},<br>\ntitle = {Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Nguyen_Improved_Fusion_of_CVPR_2018_paper.html\">Improved Fusion of Visual and Language Representations by Dense Symmetric Co-Attention for Visual Question Answering</a></dt>\n<dd>\n<form id=\"form-Duy-KienNguyenImprovedFusionof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Duy-Kien Nguyen\">\n<a href=\"#\" onclick=\"document.getElementById('form-Duy-KienNguyenImprovedFusionof').submit();\">Duy-Kien Nguyen</a>,\n</form>\n<form id=\"form-TakayukiOkataniImprovedFusionof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Takayuki Okatani\">\n<a href=\"#\" onclick=\"document.getElementById('form-TakayukiOkataniImprovedFusionof').submit();\">Takayuki Okatani</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Nguyen_Improved_Fusion_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3586-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00775\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Nguyen_2018_CVPR,<br>\nauthor = {Nguyen, Duy-Kien and Okatani, Takayuki},<br>\ntitle = {Improved Fusion of Visual and Language Representations by Dense Symmetric Co-Attention for Visual Question Answering},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Massiceti_FlipDial_A_Generative_CVPR_2018_paper.html\">FlipDial: A Generative Model for Two-Way Visual Dialogue</a></dt>\n<dd>\n<form id=\"form-DanielaMassicetiFlipDialAGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daniela Massiceti\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanielaMassicetiFlipDialAGenerative').submit();\">Daniela Massiceti</a>,\n</form>\n<form id=\"form-N.SiddharthFlipDialAGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"N. Siddharth\">\n<a href=\"#\" onclick=\"document.getElementById('form-N.SiddharthFlipDialAGenerative').submit();\">N. Siddharth</a>,\n</form>\n<form id=\"form-PuneetK.FlipDialAGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Puneet K. Dokania\">\n<a href=\"#\" onclick=\"document.getElementById('form-PuneetK.FlipDialAGenerative').submit();\">Puneet K. Dokania</a>,\n</form>\n<form id=\"form-PhilipH.S.FlipDialAGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Philip H.S. Torr\">\n<a href=\"#\" onclick=\"document.getElementById('form-PhilipH.S.FlipDialAGenerative').submit();\">Philip H.S. Torr</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Massiceti_FlipDial_A_Generative_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3275-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.03803\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Massiceti_2018_CVPR,<br>\nauthor = {Massiceti, Daniela and Siddharth, N. and Dokania, Puneet K. and Torr, Philip H.S.},<br>\ntitle = {FlipDial: A Generative Model for Two-Way Visual Dialogue},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wu_Are_You_Talking_CVPR_2018_paper.html\">Are You Talking to Me? Reasoned Visual Dialog Generation Through Adversarial Learning</a></dt>\n<dd>\n<form id=\"form-QiWuAreYouTalking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qi Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiWuAreYouTalking').submit();\">Qi Wu</a>,\n</form>\n<form id=\"form-PengWangAreYouTalking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peng Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-PengWangAreYouTalking').submit();\">Peng Wang</a>,\n</form>\n<form id=\"form-ChunhuaShenAreYouTalking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chunhua Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChunhuaShenAreYouTalking').submit();\">Chunhua Shen</a>,\n</form>\n<form id=\"form-IanReidAreYouTalking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ian Reid\">\n<a href=\"#\" onclick=\"document.getElementById('form-IanReidAreYouTalking').submit();\">Ian Reid</a>,\n</form>\n<form id=\"form-AntonvanAreYouTalking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anton van den Hengel\">\n<a href=\"#\" onclick=\"document.getElementById('form-AntonvanAreYouTalking').submit();\">Anton van den Hengel</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wu_Are_You_Talking_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0185-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wu_2018_CVPR,<br>\nauthor = {Wu, Qi and Wang, Peng and Shen, Chunhua and Reid, Ian and van den Hengel, Anton},<br>\ntitle = {Are You Talking to Me? Reasoned Visual Dialog Generation Through Adversarial Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Visual_Question_Generation_CVPR_2018_paper.html\">Visual Question Generation as Dual Task of Visual Question Answering</a></dt>\n<dd>\n<form id=\"form-YikangLiVisualQuestionGeneration\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yikang Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-YikangLiVisualQuestionGeneration').submit();\">Yikang Li</a>,\n</form>\n<form id=\"form-NanDuanVisualQuestionGeneration\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nan Duan\">\n<a href=\"#\" onclick=\"document.getElementById('form-NanDuanVisualQuestionGeneration').submit();\">Nan Duan</a>,\n</form>\n<form id=\"form-BoleiZhouVisualQuestionGeneration\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bolei Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoleiZhouVisualQuestionGeneration').submit();\">Bolei Zhou</a>,\n</form>\n<form id=\"form-XiaoChuVisualQuestionGeneration\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiao Chu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaoChuVisualQuestionGeneration').submit();\">Xiao Chu</a>,\n</form>\n<form id=\"form-WanliOuyangVisualQuestionGeneration\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wanli Ouyang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WanliOuyangVisualQuestionGeneration').submit();\">Wanli Ouyang</a>,\n</form>\n<form id=\"form-XiaogangWangVisualQuestionGeneration\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaogang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaogangWangVisualQuestionGeneration').submit();\">Xiaogang Wang</a>,\n</form>\n<form id=\"form-MingZhouVisualQuestionGeneration\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingZhouVisualQuestionGeneration').submit();\">Ming Zhou</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Visual_Question_Generation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1709.07192\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Yikang and Duan, Nan and Zhou, Bolei and Chu, Xiao and Ouyang, Wanli and Wang, Xiaogang and Zhou, Ming},<br>\ntitle = {Visual Question Generation as Dual Task of Visual Question Answering},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yeh_Unsupervised_Textual_Grounding_CVPR_2018_paper.html\">Unsupervised Textual Grounding: Linking Words to Image Concepts</a></dt>\n<dd>\n<form id=\"form-RaymondA.UnsupervisedTextualGrounding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Raymond A. Yeh\">\n<a href=\"#\" onclick=\"document.getElementById('form-RaymondA.UnsupervisedTextualGrounding').submit();\">Raymond A. Yeh</a>,\n</form>\n<form id=\"form-MinhN.UnsupervisedTextualGrounding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Minh N. Do\">\n<a href=\"#\" onclick=\"document.getElementById('form-MinhN.UnsupervisedTextualGrounding').submit();\">Minh N. Do</a>,\n</form>\n<form id=\"form-AlexanderG.UnsupervisedTextualGrounding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexander G. Schwing\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexanderG.UnsupervisedTextualGrounding').submit();\">Alexander G. Schwing</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yeh_Unsupervised_Textual_Grounding_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.11185\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yeh_2018_CVPR,<br>\nauthor = {Yeh, Raymond A. and Do, Minh N. and Schwing, Alexander G.},<br>\ntitle = {Unsupervised Textual Grounding: Linking Words to Image Concepts},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liang_Focal_Visual-Text_Attention_CVPR_2018_paper.html\">Focal Visual-Text Attention for Visual Question Answering</a></dt>\n<dd>\n<form id=\"form-JunweiLiangFocalVisualTextAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junwei Liang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunweiLiangFocalVisualTextAttention').submit();\">Junwei Liang</a>,\n</form>\n<form id=\"form-LuJiangFocalVisualTextAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lu Jiang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LuJiangFocalVisualTextAttention').submit();\">Lu Jiang</a>,\n</form>\n<form id=\"form-LiangliangCaoFocalVisualTextAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liangliang Cao\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiangliangCaoFocalVisualTextAttention').submit();\">Liangliang Cao</a>,\n</form>\n<form id=\"form-Li-JiaLiFocalVisualTextAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Li-Jia Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-Li-JiaLiFocalVisualTextAttention').submit();\">Li-Jia Li</a>,\n</form>\n<form id=\"form-AlexanderG.FocalVisualTextAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexander G. Hauptmann\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexanderG.FocalVisualTextAttention').submit();\">Alexander G. Hauptmann</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liang_Focal_Visual-Text_Attention_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1806.01873\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liang_2018_CVPR,<br>\nauthor = {Liang, Junwei and Jiang, Lu and Cao, Liangliang and Li, Li-Jia and Hauptmann, Alexander G.},<br>\ntitle = {Focal Visual-Text Attention for Visual Question Answering},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ehsani_SeGAN_Segmenting_and_CVPR_2018_paper.html\">SeGAN: Segmenting and Generating the Invisible</a></dt>\n<dd>\n<form id=\"form-KianaEhsaniSeGANSegmentingand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kiana Ehsani\">\n<a href=\"#\" onclick=\"document.getElementById('form-KianaEhsaniSeGANSegmentingand').submit();\">Kiana Ehsani</a>,\n</form>\n<form id=\"form-RoozbehMottaghiSeGANSegmentingand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Roozbeh Mottaghi\">\n<a href=\"#\" onclick=\"document.getElementById('form-RoozbehMottaghiSeGANSegmentingand').submit();\">Roozbeh Mottaghi</a>,\n</form>\n<form id=\"form-AliFarhadiSeGANSegmentingand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ali Farhadi\">\n<a href=\"#\" onclick=\"document.getElementById('form-AliFarhadiSeGANSegmentingand').submit();\">Ali Farhadi</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ehsani_SeGAN_Segmenting_and_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1703.10239\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ehsani_2018_CVPR,<br>\nauthor = {Ehsani, Kiana and Mottaghi, Roozbeh and Farhadi, Ali},<br>\ntitle = {SeGAN: Segmenting and Generating the Invisible},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Cai_Cascade_R-CNN_Delving_CVPR_2018_paper.html\">Cascade R-CNN: Delving Into High Quality Object Detection</a></dt>\n<dd>\n<form id=\"form-ZhaoweiCaiCascadeRCNNDelving\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhaowei Cai\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhaoweiCaiCascadeRCNNDelving').submit();\">Zhaowei Cai</a>,\n</form>\n<form id=\"form-NunoVasconcelosCascadeRCNNDelving\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nuno Vasconcelos\">\n<a href=\"#\" onclick=\"document.getElementById('form-NunoVasconcelosCascadeRCNNDelving').submit();\">Nuno Vasconcelos</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Cai_Cascade_R-CNN_Delving_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.00726\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Cai_2018_CVPR,<br>\nauthor = {Cai, Zhaowei and Vasconcelos, Nuno},<br>\ntitle = {Cascade R-CNN: Delving Into High Quality Object Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Huang_Learning_Semantic_Concepts_CVPR_2018_paper.html\">Learning Semantic Concepts and Order for Image and Sentence Matching</a></dt>\n<dd>\n<form id=\"form-YanHuangLearningSemanticConcepts\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yan Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanHuangLearningSemanticConcepts').submit();\">Yan Huang</a>,\n</form>\n<form id=\"form-QiWuLearningSemanticConcepts\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qi Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiWuLearningSemanticConcepts').submit();\">Qi Wu</a>,\n</form>\n<form id=\"form-ChunfengSongLearningSemanticConcepts\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chunfeng Song\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChunfengSongLearningSemanticConcepts').submit();\">Chunfeng Song</a>,\n</form>\n<form id=\"form-LiangWangLearningSemanticConcepts\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiangWangLearningSemanticConcepts').submit();\">Liang Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Huang_Learning_Semantic_Concepts_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.02036\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Huang_2018_CVPR,<br>\nauthor = {Huang, Yan and Wu, Qi and Song, Chunfeng and Wang, Liang},<br>\ntitle = {Learning Semantic Concepts and Order for Image and Sentence Matching},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Christie_Functional_Map_of_CVPR_2018_paper.html\">Functional Map of the World</a></dt>\n<dd>\n<form id=\"form-GordonChristieFunctionalMapof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gordon Christie\">\n<a href=\"#\" onclick=\"document.getElementById('form-GordonChristieFunctionalMapof').submit();\">Gordon Christie</a>,\n</form>\n<form id=\"form-NeilFendleyFunctionalMapof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Neil Fendley\">\n<a href=\"#\" onclick=\"document.getElementById('form-NeilFendleyFunctionalMapof').submit();\">Neil Fendley</a>,\n</form>\n<form id=\"form-JamesWilsonFunctionalMapof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"James Wilson\">\n<a href=\"#\" onclick=\"document.getElementById('form-JamesWilsonFunctionalMapof').submit();\">James Wilson</a>,\n</form>\n<form id=\"form-RyanMukherjeeFunctionalMapof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ryan Mukherjee\">\n<a href=\"#\" onclick=\"document.getElementById('form-RyanMukherjeeFunctionalMapof').submit();\">Ryan Mukherjee</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Christie_Functional_Map_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0471-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.07846\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Christie_2018_CVPR,<br>\nauthor = {Christie, Gordon and Fendley, Neil and Wilson, James and Mukherjee, Ryan},<br>\ntitle = {Functional Map of the World},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Peng_MegDet_A_Large_CVPR_2018_paper.html\">MegDet: A Large Mini-Batch Object Detector</a></dt>\n<dd>\n<form id=\"form-ChaoPengMegDetALarge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chao Peng\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChaoPengMegDetALarge').submit();\">Chao Peng</a>,\n</form>\n<form id=\"form-TeteXiaoMegDetALarge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tete Xiao\">\n<a href=\"#\" onclick=\"document.getElementById('form-TeteXiaoMegDetALarge').submit();\">Tete Xiao</a>,\n</form>\n<form id=\"form-ZemingLiMegDetALarge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zeming Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZemingLiMegDetALarge').submit();\">Zeming Li</a>,\n</form>\n<form id=\"form-YuningJiangMegDetALarge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuning Jiang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuningJiangMegDetALarge').submit();\">Yuning Jiang</a>,\n</form>\n<form id=\"form-XiangyuZhangMegDetALarge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiangyu Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiangyuZhangMegDetALarge').submit();\">Xiangyu Zhang</a>,\n</form>\n<form id=\"form-KaiJiaMegDetALarge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kai Jia\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaiJiaMegDetALarge').submit();\">Kai Jia</a>,\n</form>\n<form id=\"form-GangYuMegDetALarge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gang Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-GangYuMegDetALarge').submit();\">Gang Yu</a>,\n</form>\n<form id=\"form-JianSunMegDetALarge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jian Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianSunMegDetALarge').submit();\">Jian Sun</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Peng_MegDet_A_Large_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.07240\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Peng_2018_CVPR,<br>\nauthor = {Peng, Chao and Xiao, Tete and Li, Zeming and Jiang, Yuning and Zhang, Xiangyu and Jia, Kai and Yu, Gang and Sun, Jian},<br>\ntitle = {MegDet: A Large Mini-Batch Object Detector},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Rao_Learning_Globally_Optimized_CVPR_2018_paper.html\">Learning Globally Optimized Object Detector via Policy Gradient</a></dt>\n<dd>\n<form id=\"form-YongmingRaoLearningGloballyOptimized\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yongming Rao\">\n<a href=\"#\" onclick=\"document.getElementById('form-YongmingRaoLearningGloballyOptimized').submit();\">Yongming Rao</a>,\n</form>\n<form id=\"form-DahuaLinLearningGloballyOptimized\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dahua Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-DahuaLinLearningGloballyOptimized').submit();\">Dahua Lin</a>,\n</form>\n<form id=\"form-JiwenLuLearningGloballyOptimized\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiwen Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiwenLuLearningGloballyOptimized').submit();\">Jiwen Lu</a>,\n</form>\n<form id=\"form-JieZhouLearningGloballyOptimized\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jie Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-JieZhouLearningGloballyOptimized').submit();\">Jie Zhou</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Rao_Learning_Globally_Optimized_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Rao_2018_CVPR,<br>\nauthor = {Rao, Yongming and Lin, Dahua and Lu, Jiwen and Zhou, Jie},<br>\ntitle = {Learning Globally Optimized Object Detector via Policy Gradient},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Photographic_Text-to-Image_Synthesis_CVPR_2018_paper.html\">Photographic Text-to-Image Synthesis With a Hierarchically-Nested Adversarial Network</a></dt>\n<dd>\n<form id=\"form-ZizhaoZhangPhotographicTexttoImageSynthesis\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zizhao Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZizhaoZhangPhotographicTexttoImageSynthesis').submit();\">Zizhao Zhang</a>,\n</form>\n<form id=\"form-YuanpuXiePhotographicTexttoImageSynthesis\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuanpu Xie\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuanpuXiePhotographicTexttoImageSynthesis').submit();\">Yuanpu Xie</a>,\n</form>\n<form id=\"form-LinYangPhotographicTexttoImageSynthesis\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lin Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LinYangPhotographicTexttoImageSynthesis').submit();\">Lin Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Photographic_Text-to-Image_Synthesis_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.09178\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Zizhao and Xie, Yuanpu and Yang, Lin},<br>\ntitle = {Photographic Text-to-Image Synthesis With a Hierarchically-Nested Adversarial Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hui_Illuminant_Spectra-Based_Source_CVPR_2018_paper.html\">Illuminant Spectra-Based Source Separation Using Flash Photography</a></dt>\n<dd>\n<form id=\"form-ZhuoHuiIlluminantSpectraBasedSource\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhuo Hui\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhuoHuiIlluminantSpectraBasedSource').submit();\">Zhuo Hui</a>,\n</form>\n<form id=\"form-KalyanSunkavalliIlluminantSpectraBasedSource\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kalyan Sunkavalli\">\n<a href=\"#\" onclick=\"document.getElementById('form-KalyanSunkavalliIlluminantSpectraBasedSource').submit();\">Kalyan Sunkavalli</a>,\n</form>\n<form id=\"form-SunilHadapIlluminantSpectraBasedSource\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sunil Hadap\">\n<a href=\"#\" onclick=\"document.getElementById('form-SunilHadapIlluminantSpectraBasedSource').submit();\">Sunil Hadap</a>,\n</form>\n<form id=\"form-AswinC.IlluminantSpectraBasedSource\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Aswin C. Sankaranarayanan\">\n<a href=\"#\" onclick=\"document.getElementById('form-AswinC.IlluminantSpectraBasedSource').submit();\">Aswin C. Sankaranarayanan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hui_Illuminant_Spectra-Based_Source_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0270-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1704.05564\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hui_2018_CVPR,<br>\nauthor = {Hui, Zhuo and Sunkavalli, Kalyan and Hadap, Sunil and Sankaranarayanan, Aswin C.},<br>\ntitle = {Illuminant Spectra-Based Source Separation Using Flash Photography},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xu_Trapping_Light_for_CVPR_2018_paper.html\">Trapping Light for Time of Flight</a></dt>\n<dd>\n<form id=\"form-RuilinXuTrappingLightfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ruilin Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-RuilinXuTrappingLightfor').submit();\">Ruilin Xu</a>,\n</form>\n<form id=\"form-MohitGuptaTrappingLightfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mohit Gupta\">\n<a href=\"#\" onclick=\"document.getElementById('form-MohitGuptaTrappingLightfor').submit();\">Mohit Gupta</a>,\n</form>\n<form id=\"form-ShreeK.TrappingLightfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shree K. Nayar\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShreeK.TrappingLightfor').submit();\">Shree K. Nayar</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xu_Trapping_Light_for_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xu_2018_CVPR,<br>\nauthor = {Xu, Ruilin and Gupta, Mohit and Nayar, Shree K.},<br>\ntitle = {Trapping Light for Time of Flight},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Blau_The_Perception-Distortion_Tradeoff_CVPR_2018_paper.html\">The Perception-Distortion Tradeoff</a></dt>\n<dd>\n<form id=\"form-YochaiBlauThePerceptionDistortionTradeoff\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yochai Blau\">\n<a href=\"#\" onclick=\"document.getElementById('form-YochaiBlauThePerceptionDistortionTradeoff').submit();\">Yochai Blau</a>,\n</form>\n<form id=\"form-TomerMichaeliThePerceptionDistortionTradeoff\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tomer Michaeli\">\n<a href=\"#\" onclick=\"document.getElementById('form-TomerMichaeliThePerceptionDistortionTradeoff').submit();\">Tomer Michaeli</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Blau_The_Perception-Distortion_Tradeoff_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2765-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.06077\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Blau_2018_CVPR,<br>\nauthor = {Blau, Yochai and Michaeli, Tomer},<br>\ntitle = {The Perception-Distortion Tradeoff},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhou_Label_Denoising_Adversarial_CVPR_2018_paper.html\">Label Denoising Adversarial Network (LDAN) for Inverse Lighting of Faces</a></dt>\n<dd>\n<form id=\"form-HaoZhouLabelDenoisingAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hao Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaoZhouLabelDenoisingAdversarial').submit();\">Hao Zhou</a>,\n</form>\n<form id=\"form-JinSunLabelDenoisingAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jin Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-JinSunLabelDenoisingAdversarial').submit();\">Jin Sun</a>,\n</form>\n<form id=\"form-YaserYacoobLabelDenoisingAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yaser Yacoob\">\n<a href=\"#\" onclick=\"document.getElementById('form-YaserYacoobLabelDenoisingAdversarial').submit();\">Yaser Yacoob</a>,\n</form>\n<form id=\"form-DavidW.LabelDenoisingAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"David W. Jacobs\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavidW.LabelDenoisingAdversarial').submit();\">David W. Jacobs</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhou_Label_Denoising_Adversarial_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0906-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1709.01993\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhou_2018_CVPR,<br>\nauthor = {Zhou, Hao and Sun, Jin and Yacoob, Yaser and Jacobs, David W.},<br>\ntitle = {Label Denoising Adversarial Network (LDAN) for Inverse Lighting of Faces},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Mirdehghan_Optimal_Structured_Light_CVPR_2018_paper.html\">Optimal Structured Light \u00c3\u00a0 La Carte</a></dt>\n<dd>\n<form id=\"form-ParsaMirdehghanOptimalStructuredLight\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Parsa Mirdehghan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ParsaMirdehghanOptimalStructuredLight').submit();\">Parsa Mirdehghan</a>,\n</form>\n<form id=\"form-WenzhengChenOptimalStructuredLight\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenzheng Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenzhengChenOptimalStructuredLight').submit();\">Wenzheng Chen</a>,\n</form>\n<form id=\"form-KiriakosN.OptimalStructuredLight\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kiriakos N. Kutulakos\">\n<a href=\"#\" onclick=\"document.getElementById('form-KiriakosN.OptimalStructuredLight').submit();\">Kiriakos N. Kutulakos</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Mirdehghan_Optimal_Structured_Light_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1697-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Mirdehghan_2018_CVPR,<br>\nauthor = {Mirdehghan, Parsa and Chen, Wenzheng and Kutulakos, Kiriakos N.},<br>\ntitle = {Optimal Structured Light \u00c3\u00a0 La Carte},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Smith_Tracking_Multiple_Objects_CVPR_2018_paper.html\">Tracking Multiple Objects Outside the Line of Sight Using Speckle Imaging</a></dt>\n<dd>\n<form id=\"form-BrandonM.TrackingMultipleObjects\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Brandon M. Smith\">\n<a href=\"#\" onclick=\"document.getElementById('form-BrandonM.TrackingMultipleObjects').submit();\">Brandon M. Smith</a>,\n</form>\n<form id=\"form-MatthewOTooleTrackingMultipleObjects\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Matthew O'Toole\">\n<a href=\"#\" onclick=\"document.getElementById('form-MatthewOTooleTrackingMultipleObjects').submit();\">Matthew O'Toole</a>,\n</form>\n<form id=\"form-MohitGuptaTrackingMultipleObjects\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mohit Gupta\">\n<a href=\"#\" onclick=\"document.getElementById('form-MohitGuptaTrackingMultipleObjects').submit();\">Mohit Gupta</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Smith_Tracking_Multiple_Objects_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0281-supp.zip\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Smith_2018_CVPR,<br>\nauthor = {Smith, Brandon M. and O'Toole, Matthew and Gupta, Mohit},<br>\ntitle = {Tracking Multiple Objects Outside the Line of Sight Using Speckle Imaging},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Baradad_Inferring_Light_Fields_CVPR_2018_paper.html\">Inferring Light Fields From Shadows</a></dt>\n<dd>\n<form id=\"form-ManelBaradadInferringLightFields\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Manel Baradad\">\n<a href=\"#\" onclick=\"document.getElementById('form-ManelBaradadInferringLightFields').submit();\">Manel Baradad</a>,\n</form>\n<form id=\"form-VickieYeInferringLightFields\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vickie Ye\">\n<a href=\"#\" onclick=\"document.getElementById('form-VickieYeInferringLightFields').submit();\">Vickie Ye</a>,\n</form>\n<form id=\"form-AdamB.InferringLightFields\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Adam B. Yedidia\">\n<a href=\"#\" onclick=\"document.getElementById('form-AdamB.InferringLightFields').submit();\">Adam B. Yedidia</a>,\n</form>\n<form id=\"form-Fr\u00c3\u00a9doDurandInferringLightFields\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fr\u00c3\u00a9do Durand\">\n<a href=\"#\" onclick=\"document.getElementById('form-Fr\u00c3\u00a9doDurandInferringLightFields').submit();\">Fr\u00c3\u00a9do Durand</a>,\n</form>\n<form id=\"form-WilliamT.InferringLightFields\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"William T. Freeman\">\n<a href=\"#\" onclick=\"document.getElementById('form-WilliamT.InferringLightFields').submit();\">William T. Freeman</a>,\n</form>\n<form id=\"form-GregoryW.InferringLightFields\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gregory W. Wornell\">\n<a href=\"#\" onclick=\"document.getElementById('form-GregoryW.InferringLightFields').submit();\">Gregory W. Wornell</a>,\n</form>\n<form id=\"form-AntonioTorralbaInferringLightFields\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Antonio Torralba\">\n<a href=\"#\" onclick=\"document.getElementById('form-AntonioTorralbaInferringLightFields').submit();\">Antonio Torralba</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Baradad_Inferring_Light_Fields_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Baradad_2018_CVPR,<br>\nauthor = {Baradad, Manel and Ye, Vickie and Yedidia, Adam B. and Durand, Fr\u00c3\u00a9do and Freeman, William T. and Wornell, Gregory W. and Torralba, Antonio},<br>\ntitle = {Inferring Light Fields From Shadows},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tlusty_Modifying_Non-Local_Variations_CVPR_2018_paper.html\">Modifying Non-Local Variations Across Multiple Views</a></dt>\n<dd>\n<form id=\"form-TalTlustyModifyingNonLocalVariations\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tal Tlusty\">\n<a href=\"#\" onclick=\"document.getElementById('form-TalTlustyModifyingNonLocalVariations').submit();\">Tal Tlusty</a>,\n</form>\n<form id=\"form-TomerMichaeliModifyingNonLocalVariations\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tomer Michaeli\">\n<a href=\"#\" onclick=\"document.getElementById('form-TomerMichaeliModifyingNonLocalVariations').submit();\">Tomer Michaeli</a>,\n</form>\n<form id=\"form-TaliDekelModifyingNonLocalVariations\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tali Dekel\">\n<a href=\"#\" onclick=\"document.getElementById('form-TaliDekelModifyingNonLocalVariations').submit();\">Tali Dekel</a>,\n</form>\n<form id=\"form-LihiZelnik-ManorModifyingNonLocalVariations\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lihi Zelnik-Manor\">\n<a href=\"#\" onclick=\"document.getElementById('form-LihiZelnik-ManorModifyingNonLocalVariations').submit();\">Lihi Zelnik-Manor</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tlusty_Modifying_Non-Local_Variations_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2805-supp.zip\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tlusty_2018_CVPR,<br>\nauthor = {Tlusty, Tal and Michaeli, Tomer and Dekel, Tali and Zelnik-Manor, Lihi},<br>\ntitle = {Modifying Non-Local Variations Across Multiple Views},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_Robust_Video_Content_CVPR_2018_paper.html\">Robust Video Content Alignment and Compensation for Rain Removal in a CNN Framework</a></dt>\n<dd>\n<form id=\"form-JieChenRobustVideoContent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jie Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-JieChenRobustVideoContent').submit();\">Jie Chen</a>,\n</form>\n<form id=\"form-Cheen-HauTanRobustVideoContent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cheen-Hau Tan\">\n<a href=\"#\" onclick=\"document.getElementById('form-Cheen-HauTanRobustVideoContent').submit();\">Cheen-Hau Tan</a>,\n</form>\n<form id=\"form-JunhuiHouRobustVideoContent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junhui Hou\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunhuiHouRobustVideoContent').submit();\">Junhui Hou</a>,\n</form>\n<form id=\"form-Lap-PuiChauRobustVideoContent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lap-Pui Chau\">\n<a href=\"#\" onclick=\"document.getElementById('form-Lap-PuiChauRobustVideoContent').submit();\">Lap-Pui Chau</a>,\n</form>\n<form id=\"form-HeLiRobustVideoContent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"He Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-HeLiRobustVideoContent').submit();\">He Li</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_Robust_Video_Content_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.10433\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Jie and Tan, Cheen-Hau and Hou, Junhui and Chau, Lap-Pui and Li, He},<br>\ntitle = {Robust Video Content Alignment and Compensation for Rain Removal in a CNN Framework},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sengupta_SfSNet_Learning_Shape_CVPR_2018_paper.html\">SfSNet: Learning Shape, Reflectance and Illuminance of Faces `in the Wild'</a></dt>\n<dd>\n<form id=\"form-SoumyadipSenguptaSfSNetLearningShape\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Soumyadip Sengupta\">\n<a href=\"#\" onclick=\"document.getElementById('form-SoumyadipSenguptaSfSNetLearningShape').submit();\">Soumyadip Sengupta</a>,\n</form>\n<form id=\"form-AngjooKanazawaSfSNetLearningShape\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Angjoo Kanazawa\">\n<a href=\"#\" onclick=\"document.getElementById('form-AngjooKanazawaSfSNetLearningShape').submit();\">Angjoo Kanazawa</a>,\n</form>\n<form id=\"form-CarlosD.SfSNetLearningShape\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Carlos D. Castillo\">\n<a href=\"#\" onclick=\"document.getElementById('form-CarlosD.SfSNetLearningShape').submit();\">Carlos D. Castillo</a>,\n</form>\n<form id=\"form-DavidW.SfSNetLearningShape\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"David W. Jacobs\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavidW.SfSNetLearningShape').submit();\">David W. Jacobs</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sengupta_SfSNet_Learning_Shape_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0754-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sengupta_2018_CVPR,<br>\nauthor = {Sengupta, Soumyadip and Kanazawa, Angjoo and Castillo, Carlos D. and Jacobs, David W.},<br>\ntitle = {SfSNet: Learning Shape, Reflectance and Illuminance of Faces `in the Wild'},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_Deep_Photo_Enhancer_CVPR_2018_paper.html\">Deep Photo Enhancer: Unpaired Learning for Image Enhancement From Photographs With GANs</a></dt>\n<dd>\n<form id=\"form-Yu-ShengChenDeepPhotoEnhancer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu-Sheng Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yu-ShengChenDeepPhotoEnhancer').submit();\">Yu-Sheng Chen</a>,\n</form>\n<form id=\"form-Yu-ChingWangDeepPhotoEnhancer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu-Ching Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yu-ChingWangDeepPhotoEnhancer').submit();\">Yu-Ching Wang</a>,\n</form>\n<form id=\"form-Man-HsinKaoDeepPhotoEnhancer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Man-Hsin Kao\">\n<a href=\"#\" onclick=\"document.getElementById('form-Man-HsinKaoDeepPhotoEnhancer').submit();\">Man-Hsin Kao</a>,\n</form>\n<form id=\"form-Yung-YuChuangDeepPhotoEnhancer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yung-Yu Chuang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yung-YuChuangDeepPhotoEnhancer').submit();\">Yung-Yu Chuang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_Deep_Photo_Enhancer_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Yu-Sheng and Wang, Yu-Ching and Kao, Man-Hsin and Chuang, Yung-Yu},<br>\ntitle = {Deep Photo Enhancer: Unpaired Learning for Image Enhancement From Photographs With GANs},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Meka_LIME_Live_Intrinsic_CVPR_2018_paper.html\">LIME: Live Intrinsic Material Estimation</a></dt>\n<dd>\n<form id=\"form-AbhimitraMekaLIMELiveIntrinsic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Abhimitra Meka\">\n<a href=\"#\" onclick=\"document.getElementById('form-AbhimitraMekaLIMELiveIntrinsic').submit();\">Abhimitra Meka</a>,\n</form>\n<form id=\"form-MaximMaximovLIMELiveIntrinsic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Maxim Maximov\">\n<a href=\"#\" onclick=\"document.getElementById('form-MaximMaximovLIMELiveIntrinsic').submit();\">Maxim Maximov</a>,\n</form>\n<form id=\"form-MichaelZollh\u00c3\u00b6ferLIMELiveIntrinsic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michael Zollh\u00c3\u00b6fer\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichaelZollh\u00c3\u00b6ferLIMELiveIntrinsic').submit();\">Michael Zollh\u00c3\u00b6fer</a>,\n</form>\n<form id=\"form-AvishekChatterjeeLIMELiveIntrinsic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Avishek Chatterjee\">\n<a href=\"#\" onclick=\"document.getElementById('form-AvishekChatterjeeLIMELiveIntrinsic').submit();\">Avishek Chatterjee</a>,\n</form>\n<form id=\"form-Hans-PeterSeidelLIMELiveIntrinsic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hans-Peter Seidel\">\n<a href=\"#\" onclick=\"document.getElementById('form-Hans-PeterSeidelLIMELiveIntrinsic').submit();\">Hans-Peter Seidel</a>,\n</form>\n<form id=\"form-ChristianRichardtLIMELiveIntrinsic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Christian Richardt\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChristianRichardtLIMELiveIntrinsic').submit();\">Christian Richardt</a>,\n</form>\n<form id=\"form-ChristianTheobaltLIMELiveIntrinsic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Christian Theobalt\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChristianTheobaltLIMELiveIntrinsic').submit();\">Christian Theobalt</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Meka_LIME_Live_Intrinsic_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2344-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.01075\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Meka_2018_CVPR,<br>\nauthor = {Meka, Abhimitra and Maximov, Maxim and Zollh\u00c3\u00b6fer, Michael and Chatterjee, Avishek and Seidel, Hans-Peter and Richardt, Christian and Theobalt, Christian},<br>\ntitle = {LIME: Live Intrinsic Material Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Learning_to_Detect_CVPR_2018_paper.html\">Learning to Detect Features in Texture Images</a></dt>\n<dd>\n<form id=\"form-LinguangZhangLearningtoDetect\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Linguang Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LinguangZhangLearningtoDetect').submit();\">Linguang Zhang</a>,\n</form>\n<form id=\"form-SzymonRusinkiewiczLearningtoDetect\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Szymon Rusinkiewicz\">\n<a href=\"#\" onclick=\"document.getElementById('form-SzymonRusinkiewiczLearningtoDetect').submit();\">Szymon Rusinkiewicz</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Learning_to_Detect_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0878-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Linguang and Rusinkiewicz, Szymon},<br>\ntitle = {Learning to Detect Features in Texture Images},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Jin_Learning_to_Extract_CVPR_2018_paper.html\">Learning to Extract a Video Sequence From a Single Motion-Blurred Image</a></dt>\n<dd>\n<form id=\"form-MeiguangJinLearningtoExtract\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Meiguang Jin\">\n<a href=\"#\" onclick=\"document.getElementById('form-MeiguangJinLearningtoExtract').submit();\">Meiguang Jin</a>,\n</form>\n<form id=\"form-GiviMeishviliLearningtoExtract\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Givi Meishvili\">\n<a href=\"#\" onclick=\"document.getElementById('form-GiviMeishviliLearningtoExtract').submit();\">Givi Meishvili</a>,\n</form>\n<form id=\"form-PaoloFavaroLearningtoExtract\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Paolo Favaro\">\n<a href=\"#\" onclick=\"document.getElementById('form-PaoloFavaroLearningtoExtract').submit();\">Paolo Favaro</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Jin_Learning_to_Extract_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.04065\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Jin_2018_CVPR,<br>\nauthor = {Jin, Meiguang and Meishvili, Givi and Favaro, Paolo},<br>\ntitle = {Learning to Extract a Video Sequence From a Single Motion-Blurred Image},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Anirudh_Lose_the_Views_CVPR_2018_paper.html\">Lose the Views: Limited Angle CT Reconstruction via Implicit Sinogram Completion</a></dt>\n<dd>\n<form id=\"form-RushilAnirudhLosetheViews\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rushil Anirudh\">\n<a href=\"#\" onclick=\"document.getElementById('form-RushilAnirudhLosetheViews').submit();\">Rushil Anirudh</a>,\n</form>\n<form id=\"form-HyojinKimLosetheViews\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hyojin Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-HyojinKimLosetheViews').submit();\">Hyojin Kim</a>,\n</form>\n<form id=\"form-JayaramanJ.LosetheViews\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jayaraman J. Thiagarajan\">\n<a href=\"#\" onclick=\"document.getElementById('form-JayaramanJ.LosetheViews').submit();\">Jayaraman J. Thiagarajan</a>,\n</form>\n<form id=\"form-K.AdityaLosetheViews\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"K. Aditya Mohan\">\n<a href=\"#\" onclick=\"document.getElementById('form-K.AdityaLosetheViews').submit();\">K. Aditya Mohan</a>,\n</form>\n<form id=\"form-KyleChampleyLosetheViews\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kyle Champley\">\n<a href=\"#\" onclick=\"document.getElementById('form-KyleChampleyLosetheViews').submit();\">Kyle Champley</a>,\n</form>\n<form id=\"form-TimoBremerLosetheViews\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Timo Bremer\">\n<a href=\"#\" onclick=\"document.getElementById('form-TimoBremerLosetheViews').submit();\">Timo Bremer</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Anirudh_Lose_the_Views_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3329-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.10388\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Anirudh_2018_CVPR,<br>\nauthor = {Anirudh, Rushil and Kim, Hyojin and Thiagarajan, Jayaraman J. and Aditya Mohan, K. and Champley, Kyle and Bremer, Timo},<br>\ntitle = {Lose the Views: Limited Angle CT Reconstruction via Implicit Sinogram Completion},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Men_A_Common_Framework_CVPR_2018_paper.html\">A Common Framework for Interactive Texture Transfer</a></dt>\n<dd>\n<form id=\"form-YifangMenACommonFramework\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yifang Men\">\n<a href=\"#\" onclick=\"document.getElementById('form-YifangMenACommonFramework').submit();\">Yifang Men</a>,\n</form>\n<form id=\"form-ZhouhuiLianACommonFramework\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhouhui Lian\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhouhuiLianACommonFramework').submit();\">Zhouhui Lian</a>,\n</form>\n<form id=\"form-YingminTangACommonFramework\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yingmin Tang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YingminTangACommonFramework').submit();\">Yingmin Tang</a>,\n</form>\n<form id=\"form-JianguoXiaoACommonFramework\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianguo Xiao\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianguoXiaoACommonFramework').submit();\">Jianguo Xiao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Men_A_Common_Framework_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3482-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Men_2018_CVPR,<br>\nauthor = {Men, Yifang and Lian, Zhouhui and Tang, Yingmin and Xiao, Jianguo},<br>\ntitle = {A Common Framework for Interactive Texture Transfer},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Fajtl_AMNet_Memorability_Estimation_CVPR_2018_paper.html\">AMNet: Memorability Estimation With Attention</a></dt>\n<dd>\n<form id=\"form-JiriFajtlAMNetMemorabilityEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiri Fajtl\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiriFajtlAMNetMemorabilityEstimation').submit();\">Jiri Fajtl</a>,\n</form>\n<form id=\"form-VasileiosArgyriouAMNetMemorabilityEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vasileios Argyriou\">\n<a href=\"#\" onclick=\"document.getElementById('form-VasileiosArgyriouAMNetMemorabilityEstimation').submit();\">Vasileios Argyriou</a>,\n</form>\n<form id=\"form-DorothyMonekossoAMNetMemorabilityEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dorothy Monekosso\">\n<a href=\"#\" onclick=\"document.getElementById('form-DorothyMonekossoAMNetMemorabilityEstimation').submit();\">Dorothy Monekosso</a>,\n</form>\n<form id=\"form-PaoloRemagninoAMNetMemorabilityEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Paolo Remagnino\">\n<a href=\"#\" onclick=\"document.getElementById('form-PaoloRemagninoAMNetMemorabilityEstimation').submit();\">Paolo Remagnino</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Fajtl_AMNet_Memorability_Estimation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.03115\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Fajtl_2018_CVPR,<br>\nauthor = {Fajtl, Jiri and Argyriou, Vasileios and Monekosso, Dorothy and Remagnino, Paolo},<br>\ntitle = {AMNet: Memorability Estimation With Attention},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Pan_Blind_Predicting_Similar_CVPR_2018_paper.html\">Blind Predicting Similar Quality Map for Image Quality Assessment</a></dt>\n<dd>\n<form id=\"form-DaPanBlindPredictingSimilar\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Da Pan\">\n<a href=\"#\" onclick=\"document.getElementById('form-DaPanBlindPredictingSimilar').submit();\">Da Pan</a>,\n</form>\n<form id=\"form-PingShiBlindPredictingSimilar\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ping Shi\">\n<a href=\"#\" onclick=\"document.getElementById('form-PingShiBlindPredictingSimilar').submit();\">Ping Shi</a>,\n</form>\n<form id=\"form-MingHouBlindPredictingSimilar\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming Hou\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingHouBlindPredictingSimilar').submit();\">Ming Hou</a>,\n</form>\n<form id=\"form-ZefengYingBlindPredictingSimilar\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zefeng Ying\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZefengYingBlindPredictingSimilar').submit();\">Zefeng Ying</a>,\n</form>\n<form id=\"form-SizheFuBlindPredictingSimilar\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sizhe Fu\">\n<a href=\"#\" onclick=\"document.getElementById('form-SizheFuBlindPredictingSimilar').submit();\">Sizhe Fu</a>,\n</form>\n<form id=\"form-YuanZhangBlindPredictingSimilar\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuan Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuanZhangBlindPredictingSimilar').submit();\">Yuan Zhang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Pan_Blind_Predicting_Similar_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.08493\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Pan_2018_CVPR,<br>\nauthor = {Pan, Da and Shi, Ping and Hou, Ming and Ying, Zefeng and Fu, Sizhe and Zhang, Yuan},<br>\ntitle = {Blind Predicting Similar Quality Map for Image Quality Assessment},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Su_Deep_End-to-End_Time-of-Flight_CVPR_2018_paper.html\">Deep End-to-End Time-of-Flight Imaging</a></dt>\n<dd>\n<form id=\"form-ShuochenSuDeepEndtoEndTimeofFlight\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuochen Su\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuochenSuDeepEndtoEndTimeofFlight').submit();\">Shuochen Su</a>,\n</form>\n<form id=\"form-FelixHeideDeepEndtoEndTimeofFlight\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Felix Heide\">\n<a href=\"#\" onclick=\"document.getElementById('form-FelixHeideDeepEndtoEndTimeofFlight').submit();\">Felix Heide</a>,\n</form>\n<form id=\"form-GordonWetzsteinDeepEndtoEndTimeofFlight\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gordon Wetzstein\">\n<a href=\"#\" onclick=\"document.getElementById('form-GordonWetzsteinDeepEndtoEndTimeofFlight').submit();\">Gordon Wetzstein</a>,\n</form>\n<form id=\"form-WolfgangHeidrichDeepEndtoEndTimeofFlight\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wolfgang Heidrich\">\n<a href=\"#\" onclick=\"document.getElementById('form-WolfgangHeidrichDeepEndtoEndTimeofFlight').submit();\">Wolfgang Heidrich</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Su_Deep_End-to-End_Time-of-Flight_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0421-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Su_2018_CVPR,<br>\nauthor = {Su, Shuochen and Heide, Felix and Wetzstein, Gordon and Heidrich, Wolfgang},<br>\ntitle = {Deep End-to-End Time-of-Flight Imaging},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Srinivasan_Aperture_Supervision_for_CVPR_2018_paper.html\">Aperture Supervision for Monocular Depth Estimation</a></dt>\n<dd>\n<form id=\"form-PratulP.ApertureSupervisionfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pratul P. Srinivasan\">\n<a href=\"#\" onclick=\"document.getElementById('form-PratulP.ApertureSupervisionfor').submit();\">Pratul P. Srinivasan</a>,\n</form>\n<form id=\"form-RahulGargApertureSupervisionfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rahul Garg\">\n<a href=\"#\" onclick=\"document.getElementById('form-RahulGargApertureSupervisionfor').submit();\">Rahul Garg</a>,\n</form>\n<form id=\"form-NealWadhwaApertureSupervisionfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Neal Wadhwa\">\n<a href=\"#\" onclick=\"document.getElementById('form-NealWadhwaApertureSupervisionfor').submit();\">Neal Wadhwa</a>,\n</form>\n<form id=\"form-RenNgApertureSupervisionfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ren Ng\">\n<a href=\"#\" onclick=\"document.getElementById('form-RenNgApertureSupervisionfor').submit();\">Ren Ng</a>,\n</form>\n<form id=\"form-JonathanT.ApertureSupervisionfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jonathan T. Barron\">\n<a href=\"#\" onclick=\"document.getElementById('form-JonathanT.ApertureSupervisionfor').submit();\">Jonathan T. Barron</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Srinivasan_Aperture_Supervision_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3751-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.07933\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Srinivasan_2018_CVPR,<br>\nauthor = {Srinivasan, Pratul P. and Garg, Rahul and Wadhwa, Neal and Ng, Ren and Barron, Jonathan T.},<br>\ntitle = {Aperture Supervision for Monocular Depth Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sakakibara_Seeing_Temporal_Modulation_CVPR_2018_paper.html\">Seeing Temporal Modulation of Lights From Standard Cameras</a></dt>\n<dd>\n<form id=\"form-NaokiSakakibaraSeeingTemporalModulation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Naoki Sakakibara\">\n<a href=\"#\" onclick=\"document.getElementById('form-NaokiSakakibaraSeeingTemporalModulation').submit();\">Naoki Sakakibara</a>,\n</form>\n<form id=\"form-FumihikoSakaueSeeingTemporalModulation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fumihiko Sakaue\">\n<a href=\"#\" onclick=\"document.getElementById('form-FumihikoSakaueSeeingTemporalModulation').submit();\">Fumihiko Sakaue</a>,\n</form>\n<form id=\"form-JunSatoSeeingTemporalModulation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jun Sato\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunSatoSeeingTemporalModulation').submit();\">Jun Sato</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sakakibara_Seeing_Temporal_Modulation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0648-supp.zip\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sakakibara_2018_CVPR,<br>\nauthor = {Sakakibara, Naoki and Sakaue, Fumihiko and Sato, Jun},<br>\ntitle = {Seeing Temporal Modulation of Lights From Standard Cameras},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Levis_Statistical_Tomography_of_CVPR_2018_paper.html\">Statistical Tomography of Microscopic Life</a></dt>\n<dd>\n<form id=\"form-AviadLevisStatisticalTomographyof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Aviad Levis\">\n<a href=\"#\" onclick=\"document.getElementById('form-AviadLevisStatisticalTomographyof').submit();\">Aviad Levis</a>,\n</form>\n<form id=\"form-YoavY.StatisticalTomographyof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yoav Y. Schechner\">\n<a href=\"#\" onclick=\"document.getElementById('form-YoavY.StatisticalTomographyof').submit();\">Yoav Y. Schechner</a>,\n</form>\n<form id=\"form-RonenTalmonStatisticalTomographyof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ronen Talmon\">\n<a href=\"#\" onclick=\"document.getElementById('form-RonenTalmonStatisticalTomographyof').submit();\">Ronen Talmon</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Levis_Statistical_Tomography_of_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Levis_2018_CVPR,<br>\nauthor = {Levis, Aviad and Schechner, Yoav Y. and Talmon, Ronen},<br>\ntitle = {Statistical Tomography of Microscopic Life},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Mohan_Divide_and_Conquer_CVPR_2018_paper.html\">Divide and Conquer for Full-Resolution Light Field Deblurring</a></dt>\n<dd>\n<form id=\"form-M.R.DivideandConquer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"M. R. Mahesh Mohan\">\n<a href=\"#\" onclick=\"document.getElementById('form-M.R.DivideandConquer').submit();\">M. R. Mahesh Mohan</a>,\n</form>\n<form id=\"form-A.N.DivideandConquer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"A. N. Rajagopalan\">\n<a href=\"#\" onclick=\"document.getElementById('form-A.N.DivideandConquer').submit();\">A. N. Rajagopalan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Mohan_Divide_and_Conquer_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2165-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Mohan_2018_CVPR,<br>\nauthor = {Mahesh Mohan, M. R. and Rajagopalan, A. N.},<br>\ntitle = {Divide and Conquer for Full-Resolution Light Field Deblurring},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Huang_Multispectral_Image_Intrinsic_CVPR_2018_paper.html\">Multispectral Image Intrinsic Decomposition via Subspace Constraint</a></dt>\n<dd>\n<form id=\"form-QianHuangMultispectralImageIntrinsic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qian Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-QianHuangMultispectralImageIntrinsic').submit();\">Qian Huang</a>,\n</form>\n<form id=\"form-WeixinZhuMultispectralImageIntrinsic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weixin Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeixinZhuMultispectralImageIntrinsic').submit();\">Weixin Zhu</a>,\n</form>\n<form id=\"form-YangZhaoMultispectralImageIntrinsic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yang Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-YangZhaoMultispectralImageIntrinsic').submit();\">Yang Zhao</a>,\n</form>\n<form id=\"form-LinsenChenMultispectralImageIntrinsic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Linsen Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-LinsenChenMultispectralImageIntrinsic').submit();\">Linsen Chen</a>,\n</form>\n<form id=\"form-YaoWangMultispectralImageIntrinsic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yao Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YaoWangMultispectralImageIntrinsic').submit();\">Yao Wang</a>,\n</form>\n<form id=\"form-TaoYueMultispectralImageIntrinsic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tao Yue\">\n<a href=\"#\" onclick=\"document.getElementById('form-TaoYueMultispectralImageIntrinsic').submit();\">Tao Yue</a>,\n</form>\n<form id=\"form-XunCaoMultispectralImageIntrinsic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xun Cao\">\n<a href=\"#\" onclick=\"document.getElementById('form-XunCaoMultispectralImageIntrinsic').submit();\">Xun Cao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Huang_Multispectral_Image_Intrinsic_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Huang_2018_CVPR,<br>\nauthor = {Huang, Qian and Zhu, Weixin and Zhao, Yang and Chen, Linsen and Wang, Yao and Yue, Tao and Cao, Xun},<br>\ntitle = {Multispectral Image Intrinsic Decomposition via Subspace Constraint},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Karaimer_Improving_Color_Reproduction_CVPR_2018_paper.html\">Improving Color Reproduction Accuracy on Cameras</a></dt>\n<dd>\n<form id=\"form-HakkiCanImprovingColorReproduction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hakki Can Karaimer\">\n<a href=\"#\" onclick=\"document.getElementById('form-HakkiCanImprovingColorReproduction').submit();\">Hakki Can Karaimer</a>,\n</form>\n<form id=\"form-MichaelS.ImprovingColorReproduction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michael S. Brown\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichaelS.ImprovingColorReproduction').submit();\">Michael S. Brown</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Karaimer_Improving_Color_Reproduction_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Karaimer_2018_CVPR,<br>\nauthor = {Can Karaimer, Hakki and Brown, Michael S.},<br>\ntitle = {Improving Color Reproduction Accuracy on Cameras},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tran_A_Closer_Look_CVPR_2018_paper.html\">A Closer Look at Spatiotemporal Convolutions for Action Recognition</a></dt>\n<dd>\n<form id=\"form-DuTranACloserLook\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Du Tran\">\n<a href=\"#\" onclick=\"document.getElementById('form-DuTranACloserLook').submit();\">Du Tran</a>,\n</form>\n<form id=\"form-HengWangACloserLook\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Heng Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HengWangACloserLook').submit();\">Heng Wang</a>,\n</form>\n<form id=\"form-LorenzoTorresaniACloserLook\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lorenzo Torresani\">\n<a href=\"#\" onclick=\"document.getElementById('form-LorenzoTorresaniACloserLook').submit();\">Lorenzo Torresani</a>,\n</form>\n<form id=\"form-JamieRayACloserLook\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jamie Ray\">\n<a href=\"#\" onclick=\"document.getElementById('form-JamieRayACloserLook').submit();\">Jamie Ray</a>,\n</form>\n<form id=\"form-YannLeCunACloserLook\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yann LeCun\">\n<a href=\"#\" onclick=\"document.getElementById('form-YannLeCunACloserLook').submit();\">Yann LeCun</a>,\n</form>\n<form id=\"form-ManoharPaluriACloserLook\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Manohar Paluri\">\n<a href=\"#\" onclick=\"document.getElementById('form-ManoharPaluriACloserLook').submit();\">Manohar Paluri</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tran_A_Closer_Look_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.11248\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tran_2018_CVPR,<br>\nauthor = {Tran, Du and Wang, Heng and Torresani, Lorenzo and Ray, Jamie and LeCun, Yann and Paluri, Manohar},<br>\ntitle = {A Closer Look at Spatiotemporal Convolutions for Action Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Fan_Inferring_Shared_Attention_CVPR_2018_paper.html\">Inferring Shared Attention in Social Scene Videos</a></dt>\n<dd>\n<form id=\"form-LifengFanInferringSharedAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lifeng Fan\">\n<a href=\"#\" onclick=\"document.getElementById('form-LifengFanInferringSharedAttention').submit();\">Lifeng Fan</a>,\n</form>\n<form id=\"form-YixinChenInferringSharedAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yixin Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-YixinChenInferringSharedAttention').submit();\">Yixin Chen</a>,\n</form>\n<form id=\"form-PingWeiInferringSharedAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ping Wei\">\n<a href=\"#\" onclick=\"document.getElementById('form-PingWeiInferringSharedAttention').submit();\">Ping Wei</a>,\n</form>\n<form id=\"form-WenguanWangInferringSharedAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenguan Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenguanWangInferringSharedAttention').submit();\">Wenguan Wang</a>,\n</form>\n<form id=\"form-Song-ChunZhuInferringSharedAttention\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Song-Chun Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Song-ChunZhuInferringSharedAttention').submit();\">Song-Chun Zhu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Fan_Inferring_Shared_Attention_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Fan_2018_CVPR,<br>\nauthor = {Fan, Lifeng and Chen, Yixin and Wei, Ping and Wang, Wenguan and Zhu, Song-Chun},<br>\ntitle = {Inferring Shared Attention in Social Scene Videos},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yang_Making_Convolutional_Networks_CVPR_2018_paper.html\">Making Convolutional Networks Recurrent for Visual Sequence Learning</a></dt>\n<dd>\n<form id=\"form-XiaodongYangMakingConvolutionalNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaodong Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaodongYangMakingConvolutionalNetworks').submit();\">Xiaodong Yang</a>,\n</form>\n<form id=\"form-PavloMolchanovMakingConvolutionalNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pavlo Molchanov\">\n<a href=\"#\" onclick=\"document.getElementById('form-PavloMolchanovMakingConvolutionalNetworks').submit();\">Pavlo Molchanov</a>,\n</form>\n<form id=\"form-JanKautzMakingConvolutionalNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jan Kautz\">\n<a href=\"#\" onclick=\"document.getElementById('form-JanKautzMakingConvolutionalNetworks').submit();\">Jan Kautz</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yang_Making_Convolutional_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3241-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yang_2018_CVPR,<br>\nauthor = {Yang, Xiaodong and Molchanov, Pavlo and Kautz, Jan},<br>\ntitle = {Making Convolutional Networks Recurrent for Visual Sequence Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sultani_Real-World_Anomaly_Detection_CVPR_2018_paper.html\">Real-World Anomaly Detection in Surveillance Videos</a></dt>\n<dd>\n<form id=\"form-WaqasSultaniRealWorldAnomalyDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Waqas Sultani\">\n<a href=\"#\" onclick=\"document.getElementById('form-WaqasSultaniRealWorldAnomalyDetection').submit();\">Waqas Sultani</a>,\n</form>\n<form id=\"form-ChenChenRealWorldAnomalyDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chen Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenChenRealWorldAnomalyDetection').submit();\">Chen Chen</a>,\n</form>\n<form id=\"form-MubarakShahRealWorldAnomalyDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mubarak Shah\">\n<a href=\"#\" onclick=\"document.getElementById('form-MubarakShahRealWorldAnomalyDetection').submit();\">Mubarak Shah</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sultani_Real-World_Anomaly_Detection_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.04264\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sultani_2018_CVPR,<br>\nauthor = {Sultani, Waqas and Chen, Chen and Shah, Mubarak},<br>\ntitle = {Real-World Anomaly Detection in Surveillance Videos},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhou_Viewpoint-Aware_Attentive_Multi-View_CVPR_2018_paper.html\">Viewpoint-Aware Attentive Multi-View Inference for Vehicle Re-Identification</a></dt>\n<dd>\n<form id=\"form-YiZhouViewpointAwareAttentiveMultiView\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiZhouViewpointAwareAttentiveMultiView').submit();\">Yi Zhou</a>,\n</form>\n<form id=\"form-LingShaoViewpointAwareAttentiveMultiView\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ling Shao\">\n<a href=\"#\" onclick=\"document.getElementById('form-LingShaoViewpointAwareAttentiveMultiView').submit();\">Ling Shao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhou_Viewpoint-Aware_Attentive_Multi-View_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhou_2018_CVPR,<br>\nauthor = {Zhou, Yi and Shao, Ling},<br>\ntitle = {Viewpoint-Aware Attentive Multi-View Inference for Vehicle Re-Identification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yang_Efficient_Video_Object_CVPR_2018_paper.html\">Efficient Video Object Segmentation via Network Modulation</a></dt>\n<dd>\n<form id=\"form-LinjieYangEfficientVideoObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Linjie Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LinjieYangEfficientVideoObject').submit();\">Linjie Yang</a>,\n</form>\n<form id=\"form-YanranWangEfficientVideoObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yanran Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanranWangEfficientVideoObject').submit();\">Yanran Wang</a>,\n</form>\n<form id=\"form-XuehanXiongEfficientVideoObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xuehan Xiong\">\n<a href=\"#\" onclick=\"document.getElementById('form-XuehanXiongEfficientVideoObject').submit();\">Xuehan Xiong</a>,\n</form>\n<form id=\"form-JianchaoYangEfficientVideoObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianchao Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianchaoYangEfficientVideoObject').submit();\">Jianchao Yang</a>,\n</form>\n<form id=\"form-AggelosK.EfficientVideoObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Aggelos K. Katsaggelos\">\n<a href=\"#\" onclick=\"document.getElementById('form-AggelosK.EfficientVideoObject').submit();\">Aggelos K. Katsaggelos</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yang_Efficient_Video_Object_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.01218\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yang_2018_CVPR,<br>\nauthor = {Yang, Linjie and Wang, Yanran and Xiong, Xuehan and Yang, Jianchao and Katsaggelos, Aggelos K.},<br>\ntitle = {Efficient Video Object Segmentation via Network Modulation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ding_Weakly-Supervised_Action_Segmentation_CVPR_2018_paper.html\">Weakly-Supervised Action Segmentation With Iterative Soft Boundary Assignment</a></dt>\n<dd>\n<form id=\"form-LiDingWeaklySupervisedActionSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Li Ding\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiDingWeaklySupervisedActionSegmentation').submit();\">Li Ding</a>,\n</form>\n<form id=\"form-ChenliangXuWeaklySupervisedActionSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chenliang Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenliangXuWeaklySupervisedActionSegmentation').submit();\">Chenliang Xu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ding_Weakly-Supervised_Action_Segmentation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.10699\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ding_2018_CVPR,<br>\nauthor = {Ding, Li and Xu, Chenliang},<br>\ntitle = {Weakly-Supervised Action Segmentation With Iterative Soft Boundary Assignment},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Depth-Aware_Stereo_Video_CVPR_2018_paper.html\">Depth-Aware Stereo Video Retargeting</a></dt>\n<dd>\n<form id=\"form-BingLiDepthAwareStereoVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bing Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-BingLiDepthAwareStereoVideo').submit();\">Bing Li</a>,\n</form>\n<form id=\"form-Chia-WenLinDepthAwareStereoVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chia-Wen Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-Chia-WenLinDepthAwareStereoVideo').submit();\">Chia-Wen Lin</a>,\n</form>\n<form id=\"form-BoxinShiDepthAwareStereoVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Boxin Shi\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoxinShiDepthAwareStereoVideo').submit();\">Boxin Shi</a>,\n</form>\n<form id=\"form-TiejunHuangDepthAwareStereoVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tiejun Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-TiejunHuangDepthAwareStereoVideo').submit();\">Tiejun Huang</a>,\n</form>\n<form id=\"form-WenGaoDepthAwareStereoVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wen Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenGaoDepthAwareStereoVideo').submit();\">Wen Gao</a>,\n</form>\n<form id=\"form-C.-C.JayDepthAwareStereoVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"C.-C. Jay Kuo\">\n<a href=\"#\" onclick=\"document.getElementById('form-C.-C.JayDepthAwareStereoVideo').submit();\">C.-C. Jay Kuo</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Depth-Aware_Stereo_Video_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Bing and Lin, Chia-Wen and Shi, Boxin and Huang, Tiejun and Gao, Wen and Jay Kuo, C.-C.},<br>\ntitle = {Depth-Aware Stereo Video Retargeting},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Instance_Embedding_Transfer_CVPR_2018_paper.html\">Instance Embedding Transfer to Unsupervised Video Object Segmentation</a></dt>\n<dd>\n<form id=\"form-SiyangLiInstanceEmbeddingTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Siyang Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-SiyangLiInstanceEmbeddingTransfer').submit();\">Siyang Li</a>,\n</form>\n<form id=\"form-BryanSeyboldInstanceEmbeddingTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bryan Seybold\">\n<a href=\"#\" onclick=\"document.getElementById('form-BryanSeyboldInstanceEmbeddingTransfer').submit();\">Bryan Seybold</a>,\n</form>\n<form id=\"form-AlexeyVorobyovInstanceEmbeddingTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexey Vorobyov\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexeyVorobyovInstanceEmbeddingTransfer').submit();\">Alexey Vorobyov</a>,\n</form>\n<form id=\"form-AlirezaFathiInstanceEmbeddingTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alireza Fathi\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlirezaFathiInstanceEmbeddingTransfer').submit();\">Alireza Fathi</a>,\n</form>\n<form id=\"form-QinHuangInstanceEmbeddingTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qin Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-QinHuangInstanceEmbeddingTransfer').submit();\">Qin Huang</a>,\n</form>\n<form id=\"form-C.-C.JayInstanceEmbeddingTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"C.-C. Jay Kuo\">\n<a href=\"#\" onclick=\"document.getElementById('form-C.-C.JayInstanceEmbeddingTransfer').submit();\">C.-C. Jay Kuo</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Instance_Embedding_Transfer_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0121-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.00908\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Siyang and Seybold, Bryan and Vorobyov, Alexey and Fathi, Alireza and Huang, Qin and Jay Kuo, C.-C.},<br>\ntitle = {Instance Embedding Transfer to Unsupervised Video Object Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_Future_Frame_Prediction_CVPR_2018_paper.html\">Future Frame Prediction for Anomaly Detection \u00e2\u0080\u0093 A New Baseline</a></dt>\n<dd>\n<form id=\"form-WenLiuFutureFramePrediction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wen Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenLiuFutureFramePrediction').submit();\">Wen Liu</a>,\n</form>\n<form id=\"form-WeixinLuoFutureFramePrediction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weixin Luo\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeixinLuoFutureFramePrediction').submit();\">Weixin Luo</a>,\n</form>\n<form id=\"form-DongzeLianFutureFramePrediction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dongze Lian\">\n<a href=\"#\" onclick=\"document.getElementById('form-DongzeLianFutureFramePrediction').submit();\">Dongze Lian</a>,\n</form>\n<form id=\"form-ShenghuaGaoFutureFramePrediction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shenghua Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShenghuaGaoFutureFramePrediction').submit();\">Shenghua Gao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_Future_Frame_Prediction_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0429-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Wen and Luo, Weixin and Lian, Dongze and Gao, Shenghua},<br>\ntitle = {Future Frame Prediction for Anomaly Detection \u00e2\u0080\u0093 A New Baseline},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hara_Can_Spatiotemporal_3D_CVPR_2018_paper.html\">Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?</a></dt>\n<dd>\n<form id=\"form-KenshoHaraCanSpatiotemporal3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kensho Hara\">\n<a href=\"#\" onclick=\"document.getElementById('form-KenshoHaraCanSpatiotemporal3D').submit();\">Kensho Hara</a>,\n</form>\n<form id=\"form-HirokatsuKataokaCanSpatiotemporal3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hirokatsu Kataoka\">\n<a href=\"#\" onclick=\"document.getElementById('form-HirokatsuKataokaCanSpatiotemporal3D').submit();\">Hirokatsu Kataoka</a>,\n</form>\n<form id=\"form-YutakaSatohCanSpatiotemporal3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yutaka Satoh\">\n<a href=\"#\" onclick=\"document.getElementById('form-YutakaSatohCanSpatiotemporal3D').submit();\">Yutaka Satoh</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hara_Can_Spatiotemporal_3D_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hara_2018_CVPR,<br>\nauthor = {Hara, Kensho and Kataoka, Hirokatsu and Satoh, Yutaka},<br>\ntitle = {Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xu_Dynamic_Video_Segmentation_CVPR_2018_paper.html\">Dynamic Video Segmentation Network</a></dt>\n<dd>\n<form id=\"form-Yu-SyuanXuDynamicVideoSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu-Syuan Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yu-SyuanXuDynamicVideoSegmentation').submit();\">Yu-Syuan Xu</a>,\n</form>\n<form id=\"form-Tsu-JuiFuDynamicVideoSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tsu-Jui Fu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Tsu-JuiFuDynamicVideoSegmentation').submit();\">Tsu-Jui Fu</a>,\n</form>\n<form id=\"form-Hsuan-KungYangDynamicVideoSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hsuan-Kung Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Hsuan-KungYangDynamicVideoSegmentation').submit();\">Hsuan-Kung Yang</a>,\n</form>\n<form id=\"form-Chun-YiLeeDynamicVideoSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chun-Yi Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-Chun-YiLeeDynamicVideoSegmentation').submit();\">Chun-Yi Lee</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xu_Dynamic_Video_Segmentation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00931\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xu_2018_CVPR,<br>\nauthor = {Xu, Yu-Syuan and Fu, Tsu-Jui and Yang, Hsuan-Kung and Lee, Chun-Yi},<br>\ntitle = {Dynamic Video Segmentation Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhao_Recognize_Actions_by_CVPR_2018_paper.html\">Recognize Actions by Disentangling Components of Dynamics</a></dt>\n<dd>\n<form id=\"form-YueZhaoRecognizeActionsby\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yue Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-YueZhaoRecognizeActionsby').submit();\">Yue Zhao</a>,\n</form>\n<form id=\"form-YuanjunXiongRecognizeActionsby\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuanjun Xiong\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuanjunXiongRecognizeActionsby').submit();\">Yuanjun Xiong</a>,\n</form>\n<form id=\"form-DahuaLinRecognizeActionsby\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dahua Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-DahuaLinRecognizeActionsby').submit();\">Dahua Lin</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhao_Recognize_Actions_by_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1067-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhao_2018_CVPR,<br>\nauthor = {Zhao, Yue and Xiong, Yuanjun and Lin, Dahua},<br>\ntitle = {Recognize Actions by Disentangling Components of Dynamics},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Gao_Motion-Appearance_Co-Memory_Networks_CVPR_2018_paper.html\">Motion-Appearance Co-Memory Networks for Video Question Answering</a></dt>\n<dd>\n<form id=\"form-JiyangGaoMotionAppearanceCoMemoryNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiyang Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiyangGaoMotionAppearanceCoMemoryNetworks').submit();\">Jiyang Gao</a>,\n</form>\n<form id=\"form-RunzhouGeMotionAppearanceCoMemoryNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Runzhou Ge\">\n<a href=\"#\" onclick=\"document.getElementById('form-RunzhouGeMotionAppearanceCoMemoryNetworks').submit();\">Runzhou Ge</a>,\n</form>\n<form id=\"form-KanChenMotionAppearanceCoMemoryNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kan Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-KanChenMotionAppearanceCoMemoryNetworks').submit();\">Kan Chen</a>,\n</form>\n<form id=\"form-RamNevatiaMotionAppearanceCoMemoryNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ram Nevatia\">\n<a href=\"#\" onclick=\"document.getElementById('form-RamNevatiaMotionAppearanceCoMemoryNetworks').submit();\">Ram Nevatia</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Gao_Motion-Appearance_Co-Memory_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.10906\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Gao_2018_CVPR,<br>\nauthor = {Gao, Jiyang and Ge, Runzhou and Chen, Kan and Nevatia, Ram},<br>\ntitle = {Motion-Appearance Co-Memory Networks for Video Question Answering},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Learning_to_Understand_CVPR_2018_paper.html\">Learning to Understand Image Blur</a></dt>\n<dd>\n<form id=\"form-ShanghangZhangLearningtoUnderstand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shanghang Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShanghangZhangLearningtoUnderstand').submit();\">Shanghang Zhang</a>,\n</form>\n<form id=\"form-XiaohuiShenLearningtoUnderstand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaohui Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaohuiShenLearningtoUnderstand').submit();\">Xiaohui Shen</a>,\n</form>\n<form id=\"form-ZheLinLearningtoUnderstand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhe Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZheLinLearningtoUnderstand').submit();\">Zhe Lin</a>,\n</form>\n<form id=\"form-Radom\u00c3\u00adrM\u00c4\u009bchLearningtoUnderstand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Radom\u00c3\u00adr M\u00c4\u009bch\">\n<a href=\"#\" onclick=\"document.getElementById('form-Radom\u00c3\u00adrM\u00c4\u009bchLearningtoUnderstand').submit();\">Radom\u00c3\u00adr M\u00c4\u009bch</a>,\n</form>\n<form id=\"form-Jo\u00c3\u00a3oP.LearningtoUnderstand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jo\u00c3\u00a3o P. Costeira\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jo\u00c3\u00a3oP.LearningtoUnderstand').submit();\">Jo\u00c3\u00a3o P. Costeira</a>,\n</form>\n<form id=\"form-Jos\u00c3\u00a9M.LearningtoUnderstand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jos\u00c3\u00a9 M. F. Moura\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jos\u00c3\u00a9M.LearningtoUnderstand').submit();\">Jos\u00c3\u00a9 M. F. Moura</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Learning_to_Understand_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2302-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Shanghang and Shen, Xiaohui and Lin, Zhe and M\u00c4\u009bch, Radom\u00c3\u00adr and Costeira, Jo\u00c3\u00a3o P. and Moura, Jos\u00c3\u00a9 M. F.},<br>\ntitle = {Learning to Understand Image Blur},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Bilinski_Dense_Decoder_Shortcut_CVPR_2018_paper.html\">Dense Decoder Shortcut Connections for Single-Pass Semantic Segmentation</a></dt>\n<dd>\n<form id=\"form-PiotrBilinskiDenseDecoderShortcut\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Piotr Bilinski\">\n<a href=\"#\" onclick=\"document.getElementById('form-PiotrBilinskiDenseDecoderShortcut').submit();\">Piotr Bilinski</a>,\n</form>\n<form id=\"form-VictorPrisacariuDenseDecoderShortcut\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Victor Prisacariu\">\n<a href=\"#\" onclick=\"document.getElementById('form-VictorPrisacariuDenseDecoderShortcut').submit();\">Victor Prisacariu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Bilinski_Dense_Decoder_Shortcut_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Bilinski_2018_CVPR,<br>\nauthor = {Bilinski, Piotr and Prisacariu, Victor},<br>\ntitle = {Dense Decoder Shortcut Connections for Single-Pass Semantic Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kaneko_Generative_Adversarial_Image_CVPR_2018_paper.html\">Generative Adversarial Image Synthesis With Decision Tree Latent Controller</a></dt>\n<dd>\n<form id=\"form-TakuhiroKanekoGenerativeAdversarialImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Takuhiro Kaneko\">\n<a href=\"#\" onclick=\"document.getElementById('form-TakuhiroKanekoGenerativeAdversarialImage').submit();\">Takuhiro Kaneko</a>,\n</form>\n<form id=\"form-KaoruHiramatsuGenerativeAdversarialImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kaoru Hiramatsu\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaoruHiramatsuGenerativeAdversarialImage').submit();\">Kaoru Hiramatsu</a>,\n</form>\n<form id=\"form-KunioKashinoGenerativeAdversarialImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kunio Kashino\">\n<a href=\"#\" onclick=\"document.getElementById('form-KunioKashinoGenerativeAdversarialImage').submit();\">Kunio Kashino</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kaneko_Generative_Adversarial_Image_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3857-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.10603\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kaneko_2018_CVPR,<br>\nauthor = {Kaneko, Takuhiro and Hiramatsu, Kaoru and Kashino, Kunio},<br>\ntitle = {Generative Adversarial Image Synthesis With Decision Tree Latent Controller},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Learning_a_Discriminative_CVPR_2018_paper.html\">Learning a Discriminative Prior for Blind Image Deblurring</a></dt>\n<dd>\n<form id=\"form-LerenhanLiLearningaDiscriminative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lerenhan Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-LerenhanLiLearningaDiscriminative').submit();\">Lerenhan Li</a>,\n</form>\n<form id=\"form-JinshanPanLearningaDiscriminative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jinshan Pan\">\n<a href=\"#\" onclick=\"document.getElementById('form-JinshanPanLearningaDiscriminative').submit();\">Jinshan Pan</a>,\n</form>\n<form id=\"form-Wei-ShengLaiLearningaDiscriminative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei-Sheng Lai\">\n<a href=\"#\" onclick=\"document.getElementById('form-Wei-ShengLaiLearningaDiscriminative').submit();\">Wei-Sheng Lai</a>,\n</form>\n<form id=\"form-ChangxinGaoLearningaDiscriminative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Changxin Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChangxinGaoLearningaDiscriminative').submit();\">Changxin Gao</a>,\n</form>\n<form id=\"form-NongSangLearningaDiscriminative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nong Sang\">\n<a href=\"#\" onclick=\"document.getElementById('form-NongSangLearningaDiscriminative').submit();\">Nong Sang</a>,\n</form>\n<form id=\"form-Ming-HsuanYangLearningaDiscriminative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming-Hsuan Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ming-HsuanYangLearningaDiscriminative').submit();\">Ming-Hsuan Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Learning_a_Discriminative_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0097-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.03363\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Lerenhan and Pan, Jinshan and Lai, Wei-Sheng and Gao, Changxin and Sang, Nong and Yang, Ming-Hsuan},<br>\ntitle = {Learning a Discriminative Prior for Blind Image Deblurring},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sajjadi_Frame-Recurrent_Video_Super-Resolution_CVPR_2018_paper.html\">Frame-Recurrent Video Super-Resolution</a></dt>\n<dd>\n<form id=\"form-MehdiS.FrameRecurrentVideoSuperResolution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mehdi S. M. Sajjadi\">\n<a href=\"#\" onclick=\"document.getElementById('form-MehdiS.FrameRecurrentVideoSuperResolution').submit();\">Mehdi S. M. Sajjadi</a>,\n</form>\n<form id=\"form-RavitejaVemulapalliFrameRecurrentVideoSuperResolution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Raviteja Vemulapalli\">\n<a href=\"#\" onclick=\"document.getElementById('form-RavitejaVemulapalliFrameRecurrentVideoSuperResolution').submit();\">Raviteja Vemulapalli</a>,\n</form>\n<form id=\"form-MatthewBrownFrameRecurrentVideoSuperResolution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Matthew Brown\">\n<a href=\"#\" onclick=\"document.getElementById('form-MatthewBrownFrameRecurrentVideoSuperResolution').submit();\">Matthew Brown</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sajjadi_Frame-Recurrent_Video_Super-Resolution_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.04590\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sajjadi_2018_CVPR,<br>\nauthor = {Sajjadi, Mehdi S. M. and Vemulapalli, Raviteja and Brown, Matthew},<br>\ntitle = {Frame-Recurrent Video Super-Resolution},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Discovering_Point_Lights_CVPR_2018_paper.html\">Discovering Point Lights With Intensity Distance Fields</a></dt>\n<dd>\n<form id=\"form-EdwardZhangDiscoveringPointLights\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Edward Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-EdwardZhangDiscoveringPointLights').submit();\">Edward Zhang</a>,\n</form>\n<form id=\"form-MichaelF.DiscoveringPointLights\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michael F. Cohen\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichaelF.DiscoveringPointLights').submit();\">Michael F. Cohen</a>,\n</form>\n<form id=\"form-BrianCurlessDiscoveringPointLights\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Brian Curless\">\n<a href=\"#\" onclick=\"document.getElementById('form-BrianCurlessDiscoveringPointLights').submit();\">Brian Curless</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Discovering_Point_Lights_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0510-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Edward and Cohen, Michael F. and Curless, Brian},<br>\ntitle = {Discovering Point Lights With Intensity Distance Fields},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Video_Rain_Streak_CVPR_2018_paper.html\">Video Rain Streak Removal by Multiscale Convolutional Sparse Coding</a></dt>\n<dd>\n<form id=\"form-MinghanLiVideoRainStreak\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Minghan Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-MinghanLiVideoRainStreak').submit();\">Minghan Li</a>,\n</form>\n<form id=\"form-QiXieVideoRainStreak\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qi Xie\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiXieVideoRainStreak').submit();\">Qi Xie</a>,\n</form>\n<form id=\"form-QianZhaoVideoRainStreak\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qian Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-QianZhaoVideoRainStreak').submit();\">Qian Zhao</a>,\n</form>\n<form id=\"form-WeiWeiVideoRainStreak\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Wei\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiWeiVideoRainStreak').submit();\">Wei Wei</a>,\n</form>\n<form id=\"form-ShuhangGuVideoRainStreak\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuhang Gu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuhangGuVideoRainStreak').submit();\">Shuhang Gu</a>,\n</form>\n<form id=\"form-JingTaoVideoRainStreak\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jing Tao\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingTaoVideoRainStreak').submit();\">Jing Tao</a>,\n</form>\n<form id=\"form-DeyuMengVideoRainStreak\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Deyu Meng\">\n<a href=\"#\" onclick=\"document.getElementById('form-DeyuMengVideoRainStreak').submit();\">Deyu Meng</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Video_Rain_Streak_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Minghan and Xie, Qi and Zhao, Qian and Wei, Wei and Gu, Shuhang and Tao, Jing and Meng, Deyu},<br>\ntitle = {Video Rain Streak Removal by Multiscale Convolutional Sparse Coding},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_Stereoscopic_Neural_Style_CVPR_2018_paper.html\">Stereoscopic Neural Style Transfer</a></dt>\n<dd>\n<form id=\"form-DongdongChenStereoscopicNeuralStyle\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dongdong Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-DongdongChenStereoscopicNeuralStyle').submit();\">Dongdong Chen</a>,\n</form>\n<form id=\"form-LuYuanStereoscopicNeuralStyle\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lu Yuan\">\n<a href=\"#\" onclick=\"document.getElementById('form-LuYuanStereoscopicNeuralStyle').submit();\">Lu Yuan</a>,\n</form>\n<form id=\"form-JingLiaoStereoscopicNeuralStyle\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jing Liao\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingLiaoStereoscopicNeuralStyle').submit();\">Jing Liao</a>,\n</form>\n<form id=\"form-NenghaiYuStereoscopicNeuralStyle\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nenghai Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-NenghaiYuStereoscopicNeuralStyle').submit();\">Nenghai Yu</a>,\n</form>\n<form id=\"form-GangHuaStereoscopicNeuralStyle\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gang Hua\">\n<a href=\"#\" onclick=\"document.getElementById('form-GangHuaStereoscopicNeuralStyle').submit();\">Gang Hua</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_Stereoscopic_Neural_Style_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.10591\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Dongdong and Yuan, Lu and Liao, Jing and Yu, Nenghai and Hua, Gang},<br>\ntitle = {Stereoscopic Neural Style Transfer},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yang_Multi-Frame_Quality_Enhancement_CVPR_2018_paper.html\">Multi-Frame Quality Enhancement for Compressed Video</a></dt>\n<dd>\n<form id=\"form-RenYangMultiFrameQualityEnhancement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ren Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-RenYangMultiFrameQualityEnhancement').submit();\">Ren Yang</a>,\n</form>\n<form id=\"form-MaiXuMultiFrameQualityEnhancement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mai Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-MaiXuMultiFrameQualityEnhancement').submit();\">Mai Xu</a>,\n</form>\n<form id=\"form-ZulinWangMultiFrameQualityEnhancement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zulin Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZulinWangMultiFrameQualityEnhancement').submit();\">Zulin Wang</a>,\n</form>\n<form id=\"form-TianyiLiMultiFrameQualityEnhancement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tianyi Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-TianyiLiMultiFrameQualityEnhancement').submit();\">Tianyi Li</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yang_Multi-Frame_Quality_Enhancement_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.04680\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yang_2018_CVPR,<br>\nauthor = {Yang, Ren and Xu, Mai and Wang, Zulin and Li, Tianyi},<br>\ntitle = {Multi-Frame Quality Enhancement for Compressed Video},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Baslamisli_CNN_Based_Learning_CVPR_2018_paper.html\">CNN Based Learning Using Reflection and Retinex Models for Intrinsic Image Decomposition</a></dt>\n<dd>\n<form id=\"form-AnilS.CNNBasedLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anil S. Baslamisli\">\n<a href=\"#\" onclick=\"document.getElementById('form-AnilS.CNNBasedLearning').submit();\">Anil S. Baslamisli</a>,\n</form>\n<form id=\"form-Hoang-AnLeCNNBasedLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hoang-An Le\">\n<a href=\"#\" onclick=\"document.getElementById('form-Hoang-AnLeCNNBasedLearning').submit();\">Hoang-An Le</a>,\n</form>\n<form id=\"form-TheoGeversCNNBasedLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Theo Gevers\">\n<a href=\"#\" onclick=\"document.getElementById('form-TheoGeversCNNBasedLearning').submit();\">Theo Gevers</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Baslamisli_CNN_Based_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.01056\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Baslamisli_2018_CVPR,<br>\nauthor = {Baslamisli, Anil S. and Le, Hoang-An and Gevers, Theo},<br>\ntitle = {CNN Based Learning Using Reflection and Retinex Models for Intrinsic Image Decomposition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yoo_Image_Restoration_by_CVPR_2018_paper.html\">Image Restoration by Estimating Frequency Distribution of Local Patches</a></dt>\n<dd>\n<form id=\"form-JaeyoungYooImageRestorationby\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jaeyoung Yoo\">\n<a href=\"#\" onclick=\"document.getElementById('form-JaeyoungYooImageRestorationby').submit();\">Jaeyoung Yoo</a>,\n</form>\n<form id=\"form-Sang-hoLeeImageRestorationby\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sang-ho Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-Sang-hoLeeImageRestorationby').submit();\">Sang-ho Lee</a>,\n</form>\n<form id=\"form-NojunKwakImageRestorationby\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nojun Kwak\">\n<a href=\"#\" onclick=\"document.getElementById('form-NojunKwakImageRestorationby').submit();\">Nojun Kwak</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yoo_Image_Restoration_by_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2914-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.09097\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yoo_2018_CVPR,<br>\nauthor = {Yoo, Jaeyoung and Lee, Sang-ho and Kwak, Nojun},<br>\ntitle = {Image Restoration by Estimating Frequency Distribution of Local Patches},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Korman_Latent_RANSAC_CVPR_2018_paper.html\">Latent RANSAC</a></dt>\n<dd>\n<form id=\"form-SimonKormanLatentRANSAC\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Simon Korman\">\n<a href=\"#\" onclick=\"document.getElementById('form-SimonKormanLatentRANSAC').submit();\">Simon Korman</a>,\n</form>\n<form id=\"form-RoeeLitmanLatentRANSAC\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Roee Litman\">\n<a href=\"#\" onclick=\"document.getElementById('form-RoeeLitmanLatentRANSAC').submit();\">Roee Litman</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Korman_Latent_RANSAC_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.07045\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Korman_2018_CVPR,<br>\nauthor = {Korman, Simon and Litman, Roee},<br>\ntitle = {Latent RANSAC},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tesfaldet_Two-Stream_Convolutional_Networks_CVPR_2018_paper.html\">Two-Stream Convolutional Networks for Dynamic Texture Synthesis</a></dt>\n<dd>\n<form id=\"form-MatthewTesfaldetTwoStreamConvolutionalNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Matthew Tesfaldet\">\n<a href=\"#\" onclick=\"document.getElementById('form-MatthewTesfaldetTwoStreamConvolutionalNetworks').submit();\">Matthew Tesfaldet</a>,\n</form>\n<form id=\"form-MarcusA.TwoStreamConvolutionalNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Marcus A. Brubaker\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarcusA.TwoStreamConvolutionalNetworks').submit();\">Marcus A. Brubaker</a>,\n</form>\n<form id=\"form-KonstantinosG.TwoStreamConvolutionalNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Konstantinos G. Derpanis\">\n<a href=\"#\" onclick=\"document.getElementById('form-KonstantinosG.TwoStreamConvolutionalNetworks').submit();\">Konstantinos G. Derpanis</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tesfaldet_Two-Stream_Convolutional_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3805-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1706.06982\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tesfaldet_2018_CVPR,<br>\nauthor = {Tesfaldet, Matthew and Brubaker, Marcus A. and Derpanis, Konstantinos G.},<br>\ntitle = {Two-Stream Convolutional Networks for Dynamic Texture Synthesis},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Bao_Towards_Open-Set_Identity_CVPR_2018_paper.html\">Towards Open-Set Identity Preserving Face Synthesis</a></dt>\n<dd>\n<form id=\"form-JianminBaoTowardsOpenSetIdentity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianmin Bao\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianminBaoTowardsOpenSetIdentity').submit();\">Jianmin Bao</a>,\n</form>\n<form id=\"form-DongChenTowardsOpenSetIdentity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dong Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-DongChenTowardsOpenSetIdentity').submit();\">Dong Chen</a>,\n</form>\n<form id=\"form-FangWenTowardsOpenSetIdentity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fang Wen\">\n<a href=\"#\" onclick=\"document.getElementById('form-FangWenTowardsOpenSetIdentity').submit();\">Fang Wen</a>,\n</form>\n<form id=\"form-HouqiangLiTowardsOpenSetIdentity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Houqiang Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-HouqiangLiTowardsOpenSetIdentity').submit();\">Houqiang Li</a>,\n</form>\n<form id=\"form-GangHuaTowardsOpenSetIdentity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gang Hua\">\n<a href=\"#\" onclick=\"document.getElementById('form-GangHuaTowardsOpenSetIdentity').submit();\">Gang Hua</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Bao_Towards_Open-Set_Identity_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.11182\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Bao_2018_CVPR,<br>\nauthor = {Bao, Jianmin and Chen, Dong and Wen, Fang and Li, Houqiang and Hua, Gang},<br>\ntitle = {Towards Open-Set Identity Preserving Face Synthesis},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Akkaynak_A_Revised_Underwater_CVPR_2018_paper.html\">A Revised Underwater Image Formation Model</a></dt>\n<dd>\n<form id=\"form-DeryaAkkaynakARevisedUnderwater\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Derya Akkaynak\">\n<a href=\"#\" onclick=\"document.getElementById('form-DeryaAkkaynakARevisedUnderwater').submit();\">Derya Akkaynak</a>,\n</form>\n<form id=\"form-TaliTreibitzARevisedUnderwater\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tali Treibitz\">\n<a href=\"#\" onclick=\"document.getElementById('form-TaliTreibitzARevisedUnderwater').submit();\">Tali Treibitz</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Akkaynak_A_Revised_Underwater_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0068-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Akkaynak_2018_CVPR,<br>\nauthor = {Akkaynak, Derya and Treibitz, Tali},<br>\ntitle = {A Revised Underwater Image Formation Model},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Barath_Graph-Cut_RANSAC_CVPR_2018_paper.html\">Graph-Cut RANSAC</a></dt>\n<dd>\n<form id=\"form-DanielBarathGraphCutRANSAC\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daniel Barath\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanielBarathGraphCutRANSAC').submit();\">Daniel Barath</a>,\n</form>\n<form id=\"form-Ji\u00c5\u0099\u00c3\u00adMatasGraphCutRANSAC\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ji\u00c5\u0099\u00c3\u00ad Matas\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ji\u00c5\u0099\u00c3\u00adMatasGraphCutRANSAC').submit();\">Ji\u00c5\u0099\u00c3\u00ad Matas</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Barath_Graph-Cut_RANSAC_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1706.00984\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Barath_2018_CVPR,<br>\nauthor = {Barath, Daniel and Matas, Ji\u00c5\u0099\u00c3\u00ad},<br>\ntitle = {Graph-Cut RANSAC},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lei_Temporal_Deformable_Residual_CVPR_2018_paper.html\">Temporal Deformable Residual Networks for Action Segmentation in Videos</a></dt>\n<dd>\n<form id=\"form-PengLeiTemporalDeformableResidual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peng Lei\">\n<a href=\"#\" onclick=\"document.getElementById('form-PengLeiTemporalDeformableResidual').submit();\">Peng Lei</a>,\n</form>\n<form id=\"form-SinisaTodorovicTemporalDeformableResidual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sinisa Todorovic\">\n<a href=\"#\" onclick=\"document.getElementById('form-SinisaTodorovicTemporalDeformableResidual').submit();\">Sinisa Todorovic</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lei_Temporal_Deformable_Residual_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lei_2018_CVPR,<br>\nauthor = {Lei, Peng and Todorovic, Sinisa},<br>\ntitle = {Temporal Deformable Residual Networks for Action Segmentation in Videos},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Nguyen_Weakly_Supervised_Action_CVPR_2018_paper.html\">Weakly Supervised Action Localization by Sparse Temporal Pooling Network</a></dt>\n<dd>\n<form id=\"form-PhucNguyenWeaklySupervisedAction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Phuc Nguyen\">\n<a href=\"#\" onclick=\"document.getElementById('form-PhucNguyenWeaklySupervisedAction').submit();\">Phuc Nguyen</a>,\n</form>\n<form id=\"form-TingLiuWeaklySupervisedAction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ting Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-TingLiuWeaklySupervisedAction').submit();\">Ting Liu</a>,\n</form>\n<form id=\"form-GautamPrasadWeaklySupervisedAction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gautam Prasad\">\n<a href=\"#\" onclick=\"document.getElementById('form-GautamPrasadWeaklySupervisedAction').submit();\">Gautam Prasad</a>,\n</form>\n<form id=\"form-BohyungHanWeaklySupervisedAction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bohyung Han\">\n<a href=\"#\" onclick=\"document.getElementById('form-BohyungHanWeaklySupervisedAction').submit();\">Bohyung Han</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Nguyen_Weakly_Supervised_Action_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2013-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.05080\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Nguyen_2018_CVPR,<br>\nauthor = {Nguyen, Phuc and Liu, Ting and Prasad, Gautam and Han, Bohyung},<br>\ntitle = {Weakly Supervised Action Localization by Sparse Temporal Pooling Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_PoseFlow_A_Deep_CVPR_2018_paper.html\">PoseFlow: A Deep Motion Representation for Understanding Human Behaviors in Videos</a></dt>\n<dd>\n<form id=\"form-DingwenZhangPoseFlowADeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dingwen Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-DingwenZhangPoseFlowADeep').submit();\">Dingwen Zhang</a>,\n</form>\n<form id=\"form-GuangyuGuoPoseFlowADeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guangyu Guo\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuangyuGuoPoseFlowADeep').submit();\">Guangyu Guo</a>,\n</form>\n<form id=\"form-DongHuangPoseFlowADeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dong Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-DongHuangPoseFlowADeep').submit();\">Dong Huang</a>,\n</form>\n<form id=\"form-JunweiHanPoseFlowADeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junwei Han\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunweiHanPoseFlowADeep').submit();\">Junwei Han</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_PoseFlow_A_Deep_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Dingwen and Guo, Guangyu and Huang, Dong and Han, Junwei},<br>\ntitle = {PoseFlow: A Deep Motion Representation for Understanding Human Behaviors in Videos},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lan_FFNet_Video_Fast-Forwarding_CVPR_2018_paper.html\">FFNet: Video Fast-Forwarding via Reinforcement Learning</a></dt>\n<dd>\n<form id=\"form-ShuyueLanFFNetVideoFastForwarding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuyue Lan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuyueLanFFNetVideoFastForwarding').submit();\">Shuyue Lan</a>,\n</form>\n<form id=\"form-RameswarPandaFFNetVideoFastForwarding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rameswar Panda\">\n<a href=\"#\" onclick=\"document.getElementById('form-RameswarPandaFFNetVideoFastForwarding').submit();\">Rameswar Panda</a>,\n</form>\n<form id=\"form-QiZhuFFNetVideoFastForwarding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qi Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiZhuFFNetVideoFastForwarding').submit();\">Qi Zhu</a>,\n</form>\n<form id=\"form-AmitK.FFNetVideoFastForwarding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Amit K. Roy-Chowdhury\">\n<a href=\"#\" onclick=\"document.getElementById('form-AmitK.FFNetVideoFastForwarding').submit();\">Amit K. Roy-Chowdhury</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lan_FFNet_Video_Fast-Forwarding_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3494-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.02792\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lan_2018_CVPR,<br>\nauthor = {Lan, Shuyue and Panda, Rameswar and Zhu, Qi and Roy-Chowdhury, Amit K.},<br>\ntitle = {FFNet: Video Fast-Forwarding via Reinforcement Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Multi-Shot_Pedestrian_Re-Identification_CVPR_2018_paper.html\">Multi-Shot Pedestrian Re-Identification via Sequential Decision Making</a></dt>\n<dd>\n<form id=\"form-JianfuZhangMultiShotPedestrianReIdentification\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianfu Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianfuZhangMultiShotPedestrianReIdentification').submit();\">Jianfu Zhang</a>,\n</form>\n<form id=\"form-NaiyanWangMultiShotPedestrianReIdentification\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Naiyan Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-NaiyanWangMultiShotPedestrianReIdentification').submit();\">Naiyan Wang</a>,\n</form>\n<form id=\"form-LiqingZhangMultiShotPedestrianReIdentification\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liqing Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiqingZhangMultiShotPedestrianReIdentification').submit();\">Liqing Zhang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Multi-Shot_Pedestrian_Re-Identification_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.07257\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Jianfu and Wang, Naiyan and Zhang, Liqing},<br>\ntitle = {Multi-Shot Pedestrian Re-Identification via Sequential Decision Making},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ma_Attend_and_Interact_CVPR_2018_paper.html\">Attend and Interact: Higher-Order Object Interactions for Video Understanding</a></dt>\n<dd>\n<form id=\"form-Chih-YaoMaAttendandInteract\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chih-Yao Ma\">\n<a href=\"#\" onclick=\"document.getElementById('form-Chih-YaoMaAttendandInteract').submit();\">Chih-Yao Ma</a>,\n</form>\n<form id=\"form-AsimKadavAttendandInteract\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Asim Kadav\">\n<a href=\"#\" onclick=\"document.getElementById('form-AsimKadavAttendandInteract').submit();\">Asim Kadav</a>,\n</form>\n<form id=\"form-IainMelvinAttendandInteract\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Iain Melvin\">\n<a href=\"#\" onclick=\"document.getElementById('form-IainMelvinAttendandInteract').submit();\">Iain Melvin</a>,\n</form>\n<form id=\"form-ZsoltKiraAttendandInteract\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zsolt Kira\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZsoltKiraAttendandInteract').submit();\">Zsolt Kira</a>,\n</form>\n<form id=\"form-GhassanAlRegibAttendandInteract\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ghassan AlRegib\">\n<a href=\"#\" onclick=\"document.getElementById('form-GhassanAlRegibAttendandInteract').submit();\">Ghassan AlRegib</a>,\n</form>\n<form id=\"form-HansPeterAttendandInteract\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hans Peter Graf\">\n<a href=\"#\" onclick=\"document.getElementById('form-HansPeterAttendandInteract').submit();\">Hans Peter Graf</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ma_Attend_and_Interact_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0330-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.06330\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ma_2018_CVPR,<br>\nauthor = {Ma, Chih-Yao and Kadav, Asim and Melvin, Iain and Kira, Zsolt and AlRegib, Ghassan and Peter Graf, Hans},<br>\ntitle = {Attend and Interact: Higher-Order Object Interactions for Video Understanding},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wei_Where_and_Why_CVPR_2018_paper.html\">Where and Why Are They Looking? Jointly Inferring Human Attention and Intentions in Complex Tasks</a></dt>\n<dd>\n<form id=\"form-PingWeiWhereandWhy\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ping Wei\">\n<a href=\"#\" onclick=\"document.getElementById('form-PingWeiWhereandWhy').submit();\">Ping Wei</a>,\n</form>\n<form id=\"form-YangLiuWhereandWhy\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yang Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YangLiuWhereandWhy').submit();\">Yang Liu</a>,\n</form>\n<form id=\"form-TianminShuWhereandWhy\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tianmin Shu\">\n<a href=\"#\" onclick=\"document.getElementById('form-TianminShuWhereandWhy').submit();\">Tianmin Shu</a>,\n</form>\n<form id=\"form-NanningZhengWhereandWhy\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nanning Zheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-NanningZhengWhereandWhy').submit();\">Nanning Zheng</a>,\n</form>\n<form id=\"form-Song-ChunZhuWhereandWhy\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Song-Chun Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Song-ChunZhuWhereandWhy').submit();\">Song-Chun Zhu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wei_Where_and_Why_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wei_2018_CVPR,<br>\nauthor = {Wei, Ping and Liu, Yang and Shu, Tianmin and Zheng, Nanning and Zhu, Song-Chun},<br>\ntitle = {Where and Why Are They Looking? Jointly Inferring Human Attention and Intentions in Complex Tasks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Fully_Convolutional_Adaptation_CVPR_2018_paper.html\">Fully Convolutional Adaptation Networks for Semantic Segmentation</a></dt>\n<dd>\n<form id=\"form-YihengZhangFullyConvolutionalAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yiheng Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YihengZhangFullyConvolutionalAdaptation').submit();\">Yiheng Zhang</a>,\n</form>\n<form id=\"form-ZhaofanQiuFullyConvolutionalAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhaofan Qiu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhaofanQiuFullyConvolutionalAdaptation').submit();\">Zhaofan Qiu</a>,\n</form>\n<form id=\"form-TingYaoFullyConvolutionalAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ting Yao\">\n<a href=\"#\" onclick=\"document.getElementById('form-TingYaoFullyConvolutionalAdaptation').submit();\">Ting Yao</a>,\n</form>\n<form id=\"form-DongLiuFullyConvolutionalAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dong Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-DongLiuFullyConvolutionalAdaptation').submit();\">Dong Liu</a>,\n</form>\n<form id=\"form-TaoMeiFullyConvolutionalAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tao Mei\">\n<a href=\"#\" onclick=\"document.getElementById('form-TaoMeiFullyConvolutionalAdaptation').submit();\">Tao Mei</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Fully_Convolutional_Adaptation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.08286\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Yiheng and Qiu, Zhaofan and Yao, Ting and Liu, Dong and Mei, Tao},<br>\ntitle = {Fully Convolutional Adaptation Networks for Semantic Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Nilsson_Semantic_Video_Segmentation_CVPR_2018_paper.html\">Semantic Video Segmentation by Gated Recurrent Flow Propagation</a></dt>\n<dd>\n<form id=\"form-DavidNilssonSemanticVideoSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"David Nilsson\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavidNilssonSemanticVideoSegmentation').submit();\">David Nilsson</a>,\n</form>\n<form id=\"form-CristianSminchisescuSemanticVideoSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cristian Sminchisescu\">\n<a href=\"#\" onclick=\"document.getElementById('form-CristianSminchisescuSemanticVideoSegmentation').submit();\">Cristian Sminchisescu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Nilsson_Semantic_Video_Segmentation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2131-supp.zip\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1612.08871\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Nilsson_2018_CVPR,<br>\nauthor = {Nilsson, David and Sminchisescu, Cristian},<br>\ntitle = {Semantic Video Segmentation by Gated Recurrent Flow Propagation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wu_Interpretable_Video_Captioning_CVPR_2018_paper.html\">Interpretable Video Captioning via Trajectory Structured Localization</a></dt>\n<dd>\n<form id=\"form-XianWuInterpretableVideoCaptioning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xian Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XianWuInterpretableVideoCaptioning').submit();\">Xian Wu</a>,\n</form>\n<form id=\"form-GuanbinLiInterpretableVideoCaptioning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guanbin Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuanbinLiInterpretableVideoCaptioning').submit();\">Guanbin Li</a>,\n</form>\n<form id=\"form-QingxingCaoInterpretableVideoCaptioning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qingxing Cao\">\n<a href=\"#\" onclick=\"document.getElementById('form-QingxingCaoInterpretableVideoCaptioning').submit();\">Qingxing Cao</a>,\n</form>\n<form id=\"form-QinggeJiInterpretableVideoCaptioning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qingge Ji\">\n<a href=\"#\" onclick=\"document.getElementById('form-QinggeJiInterpretableVideoCaptioning').submit();\">Qingge Ji</a>,\n</form>\n<form id=\"form-LiangLinInterpretableVideoCaptioning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liang Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiangLinInterpretableVideoCaptioning').submit();\">Liang Lin</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wu_Interpretable_Video_Captioning_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wu_2018_CVPR,<br>\nauthor = {Wu, Xian and Li, Guanbin and Cao, Qingxing and Ji, Qingge and Lin, Liang},<br>\ntitle = {Interpretable Video Captioning via Trajectory Structured Localization},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_Deep_Hashing_via_CVPR_2018_paper.html\">Deep Hashing via Discrepancy Minimization</a></dt>\n<dd>\n<form id=\"form-ZhixiangChenDeepHashingvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhixiang Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhixiangChenDeepHashingvia').submit();\">Zhixiang Chen</a>,\n</form>\n<form id=\"form-XinYuanDeepHashingvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xin Yuan\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinYuanDeepHashingvia').submit();\">Xin Yuan</a>,\n</form>\n<form id=\"form-JiwenLuDeepHashingvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiwen Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiwenLuDeepHashingvia').submit();\">Jiwen Lu</a>,\n</form>\n<form id=\"form-QiTianDeepHashingvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qi Tian\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiTianDeepHashingvia').submit();\">Qi Tian</a>,\n</form>\n<form id=\"form-JieZhouDeepHashingvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jie Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-JieZhouDeepHashingvia').submit();\">Jie Zhou</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_Deep_Hashing_via_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Zhixiang and Yuan, Xin and Lu, Jiwen and Tian, Qi and Zhou, Jie},<br>\ntitle = {Deep Hashing via Discrepancy Minimization},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_ShuffleNet_An_Extremely_CVPR_2018_paper.html\">ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices</a></dt>\n<dd>\n<form id=\"form-XiangyuZhangShuffleNetAnExtremely\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiangyu Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiangyuZhangShuffleNetAnExtremely').submit();\">Xiangyu Zhang</a>,\n</form>\n<form id=\"form-XinyuZhouShuffleNetAnExtremely\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xinyu Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinyuZhouShuffleNetAnExtremely').submit();\">Xinyu Zhou</a>,\n</form>\n<form id=\"form-MengxiaoLinShuffleNetAnExtremely\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mengxiao Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-MengxiaoLinShuffleNetAnExtremely').submit();\">Mengxiao Lin</a>,\n</form>\n<form id=\"form-JianSunShuffleNetAnExtremely\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jian Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianSunShuffleNetAnExtremely').submit();\">Jian Sun</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_ShuffleNet_An_Extremely_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1707.01083\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and Sun, Jian},<br>\ntitle = {ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Zero-Shot_Recognition_via_CVPR_2018_paper.html\">Zero-Shot Recognition via Semantic Embeddings and Knowledge Graphs</a></dt>\n<dd>\n<form id=\"form-XiaolongWangZeroShotRecognitionvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaolong Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaolongWangZeroShotRecognitionvia').submit();\">Xiaolong Wang</a>,\n</form>\n<form id=\"form-YufeiYeZeroShotRecognitionvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yufei Ye\">\n<a href=\"#\" onclick=\"document.getElementById('form-YufeiYeZeroShotRecognitionvia').submit();\">Yufei Ye</a>,\n</form>\n<form id=\"form-AbhinavGuptaZeroShotRecognitionvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Abhinav Gupta\">\n<a href=\"#\" onclick=\"document.getElementById('form-AbhinavGuptaZeroShotRecognitionvia').submit();\">Abhinav Gupta</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Zero-Shot_Recognition_via_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.08035\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Xiaolong and Ye, Yufei and Gupta, Abhinav},<br>\ntitle = {Zero-Shot Recognition via Semantic Embeddings and Knowledge Graphs},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Krishna_Referring_Relationships_CVPR_2018_paper.html\">Referring Relationships</a></dt>\n<dd>\n<form id=\"form-RanjayKrishnaReferringRelationships\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ranjay Krishna\">\n<a href=\"#\" onclick=\"document.getElementById('form-RanjayKrishnaReferringRelationships').submit();\">Ranjay Krishna</a>,\n</form>\n<form id=\"form-InesChamiReferringRelationships\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ines Chami\">\n<a href=\"#\" onclick=\"document.getElementById('form-InesChamiReferringRelationships').submit();\">Ines Chami</a>,\n</form>\n<form id=\"form-MichaelBernsteinReferringRelationships\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michael Bernstein\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichaelBernsteinReferringRelationships').submit();\">Michael Bernstein</a>,\n</form>\n<form id=\"form-LiFei-FeiReferringRelationships\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Li Fei-Fei\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiFei-FeiReferringRelationships').submit();\">Li Fei-Fei</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Krishna_Referring_Relationships_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0792-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.10362\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Krishna_2018_CVPR,<br>\nauthor = {Krishna, Ranjay and Chami, Ines and Bernstein, Michael and Fei-Fei, Li},<br>\ntitle = {Referring Relationships},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tychsen-Smith_Improving_Object_Localization_CVPR_2018_paper.html\">Improving Object Localization With Fitness NMS and Bounded IoU Loss</a></dt>\n<dd>\n<form id=\"form-LachlanTychsen-SmithImprovingObjectLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lachlan Tychsen-Smith\">\n<a href=\"#\" onclick=\"document.getElementById('form-LachlanTychsen-SmithImprovingObjectLocalization').submit();\">Lachlan Tychsen-Smith</a>,\n</form>\n<form id=\"form-LarsPeterssonImprovingObjectLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lars Petersson\">\n<a href=\"#\" onclick=\"document.getElementById('form-LarsPeterssonImprovingObjectLocalization').submit();\">Lars Petersson</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tychsen-Smith_Improving_Object_Localization_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.00164\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tychsen-Smith_2018_CVPR,<br>\nauthor = {Tychsen-Smith, Lachlan and Petersson, Lars},<br>\ntitle = {Improving Object Localization With Fitness NMS and Bounded IoU Loss},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Shen_End-to-End_Deep_Kronecker-Product_CVPR_2018_paper.html\">End-to-End Deep Kronecker-Product Matching for Person Re-Identification</a></dt>\n<dd>\n<form id=\"form-YantaoShenEndtoEndDeepKroneckerProduct\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yantao Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-YantaoShenEndtoEndDeepKroneckerProduct').submit();\">Yantao Shen</a>,\n</form>\n<form id=\"form-TongXiaoEndtoEndDeepKroneckerProduct\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tong Xiao\">\n<a href=\"#\" onclick=\"document.getElementById('form-TongXiaoEndtoEndDeepKroneckerProduct').submit();\">Tong Xiao</a>,\n</form>\n<form id=\"form-HongshengLiEndtoEndDeepKroneckerProduct\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hongsheng Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-HongshengLiEndtoEndDeepKroneckerProduct').submit();\">Hongsheng Li</a>,\n</form>\n<form id=\"form-ShuaiYiEndtoEndDeepKroneckerProduct\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuai Yi\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuaiYiEndtoEndDeepKroneckerProduct').submit();\">Shuai Yi</a>,\n</form>\n<form id=\"form-XiaogangWangEndtoEndDeepKroneckerProduct\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaogang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaogangWangEndtoEndDeepKroneckerProduct').submit();\">Xiaogang Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Shen_End-to-End_Deep_Kronecker-Product_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1807.11182\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Shen_2018_CVPR,<br>\nauthor = {Shen, Yantao and Xiao, Tong and Li, Hongsheng and Yi, Shuai and Wang, Xiaogang},<br>\ntitle = {End-to-End Deep Kronecker-Product Matching for Person Re-Identification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Schonberger_Semantic_Visual_Localization_CVPR_2018_paper.html\">Semantic Visual Localization</a></dt>\n<dd>\n<form id=\"form-JohannesL.SemanticVisualLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Johannes L. Sch\u00c3\u00b6nberger\">\n<a href=\"#\" onclick=\"document.getElementById('form-JohannesL.SemanticVisualLocalization').submit();\">Johannes L. Sch\u00c3\u00b6nberger</a>,\n</form>\n<form id=\"form-MarcPollefeysSemanticVisualLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Marc Pollefeys\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarcPollefeysSemanticVisualLocalization').submit();\">Marc Pollefeys</a>,\n</form>\n<form id=\"form-AndreasGeigerSemanticVisualLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andreas Geiger\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndreasGeigerSemanticVisualLocalization').submit();\">Andreas Geiger</a>,\n</form>\n<form id=\"form-TorstenSattlerSemanticVisualLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Torsten Sattler\">\n<a href=\"#\" onclick=\"document.getElementById('form-TorstenSattlerSemanticVisualLocalization').submit();\">Torsten Sattler</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Schonberger_Semantic_Visual_Localization_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0849-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.08366\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sch\u00c3\u00b6nberger_2018_CVPR,<br>\nauthor = {Sch\u00c3\u00b6nberger, Johannes L. and Pollefeys, Marc and Geiger, Andreas and Sattler, Torsten},<br>\ntitle = {Semantic Visual Localization},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Gonzalez-Garcia_Objects_as_Context_CVPR_2018_paper.html\">Objects as Context for Detecting Their Semantic Parts</a></dt>\n<dd>\n<form id=\"form-AbelGonzalez-GarciaObjectsasContext\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Abel Gonzalez-Garcia\">\n<a href=\"#\" onclick=\"document.getElementById('form-AbelGonzalez-GarciaObjectsasContext').submit();\">Abel Gonzalez-Garcia</a>,\n</form>\n<form id=\"form-DavideModoloObjectsasContext\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Davide Modolo\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavideModoloObjectsasContext').submit();\">Davide Modolo</a>,\n</form>\n<form id=\"form-VittorioFerrariObjectsasContext\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vittorio Ferrari\">\n<a href=\"#\" onclick=\"document.getElementById('form-VittorioFerrariObjectsasContext').submit();\">Vittorio Ferrari</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Gonzalez-Garcia_Objects_as_Context_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1703.09529\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Gonzalez-Garcia_2018_CVPR,<br>\nauthor = {Gonzalez-Garcia, Abel and Modolo, Davide and Ferrari, Vittorio},<br>\ntitle = {Objects as Context for Detecting Their Semantic Parts},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Rocco_End-to-End_Weakly-Supervised_Semantic_CVPR_2018_paper.html\">End-to-End Weakly-Supervised Semantic Alignment</a></dt>\n<dd>\n<form id=\"form-IgnacioRoccoEndtoEndWeaklySupervisedSemantic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ignacio Rocco\">\n<a href=\"#\" onclick=\"document.getElementById('form-IgnacioRoccoEndtoEndWeaklySupervisedSemantic').submit();\">Ignacio Rocco</a>,\n</form>\n<form id=\"form-ReljaArandjelovi\u00c4\u0087EndtoEndWeaklySupervisedSemantic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Relja Arandjelovi\u00c4\u0087\">\n<a href=\"#\" onclick=\"document.getElementById('form-ReljaArandjelovi\u00c4\u0087EndtoEndWeaklySupervisedSemantic').submit();\">Relja Arandjelovi\u00c4\u0087</a>,\n</form>\n<form id=\"form-JosefSivicEndtoEndWeaklySupervisedSemantic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Josef Sivic\">\n<a href=\"#\" onclick=\"document.getElementById('form-JosefSivicEndtoEndWeaklySupervisedSemantic').submit();\">Josef Sivic</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Rocco_End-to-End_Weakly-Supervised_Semantic_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.06861\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Rocco_2018_CVPR,<br>\nauthor = {Rocco, Ignacio and Arandjelovi\u00c4\u0087, Relja and Sivic, Josef},<br>\ntitle = {End-to-End Weakly-Supervised Semantic Alignment},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Gao_Dynamic_Zoom-In_Network_CVPR_2018_paper.html\">Dynamic Zoom-In Network for Fast Object Detection in Large Images</a></dt>\n<dd>\n<form id=\"form-MingfeiGaoDynamicZoomInNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mingfei Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingfeiGaoDynamicZoomInNetwork').submit();\">Mingfei Gao</a>,\n</form>\n<form id=\"form-RuichiYuDynamicZoomInNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ruichi Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-RuichiYuDynamicZoomInNetwork').submit();\">Ruichi Yu</a>,\n</form>\n<form id=\"form-AngLiDynamicZoomInNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ang Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-AngLiDynamicZoomInNetwork').submit();\">Ang Li</a>,\n</form>\n<form id=\"form-VladI.DynamicZoomInNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vlad I. Morariu\">\n<a href=\"#\" onclick=\"document.getElementById('form-VladI.DynamicZoomInNetwork').submit();\">Vlad I. Morariu</a>,\n</form>\n<form id=\"form-LarryS.DynamicZoomInNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Larry S. Davis\">\n<a href=\"#\" onclick=\"document.getElementById('form-LarryS.DynamicZoomInNetwork').submit();\">Larry S. Davis</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Gao_Dynamic_Zoom-In_Network_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.05187\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Gao_2018_CVPR,<br>\nauthor = {Gao, Mingfei and Yu, Ruichi and Li, Ang and Morariu, Vlad I. and Davis, Larry S.},<br>\ntitle = {Dynamic Zoom-In Network for Fast Object Detection in Large Images},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_Learning_Markov_Clustering_CVPR_2018_paper.html\">Learning Markov Clustering Networks for Scene Text Detection</a></dt>\n<dd>\n<form id=\"form-ZichuanLiuLearningMarkovClustering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zichuan Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZichuanLiuLearningMarkovClustering').submit();\">Zichuan Liu</a>,\n</form>\n<form id=\"form-GuoshengLinLearningMarkovClustering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guosheng Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuoshengLinLearningMarkovClustering').submit();\">Guosheng Lin</a>,\n</form>\n<form id=\"form-ShengYangLearningMarkovClustering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sheng Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShengYangLearningMarkovClustering').submit();\">Sheng Yang</a>,\n</form>\n<form id=\"form-JiashiFengLearningMarkovClustering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiashi Feng\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiashiFengLearningMarkovClustering').submit();\">Jiashi Feng</a>,\n</form>\n<form id=\"form-WeisiLinLearningMarkovClustering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weisi Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeisiLinLearningMarkovClustering').submit();\">Weisi Lin</a>,\n</form>\n<form id=\"form-WangLingLearningMarkovClustering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wang Ling Goh\">\n<a href=\"#\" onclick=\"document.getElementById('form-WangLingLearningMarkovClustering').submit();\">Wang Ling Goh</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_Learning_Markov_Clustering_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1408-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.08365\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Zichuan and Lin, Guosheng and Yang, Sheng and Feng, Jiashi and Lin, Weisi and Ling Goh, Wang},<br>\ntitle = {Learning Markov Clustering Networks for Scene Text Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Pirinen_Deep_Reinforcement_Learning_CVPR_2018_paper.html\">Deep Reinforcement Learning of Region Proposal Networks for Object Detection</a></dt>\n<dd>\n<form id=\"form-AleksisPirinenDeepReinforcementLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Aleksis Pirinen\">\n<a href=\"#\" onclick=\"document.getElementById('form-AleksisPirinenDeepReinforcementLearning').submit();\">Aleksis Pirinen</a>,\n</form>\n<form id=\"form-CristianSminchisescuDeepReinforcementLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cristian Sminchisescu\">\n<a href=\"#\" onclick=\"document.getElementById('form-CristianSminchisescuDeepReinforcementLearning').submit();\">Cristian Sminchisescu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Pirinen_Deep_Reinforcement_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1543-supp.zip\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Pirinen_2018_CVPR,<br>\nauthor = {Pirinen, Aleksis and Sminchisescu, Cristian},<br>\ntitle = {Deep Reinforcement Learning of Region Proposal Networks for Object Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lu_Beyond_Holistic_Object_CVPR_2018_paper.html\">Beyond Holistic Object Recognition: Enriching Image Understanding With Part States</a></dt>\n<dd>\n<form id=\"form-CewuLuBeyondHolisticObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cewu Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-CewuLuBeyondHolisticObject').submit();\">Cewu Lu</a>,\n</form>\n<form id=\"form-HaoSuBeyondHolisticObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hao Su\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaoSuBeyondHolisticObject').submit();\">Hao Su</a>,\n</form>\n<form id=\"form-YongluLiBeyondHolisticObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yonglu Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-YongluLiBeyondHolisticObject').submit();\">Yonglu Li</a>,\n</form>\n<form id=\"form-YongyiLuBeyondHolisticObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yongyi Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YongyiLuBeyondHolisticObject').submit();\">Yongyi Lu</a>,\n</form>\n<form id=\"form-LiYiBeyondHolisticObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Li Yi\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiYiBeyondHolisticObject').submit();\">Li Yi</a>,\n</form>\n<form id=\"form-Chi-KeungTangBeyondHolisticObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chi-Keung Tang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Chi-KeungTangBeyondHolisticObject').submit();\">Chi-Keung Tang</a>,\n</form>\n<form id=\"form-LeonidasJ.BeyondHolisticObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Leonidas J. Guibas\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeonidasJ.BeyondHolisticObject').submit();\">Leonidas J. Guibas</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lu_Beyond_Holistic_Object_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1612.07310\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lu_2018_CVPR,<br>\nauthor = {Lu, Cewu and Su, Hao and Li, Yonglu and Lu, Yongyi and Yi, Li and Tang, Chi-Keung and Guibas, Leonidas J.},<br>\ntitle = {Beyond Holistic Object Recognition: Enriching Image Understanding With Part States},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Luo_Discriminability_Objective_for_CVPR_2018_paper.html\">Discriminability Objective for Training Descriptive Captions</a></dt>\n<dd>\n<form id=\"form-RuotianLuoDiscriminabilityObjectivefor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ruotian Luo\">\n<a href=\"#\" onclick=\"document.getElementById('form-RuotianLuoDiscriminabilityObjectivefor').submit();\">Ruotian Luo</a>,\n</form>\n<form id=\"form-BrianPriceDiscriminabilityObjectivefor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Brian Price\">\n<a href=\"#\" onclick=\"document.getElementById('form-BrianPriceDiscriminabilityObjectivefor').submit();\">Brian Price</a>,\n</form>\n<form id=\"form-ScottCohenDiscriminabilityObjectivefor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Scott Cohen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ScottCohenDiscriminabilityObjectivefor').submit();\">Scott Cohen</a>,\n</form>\n<form id=\"form-GregoryShakhnarovichDiscriminabilityObjectivefor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gregory Shakhnarovich\">\n<a href=\"#\" onclick=\"document.getElementById('form-GregoryShakhnarovichDiscriminabilityObjectivefor').submit();\">Gregory Shakhnarovich</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Luo_Discriminability_Objective_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1946-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.04376\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Luo_2018_CVPR,<br>\nauthor = {Luo, Ruotian and Price, Brian and Cohen, Scott and Shakhnarovich, Gregory},<br>\ntitle = {Discriminability Objective for Training Descriptive Captions},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ma_Visual_Question_Answering_CVPR_2018_paper.html\">Visual Question Answering With Memory-Augmented Networks</a></dt>\n<dd>\n<form id=\"form-ChaoMaVisualQuestionAnswering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chao Ma\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChaoMaVisualQuestionAnswering').submit();\">Chao Ma</a>,\n</form>\n<form id=\"form-ChunhuaShenVisualQuestionAnswering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chunhua Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChunhuaShenVisualQuestionAnswering').submit();\">Chunhua Shen</a>,\n</form>\n<form id=\"form-AnthonyDickVisualQuestionAnswering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anthony Dick\">\n<a href=\"#\" onclick=\"document.getElementById('form-AnthonyDickVisualQuestionAnswering').submit();\">Anthony Dick</a>,\n</form>\n<form id=\"form-QiWuVisualQuestionAnswering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qi Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiWuVisualQuestionAnswering').submit();\">Qi Wu</a>,\n</form>\n<form id=\"form-PengWangVisualQuestionAnswering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peng Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-PengWangVisualQuestionAnswering').submit();\">Peng Wang</a>,\n</form>\n<form id=\"form-AntonvanVisualQuestionAnswering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anton van den Hengel\">\n<a href=\"#\" onclick=\"document.getElementById('form-AntonvanVisualQuestionAnswering').submit();\">Anton van den Hengel</a>,\n</form>\n<form id=\"form-IanReidVisualQuestionAnswering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ian Reid\">\n<a href=\"#\" onclick=\"document.getElementById('form-IanReidVisualQuestionAnswering').submit();\">Ian Reid</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ma_Visual_Question_Answering_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1707.04968\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ma_2018_CVPR,<br>\nauthor = {Ma, Chao and Shen, Chunhua and Dick, Anthony and Wu, Qi and Wang, Peng and van den Hengel, Anton and Reid, Ian},<br>\ntitle = {Visual Question Answering With Memory-Augmented Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_Structure_Inference_Net_CVPR_2018_paper.html\">Structure Inference Net: Object Detection Using Scene-Level Context and Instance-Level Relationships</a></dt>\n<dd>\n<form id=\"form-YongLiuStructureInferenceNet\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yong Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YongLiuStructureInferenceNet').submit();\">Yong Liu</a>,\n</form>\n<form id=\"form-RuipingWangStructureInferenceNet\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ruiping Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-RuipingWangStructureInferenceNet').submit();\">Ruiping Wang</a>,\n</form>\n<form id=\"form-ShiguangShanStructureInferenceNet\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shiguang Shan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShiguangShanStructureInferenceNet').submit();\">Shiguang Shan</a>,\n</form>\n<form id=\"form-XilinChenStructureInferenceNet\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xilin Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-XilinChenStructureInferenceNet').submit();\">Xilin Chen</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_Structure_Inference_Net_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2114-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1807.00119\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Yong and Wang, Ruiping and Shan, Shiguang and Chen, Xilin},<br>\ntitle = {Structure Inference Net: Object Detection Using Scene-Level Context and Instance-Level Relationships},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Occluded_Pedestrian_Detection_CVPR_2018_paper.html\">Occluded Pedestrian Detection Through Guided Attention in CNNs</a></dt>\n<dd>\n<form id=\"form-ShanshanZhangOccludedPedestrianDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shanshan Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShanshanZhangOccludedPedestrianDetection').submit();\">Shanshan Zhang</a>,\n</form>\n<form id=\"form-JianYangOccludedPedestrianDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jian Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianYangOccludedPedestrianDetection').submit();\">Jian Yang</a>,\n</form>\n<form id=\"form-BerntSchieleOccludedPedestrianDetection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bernt Schiele\">\n<a href=\"#\" onclick=\"document.getElementById('form-BerntSchieleOccludedPedestrianDetection').submit();\">Bernt Schiele</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Occluded_Pedestrian_Detection_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Shanshan and Yang, Jian and Schiele, Bernt},<br>\ntitle = {Occluded Pedestrian Detection Through Guided Attention in CNNs},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tung_Reward_Learning_From_CVPR_2018_paper.html\">Reward Learning From Narrated Demonstrations</a></dt>\n<dd>\n<form id=\"form-Hsiao-YuTungRewardLearningFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hsiao-Yu Tung\">\n<a href=\"#\" onclick=\"document.getElementById('form-Hsiao-YuTungRewardLearningFrom').submit();\">Hsiao-Yu Tung</a>,\n</form>\n<form id=\"form-AdamW.RewardLearningFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Adam W. Harley\">\n<a href=\"#\" onclick=\"document.getElementById('form-AdamW.RewardLearningFrom').submit();\">Adam W. Harley</a>,\n</form>\n<form id=\"form-Liang-KangHuangRewardLearningFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liang-Kang Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Liang-KangHuangRewardLearningFrom').submit();\">Liang-Kang Huang</a>,\n</form>\n<form id=\"form-KaterinaFragkiadakiRewardLearningFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Katerina Fragkiadaki\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaterinaFragkiadakiRewardLearningFrom').submit();\">Katerina Fragkiadaki</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tung_Reward_Learning_From_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.10692\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tung_2018_CVPR,<br>\nauthor = {Tung, Hsiao-Yu and Harley, Adam W. and Huang, Liang-Kang and Fragkiadaki, Katerina},<br>\ntitle = {Reward Learning From Narrated Demonstrations},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Huang_Weakly-Supervised_Semantic_Segmentation_CVPR_2018_paper.html\">Weakly-Supervised Semantic Segmentation Network With Deep Seeded Region Growing</a></dt>\n<dd>\n<form id=\"form-ZilongHuangWeaklySupervisedSemanticSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zilong Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZilongHuangWeaklySupervisedSemanticSegmentation').submit();\">Zilong Huang</a>,\n</form>\n<form id=\"form-XinggangWangWeaklySupervisedSemanticSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xinggang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinggangWangWeaklySupervisedSemanticSegmentation').submit();\">Xinggang Wang</a>,\n</form>\n<form id=\"form-JiasiWangWeaklySupervisedSemanticSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiasi Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiasiWangWeaklySupervisedSemanticSegmentation').submit();\">Jiasi Wang</a>,\n</form>\n<form id=\"form-WenyuLiuWeaklySupervisedSemanticSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenyu Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenyuLiuWeaklySupervisedSemanticSegmentation').submit();\">Wenyu Liu</a>,\n</form>\n<form id=\"form-JingdongWangWeaklySupervisedSemanticSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jingdong Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingdongWangWeaklySupervisedSemanticSegmentation').submit();\">Jingdong Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Huang_Weakly-Supervised_Semantic_Segmentation_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Huang_2018_CVPR,<br>\nauthor = {Huang, Zilong and Wang, Xinggang and Wang, Jiasi and Liu, Wenyu and Wang, Jingdong},<br>\ntitle = {Weakly-Supervised Semantic Segmentation Network With Deep Seeded Region Growing},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Choutas_PoTion_Pose_MoTion_CVPR_2018_paper.html\">PoTion: Pose MoTion Representation for Action Recognition</a></dt>\n<dd>\n<form id=\"form-VasileiosChoutasPoTionPoseMoTion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vasileios Choutas\">\n<a href=\"#\" onclick=\"document.getElementById('form-VasileiosChoutasPoTionPoseMoTion').submit();\">Vasileios Choutas</a>,\n</form>\n<form id=\"form-PhilippeWeinzaepfelPoTionPoseMoTion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Philippe Weinzaepfel\">\n<a href=\"#\" onclick=\"document.getElementById('form-PhilippeWeinzaepfelPoTionPoseMoTion').submit();\">Philippe Weinzaepfel</a>,\n</form>\n<form id=\"form-J\u00c3\u00a9r\u00c3\u00b4meRevaudPoTionPoseMoTion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"J\u00c3\u00a9r\u00c3\u00b4me Revaud\">\n<a href=\"#\" onclick=\"document.getElementById('form-J\u00c3\u00a9r\u00c3\u00b4meRevaudPoTionPoseMoTion').submit();\">J\u00c3\u00a9r\u00c3\u00b4me Revaud</a>,\n</form>\n<form id=\"form-CordeliaSchmidPoTionPoseMoTion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cordelia Schmid\">\n<a href=\"#\" onclick=\"document.getElementById('form-CordeliaSchmidPoTionPoseMoTion').submit();\">Cordelia Schmid</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Choutas_PoTion_Pose_MoTion_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Choutas_2018_CVPR,<br>\nauthor = {Choutas, Vasileios and Weinzaepfel, Philippe and Revaud, J\u00c3\u00a9r\u00c3\u00b4me and Schmid, Cordelia},<br>\ntitle = {PoTion: Pose MoTion Representation for Action Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Bilateral_Ordinal_Relevance_CVPR_2018_paper.html\">Bilateral Ordinal Relevance Multi-Instance Regression for Facial Action Unit Intensity Estimation</a></dt>\n<dd>\n<form id=\"form-YongZhangBilateralOrdinalRelevance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yong Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YongZhangBilateralOrdinalRelevance').submit();\">Yong Zhang</a>,\n</form>\n<form id=\"form-RuiZhaoBilateralOrdinalRelevance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rui Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-RuiZhaoBilateralOrdinalRelevance').submit();\">Rui Zhao</a>,\n</form>\n<form id=\"form-WeimingDongBilateralOrdinalRelevance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weiming Dong\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeimingDongBilateralOrdinalRelevance').submit();\">Weiming Dong</a>,\n</form>\n<form id=\"form-Bao-GangHuBilateralOrdinalRelevance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bao-Gang Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Bao-GangHuBilateralOrdinalRelevance').submit();\">Bao-Gang Hu</a>,\n</form>\n<form id=\"form-QiangJiBilateralOrdinalRelevance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qiang Ji\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiangJiBilateralOrdinalRelevance').submit();\">Qiang Ji</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Bilateral_Ordinal_Relevance_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3075-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Yong and Zhao, Rui and Dong, Weiming and Hu, Bao-Gang and Ji, Qiang},<br>\ntitle = {Bilateral Ordinal Relevance Multi-Instance Regression for Facial Action Unit Intensity Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Pulling_Actions_out_CVPR_2018_paper.html\">Pulling Actions out of Context: Explicit Separation for Effective Combination</a></dt>\n<dd>\n<form id=\"form-YangWangPullingActionsout\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YangWangPullingActionsout').submit();\">Yang Wang</a>,\n</form>\n<form id=\"form-MinhHoaiPullingActionsout\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Minh Hoai\">\n<a href=\"#\" onclick=\"document.getElementById('form-MinhHoaiPullingActionsout').submit();\">Minh Hoai</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Pulling_Actions_out_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Yang and Hoai, Minh},<br>\ntitle = {Pulling Actions out of Context: Explicit Separation for Effective Combination},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/He_Dynamic_Feature_Learning_CVPR_2018_paper.html\">Dynamic Feature Learning for Partial Face Recognition</a></dt>\n<dd>\n<form id=\"form-LingxiaoHeDynamicFeatureLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lingxiao He\">\n<a href=\"#\" onclick=\"document.getElementById('form-LingxiaoHeDynamicFeatureLearning').submit();\">Lingxiao He</a>,\n</form>\n<form id=\"form-HaiqingLiDynamicFeatureLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Haiqing Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaiqingLiDynamicFeatureLearning').submit();\">Haiqing Li</a>,\n</form>\n<form id=\"form-QiZhangDynamicFeatureLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qi Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiZhangDynamicFeatureLearning').submit();\">Qi Zhang</a>,\n</form>\n<form id=\"form-ZhenanSunDynamicFeatureLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhenan Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhenanSunDynamicFeatureLearning').submit();\">Zhenan Sun</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/He_Dynamic_Feature_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{He_2018_CVPR,<br>\nauthor = {He, Lingxiao and Li, Haiqing and Zhang, Qi and Sun, Zhenan},<br>\ntitle = {Dynamic Feature Learning for Partial Face Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Roy_Exploiting_Transitivity_for_CVPR_2018_paper.html\">Exploiting Transitivity for Learning Person Re-Identification Models on a Budget</a></dt>\n<dd>\n<form id=\"form-SouryaRoyExploitingTransitivityfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sourya Roy\">\n<a href=\"#\" onclick=\"document.getElementById('form-SouryaRoyExploitingTransitivityfor').submit();\">Sourya Roy</a>,\n</form>\n<form id=\"form-SujoyPaulExploitingTransitivityfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sujoy Paul\">\n<a href=\"#\" onclick=\"document.getElementById('form-SujoyPaulExploitingTransitivityfor').submit();\">Sujoy Paul</a>,\n</form>\n<form id=\"form-NealE.ExploitingTransitivityfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Neal E. Young\">\n<a href=\"#\" onclick=\"document.getElementById('form-NealE.ExploitingTransitivityfor').submit();\">Neal E. Young</a>,\n</form>\n<form id=\"form-AmitK.ExploitingTransitivityfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Amit K. Roy-Chowdhury\">\n<a href=\"#\" onclick=\"document.getElementById('form-AmitK.ExploitingTransitivityfor').submit();\">Amit K. Roy-Chowdhury</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Roy_Exploiting_Transitivity_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/4066-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Roy_2018_CVPR,<br>\nauthor = {Roy, Sourya and Paul, Sujoy and Young, Neal E. and Roy-Chowdhury, Amit K.},<br>\ntitle = {Exploiting Transitivity for Learning Person Re-Identification Models on a Budget},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/He_Deep_Spatial_Feature_CVPR_2018_paper.html\">Deep Spatial Feature Reconstruction for Partial Person Re-Identification: Alignment-Free Approach</a></dt>\n<dd>\n<form id=\"form-LingxiaoHeDeepSpatialFeature\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lingxiao He\">\n<a href=\"#\" onclick=\"document.getElementById('form-LingxiaoHeDeepSpatialFeature').submit();\">Lingxiao He</a>,\n</form>\n<form id=\"form-JianLiangDeepSpatialFeature\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jian Liang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianLiangDeepSpatialFeature').submit();\">Jian Liang</a>,\n</form>\n<form id=\"form-HaiqingLiDeepSpatialFeature\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Haiqing Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaiqingLiDeepSpatialFeature').submit();\">Haiqing Li</a>,\n</form>\n<form id=\"form-ZhenanSunDeepSpatialFeature\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhenan Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhenanSunDeepSpatialFeature').submit();\">Zhenan Sun</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/He_Deep_Spatial_Feature_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.00881\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{He_2018_CVPR,<br>\nauthor = {He, Lingxiao and Liang, Jian and Li, Haiqing and Sun, Zhenan},<br>\ntitle = {Deep Spatial Feature Reconstruction for Partial Person Re-Identification: Alignment-Free Approach},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Every_Smile_Is_CVPR_2018_paper.html\">Every Smile Is Unique: Landmark-Guided Diverse Smile Generation</a></dt>\n<dd>\n<form id=\"form-WeiWangEverySmileIs\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiWangEverySmileIs').submit();\">Wei Wang</a>,\n</form>\n<form id=\"form-XavierAlameda-PinedaEverySmileIs\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xavier Alameda-Pineda\">\n<a href=\"#\" onclick=\"document.getElementById('form-XavierAlameda-PinedaEverySmileIs').submit();\">Xavier Alameda-Pineda</a>,\n</form>\n<form id=\"form-DanXuEverySmileIs\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dan Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanXuEverySmileIs').submit();\">Dan Xu</a>,\n</form>\n<form id=\"form-PascalFuaEverySmileIs\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pascal Fua\">\n<a href=\"#\" onclick=\"document.getElementById('form-PascalFuaEverySmileIs').submit();\">Pascal Fua</a>,\n</form>\n<form id=\"form-ElisaRicciEverySmileIs\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Elisa Ricci\">\n<a href=\"#\" onclick=\"document.getElementById('form-ElisaRicciEverySmileIs').submit();\">Elisa Ricci</a>,\n</form>\n<form id=\"form-NicuSebeEverySmileIs\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nicu Sebe\">\n<a href=\"#\" onclick=\"document.getElementById('form-NicuSebeEverySmileIs').submit();\">Nicu Sebe</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Every_Smile_Is_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.01873\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Wei and Alameda-Pineda, Xavier and Xu, Dan and Fua, Pascal and Ricci, Elisa and Sebe, Nicu},<br>\ntitle = {Every Smile Is Unique: Landmark-Guided Diverse Smile Generation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Deng_UV-GAN_Adversarial_Facial_CVPR_2018_paper.html\">UV-GAN: Adversarial Facial UV Map Completion for Pose-Invariant Face Recognition</a></dt>\n<dd>\n<form id=\"form-JiankangDengUVGANAdversarialFacial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiankang Deng\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiankangDengUVGANAdversarialFacial').submit();\">Jiankang Deng</a>,\n</form>\n<form id=\"form-ShiyangChengUVGANAdversarialFacial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shiyang Cheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShiyangChengUVGANAdversarialFacial').submit();\">Shiyang Cheng</a>,\n</form>\n<form id=\"form-NiannanXueUVGANAdversarialFacial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Niannan Xue\">\n<a href=\"#\" onclick=\"document.getElementById('form-NiannanXueUVGANAdversarialFacial').submit();\">Niannan Xue</a>,\n</form>\n<form id=\"form-YuxiangZhouUVGANAdversarialFacial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuxiang Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuxiangZhouUVGANAdversarialFacial').submit();\">Yuxiang Zhou</a>,\n</form>\n<form id=\"form-StefanosZafeiriouUVGANAdversarialFacial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stefanos Zafeiriou\">\n<a href=\"#\" onclick=\"document.getElementById('form-StefanosZafeiriouUVGANAdversarialFacial').submit();\">Stefanos Zafeiriou</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Deng_UV-GAN_Adversarial_Facial_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.04695\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Deng_2018_CVPR,<br>\nauthor = {Deng, Jiankang and Cheng, Shiyang and Xue, Niannan and Zhou, Yuxiang and Zafeiriou, Stefanos},<br>\ntitle = {UV-GAN: Adversarial Facial UV Map Completion for Pose-Invariant Face Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_Cascaded_Pyramid_Network_CVPR_2018_paper.html\">Cascaded Pyramid Network for Multi-Person Pose Estimation</a></dt>\n<dd>\n<form id=\"form-YilunChenCascadedPyramidNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yilun Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-YilunChenCascadedPyramidNetwork').submit();\">Yilun Chen</a>,\n</form>\n<form id=\"form-ZhichengWangCascadedPyramidNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhicheng Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhichengWangCascadedPyramidNetwork').submit();\">Zhicheng Wang</a>,\n</form>\n<form id=\"form-YuxiangPengCascadedPyramidNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuxiang Peng\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuxiangPengCascadedPyramidNetwork').submit();\">Yuxiang Peng</a>,\n</form>\n<form id=\"form-ZhiqiangZhangCascadedPyramidNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhiqiang Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhiqiangZhangCascadedPyramidNetwork').submit();\">Zhiqiang Zhang</a>,\n</form>\n<form id=\"form-GangYuCascadedPyramidNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gang Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-GangYuCascadedPyramidNetwork').submit();\">Gang Yu</a>,\n</form>\n<form id=\"form-JianSunCascadedPyramidNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jian Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianSunCascadedPyramidNetwork').submit();\">Jian Sun</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_Cascaded_Pyramid_Network_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.07319\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Yilun and Wang, Zhicheng and Peng, Yuxiang and Zhang, Zhiqiang and Yu, Gang and Sun, Jian},<br>\ntitle = {Cascaded Pyramid Network for Multi-Person Pose Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chu_A_Face-to-Face_Neural_CVPR_2018_paper.html\">A Face-to-Face Neural Conversation Model</a></dt>\n<dd>\n<form id=\"form-HangChuAFacetoFaceNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hang Chu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HangChuAFacetoFaceNeural').submit();\">Hang Chu</a>,\n</form>\n<form id=\"form-DaiqingLiAFacetoFaceNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daiqing Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-DaiqingLiAFacetoFaceNeural').submit();\">Daiqing Li</a>,\n</form>\n<form id=\"form-SanjaFidlerAFacetoFaceNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sanja Fidler\">\n<a href=\"#\" onclick=\"document.getElementById('form-SanjaFidlerAFacetoFaceNeural').submit();\">Sanja Fidler</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chu_A_Face-to-Face_Neural_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chu_2018_CVPR,<br>\nauthor = {Chu, Hang and Li, Daiqing and Fidler, Sanja},<br>\ntitle = {A Face-to-Face Neural Conversation Model},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kanazawa_End-to-End_Recovery_of_CVPR_2018_paper.html\">End-to-End Recovery of Human Shape and Pose</a></dt>\n<dd>\n<form id=\"form-AngjooKanazawaEndtoEndRecoveryof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Angjoo Kanazawa\">\n<a href=\"#\" onclick=\"document.getElementById('form-AngjooKanazawaEndtoEndRecoveryof').submit();\">Angjoo Kanazawa</a>,\n</form>\n<form id=\"form-MichaelJ.EndtoEndRecoveryof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michael J. Black\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichaelJ.EndtoEndRecoveryof').submit();\">Michael J. Black</a>,\n</form>\n<form id=\"form-DavidW.EndtoEndRecoveryof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"David W. Jacobs\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavidW.EndtoEndRecoveryof').submit();\">David W. Jacobs</a>,\n</form>\n<form id=\"form-JitendraMalikEndtoEndRecoveryof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jitendra Malik\">\n<a href=\"#\" onclick=\"document.getElementById('form-JitendraMalikEndtoEndRecoveryof').submit();\">Jitendra Malik</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kanazawa_End-to-End_Recovery_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.06584\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kanazawa_2018_CVPR,<br>\nauthor = {Kanazawa, Angjoo and Black, Michael J. and Jacobs, David W. and Malik, Jitendra},<br>\ntitle = {End-to-End Recovery of Human Shape and Pose},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hu_Squeeze-and-Excitation_Networks_CVPR_2018_paper.html\">Squeeze-and-Excitation Networks</a></dt>\n<dd>\n<form id=\"form-JieHuSqueezeandExcitationNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jie Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JieHuSqueezeandExcitationNetworks').submit();\">Jie Hu</a>,\n</form>\n<form id=\"form-LiShenSqueezeandExcitationNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Li Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiShenSqueezeandExcitationNetworks').submit();\">Li Shen</a>,\n</form>\n<form id=\"form-GangSunSqueezeandExcitationNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gang Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-GangSunSqueezeandExcitationNetworks').submit();\">Gang Sun</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hu_Squeeze-and-Excitation_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1287-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1807.08920\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hu_2018_CVPR,<br>\nauthor = {Hu, Jie and Shen, Li and Sun, Gang},<br>\ntitle = {Squeeze-and-Excitation Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Islam_Revisiting_Salient_Object_CVPR_2018_paper.html\">Revisiting Salient Object Detection: Simultaneous Detection, Ranking, and Subitizing of Multiple Salient Objects</a></dt>\n<dd>\n<form id=\"form-MdAmirulRevisitingSalientObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Md Amirul Islam\">\n<a href=\"#\" onclick=\"document.getElementById('form-MdAmirulRevisitingSalientObject').submit();\">Md Amirul Islam</a>,\n</form>\n<form id=\"form-MahmoudKalashRevisitingSalientObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mahmoud Kalash\">\n<a href=\"#\" onclick=\"document.getElementById('form-MahmoudKalashRevisitingSalientObject').submit();\">Mahmoud Kalash</a>,\n</form>\n<form id=\"form-NeilD.RevisitingSalientObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Neil D. B. Bruce\">\n<a href=\"#\" onclick=\"document.getElementById('form-NeilD.RevisitingSalientObject').submit();\">Neil D. B. Bruce</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Islam_Revisiting_Salient_Object_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Islam_2018_CVPR,<br>\nauthor = {Amirul Islam, Md and Kalash, Mahmoud and Bruce, Neil D. B.},<br>\ntitle = {Revisiting Salient Object Detection: Simultaneous Detection, Ranking, and Subitizing of Multiple Salient Objects},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Context_Encoding_for_CVPR_2018_paper.html\">Context Encoding for Semantic Segmentation</a></dt>\n<dd>\n<form id=\"form-HangZhangContextEncodingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hang Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HangZhangContextEncodingfor').submit();\">Hang Zhang</a>,\n</form>\n<form id=\"form-KristinDanaContextEncodingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kristin Dana\">\n<a href=\"#\" onclick=\"document.getElementById('form-KristinDanaContextEncodingfor').submit();\">Kristin Dana</a>,\n</form>\n<form id=\"form-JianpingShiContextEncodingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianping Shi\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianpingShiContextEncodingfor').submit();\">Jianping Shi</a>,\n</form>\n<form id=\"form-ZhongyueZhangContextEncodingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhongyue Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhongyueZhangContextEncodingfor').submit();\">Zhongyue Zhang</a>,\n</form>\n<form id=\"form-XiaogangWangContextEncodingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaogang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaogangWangContextEncodingfor').submit();\">Xiaogang Wang</a>,\n</form>\n<form id=\"form-AmbrishTyagiContextEncodingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ambrish Tyagi\">\n<a href=\"#\" onclick=\"document.getElementById('form-AmbrishTyagiContextEncodingfor').submit();\">Ambrish Tyagi</a>,\n</form>\n<form id=\"form-AmitAgrawalContextEncodingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Amit Agrawal\">\n<a href=\"#\" onclick=\"document.getElementById('form-AmitAgrawalContextEncodingfor').submit();\">Amit Agrawal</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Context_Encoding_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.08904\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Hang and Dana, Kristin and Shi, Jianping and Zhang, Zhongyue and Wang, Xiaogang and Tyagi, Ambrish and Agrawal, Amit},<br>\ntitle = {Context Encoding for Semantic Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hsiao_Creating_Capsule_Wardrobes_CVPR_2018_paper.html\">Creating Capsule Wardrobes From Fashion Images</a></dt>\n<dd>\n<form id=\"form-Wei-LinHsiaoCreatingCapsuleWardrobes\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei-Lin Hsiao\">\n<a href=\"#\" onclick=\"document.getElementById('form-Wei-LinHsiaoCreatingCapsuleWardrobes').submit();\">Wei-Lin Hsiao</a>,\n</form>\n<form id=\"form-KristenGraumanCreatingCapsuleWardrobes\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kristen Grauman\">\n<a href=\"#\" onclick=\"document.getElementById('form-KristenGraumanCreatingCapsuleWardrobes').submit();\">Kristen Grauman</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hsiao_Creating_Capsule_Wardrobes_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3021-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.02662\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hsiao_2018_CVPR,<br>\nauthor = {Hsiao, Wei-Lin and Grauman, Kristen},<br>\ntitle = {Creating Capsule Wardrobes From Fashion Images},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Niu_Webly_Supervised_Learning_CVPR_2018_paper.html\">Webly Supervised Learning Meets Zero-Shot Learning: A Hybrid Approach for Fine-Grained Classification</a></dt>\n<dd>\n<form id=\"form-LiNiuWeblySupervisedLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Li Niu\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiNiuWeblySupervisedLearning').submit();\">Li Niu</a>,\n</form>\n<form id=\"form-AshokVeeraraghavanWeblySupervisedLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ashok Veeraraghavan\">\n<a href=\"#\" onclick=\"document.getElementById('form-AshokVeeraraghavanWeblySupervisedLearning').submit();\">Ashok Veeraraghavan</a>,\n</form>\n<form id=\"form-AshutoshSabharwalWeblySupervisedLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ashutosh Sabharwal\">\n<a href=\"#\" onclick=\"document.getElementById('form-AshutoshSabharwalWeblySupervisedLearning').submit();\">Ashutosh Sabharwal</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Niu_Webly_Supervised_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Niu_2018_CVPR,<br>\nauthor = {Niu, Li and Veeraraghavan, Ashok and Sabharwal, Ashutosh},<br>\ntitle = {Webly Supervised Learning Meets Zero-Shot Learning: A Hybrid Approach for Fine-Grained Classification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Gu_Look_Imagine_and_CVPR_2018_paper.html\">Look, Imagine and Match: Improving Textual-Visual Cross-Modal Retrieval With Generative Models</a></dt>\n<dd>\n<form id=\"form-JiuxiangGuLookImagineand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiuxiang Gu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiuxiangGuLookImagineand').submit();\">Jiuxiang Gu</a>,\n</form>\n<form id=\"form-JianfeiCaiLookImagineand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianfei Cai\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianfeiCaiLookImagineand').submit();\">Jianfei Cai</a>,\n</form>\n<form id=\"form-ShafiqR.LookImagineand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shafiq R. Joty\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShafiqR.LookImagineand').submit();\">Shafiq R. Joty</a>,\n</form>\n<form id=\"form-LiNiuLookImagineand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Li Niu\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiNiuLookImagineand').submit();\">Li Niu</a>,\n</form>\n<form id=\"form-GangWangLookImagineand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-GangWangLookImagineand').submit();\">Gang Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Gu_Look_Imagine_and_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Gu_2018_CVPR,<br>\nauthor = {Gu, Jiuxiang and Cai, Jianfei and Joty, Shafiq R. and Niu, Li and Wang, Gang},<br>\ntitle = {Look, Imagine and Match: Improving Textual-Visual Cross-Modal Retrieval With Generative Models},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Bidirectional_Attentive_Fusion_CVPR_2018_paper.html\">Bidirectional Attentive Fusion With Context Gating for Dense Video Captioning</a></dt>\n<dd>\n<form id=\"form-JingwenWangBidirectionalAttentiveFusion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jingwen Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingwenWangBidirectionalAttentiveFusion').submit();\">Jingwen Wang</a>,\n</form>\n<form id=\"form-WenhaoJiangBidirectionalAttentiveFusion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenhao Jiang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenhaoJiangBidirectionalAttentiveFusion').submit();\">Wenhao Jiang</a>,\n</form>\n<form id=\"form-LinMaBidirectionalAttentiveFusion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lin Ma\">\n<a href=\"#\" onclick=\"document.getElementById('form-LinMaBidirectionalAttentiveFusion').submit();\">Lin Ma</a>,\n</form>\n<form id=\"form-WeiLiuBidirectionalAttentiveFusion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiLiuBidirectionalAttentiveFusion').submit();\">Wei Liu</a>,\n</form>\n<form id=\"form-YongXuBidirectionalAttentiveFusion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yong Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YongXuBidirectionalAttentiveFusion').submit();\">Yong Xu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Bidirectional_Attentive_Fusion_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00100\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Jingwen and Jiang, Wenhao and Ma, Lin and Liu, Wei and Xu, Yong},<br>\ntitle = {Bidirectional Attentive Fusion With Context Gating for Dense Video Captioning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Taira_InLoc_Indoor_Visual_CVPR_2018_paper.html\">InLoc: Indoor Visual Localization With Dense Matching and View Synthesis</a></dt>\n<dd>\n<form id=\"form-HajimeTairaInLocIndoorVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hajime Taira\">\n<a href=\"#\" onclick=\"document.getElementById('form-HajimeTairaInLocIndoorVisual').submit();\">Hajime Taira</a>,\n</form>\n<form id=\"form-MasatoshiOkutomiInLocIndoorVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Masatoshi Okutomi\">\n<a href=\"#\" onclick=\"document.getElementById('form-MasatoshiOkutomiInLocIndoorVisual').submit();\">Masatoshi Okutomi</a>,\n</form>\n<form id=\"form-TorstenSattlerInLocIndoorVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Torsten Sattler\">\n<a href=\"#\" onclick=\"document.getElementById('form-TorstenSattlerInLocIndoorVisual').submit();\">Torsten Sattler</a>,\n</form>\n<form id=\"form-MirceaCimpoiInLocIndoorVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mircea Cimpoi\">\n<a href=\"#\" onclick=\"document.getElementById('form-MirceaCimpoiInLocIndoorVisual').submit();\">Mircea Cimpoi</a>,\n</form>\n<form id=\"form-MarcPollefeysInLocIndoorVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Marc Pollefeys\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarcPollefeysInLocIndoorVisual').submit();\">Marc Pollefeys</a>,\n</form>\n<form id=\"form-JosefSivicInLocIndoorVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Josef Sivic\">\n<a href=\"#\" onclick=\"document.getElementById('form-JosefSivicInLocIndoorVisual').submit();\">Josef Sivic</a>,\n</form>\n<form id=\"form-TomasPajdlaInLocIndoorVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tomas Pajdla\">\n<a href=\"#\" onclick=\"document.getElementById('form-TomasPajdlaInLocIndoorVisual').submit();\">Tomas Pajdla</a>,\n</form>\n<form id=\"form-AkihikoToriiInLocIndoorVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Akihiko Torii\">\n<a href=\"#\" onclick=\"document.getElementById('form-AkihikoToriiInLocIndoorVisual').submit();\">Akihiko Torii</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Taira_InLoc_Indoor_Visual_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.10368\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Taira_2018_CVPR,<br>\nauthor = {Taira, Hajime and Okutomi, Masatoshi and Sattler, Torsten and Cimpoi, Mircea and Pollefeys, Marc and Sivic, Josef and Pajdla, Tomas and Torii, Akihiko},<br>\ntitle = {InLoc: Indoor Visual Localization With Dense Matching and View Synthesis},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhu_Towards_High_Performance_CVPR_2018_paper.html\">Towards High Performance Video Object Detection</a></dt>\n<dd>\n<form id=\"form-XizhouZhuTowardsHighPerformance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xizhou Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XizhouZhuTowardsHighPerformance').submit();\">Xizhou Zhu</a>,\n</form>\n<form id=\"form-JifengDaiTowardsHighPerformance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jifeng Dai\">\n<a href=\"#\" onclick=\"document.getElementById('form-JifengDaiTowardsHighPerformance').submit();\">Jifeng Dai</a>,\n</form>\n<form id=\"form-LuYuanTowardsHighPerformance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lu Yuan\">\n<a href=\"#\" onclick=\"document.getElementById('form-LuYuanTowardsHighPerformance').submit();\">Lu Yuan</a>,\n</form>\n<form id=\"form-YichenWeiTowardsHighPerformance\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yichen Wei\">\n<a href=\"#\" onclick=\"document.getElementById('form-YichenWeiTowardsHighPerformance').submit();\">Yichen Wei</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhu_Towards_High_Performance_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.05830\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhu_2018_CVPR,<br>\nauthor = {Zhu, Xizhou and Dai, Jifeng and Yuan, Lu and Wei, Yichen},<br>\ntitle = {Towards High Performance Video Object Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lu_Neural_Baby_Talk_CVPR_2018_paper.html\">Neural Baby Talk</a></dt>\n<dd>\n<form id=\"form-JiasenLuNeuralBabyTalk\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiasen Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiasenLuNeuralBabyTalk').submit();\">Jiasen Lu</a>,\n</form>\n<form id=\"form-JianweiYangNeuralBabyTalk\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianwei Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianweiYangNeuralBabyTalk').submit();\">Jianwei Yang</a>,\n</form>\n<form id=\"form-DhruvBatraNeuralBabyTalk\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dhruv Batra\">\n<a href=\"#\" onclick=\"document.getElementById('form-DhruvBatraNeuralBabyTalk').submit();\">Dhruv Batra</a>,\n</form>\n<form id=\"form-DeviParikhNeuralBabyTalk\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Devi Parikh\">\n<a href=\"#\" onclick=\"document.getElementById('form-DeviParikhNeuralBabyTalk').submit();\">Devi Parikh</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lu_Neural_Baby_Talk_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0205-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.09845\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lu_2018_CVPR,<br>\nauthor = {Lu, Jiasen and Yang, Jianwei and Batra, Dhruv and Parikh, Devi},<br>\ntitle = {Neural Baby Talk},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Qiao_Few-Shot_Image_Recognition_CVPR_2018_paper.html\">Few-Shot Image Recognition by Predicting Parameters From Activations</a></dt>\n<dd>\n<form id=\"form-SiyuanQiaoFewShotImageRecognition\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Siyuan Qiao\">\n<a href=\"#\" onclick=\"document.getElementById('form-SiyuanQiaoFewShotImageRecognition').submit();\">Siyuan Qiao</a>,\n</form>\n<form id=\"form-ChenxiLiuFewShotImageRecognition\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chenxi Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenxiLiuFewShotImageRecognition').submit();\">Chenxi Liu</a>,\n</form>\n<form id=\"form-WeiShenFewShotImageRecognition\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiShenFewShotImageRecognition').submit();\">Wei Shen</a>,\n</form>\n<form id=\"form-AlanL.FewShotImageRecognition\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alan L. Yuille\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlanL.FewShotImageRecognition').submit();\">Alan L. Yuille</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Qiao_Few-Shot_Image_Recognition_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0242-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1706.03466\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Qiao_2018_CVPR,<br>\nauthor = {Qiao, Siyuan and Liu, Chenxi and Shen, Wei and Yuille, Alan L.},<br>\ntitle = {Few-Shot Image Recognition by Predicting Parameters From Activations},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_Iterative_Visual_Reasoning_CVPR_2018_paper.html\">Iterative Visual Reasoning Beyond Convolutions</a></dt>\n<dd>\n<form id=\"form-XinleiChenIterativeVisualReasoning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xinlei Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinleiChenIterativeVisualReasoning').submit();\">Xinlei Chen</a>,\n</form>\n<form id=\"form-Li-JiaLiIterativeVisualReasoning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Li-Jia Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-Li-JiaLiIterativeVisualReasoning').submit();\">Li-Jia Li</a>,\n</form>\n<form id=\"form-LiFei-FeiIterativeVisualReasoning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Li Fei-Fei\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiFei-FeiIterativeVisualReasoning').submit();\">Li Fei-Fei</a>,\n</form>\n<form id=\"form-AbhinavGuptaIterativeVisualReasoning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Abhinav Gupta\">\n<a href=\"#\" onclick=\"document.getElementById('form-AbhinavGuptaIterativeVisualReasoning').submit();\">Abhinav Gupta</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_Iterative_Visual_Reasoning_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.11189\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Xinlei and Li, Li-Jia and Fei-Fei, Li and Gupta, Abhinav},<br>\ntitle = {Iterative Visual Reasoning Beyond Convolutions},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Cao_Visual_Question_Reasoning_CVPR_2018_paper.html\">Visual Question Reasoning on General Dependency Tree</a></dt>\n<dd>\n<form id=\"form-QingxingCaoVisualQuestionReasoning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qingxing Cao\">\n<a href=\"#\" onclick=\"document.getElementById('form-QingxingCaoVisualQuestionReasoning').submit();\">Qingxing Cao</a>,\n</form>\n<form id=\"form-XiaodanLiangVisualQuestionReasoning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaodan Liang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaodanLiangVisualQuestionReasoning').submit();\">Xiaodan Liang</a>,\n</form>\n<form id=\"form-BailingLiVisualQuestionReasoning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bailing Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-BailingLiVisualQuestionReasoning').submit();\">Bailing Li</a>,\n</form>\n<form id=\"form-GuanbinLiVisualQuestionReasoning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guanbin Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuanbinLiVisualQuestionReasoning').submit();\">Guanbin Li</a>,\n</form>\n<form id=\"form-LiangLinVisualQuestionReasoning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liang Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiangLinVisualQuestionReasoning').submit();\">Liang Lin</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Cao_Visual_Question_Reasoning_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00105\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Cao_2018_CVPR,<br>\nauthor = {Cao, Qingxing and Liang, Xiaodan and Li, Bailing and Li, Guanbin and Lin, Liang},<br>\ntitle = {Visual Question Reasoning on General Dependency Tree},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hu_CVM-Net_Cross-View_Matching_CVPR_2018_paper.html\">CVM-Net: Cross-View Matching Network for Image-Based Ground-to-Aerial Geo-Localization</a></dt>\n<dd>\n<form id=\"form-SixingHuCVMNetCrossViewMatching\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sixing Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-SixingHuCVMNetCrossViewMatching').submit();\">Sixing Hu</a>,\n</form>\n<form id=\"form-MengdanFengCVMNetCrossViewMatching\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mengdan Feng\">\n<a href=\"#\" onclick=\"document.getElementById('form-MengdanFengCVMNetCrossViewMatching').submit();\">Mengdan Feng</a>,\n</form>\n<form id=\"form-RangM.CVMNetCrossViewMatching\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rang M. H. Nguyen\">\n<a href=\"#\" onclick=\"document.getElementById('form-RangM.CVMNetCrossViewMatching').submit();\">Rang M. H. Nguyen</a>,\n</form>\n<form id=\"form-GimHeeCVMNetCrossViewMatching\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gim Hee Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-GimHeeCVMNetCrossViewMatching').submit();\">Gim Hee Lee</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hu_CVM-Net_Cross-View_Matching_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hu_2018_CVPR,<br>\nauthor = {Hu, Sixing and Feng, Mengdan and Nguyen, Rang M. H. and Hee Lee, Gim},<br>\ntitle = {CVM-Net: Cross-View Matching Network for Image-Based Ground-to-Aerial Geo-Localization},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wei_Revisiting_Dilated_Convolution_CVPR_2018_paper.html\">Revisiting Dilated Convolution: A Simple Approach for Weakly- and Semi-Supervised Semantic Segmentation</a></dt>\n<dd>\n<form id=\"form-YunchaoWeiRevisitingDilatedConvolution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yunchao Wei\">\n<a href=\"#\" onclick=\"document.getElementById('form-YunchaoWeiRevisitingDilatedConvolution').submit();\">Yunchao Wei</a>,\n</form>\n<form id=\"form-HuaxinXiaoRevisitingDilatedConvolution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huaxin Xiao\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuaxinXiaoRevisitingDilatedConvolution').submit();\">Huaxin Xiao</a>,\n</form>\n<form id=\"form-HonghuiShiRevisitingDilatedConvolution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Honghui Shi\">\n<a href=\"#\" onclick=\"document.getElementById('form-HonghuiShiRevisitingDilatedConvolution').submit();\">Honghui Shi</a>,\n</form>\n<form id=\"form-ZequnJieRevisitingDilatedConvolution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zequn Jie\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZequnJieRevisitingDilatedConvolution').submit();\">Zequn Jie</a>,\n</form>\n<form id=\"form-JiashiFengRevisitingDilatedConvolution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiashi Feng\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiashiFengRevisitingDilatedConvolution').submit();\">Jiashi Feng</a>,\n</form>\n<form id=\"form-ThomasS.RevisitingDilatedConvolution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Thomas S. Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ThomasS.RevisitingDilatedConvolution').submit();\">Thomas S. Huang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wei_Revisiting_Dilated_Convolution_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.04574\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wei_2018_CVPR,<br>\nauthor = {Wei, Yunchao and Xiao, Huaxin and Shi, Honghui and Jie, Zequn and Feng, Jiashi and Huang, Thomas S.},<br>\ntitle = {Revisiting Dilated Convolution: A Simple Approach for Weakly- and Semi-Supervised Semantic Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Low-Shot_Learning_From_CVPR_2018_paper.html\">Low-Shot Learning From Imaginary Data</a></dt>\n<dd>\n<form id=\"form-Yu-XiongWangLowShotLearningFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu-Xiong Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yu-XiongWangLowShotLearningFrom').submit();\">Yu-Xiong Wang</a>,\n</form>\n<form id=\"form-RossGirshickLowShotLearningFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ross Girshick\">\n<a href=\"#\" onclick=\"document.getElementById('form-RossGirshickLowShotLearningFrom').submit();\">Ross Girshick</a>,\n</form>\n<form id=\"form-MartialHebertLowShotLearningFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Martial Hebert\">\n<a href=\"#\" onclick=\"document.getElementById('form-MartialHebertLowShotLearningFrom').submit();\">Martial Hebert</a>,\n</form>\n<form id=\"form-BharathHariharanLowShotLearningFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bharath Hariharan\">\n<a href=\"#\" onclick=\"document.getElementById('form-BharathHariharanLowShotLearningFrom').submit();\">Bharath Hariharan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Low-Shot_Learning_From_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.05401\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Yu-Xiong and Girshick, Ross and Hebert, Martial and Hariharan, Bharath},<br>\ntitle = {Low-Shot Learning From Imaginary Data},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yu_DoubleFusion_Real-Time_Capture_CVPR_2018_paper.html\">DoubleFusion: Real-Time Capture of Human Performances With Inner Body Shapes From a Single Depth Sensor</a></dt>\n<dd>\n<form id=\"form-TaoYuDoubleFusionRealTimeCapture\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tao Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-TaoYuDoubleFusionRealTimeCapture').submit();\">Tao Yu</a>,\n</form>\n<form id=\"form-ZerongZhengDoubleFusionRealTimeCapture\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zerong Zheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZerongZhengDoubleFusionRealTimeCapture').submit();\">Zerong Zheng</a>,\n</form>\n<form id=\"form-KaiwenGuoDoubleFusionRealTimeCapture\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kaiwen Guo\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaiwenGuoDoubleFusionRealTimeCapture').submit();\">Kaiwen Guo</a>,\n</form>\n<form id=\"form-JianhuiZhaoDoubleFusionRealTimeCapture\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianhui Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianhuiZhaoDoubleFusionRealTimeCapture').submit();\">Jianhui Zhao</a>,\n</form>\n<form id=\"form-QionghaiDaiDoubleFusionRealTimeCapture\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qionghai Dai\">\n<a href=\"#\" onclick=\"document.getElementById('form-QionghaiDaiDoubleFusionRealTimeCapture').submit();\">Qionghai Dai</a>,\n</form>\n<form id=\"form-HaoLiDoubleFusionRealTimeCapture\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hao Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaoLiDoubleFusionRealTimeCapture').submit();\">Hao Li</a>,\n</form>\n<form id=\"form-GerardPons-MollDoubleFusionRealTimeCapture\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gerard Pons-Moll\">\n<a href=\"#\" onclick=\"document.getElementById('form-GerardPons-MollDoubleFusionRealTimeCapture').submit();\">Gerard Pons-Moll</a>,\n</form>\n<form id=\"form-YebinLiuDoubleFusionRealTimeCapture\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yebin Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YebinLiuDoubleFusionRealTimeCapture').submit();\">Yebin Liu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yu_DoubleFusion_Real-Time_Capture_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.06023\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yu_2018_CVPR,<br>\nauthor = {Yu, Tao and Zheng, Zerong and Guo, Kaiwen and Zhao, Jianhui and Dai, Qionghai and Li, Hao and Pons-Moll, Gerard and Liu, Yebin},<br>\ntitle = {DoubleFusion: Real-Time Capture of Human Performances With Inner Body Shapes From a Single Depth Sensor},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Guler_DensePose_Dense_Human_CVPR_2018_paper.html\">DensePose: Dense Human Pose Estimation in the Wild</a></dt>\n<dd>\n<form id=\"form-R\u00c4\u00b1zaAlpDensePoseDenseHuman\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"R\u00c4\u00b1za Alp G\u00c3\u00bcler\">\n<a href=\"#\" onclick=\"document.getElementById('form-R\u00c4\u00b1zaAlpDensePoseDenseHuman').submit();\">R\u00c4\u00b1za Alp G\u00c3\u00bcler</a>,\n</form>\n<form id=\"form-NataliaNeverovaDensePoseDenseHuman\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Natalia Neverova\">\n<a href=\"#\" onclick=\"document.getElementById('form-NataliaNeverovaDensePoseDenseHuman').submit();\">Natalia Neverova</a>,\n</form>\n<form id=\"form-IasonasKokkinosDensePoseDenseHuman\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Iasonas Kokkinos\">\n<a href=\"#\" onclick=\"document.getElementById('form-IasonasKokkinosDensePoseDenseHuman').submit();\">Iasonas Kokkinos</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Guler_DensePose_Dense_Human_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.00434\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{G\u00c3\u00bcler_2018_CVPR,<br>\nauthor = {Alp G\u00c3\u00bcler, R\u00c4\u00b1za and Neverova, Natalia and Kokkinos, Iasonas},<br>\ntitle = {DensePose: Dense Human Pose Estimation in the Wild},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Pavlakos_Ordinal_Depth_Supervision_CVPR_2018_paper.html\">Ordinal Depth Supervision for 3D Human Pose Estimation</a></dt>\n<dd>\n<form id=\"form-GeorgiosPavlakosOrdinalDepthSupervision\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Georgios Pavlakos\">\n<a href=\"#\" onclick=\"document.getElementById('form-GeorgiosPavlakosOrdinalDepthSupervision').submit();\">Georgios Pavlakos</a>,\n</form>\n<form id=\"form-XiaoweiZhouOrdinalDepthSupervision\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaowei Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaoweiZhouOrdinalDepthSupervision').submit();\">Xiaowei Zhou</a>,\n</form>\n<form id=\"form-KostasDaniilidisOrdinalDepthSupervision\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kostas Daniilidis\">\n<a href=\"#\" onclick=\"document.getElementById('form-KostasDaniilidisOrdinalDepthSupervision').submit();\">Kostas Daniilidis</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Pavlakos_Ordinal_Depth_Supervision_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3718-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.04095\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Pavlakos_2018_CVPR,<br>\nauthor = {Pavlakos, Georgios and Zhou, Xiaowei and Daniilidis, Kostas},<br>\ntitle = {Ordinal Depth Supervision for 3D Human Pose Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Speciale_Consensus_Maximization_for_CVPR_2018_paper.html\">Consensus Maximization for Semantic Region Correspondences</a></dt>\n<dd>\n<form id=\"form-PabloSpecialeConsensusMaximizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pablo Speciale\">\n<a href=\"#\" onclick=\"document.getElementById('form-PabloSpecialeConsensusMaximizationfor').submit();\">Pablo Speciale</a>,\n</form>\n<form id=\"form-DandaP.ConsensusMaximizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Danda P. Paudel\">\n<a href=\"#\" onclick=\"document.getElementById('form-DandaP.ConsensusMaximizationfor').submit();\">Danda P. Paudel</a>,\n</form>\n<form id=\"form-MartinR.ConsensusMaximizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Martin R. Oswald\">\n<a href=\"#\" onclick=\"document.getElementById('form-MartinR.ConsensusMaximizationfor').submit();\">Martin R. Oswald</a>,\n</form>\n<form id=\"form-HaykoRiemenschneiderConsensusMaximizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hayko Riemenschneider\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaykoRiemenschneiderConsensusMaximizationfor').submit();\">Hayko Riemenschneider</a>,\n</form>\n<form id=\"form-LucVanConsensusMaximizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Luc Van Gool\">\n<a href=\"#\" onclick=\"document.getElementById('form-LucVanConsensusMaximizationfor').submit();\">Luc Van Gool</a>,\n</form>\n<form id=\"form-MarcPollefeysConsensusMaximizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Marc Pollefeys\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarcPollefeysConsensusMaximizationfor').submit();\">Marc Pollefeys</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Speciale_Consensus_Maximization_for_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Speciale_2018_CVPR,<br>\nauthor = {Speciale, Pablo and Paudel, Danda P. and Oswald, Martin R. and Riemenschneider, Hayko and Van Gool, Luc and Pollefeys, Marc},<br>\ntitle = {Consensus Maximization for Semantic Region Correspondences},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Vianello_Robust_Hough_Transform_CVPR_2018_paper.html\">Robust Hough Transform Based 3D Reconstruction From Circular Light Fields</a></dt>\n<dd>\n<form id=\"form-AlessandroVianelloRobustHoughTransform\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alessandro Vianello\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlessandroVianelloRobustHoughTransform').submit();\">Alessandro Vianello</a>,\n</form>\n<form id=\"form-JensAckermannRobustHoughTransform\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jens Ackermann\">\n<a href=\"#\" onclick=\"document.getElementById('form-JensAckermannRobustHoughTransform').submit();\">Jens Ackermann</a>,\n</form>\n<form id=\"form-MaximilianDieboldRobustHoughTransform\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Maximilian Diebold\">\n<a href=\"#\" onclick=\"document.getElementById('form-MaximilianDieboldRobustHoughTransform').submit();\">Maximilian Diebold</a>,\n</form>\n<form id=\"form-BerndJ\u00c3\u00a4hneRobustHoughTransform\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bernd J\u00c3\u00a4hne\">\n<a href=\"#\" onclick=\"document.getElementById('form-BerndJ\u00c3\u00a4hneRobustHoughTransform').submit();\">Bernd J\u00c3\u00a4hne</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Vianello_Robust_Hough_Transform_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Vianello_2018_CVPR,<br>\nauthor = {Vianello, Alessandro and Ackermann, Jens and Diebold, Maximilian and J\u00c3\u00a4hne, Bernd},<br>\ntitle = {Robust Hough Transform Based 3D Reconstruction From Circular Light Fields},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wu_Alive_Caricature_From_CVPR_2018_paper.html\">Alive Caricature From 2D to 3D</a></dt>\n<dd>\n<form id=\"form-QianyiWuAliveCaricatureFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qianyi Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-QianyiWuAliveCaricatureFrom').submit();\">Qianyi Wu</a>,\n</form>\n<form id=\"form-JuyongZhangAliveCaricatureFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Juyong Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JuyongZhangAliveCaricatureFrom').submit();\">Juyong Zhang</a>,\n</form>\n<form id=\"form-Yu-KunLaiAliveCaricatureFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu-Kun Lai\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yu-KunLaiAliveCaricatureFrom').submit();\">Yu-Kun Lai</a>,\n</form>\n<form id=\"form-JianminZhengAliveCaricatureFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianmin Zheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianminZhengAliveCaricatureFrom').submit();\">Jianmin Zheng</a>,\n</form>\n<form id=\"form-JianfeiCaiAliveCaricatureFrom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianfei Cai\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianfeiCaiAliveCaricatureFrom').submit();\">Jianfei Cai</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wu_Alive_Caricature_From_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.06802\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wu_2018_CVPR,<br>\nauthor = {Wu, Qianyi and Zhang, Juyong and Lai, Yu-Kun and Zheng, Jianmin and Cai, Jianfei},<br>\ntitle = {Alive Caricature From 2D to 3D},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tran_Nonlinear_3D_Face_CVPR_2018_paper.html\">Nonlinear 3D Face Morphable Model</a></dt>\n<dd>\n<form id=\"form-LuanTranNonlinear3DFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Luan Tran\">\n<a href=\"#\" onclick=\"document.getElementById('form-LuanTranNonlinear3DFace').submit();\">Luan Tran</a>,\n</form>\n<form id=\"form-XiaomingLiuNonlinear3DFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaoming Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaomingLiuNonlinear3DFace').submit();\">Xiaoming Liu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tran_Nonlinear_3D_Face_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.03786\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tran_2018_CVPR,<br>\nauthor = {Tran, Luan and Liu, Xiaoming},<br>\ntitle = {Nonlinear 3D Face Morphable Model},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhao_Through-Wall_Human_Pose_CVPR_2018_paper.html\">Through-Wall Human Pose Estimation Using Radio Signals</a></dt>\n<dd>\n<form id=\"form-MingminZhaoThroughWallHumanPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mingmin Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingminZhaoThroughWallHumanPose').submit();\">Mingmin Zhao</a>,\n</form>\n<form id=\"form-TianhongLiThroughWallHumanPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tianhong Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-TianhongLiThroughWallHumanPose').submit();\">Tianhong Li</a>,\n</form>\n<form id=\"form-MohammadAbuThroughWallHumanPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mohammad Abu Alsheikh\">\n<a href=\"#\" onclick=\"document.getElementById('form-MohammadAbuThroughWallHumanPose').submit();\">Mohammad Abu Alsheikh</a>,\n</form>\n<form id=\"form-YonglongTianThroughWallHumanPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yonglong Tian\">\n<a href=\"#\" onclick=\"document.getElementById('form-YonglongTianThroughWallHumanPose').submit();\">Yonglong Tian</a>,\n</form>\n<form id=\"form-HangZhaoThroughWallHumanPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hang Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-HangZhaoThroughWallHumanPose').submit();\">Hang Zhao</a>,\n</form>\n<form id=\"form-AntonioTorralbaThroughWallHumanPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Antonio Torralba\">\n<a href=\"#\" onclick=\"document.getElementById('form-AntonioTorralbaThroughWallHumanPose').submit();\">Antonio Torralba</a>,\n</form>\n<form id=\"form-DinaKatabiThroughWallHumanPose\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dina Katabi\">\n<a href=\"#\" onclick=\"document.getElementById('form-DinaKatabiThroughWallHumanPose').submit();\">Dina Katabi</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhao_Through-Wall_Human_Pose_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhao_2018_CVPR,<br>\nauthor = {Zhao, Mingmin and Li, Tianhong and Abu Alsheikh, Mohammad and Tian, Yonglong and Zhao, Hang and Torralba, Antonio and Katabi, Dina},<br>\ntitle = {Through-Wall Human Pose Estimation Using Radio Signals},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Huang_What_Makes_a_CVPR_2018_paper.html\">What Makes a Video a Video: Analyzing Temporal Information in Video Understanding Models and Datasets</a></dt>\n<dd>\n<form id=\"form-De-AnHuangWhatMakesa\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"De-An Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-De-AnHuangWhatMakesa').submit();\">De-An Huang</a>,\n</form>\n<form id=\"form-VigneshRamanathanWhatMakesa\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vignesh Ramanathan\">\n<a href=\"#\" onclick=\"document.getElementById('form-VigneshRamanathanWhatMakesa').submit();\">Vignesh Ramanathan</a>,\n</form>\n<form id=\"form-DhruvMahajanWhatMakesa\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dhruv Mahajan\">\n<a href=\"#\" onclick=\"document.getElementById('form-DhruvMahajanWhatMakesa').submit();\">Dhruv Mahajan</a>,\n</form>\n<form id=\"form-LorenzoTorresaniWhatMakesa\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lorenzo Torresani\">\n<a href=\"#\" onclick=\"document.getElementById('form-LorenzoTorresaniWhatMakesa').submit();\">Lorenzo Torresani</a>,\n</form>\n<form id=\"form-ManoharPaluriWhatMakesa\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Manohar Paluri\">\n<a href=\"#\" onclick=\"document.getElementById('form-ManoharPaluriWhatMakesa').submit();\">Manohar Paluri</a>,\n</form>\n<form id=\"form-LiFei-FeiWhatMakesa\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Li Fei-Fei\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiFei-FeiWhatMakesa').submit();\">Li Fei-Fei</a>,\n</form>\n<form id=\"form-JuanCarlosWhatMakesa\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Juan Carlos Niebles\">\n<a href=\"#\" onclick=\"document.getElementById('form-JuanCarlosWhatMakesa').submit();\">Juan Carlos Niebles</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Huang_What_Makes_a_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Huang_2018_CVPR,<br>\nauthor = {Huang, De-An and Ramanathan, Vignesh and Mahajan, Dhruv and Torresani, Lorenzo and Paluri, Manohar and Fei-Fei, Li and Carlos Niebles, Juan},<br>\ntitle = {What Makes a Video a Video: Analyzing Temporal Information in Video Understanding Models and Datasets},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Oh_Fast_Video_Object_CVPR_2018_paper.html\">Fast Video Object Segmentation by Reference-Guided Mask Propagation</a></dt>\n<dd>\n<form id=\"form-SeoungWugFastVideoObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Seoung Wug Oh\">\n<a href=\"#\" onclick=\"document.getElementById('form-SeoungWugFastVideoObject').submit();\">Seoung Wug Oh</a>,\n</form>\n<form id=\"form-Joon-YoungLeeFastVideoObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Joon-Young Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-Joon-YoungLeeFastVideoObject').submit();\">Joon-Young Lee</a>,\n</form>\n<form id=\"form-KalyanSunkavalliFastVideoObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kalyan Sunkavalli\">\n<a href=\"#\" onclick=\"document.getElementById('form-KalyanSunkavalliFastVideoObject').submit();\">Kalyan Sunkavalli</a>,\n</form>\n<form id=\"form-SeonJooFastVideoObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Seon Joo Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-SeonJooFastVideoObject').submit();\">Seon Joo Kim</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Oh_Fast_Video_Object_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Oh_2018_CVPR,<br>\nauthor = {Wug Oh, Seoung and Lee, Joon-Young and Sunkavalli, Kalyan and Joo Kim, Seon},<br>\ntitle = {Fast Video Object Segmentation by Reference-Guided Mask Propagation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Richard_NeuralNetwork-Viterbi_A_Framework_CVPR_2018_paper.html\">NeuralNetwork-Viterbi: A Framework for Weakly Supervised Video Learning</a></dt>\n<dd>\n<form id=\"form-AlexanderRichardNeuralNetworkViterbiAFramework\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexander Richard\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexanderRichardNeuralNetworkViterbiAFramework').submit();\">Alexander Richard</a>,\n</form>\n<form id=\"form-HildeKuehneNeuralNetworkViterbiAFramework\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hilde Kuehne\">\n<a href=\"#\" onclick=\"document.getElementById('form-HildeKuehneNeuralNetworkViterbiAFramework').submit();\">Hilde Kuehne</a>,\n</form>\n<form id=\"form-AhsanIqbalNeuralNetworkViterbiAFramework\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ahsan Iqbal\">\n<a href=\"#\" onclick=\"document.getElementById('form-AhsanIqbalNeuralNetworkViterbiAFramework').submit();\">Ahsan Iqbal</a>,\n</form>\n<form id=\"form-JuergenGallNeuralNetworkViterbiAFramework\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Juergen Gall\">\n<a href=\"#\" onclick=\"document.getElementById('form-JuergenGallNeuralNetworkViterbiAFramework').submit();\">Juergen Gall</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Richard_NeuralNetwork-Viterbi_A_Framework_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.06875\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Richard_2018_CVPR,<br>\nauthor = {Richard, Alexander and Kuehne, Hilde and Iqbal, Ahsan and Gall, Juergen},<br>\ntitle = {NeuralNetwork-Viterbi: A Framework for Weakly Supervised Video Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sigurdsson_Actor_and_Observer_CVPR_2018_paper.html\">Actor and Observer: Joint Modeling of First and Third-Person Videos</a></dt>\n<dd>\n<form id=\"form-GunnarA.ActorandObserver\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gunnar A. Sigurdsson\">\n<a href=\"#\" onclick=\"document.getElementById('form-GunnarA.ActorandObserver').submit();\">Gunnar A. Sigurdsson</a>,\n</form>\n<form id=\"form-AbhinavGuptaActorandObserver\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Abhinav Gupta\">\n<a href=\"#\" onclick=\"document.getElementById('form-AbhinavGuptaActorandObserver').submit();\">Abhinav Gupta</a>,\n</form>\n<form id=\"form-CordeliaSchmidActorandObserver\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cordelia Schmid\">\n<a href=\"#\" onclick=\"document.getElementById('form-CordeliaSchmidActorandObserver').submit();\">Cordelia Schmid</a>,\n</form>\n<form id=\"form-AliFarhadiActorandObserver\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ali Farhadi\">\n<a href=\"#\" onclick=\"document.getElementById('form-AliFarhadiActorandObserver').submit();\">Ali Farhadi</a>,\n</form>\n<form id=\"form-KarteekAlahariActorandObserver\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Karteek Alahari\">\n<a href=\"#\" onclick=\"document.getElementById('form-KarteekAlahariActorandObserver').submit();\">Karteek Alahari</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sigurdsson_Actor_and_Observer_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1926-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.09627\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sigurdsson_2018_CVPR,<br>\nauthor = {Sigurdsson, Gunnar A. and Gupta, Abhinav and Schmid, Cordelia and Farhadi, Ali and Alahari, Karteek},<br>\ntitle = {Actor and Observer: Joint Modeling of First and Third-Person Videos},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhao_HSA-RNN_Hierarchical_Structure-Adaptive_CVPR_2018_paper.html\">HSA-RNN: Hierarchical Structure-Adaptive RNN for Video Summarization</a></dt>\n<dd>\n<form id=\"form-BinZhaoHSARNNHierarchicalStructureAdaptive\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bin Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-BinZhaoHSARNNHierarchicalStructureAdaptive').submit();\">Bin Zhao</a>,\n</form>\n<form id=\"form-XuelongLiHSARNNHierarchicalStructureAdaptive\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xuelong Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-XuelongLiHSARNNHierarchicalStructureAdaptive').submit();\">Xuelong Li</a>,\n</form>\n<form id=\"form-XiaoqiangLuHSARNNHierarchicalStructureAdaptive\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaoqiang Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaoqiangLuHSARNNHierarchicalStructureAdaptive').submit();\">Xiaoqiang Lu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhao_HSA-RNN_Hierarchical_Structure-Adaptive_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhao_2018_CVPR,<br>\nauthor = {Zhao, Bin and Li, Xuelong and Lu, Xiaoqiang},<br>\ntitle = {HSA-RNN: Hierarchical Structure-Adaptive RNN for Video Summarization},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Cheng_Fast_and_Accurate_CVPR_2018_paper.html\">Fast and Accurate Online Video Object Segmentation via Tracking Parts</a></dt>\n<dd>\n<form id=\"form-JingchunChengFastandAccurate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jingchun Cheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingchunChengFastandAccurate').submit();\">Jingchun Cheng</a>,\n</form>\n<form id=\"form-Yi-HsuanTsaiFastandAccurate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi-Hsuan Tsai\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yi-HsuanTsaiFastandAccurate').submit();\">Yi-Hsuan Tsai</a>,\n</form>\n<form id=\"form-Wei-ChihHungFastandAccurate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei-Chih Hung\">\n<a href=\"#\" onclick=\"document.getElementById('form-Wei-ChihHungFastandAccurate').submit();\">Wei-Chih Hung</a>,\n</form>\n<form id=\"form-ShengjinWangFastandAccurate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shengjin Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShengjinWangFastandAccurate').submit();\">Shengjin Wang</a>,\n</form>\n<form id=\"form-Ming-HsuanYangFastandAccurate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming-Hsuan Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ming-HsuanYangFastandAccurate').submit();\">Ming-Hsuan Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Cheng_Fast_and_Accurate_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0423-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1806.02323\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Cheng_2018_CVPR,<br>\nauthor = {Cheng, Jingchun and Tsai, Yi-Hsuan and Hung, Wei-Chih and Wang, Shengjin and Yang, Ming-Hsuan},<br>\ntitle = {Fast and Accurate Online Video Object Segmentation via Tracking Parts},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhou_Now_You_Shake_CVPR_2018_paper.html\">Now You Shake Me: Towards Automatic 4D Cinema</a></dt>\n<dd>\n<form id=\"form-YuhaoZhouNowYouShake\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuhao Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuhaoZhouNowYouShake').submit();\">Yuhao Zhou</a>,\n</form>\n<form id=\"form-MakarandTapaswiNowYouShake\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Makarand Tapaswi\">\n<a href=\"#\" onclick=\"document.getElementById('form-MakarandTapaswiNowYouShake').submit();\">Makarand Tapaswi</a>,\n</form>\n<form id=\"form-SanjaFidlerNowYouShake\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sanja Fidler\">\n<a href=\"#\" onclick=\"document.getElementById('form-SanjaFidlerNowYouShake').submit();\">Sanja Fidler</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhou_Now_You_Shake_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3330-supp.zip\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhou_2018_CVPR,<br>\nauthor = {Zhou, Yuhao and Tapaswi, Makarand and Fidler, Sanja},<br>\ntitle = {Now You Shake Me: Towards Automatic 4D Cinema},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kanehira_Viewpoint-Aware_Video_Summarization_CVPR_2018_paper.html\">Viewpoint-Aware Video Summarization</a></dt>\n<dd>\n<form id=\"form-AtsushiKanehiraViewpointAwareVideoSummarization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Atsushi Kanehira\">\n<a href=\"#\" onclick=\"document.getElementById('form-AtsushiKanehiraViewpointAwareVideoSummarization').submit();\">Atsushi Kanehira</a>,\n</form>\n<form id=\"form-LucVanViewpointAwareVideoSummarization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Luc Van Gool\">\n<a href=\"#\" onclick=\"document.getElementById('form-LucVanViewpointAwareVideoSummarization').submit();\">Luc Van Gool</a>,\n</form>\n<form id=\"form-YoshitakaUshikuViewpointAwareVideoSummarization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yoshitaka Ushiku\">\n<a href=\"#\" onclick=\"document.getElementById('form-YoshitakaUshikuViewpointAwareVideoSummarization').submit();\">Yoshitaka Ushiku</a>,\n</form>\n<form id=\"form-TatsuyaHaradaViewpointAwareVideoSummarization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tatsuya Harada\">\n<a href=\"#\" onclick=\"document.getElementById('form-TatsuyaHaradaViewpointAwareVideoSummarization').submit();\">Tatsuya Harada</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kanehira_Viewpoint-Aware_Video_Summarization_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2161-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.02843\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kanehira_2018_CVPR,<br>\nauthor = {Kanehira, Atsushi and Van Gool, Luc and Ushiku, Yoshitaka and Harada, Tatsuya},<br>\ntitle = {Viewpoint-Aware Video Summarization},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Fujimura_Photometric_Stereo_in_CVPR_2018_paper.html\">Photometric Stereo in Participating Media Considering Shape-Dependent Forward Scatter</a></dt>\n<dd>\n<form id=\"form-YukiFujimuraPhotometricStereoin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuki Fujimura\">\n<a href=\"#\" onclick=\"document.getElementById('form-YukiFujimuraPhotometricStereoin').submit();\">Yuki Fujimura</a>,\n</form>\n<form id=\"form-MasaakiIiyamaPhotometricStereoin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Masaaki Iiyama\">\n<a href=\"#\" onclick=\"document.getElementById('form-MasaakiIiyamaPhotometricStereoin').submit();\">Masaaki Iiyama</a>,\n</form>\n<form id=\"form-AtsushiHashimotoPhotometricStereoin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Atsushi Hashimoto\">\n<a href=\"#\" onclick=\"document.getElementById('form-AtsushiHashimotoPhotometricStereoin').submit();\">Atsushi Hashimoto</a>,\n</form>\n<form id=\"form-MichihikoMinohPhotometricStereoin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michihiko Minoh\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichihikoMinohPhotometricStereoin').submit();\">Michihiko Minoh</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Fujimura_Photometric_Stereo_in_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.02836\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Fujimura_2018_CVPR,<br>\nauthor = {Fujimura, Yuki and Iiyama, Masaaki and Hashimoto, Atsushi and Minoh, Michihiko},<br>\ntitle = {Photometric Stereo in Participating Media Considering Shape-Dependent Forward Scatter},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hu_Direction-Aware_Spatial_Context_CVPR_2018_paper.html\">Direction-Aware Spatial Context Features for Shadow Detection</a></dt>\n<dd>\n<form id=\"form-XiaoweiHuDirectionAwareSpatialContext\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaowei Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaoweiHuDirectionAwareSpatialContext').submit();\">Xiaowei Hu</a>,\n</form>\n<form id=\"form-LeiZhuDirectionAwareSpatialContext\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lei Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeiZhuDirectionAwareSpatialContext').submit();\">Lei Zhu</a>,\n</form>\n<form id=\"form-Chi-WingFuDirectionAwareSpatialContext\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chi-Wing Fu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Chi-WingFuDirectionAwareSpatialContext').submit();\">Chi-Wing Fu</a>,\n</form>\n<form id=\"form-JingQinDirectionAwareSpatialContext\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jing Qin\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingQinDirectionAwareSpatialContext').submit();\">Jing Qin</a>,\n</form>\n<form id=\"form-Pheng-AnnHengDirectionAwareSpatialContext\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pheng-Ann Heng\">\n<a href=\"#\" onclick=\"document.getElementById('form-Pheng-AnnHengDirectionAwareSpatialContext').submit();\">Pheng-Ann Heng</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hu_Direction-Aware_Spatial_Context_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.04635\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hu_2018_CVPR,<br>\nauthor = {Hu, Xiaowei and Zhu, Lei and Fu, Chi-Wing and Qin, Jing and Heng, Pheng-Ann},<br>\ntitle = {Direction-Aware Spatial Context Features for Shadow Detection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Discriminative_Learning_of_CVPR_2018_paper.html\">Discriminative Learning of Latent Features for Zero-Shot Recognition</a></dt>\n<dd>\n<form id=\"form-YanLiDiscriminativeLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yan Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanLiDiscriminativeLearningof').submit();\">Yan Li</a>,\n</form>\n<form id=\"form-JungeZhangDiscriminativeLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junge Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JungeZhangDiscriminativeLearningof').submit();\">Junge Zhang</a>,\n</form>\n<form id=\"form-JianguoZhangDiscriminativeLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianguo Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianguoZhangDiscriminativeLearningof').submit();\">Jianguo Zhang</a>,\n</form>\n<form id=\"form-KaiqiHuangDiscriminativeLearningof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kaiqi Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaiqiHuangDiscriminativeLearningof').submit();\">Kaiqi Huang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Discriminative_Learning_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2812-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.06731\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Yan and Zhang, Junge and Zhang, Jianguo and Huang, Kaiqi},<br>\ntitle = {Discriminative Learning of Latent Features for Zero-Shot Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tsai_Learning_to_Adapt_CVPR_2018_paper.html\">Learning to Adapt Structured Output Space for Semantic Segmentation</a></dt>\n<dd>\n<form id=\"form-Yi-HsuanTsaiLearningtoAdapt\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi-Hsuan Tsai\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yi-HsuanTsaiLearningtoAdapt').submit();\">Yi-Hsuan Tsai</a>,\n</form>\n<form id=\"form-Wei-ChihHungLearningtoAdapt\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei-Chih Hung\">\n<a href=\"#\" onclick=\"document.getElementById('form-Wei-ChihHungLearningtoAdapt').submit();\">Wei-Chih Hung</a>,\n</form>\n<form id=\"form-SamuelSchulterLearningtoAdapt\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Samuel Schulter\">\n<a href=\"#\" onclick=\"document.getElementById('form-SamuelSchulterLearningtoAdapt').submit();\">Samuel Schulter</a>,\n</form>\n<form id=\"form-KihyukSohnLearningtoAdapt\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kihyuk Sohn\">\n<a href=\"#\" onclick=\"document.getElementById('form-KihyukSohnLearningtoAdapt').submit();\">Kihyuk Sohn</a>,\n</form>\n<form id=\"form-Ming-HsuanYangLearningtoAdapt\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming-Hsuan Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ming-HsuanYangLearningtoAdapt').submit();\">Ming-Hsuan Yang</a>,\n</form>\n<form id=\"form-ManmohanChandrakerLearningtoAdapt\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Manmohan Chandraker\">\n<a href=\"#\" onclick=\"document.getElementById('form-ManmohanChandrakerLearningtoAdapt').submit();\">Manmohan Chandraker</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tsai_Learning_to_Adapt_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1435-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.10349\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tsai_2018_CVPR,<br>\nauthor = {Tsai, Yi-Hsuan and Hung, Wei-Chih and Schulter, Samuel and Sohn, Kihyuk and Yang, Ming-Hsuan and Chandraker, Manmohan},<br>\ntitle = {Learning to Adapt Structured Output Space for Semantic Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kendall_Multi-Task_Learning_Using_CVPR_2018_paper.html\">Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics</a></dt>\n<dd>\n<form id=\"form-AlexKendallMultiTaskLearningUsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alex Kendall\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexKendallMultiTaskLearningUsing').submit();\">Alex Kendall</a>,\n</form>\n<form id=\"form-YarinGalMultiTaskLearningUsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yarin Gal\">\n<a href=\"#\" onclick=\"document.getElementById('form-YarinGalMultiTaskLearningUsing').submit();\">Yarin Gal</a>,\n</form>\n<form id=\"form-RobertoCipollaMultiTaskLearningUsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Roberto Cipolla\">\n<a href=\"#\" onclick=\"document.getElementById('form-RobertoCipollaMultiTaskLearningUsing').submit();\">Roberto Cipolla</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kendall_Multi-Task_Learning_Using_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3022-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1705.07115\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kendall_2018_CVPR,<br>\nauthor = {Kendall, Alex and Gal, Yarin and Cipolla, Roberto},<br>\ntitle = {Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Jointly_Localizing_and_CVPR_2018_paper.html\">Jointly Localizing and Describing Events for Dense Video Captioning</a></dt>\n<dd>\n<form id=\"form-YehaoLiJointlyLocalizingand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yehao Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-YehaoLiJointlyLocalizingand').submit();\">Yehao Li</a>,\n</form>\n<form id=\"form-TingYaoJointlyLocalizingand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ting Yao\">\n<a href=\"#\" onclick=\"document.getElementById('form-TingYaoJointlyLocalizingand').submit();\">Ting Yao</a>,\n</form>\n<form id=\"form-YingweiPanJointlyLocalizingand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yingwei Pan\">\n<a href=\"#\" onclick=\"document.getElementById('form-YingweiPanJointlyLocalizingand').submit();\">Yingwei Pan</a>,\n</form>\n<form id=\"form-HongyangChaoJointlyLocalizingand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hongyang Chao\">\n<a href=\"#\" onclick=\"document.getElementById('form-HongyangChaoJointlyLocalizingand').submit();\">Hongyang Chao</a>,\n</form>\n<form id=\"form-TaoMeiJointlyLocalizingand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tao Mei\">\n<a href=\"#\" onclick=\"document.getElementById('form-TaoMeiJointlyLocalizingand').submit();\">Tao Mei</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Jointly_Localizing_and_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.08274\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Yehao and Yao, Ting and Pan, Yingwei and Chao, Hongyang and Mei, Tao},<br>\ntitle = {Jointly Localizing and Describing Events for Dense Video Captioning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Gorji_Going_From_Image_CVPR_2018_paper.html\">Going From Image to Video Saliency: Augmenting Image Salience With Dynamic Attentional Push</a></dt>\n<dd>\n<form id=\"form-SiavashGorjiGoingFromImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Siavash Gorji\">\n<a href=\"#\" onclick=\"document.getElementById('form-SiavashGorjiGoingFromImage').submit();\">Siavash Gorji</a>,\n</form>\n<form id=\"form-JamesJ.GoingFromImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"James J. Clark\">\n<a href=\"#\" onclick=\"document.getElementById('form-JamesJ.GoingFromImage').submit();\">James J. Clark</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Gorji_Going_From_Image_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Gorji_2018_CVPR,<br>\nauthor = {Gorji, Siavash and Clark, James J.},<br>\ntitle = {Going From Image to Video Saliency: Augmenting Image Salience With Dynamic Attentional Push},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_M3_Multimodal_Memory_CVPR_2018_paper.html\">M3: Multimodal Memory Modelling for Video Captioning</a></dt>\n<dd>\n<form id=\"form-JunboWangM3MultimodalMemory\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junbo Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunboWangM3MultimodalMemory').submit();\">Junbo Wang</a>,\n</form>\n<form id=\"form-WeiWangM3MultimodalMemory\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiWangM3MultimodalMemory').submit();\">Wei Wang</a>,\n</form>\n<form id=\"form-YanHuangM3MultimodalMemory\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yan Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanHuangM3MultimodalMemory').submit();\">Yan Huang</a>,\n</form>\n<form id=\"form-LiangWangM3MultimodalMemory\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiangWangM3MultimodalMemory').submit();\">Liang Wang</a>,\n</form>\n<form id=\"form-TieniuTanM3MultimodalMemory\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tieniu Tan\">\n<a href=\"#\" onclick=\"document.getElementById('form-TieniuTanM3MultimodalMemory').submit();\">Tieniu Tan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_M3_Multimodal_Memory_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Junbo and Wang, Wei and Huang, Yan and Wang, Liang and Tan, Tieniu},<br>\ntitle = {M3: Multimodal Memory Modelling for Video Captioning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Fan_Emotional_Attention_A_CVPR_2018_paper.html\">Emotional Attention: A Study of Image Sentiment and Visual Attention</a></dt>\n<dd>\n<form id=\"form-ShaojingFanEmotionalAttentionA\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shaojing Fan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShaojingFanEmotionalAttentionA').submit();\">Shaojing Fan</a>,\n</form>\n<form id=\"form-ZhiqiShenEmotionalAttentionA\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhiqi Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhiqiShenEmotionalAttentionA').submit();\">Zhiqi Shen</a>,\n</form>\n<form id=\"form-MingJiangEmotionalAttentionA\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming Jiang\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingJiangEmotionalAttentionA').submit();\">Ming Jiang</a>,\n</form>\n<form id=\"form-BryanL.EmotionalAttentionA\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bryan L. Koenig\">\n<a href=\"#\" onclick=\"document.getElementById('form-BryanL.EmotionalAttentionA').submit();\">Bryan L. Koenig</a>,\n</form>\n<form id=\"form-JuanXuEmotionalAttentionA\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Juan Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JuanXuEmotionalAttentionA').submit();\">Juan Xu</a>,\n</form>\n<form id=\"form-MohanS.EmotionalAttentionA\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mohan S. Kankanhalli\">\n<a href=\"#\" onclick=\"document.getElementById('form-MohanS.EmotionalAttentionA').submit();\">Mohan S. Kankanhalli</a>,\n</form>\n<form id=\"form-QiZhaoEmotionalAttentionA\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qi Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiZhaoEmotionalAttentionA').submit();\">Qi Zhao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Fan_Emotional_Attention_A_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2361-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Fan_2018_CVPR,<br>\nauthor = {Fan, Shaojing and Shen, Zhiqi and Jiang, Ming and Koenig, Bryan L. and Xu, Juan and Kankanhalli, Mohan S. and Zhao, Qi},<br>\ntitle = {Emotional Attention: A Study of Image Sentiment and Visual Attention},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Andreopoulos_A_Low_Power_CVPR_2018_paper.html\">A Low Power, High Throughput, Fully Event-Based Stereo System</a></dt>\n<dd>\n<form id=\"form-AlexanderAndreopoulosALowPower\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexander Andreopoulos\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexanderAndreopoulosALowPower').submit();\">Alexander Andreopoulos</a>,\n</form>\n<form id=\"form-HirakJ.ALowPower\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hirak J. Kashyap\">\n<a href=\"#\" onclick=\"document.getElementById('form-HirakJ.ALowPower').submit();\">Hirak J. Kashyap</a>,\n</form>\n<form id=\"form-TapanK.ALowPower\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tapan K. Nayak\">\n<a href=\"#\" onclick=\"document.getElementById('form-TapanK.ALowPower').submit();\">Tapan K. Nayak</a>,\n</form>\n<form id=\"form-ArnonAmirALowPower\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Arnon Amir\">\n<a href=\"#\" onclick=\"document.getElementById('form-ArnonAmirALowPower').submit();\">Arnon Amir</a>,\n</form>\n<form id=\"form-MyronD.ALowPower\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Myron D. Flickner\">\n<a href=\"#\" onclick=\"document.getElementById('form-MyronD.ALowPower').submit();\">Myron D. Flickner</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Andreopoulos_A_Low_Power_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3791-supp.zip\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Andreopoulos_2018_CVPR,<br>\nauthor = {Andreopoulos, Alexander and Kashyap, Hirak J. and Nayak, Tapan K. and Amir, Arnon and Flickner, Myron D.},<br>\ntitle = {A Low Power, High Throughput, Fully Event-Based Stereo System},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Han_VITON_An_Image-Based_CVPR_2018_paper.html\">VITON: An Image-Based Virtual Try-On Network</a></dt>\n<dd>\n<form id=\"form-XintongHanVITONAnImageBased\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xintong Han\">\n<a href=\"#\" onclick=\"document.getElementById('form-XintongHanVITONAnImageBased').submit();\">Xintong Han</a>,\n</form>\n<form id=\"form-ZuxuanWuVITONAnImageBased\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zuxuan Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZuxuanWuVITONAnImageBased').submit();\">Zuxuan Wu</a>,\n</form>\n<form id=\"form-ZheWuVITONAnImageBased\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhe Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZheWuVITONAnImageBased').submit();\">Zhe Wu</a>,\n</form>\n<form id=\"form-RuichiYuVITONAnImageBased\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ruichi Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-RuichiYuVITONAnImageBased').submit();\">Ruichi Yu</a>,\n</form>\n<form id=\"form-LarryS.VITONAnImageBased\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Larry S. Davis\">\n<a href=\"#\" onclick=\"document.getElementById('form-LarryS.VITONAnImageBased').submit();\">Larry S. Davis</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Han_VITON_An_Image-Based_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0406-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.08447\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Han_2018_CVPR,<br>\nauthor = {Han, Xintong and Wu, Zuxuan and Wu, Zhe and Yu, Ruichi and Davis, Larry S.},<br>\ntitle = {VITON: An Image-Based Virtual Try-On Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lyu_Multi-Oriented_Scene_Text_CVPR_2018_paper.html\">Multi-Oriented Scene Text Detection via Corner Localization and Region Segmentation</a></dt>\n<dd>\n<form id=\"form-PengyuanLyuMultiOrientedSceneText\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pengyuan Lyu\">\n<a href=\"#\" onclick=\"document.getElementById('form-PengyuanLyuMultiOrientedSceneText').submit();\">Pengyuan Lyu</a>,\n</form>\n<form id=\"form-CongYaoMultiOrientedSceneText\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cong Yao\">\n<a href=\"#\" onclick=\"document.getElementById('form-CongYaoMultiOrientedSceneText').submit();\">Cong Yao</a>,\n</form>\n<form id=\"form-WenhaoWuMultiOrientedSceneText\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenhao Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenhaoWuMultiOrientedSceneText').submit();\">Wenhao Wu</a>,\n</form>\n<form id=\"form-ShuichengYanMultiOrientedSceneText\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuicheng Yan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuichengYanMultiOrientedSceneText').submit();\">Shuicheng Yan</a>,\n</form>\n<form id=\"form-XiangBaiMultiOrientedSceneText\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiang Bai\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiangBaiMultiOrientedSceneText').submit();\">Xiang Bai</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lyu_Multi-Oriented_Scene_Text_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.08948\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lyu_2018_CVPR,<br>\nauthor = {Lyu, Pengyuan and Yao, Cong and Wu, Wenhao and Yan, Shuicheng and Bai, Xiang},<br>\ntitle = {Multi-Oriented Scene Text Detection via Corner Localization and Region Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Azadi_Multi-Content_GAN_for_CVPR_2018_paper.html\">Multi-Content GAN for Few-Shot Font Style Transfer</a></dt>\n<dd>\n<form id=\"form-SamanehAzadiMultiContentGANfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Samaneh Azadi\">\n<a href=\"#\" onclick=\"document.getElementById('form-SamanehAzadiMultiContentGANfor').submit();\">Samaneh Azadi</a>,\n</form>\n<form id=\"form-MatthewFisherMultiContentGANfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Matthew Fisher\">\n<a href=\"#\" onclick=\"document.getElementById('form-MatthewFisherMultiContentGANfor').submit();\">Matthew Fisher</a>,\n</form>\n<form id=\"form-VladimirG.MultiContentGANfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vladimir G. Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-VladimirG.MultiContentGANfor').submit();\">Vladimir G. Kim</a>,\n</form>\n<form id=\"form-ZhaowenWangMultiContentGANfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhaowen Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhaowenWangMultiContentGANfor').submit();\">Zhaowen Wang</a>,\n</form>\n<form id=\"form-EliShechtmanMultiContentGANfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Eli Shechtman\">\n<a href=\"#\" onclick=\"document.getElementById('form-EliShechtmanMultiContentGANfor').submit();\">Eli Shechtman</a>,\n</form>\n<form id=\"form-TrevorDarrellMultiContentGANfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Trevor Darrell\">\n<a href=\"#\" onclick=\"document.getElementById('form-TrevorDarrellMultiContentGANfor').submit();\">Trevor Darrell</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Azadi_Multi-Content_GAN_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2342-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.00516\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Azadi_2018_CVPR,<br>\nauthor = {Azadi, Samaneh and Fisher, Matthew and Kim, Vladimir G. and Wang, Zhaowen and Shechtman, Eli and Darrell, Trevor},<br>\ntitle = {Multi-Content GAN for Few-Shot Font Style Transfer},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Shlizerman_Audio_to_Body_CVPR_2018_paper.html\">Audio to Body Dynamics</a></dt>\n<dd>\n<form id=\"form-EliShlizermanAudiotoBody\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Eli Shlizerman\">\n<a href=\"#\" onclick=\"document.getElementById('form-EliShlizermanAudiotoBody').submit();\">Eli Shlizerman</a>,\n</form>\n<form id=\"form-LucioDeryAudiotoBody\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lucio Dery\">\n<a href=\"#\" onclick=\"document.getElementById('form-LucioDeryAudiotoBody').submit();\">Lucio Dery</a>,\n</form>\n<form id=\"form-HaydenSchoenAudiotoBody\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hayden Schoen\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaydenSchoenAudiotoBody').submit();\">Hayden Schoen</a>,\n</form>\n<form id=\"form-IraKemelmacher-ShlizermanAudiotoBody\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ira Kemelmacher-Shlizerman\">\n<a href=\"#\" onclick=\"document.getElementById('form-IraKemelmacher-ShlizermanAudiotoBody').submit();\">Ira Kemelmacher-Shlizerman</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Shlizerman_Audio_to_Body_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.09382\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Shlizerman_2018_CVPR,<br>\nauthor = {Shlizerman, Eli and Dery, Lucio and Schoen, Hayden and Kemelmacher-Shlizerman, Ira},<br>\ntitle = {Audio to Body Dynamics},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yang_Weakly_Supervised_Coupled_CVPR_2018_paper.html\">Weakly Supervised Coupled Networks for Visual Sentiment Analysis</a></dt>\n<dd>\n<form id=\"form-JufengYangWeaklySupervisedCoupled\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jufeng Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JufengYangWeaklySupervisedCoupled').submit();\">Jufeng Yang</a>,\n</form>\n<form id=\"form-DongyuSheWeaklySupervisedCoupled\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dongyu She\">\n<a href=\"#\" onclick=\"document.getElementById('form-DongyuSheWeaklySupervisedCoupled').submit();\">Dongyu She</a>,\n</form>\n<form id=\"form-Yu-KunLaiWeaklySupervisedCoupled\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu-Kun Lai\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yu-KunLaiWeaklySupervisedCoupled').submit();\">Yu-Kun Lai</a>,\n</form>\n<form id=\"form-PaulL.WeaklySupervisedCoupled\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Paul L. Rosin\">\n<a href=\"#\" onclick=\"document.getElementById('form-PaulL.WeaklySupervisedCoupled').submit();\">Paul L. Rosin</a>,\n</form>\n<form id=\"form-Ming-HsuanYangWeaklySupervisedCoupled\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming-Hsuan Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ming-HsuanYangWeaklySupervisedCoupled').submit();\">Ming-Hsuan Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yang_Weakly_Supervised_Coupled_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yang_2018_CVPR,<br>\nauthor = {Yang, Jufeng and She, Dongyu and Lai, Yu-Kun and Rosin, Paul L. and Yang, Ming-Hsuan},<br>\ntitle = {Weakly Supervised Coupled Networks for Visual Sentiment Analysis},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yagi_Future_Person_Localization_CVPR_2018_paper.html\">Future Person Localization in First-Person Videos</a></dt>\n<dd>\n<form id=\"form-TakumaYagiFuturePersonLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Takuma Yagi\">\n<a href=\"#\" onclick=\"document.getElementById('form-TakumaYagiFuturePersonLocalization').submit();\">Takuma Yagi</a>,\n</form>\n<form id=\"form-KarttikeyaMangalamFuturePersonLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Karttikeya Mangalam\">\n<a href=\"#\" onclick=\"document.getElementById('form-KarttikeyaMangalamFuturePersonLocalization').submit();\">Karttikeya Mangalam</a>,\n</form>\n<form id=\"form-RyoYonetaniFuturePersonLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ryo Yonetani\">\n<a href=\"#\" onclick=\"document.getElementById('form-RyoYonetaniFuturePersonLocalization').submit();\">Ryo Yonetani</a>,\n</form>\n<form id=\"form-YoichiSatoFuturePersonLocalization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yoichi Sato\">\n<a href=\"#\" onclick=\"document.getElementById('form-YoichiSatoFuturePersonLocalization').submit();\">Yoichi Sato</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yagi_Future_Person_Localization_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2895-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.11217\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yagi_2018_CVPR,<br>\nauthor = {Yagi, Takuma and Mangalam, Karttikeya and Yonetani, Ryo and Sato, Yoichi},<br>\ntitle = {Future Person Localization in First-Person Videos},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Annadani_Preserving_Semantic_Relations_CVPR_2018_paper.html\">Preserving Semantic Relations for Zero-Shot Learning</a></dt>\n<dd>\n<form id=\"form-YashasAnnadaniPreservingSemanticRelations\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yashas Annadani\">\n<a href=\"#\" onclick=\"document.getElementById('form-YashasAnnadaniPreservingSemanticRelations').submit();\">Yashas Annadani</a>,\n</form>\n<form id=\"form-SomaBiswasPreservingSemanticRelations\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Soma Biswas\">\n<a href=\"#\" onclick=\"document.getElementById('form-SomaBiswasPreservingSemanticRelations').submit();\">Soma Biswas</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Annadani_Preserving_Semantic_Relations_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.03049\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Annadani_2018_CVPR,<br>\nauthor = {Annadani, Yashas and Biswas, Soma},<br>\ntitle = {Preserving Semantic Relations for Zero-Shot Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ravi_Show_Me_a_CVPR_2018_paper.html\">Show Me a Story: Towards Coherent Neural Story Illustration</a></dt>\n<dd>\n<form id=\"form-HareeshRaviShowMea\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hareesh Ravi\">\n<a href=\"#\" onclick=\"document.getElementById('form-HareeshRaviShowMea').submit();\">Hareesh Ravi</a>,\n</form>\n<form id=\"form-LeziWangShowMea\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lezi Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeziWangShowMea').submit();\">Lezi Wang</a>,\n</form>\n<form id=\"form-CarlosMunizShowMea\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Carlos Muniz\">\n<a href=\"#\" onclick=\"document.getElementById('form-CarlosMunizShowMea').submit();\">Carlos Muniz</a>,\n</form>\n<form id=\"form-LeonidSigalShowMea\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Leonid Sigal\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeonidSigalShowMea').submit();\">Leonid Sigal</a>,\n</form>\n<form id=\"form-DimitrisMetaxasShowMea\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dimitris Metaxas\">\n<a href=\"#\" onclick=\"document.getElementById('form-DimitrisMetaxasShowMea').submit();\">Dimitris Metaxas</a>,\n</form>\n<form id=\"form-MubbasirKapadiaShowMea\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mubbasir Kapadia\">\n<a href=\"#\" onclick=\"document.getElementById('form-MubbasirKapadiaShowMea').submit();\">Mubbasir Kapadia</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ravi_Show_Me_a_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ravi_2018_CVPR,<br>\nauthor = {Ravi, Hareesh and Wang, Lezi and Muniz, Carlos and Sigal, Leonid and Metaxas, Dimitris and Kapadia, Mubbasir},<br>\ntitle = {Show Me a Story: Towards Coherent Neural Story Illustration},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Reconstruction_Network_for_CVPR_2018_paper.html\">Reconstruction Network for Video Captioning</a></dt>\n<dd>\n<form id=\"form-BairuiWangReconstructionNetworkfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bairui Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-BairuiWangReconstructionNetworkfor').submit();\">Bairui Wang</a>,\n</form>\n<form id=\"form-LinMaReconstructionNetworkfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lin Ma\">\n<a href=\"#\" onclick=\"document.getElementById('form-LinMaReconstructionNetworkfor').submit();\">Lin Ma</a>,\n</form>\n<form id=\"form-WeiZhangReconstructionNetworkfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiZhangReconstructionNetworkfor').submit();\">Wei Zhang</a>,\n</form>\n<form id=\"form-WeiLiuReconstructionNetworkfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiLiuReconstructionNetworkfor').submit();\">Wei Liu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Reconstruction_Network_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.11438\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Bairui and Ma, Lin and Zhang, Wei and Liu, Wei},<br>\ntitle = {Reconstruction Network for Video Captioning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Iscen_Fast_Spectral_Ranking_CVPR_2018_paper.html\">Fast Spectral Ranking for Similarity Search</a></dt>\n<dd>\n<form id=\"form-AhmetIscenFastSpectralRanking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ahmet Iscen\">\n<a href=\"#\" onclick=\"document.getElementById('form-AhmetIscenFastSpectralRanking').submit();\">Ahmet Iscen</a>,\n</form>\n<form id=\"form-YannisAvrithisFastSpectralRanking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yannis Avrithis\">\n<a href=\"#\" onclick=\"document.getElementById('form-YannisAvrithisFastSpectralRanking').submit();\">Yannis Avrithis</a>,\n</form>\n<form id=\"form-GiorgosToliasFastSpectralRanking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Giorgos Tolias\">\n<a href=\"#\" onclick=\"document.getElementById('form-GiorgosToliasFastSpectralRanking').submit();\">Giorgos Tolias</a>,\n</form>\n<form id=\"form-TeddyFuronFastSpectralRanking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Teddy Furon\">\n<a href=\"#\" onclick=\"document.getElementById('form-TeddyFuronFastSpectralRanking').submit();\">Teddy Furon</a>,\n</form>\n<form id=\"form-Ond\u00c5\u0099ejChumFastSpectralRanking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ond\u00c5\u0099ej Chum\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ond\u00c5\u0099ejChumFastSpectralRanking').submit();\">Ond\u00c5\u0099ej Chum</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Iscen_Fast_Spectral_Ranking_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1703.06935\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Iscen_2018_CVPR,<br>\nauthor = {Iscen, Ahmet and Avrithis, Yannis and Tolias, Giorgos and Furon, Teddy and Chum, Ond\u00c5\u0099ej},<br>\ntitle = {Fast Spectral Ranking for Similarity Search},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Iscen_Mining_on_Manifolds_CVPR_2018_paper.html\">Mining on Manifolds: Metric Learning Without Labels</a></dt>\n<dd>\n<form id=\"form-AhmetIscenMiningonManifolds\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ahmet Iscen\">\n<a href=\"#\" onclick=\"document.getElementById('form-AhmetIscenMiningonManifolds').submit();\">Ahmet Iscen</a>,\n</form>\n<form id=\"form-GiorgosToliasMiningonManifolds\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Giorgos Tolias\">\n<a href=\"#\" onclick=\"document.getElementById('form-GiorgosToliasMiningonManifolds').submit();\">Giorgos Tolias</a>,\n</form>\n<form id=\"form-YannisAvrithisMiningonManifolds\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yannis Avrithis\">\n<a href=\"#\" onclick=\"document.getElementById('form-YannisAvrithisMiningonManifolds').submit();\">Yannis Avrithis</a>,\n</form>\n<form id=\"form-Ond\u00c5\u0099ejChumMiningonManifolds\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ond\u00c5\u0099ej Chum\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ond\u00c5\u0099ejChumMiningonManifolds').submit();\">Ond\u00c5\u0099ej Chum</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Iscen_Mining_on_Manifolds_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.11095\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Iscen_2018_CVPR,<br>\nauthor = {Iscen, Ahmet and Tolias, Giorgos and Avrithis, Yannis and Chum, Ond\u00c5\u0099ej},<br>\ntitle = {Mining on Manifolds: Metric Learning Without Labels},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yang_PIXOR_Real-Time_3D_CVPR_2018_paper.html\">PIXOR: Real-Time 3D Object Detection From Point Clouds</a></dt>\n<dd>\n<form id=\"form-BinYangPIXORRealTime3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bin Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-BinYangPIXORRealTime3D').submit();\">Bin Yang</a>,\n</form>\n<form id=\"form-WenjieLuoPIXORRealTime3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenjie Luo\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenjieLuoPIXORRealTime3D').submit();\">Wenjie Luo</a>,\n</form>\n<form id=\"form-RaquelUrtasunPIXORRealTime3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Raquel Urtasun\">\n<a href=\"#\" onclick=\"document.getElementById('form-RaquelUrtasunPIXORRealTime3D').submit();\">Raquel Urtasun</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yang_PIXOR_Real-Time_3D_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yang_2018_CVPR,<br>\nauthor = {Yang, Bin and Luo, Wenjie and Urtasun, Raquel},<br>\ntitle = {PIXOR: Real-Time 3D Object Detection From Point Clouds},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_Leveraging_Unlabeled_Data_CVPR_2018_paper.html\">Leveraging Unlabeled Data for Crowd Counting by Learning to Rank</a></dt>\n<dd>\n<form id=\"form-XialeiLiuLeveragingUnlabeledData\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xialei Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XialeiLiuLeveragingUnlabeledData').submit();\">Xialei Liu</a>,\n</form>\n<form id=\"form-JoostvanLeveragingUnlabeledData\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Joost van de Weijer\">\n<a href=\"#\" onclick=\"document.getElementById('form-JoostvanLeveragingUnlabeledData').submit();\">Joost van de Weijer</a>,\n</form>\n<form id=\"form-AndrewD.LeveragingUnlabeledData\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrew D. Bagdanov\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndrewD.LeveragingUnlabeledData').submit();\">Andrew D. Bagdanov</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_Leveraging_Unlabeled_Data_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.03095\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Xialei and van de Weijer, Joost and Bagdanov, Andrew D.},<br>\ntitle = {Leveraging Unlabeled Data for Crowd Counting by Learning to Rank},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Zero-Shot_Kernel_Learning_CVPR_2018_paper.html\">Zero-Shot Kernel Learning</a></dt>\n<dd>\n<form id=\"form-HongguangZhangZeroShotKernelLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hongguang Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HongguangZhangZeroShotKernelLearning').submit();\">Hongguang Zhang</a>,\n</form>\n<form id=\"form-PiotrKoniuszZeroShotKernelLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Piotr Koniusz\">\n<a href=\"#\" onclick=\"document.getElementById('form-PiotrKoniuszZeroShotKernelLearning').submit();\">Piotr Koniusz</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Zero-Shot_Kernel_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3242-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.01279\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Hongguang and Koniusz, Piotr},<br>\ntitle = {Zero-Shot Kernel Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Patro_Differential_Attention_for_CVPR_2018_paper.html\">Differential Attention for Visual Question Answering</a></dt>\n<dd>\n<form id=\"form-BadriPatroDifferentialAttentionfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Badri Patro\">\n<a href=\"#\" onclick=\"document.getElementById('form-BadriPatroDifferentialAttentionfor').submit();\">Badri Patro</a>,\n</form>\n<form id=\"form-VinayP.DifferentialAttentionfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vinay P. Namboodiri\">\n<a href=\"#\" onclick=\"document.getElementById('form-VinayP.DifferentialAttentionfor').submit();\">Vinay P. Namboodiri</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Patro_Differential_Attention_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3451-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00298\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Patro_2018_CVPR,<br>\nauthor = {Patro, Badri and Namboodiri, Vinay P.},<br>\ntitle = {Differential Attention for Visual Question Answering},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Niu_Learning_From_Noisy_CVPR_2018_paper.html\">Learning From Noisy Web Data With Category-Level Supervision</a></dt>\n<dd>\n<form id=\"form-LiNiuLearningFromNoisy\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Li Niu\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiNiuLearningFromNoisy').submit();\">Li Niu</a>,\n</form>\n<form id=\"form-QingtaoTangLearningFromNoisy\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qingtao Tang\">\n<a href=\"#\" onclick=\"document.getElementById('form-QingtaoTangLearningFromNoisy').submit();\">Qingtao Tang</a>,\n</form>\n<form id=\"form-AshokVeeraraghavanLearningFromNoisy\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ashok Veeraraghavan\">\n<a href=\"#\" onclick=\"document.getElementById('form-AshokVeeraraghavanLearningFromNoisy').submit();\">Ashok Veeraraghavan</a>,\n</form>\n<form id=\"form-AshutoshSabharwalLearningFromNoisy\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ashutosh Sabharwal\">\n<a href=\"#\" onclick=\"document.getElementById('form-AshutoshSabharwalLearningFromNoisy').submit();\">Ashutosh Sabharwal</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Niu_Learning_From_Noisy_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.03857\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Niu_2018_CVPR,<br>\nauthor = {Niu, Li and Tang, Qingtao and Veeraraghavan, Ashok and Sabharwal, Ashutosh},<br>\ntitle = {Learning From Noisy Web Data With Category-Level Supervision},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ramanishka_Toward_Driving_Scene_CVPR_2018_paper.html\">Toward Driving Scene Understanding: A Dataset for Learning Driver Behavior and Causal Reasoning</a></dt>\n<dd>\n<form id=\"form-VasiliRamanishkaTowardDrivingScene\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vasili Ramanishka\">\n<a href=\"#\" onclick=\"document.getElementById('form-VasiliRamanishkaTowardDrivingScene').submit();\">Vasili Ramanishka</a>,\n</form>\n<form id=\"form-Yi-TingChenTowardDrivingScene\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi-Ting Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yi-TingChenTowardDrivingScene').submit();\">Yi-Ting Chen</a>,\n</form>\n<form id=\"form-TeruhisaMisuTowardDrivingScene\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Teruhisa Misu\">\n<a href=\"#\" onclick=\"document.getElementById('form-TeruhisaMisuTowardDrivingScene').submit();\">Teruhisa Misu</a>,\n</form>\n<form id=\"form-KateSaenkoTowardDrivingScene\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kate Saenko\">\n<a href=\"#\" onclick=\"document.getElementById('form-KateSaenkoTowardDrivingScene').submit();\">Kate Saenko</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ramanishka_Toward_Driving_Scene_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ramanishka_2018_CVPR,<br>\nauthor = {Ramanishka, Vasili and Chen, Yi-Ting and Misu, Teruhisa and Saenko, Kate},<br>\ntitle = {Toward Driving Scene Understanding: A Dataset for Learning Driver Behavior and Causal Reasoning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ak_Learning_Attribute_Representations_CVPR_2018_paper.html\">Learning Attribute Representations With Localization for Flexible Fashion Search</a></dt>\n<dd>\n<form id=\"form-KenanE.LearningAttributeRepresentations\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kenan E. Ak\">\n<a href=\"#\" onclick=\"document.getElementById('form-KenanE.LearningAttributeRepresentations').submit();\">Kenan E. Ak</a>,\n</form>\n<form id=\"form-AshrafA.LearningAttributeRepresentations\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ashraf A. Kassim\">\n<a href=\"#\" onclick=\"document.getElementById('form-AshrafA.LearningAttributeRepresentations').submit();\">Ashraf A. Kassim</a>,\n</form>\n<form id=\"form-JooHweeLearningAttributeRepresentations\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Joo Hwee Lim\">\n<a href=\"#\" onclick=\"document.getElementById('form-JooHweeLearningAttributeRepresentations').submit();\">Joo Hwee Lim</a>,\n</form>\n<form id=\"form-JoYewLearningAttributeRepresentations\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jo Yew Tham\">\n<a href=\"#\" onclick=\"document.getElementById('form-JoYewLearningAttributeRepresentations').submit();\">Jo Yew Tham</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ak_Learning_Attribute_Representations_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3878-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ak_2018_CVPR,<br>\nauthor = {Ak, Kenan E. and Kassim, Ashraf A. and Hwee Lim, Joo and Yew Tham, Jo},<br>\ntitle = {Learning Attribute Representations With Localization for Flexible Fashion Search},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wehrmann_Bidirectional_Retrieval_Made_CVPR_2018_paper.html\">Bidirectional Retrieval Made Simple</a></dt>\n<dd>\n<form id=\"form-J\u00c3\u00b4natasWehrmannBidirectionalRetrievalMade\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"J\u00c3\u00b4natas Wehrmann\">\n<a href=\"#\" onclick=\"document.getElementById('form-J\u00c3\u00b4natasWehrmannBidirectionalRetrievalMade').submit();\">J\u00c3\u00b4natas Wehrmann</a>,\n</form>\n<form id=\"form-RodrigoC.BidirectionalRetrievalMade\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rodrigo C. Barros\">\n<a href=\"#\" onclick=\"document.getElementById('form-RodrigoC.BidirectionalRetrievalMade').submit();\">Rodrigo C. Barros</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wehrmann_Bidirectional_Retrieval_Made_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wehrmann_2018_CVPR,<br>\nauthor = {Wehrmann, J\u00c3\u00b4natas and Barros, Rodrigo C.},<br>\ntitle = {Bidirectional Retrieval Made Simple},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_Learning_Multi-Instance_Enriched_CVPR_2018_paper.html\">Learning Multi-Instance Enriched Image Representations via Non-Greedy Ratio Maximization of the l1-Norm Distances</a></dt>\n<dd>\n<form id=\"form-KaiLiuLearningMultiInstanceEnriched\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kai Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaiLiuLearningMultiInstanceEnriched').submit();\">Kai Liu</a>,\n</form>\n<form id=\"form-HuaWangLearningMultiInstanceEnriched\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hua Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuaWangLearningMultiInstanceEnriched').submit();\">Hua Wang</a>,\n</form>\n<form id=\"form-FeipingNieLearningMultiInstanceEnriched\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Feiping Nie\">\n<a href=\"#\" onclick=\"document.getElementById('form-FeipingNieLearningMultiInstanceEnriched').submit();\">Feiping Nie</a>,\n</form>\n<form id=\"form-HaoZhangLearningMultiInstanceEnriched\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hao Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaoZhangLearningMultiInstanceEnriched').submit();\">Hao Zhang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_Learning_Multi-Instance_Enriched_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Kai and Wang, Hua and Nie, Feiping and Zhang, Hao},<br>\ntitle = {Learning Multi-Instance Enriched Image Representations via Non-Greedy Ratio Maximization of the l1-Norm Distances},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Su_Learning_Visual_Knowledge_CVPR_2018_paper.html\">Learning Visual Knowledge Memory Networks for Visual Question Answering</a></dt>\n<dd>\n<form id=\"form-ZhouSuLearningVisualKnowledge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhou Su\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhouSuLearningVisualKnowledge').submit();\">Zhou Su</a>,\n</form>\n<form id=\"form-ChenZhuLearningVisualKnowledge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chen Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenZhuLearningVisualKnowledge').submit();\">Chen Zhu</a>,\n</form>\n<form id=\"form-YinpengDongLearningVisualKnowledge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yinpeng Dong\">\n<a href=\"#\" onclick=\"document.getElementById('form-YinpengDongLearningVisualKnowledge').submit();\">Yinpeng Dong</a>,\n</form>\n<form id=\"form-DongqiCaiLearningVisualKnowledge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dongqi Cai\">\n<a href=\"#\" onclick=\"document.getElementById('form-DongqiCaiLearningVisualKnowledge').submit();\">Dongqi Cai</a>,\n</form>\n<form id=\"form-YurongChenLearningVisualKnowledge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yurong Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-YurongChenLearningVisualKnowledge').submit();\">Yurong Chen</a>,\n</form>\n<form id=\"form-JianguoLiLearningVisualKnowledge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianguo Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianguoLiLearningVisualKnowledge').submit();\">Jianguo Li</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Su_Learning_Visual_Knowledge_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1806.04860\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Su_2018_CVPR,<br>\nauthor = {Su, Zhou and Zhu, Chen and Dong, Yinpeng and Cai, Dongqi and Chen, Yurong and Li, Jianguo},<br>\ntitle = {Learning Visual Knowledge Memory Networks for Visual Question Answering},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Deng_Visual_Grounding_via_CVPR_2018_paper.html\">Visual Grounding via Accumulated Attention</a></dt>\n<dd>\n<form id=\"form-ChaoruiDengVisualGroundingvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chaorui Deng\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChaoruiDengVisualGroundingvia').submit();\">Chaorui Deng</a>,\n</form>\n<form id=\"form-QiWuVisualGroundingvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qi Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiWuVisualGroundingvia').submit();\">Qi Wu</a>,\n</form>\n<form id=\"form-QingyaoWuVisualGroundingvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qingyao Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-QingyaoWuVisualGroundingvia').submit();\">Qingyao Wu</a>,\n</form>\n<form id=\"form-FuyuanHuVisualGroundingvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fuyuan Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-FuyuanHuVisualGroundingvia').submit();\">Fuyuan Hu</a>,\n</form>\n<form id=\"form-FanLyuVisualGroundingvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fan Lyu\">\n<a href=\"#\" onclick=\"document.getElementById('form-FanLyuVisualGroundingvia').submit();\">Fan Lyu</a>,\n</form>\n<form id=\"form-MingkuiTanVisualGroundingvia\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mingkui Tan\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingkuiTanVisualGroundingvia').submit();\">Mingkui Tan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Deng_Visual_Grounding_via_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Deng_2018_CVPR,<br>\nauthor = {Deng, Chaorui and Wu, Qi and Wu, Qingyao and Hu, Fuyuan and Lyu, Fan and Tan, Mingkui},<br>\ntitle = {Visual Grounding via Accumulated Attention},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Song_Beyond_Trade-Off_Accelerate_CVPR_2018_paper.html\">Beyond Trade-Off: Accelerate FCN-Based Face Detector With Higher Accuracy</a></dt>\n<dd>\n<form id=\"form-GuangluSongBeyondTradeOffAccelerate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guanglu Song\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuangluSongBeyondTradeOffAccelerate').submit();\">Guanglu Song</a>,\n</form>\n<form id=\"form-YuLiuBeyondTradeOffAccelerate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuLiuBeyondTradeOffAccelerate').submit();\">Yu Liu</a>,\n</form>\n<form id=\"form-MingJiangBeyondTradeOffAccelerate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming Jiang\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingJiangBeyondTradeOffAccelerate').submit();\">Ming Jiang</a>,\n</form>\n<form id=\"form-YujieWangBeyondTradeOffAccelerate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yujie Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YujieWangBeyondTradeOffAccelerate').submit();\">Yujie Wang</a>,\n</form>\n<form id=\"form-JunjieYanBeyondTradeOffAccelerate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junjie Yan\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunjieYanBeyondTradeOffAccelerate').submit();\">Junjie Yan</a>,\n</form>\n<form id=\"form-BiaoLengBeyondTradeOffAccelerate\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Biao Leng\">\n<a href=\"#\" onclick=\"document.getElementById('form-BiaoLengBeyondTradeOffAccelerate').submit();\">Biao Leng</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Song_Beyond_Trade-Off_Accelerate_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.05197\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Song_2018_CVPR,<br>\nauthor = {Song, Guanglu and Liu, Yu and Jiang, Ming and Wang, Yujie and Yan, Junjie and Leng, Biao},<br>\ntitle = {Beyond Trade-Off: Accelerate FCN-Based Face Detector With Higher Accuracy},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Mallya_PackNet_Adding_Multiple_CVPR_2018_paper.html\">PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning</a></dt>\n<dd>\n<form id=\"form-ArunMallyaPackNetAddingMultiple\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Arun Mallya\">\n<a href=\"#\" onclick=\"document.getElementById('form-ArunMallyaPackNetAddingMultiple').submit();\">Arun Mallya</a>,\n</form>\n<form id=\"form-SvetlanaLazebnikPackNetAddingMultiple\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Svetlana Lazebnik\">\n<a href=\"#\" onclick=\"document.getElementById('form-SvetlanaLazebnikPackNetAddingMultiple').submit();\">Svetlana Lazebnik</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Mallya_PackNet_Adding_Multiple_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.05769\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Mallya_2018_CVPR,<br>\nauthor = {Mallya, Arun and Lazebnik, Svetlana},<br>\ntitle = {PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Repulsion_Loss_Detecting_CVPR_2018_paper.html\">Repulsion Loss: Detecting Pedestrians in a Crowd</a></dt>\n<dd>\n<form id=\"form-XinlongWangRepulsionLossDetecting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xinlong Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinlongWangRepulsionLossDetecting').submit();\">Xinlong Wang</a>,\n</form>\n<form id=\"form-TeteXiaoRepulsionLossDetecting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tete Xiao\">\n<a href=\"#\" onclick=\"document.getElementById('form-TeteXiaoRepulsionLossDetecting').submit();\">Tete Xiao</a>,\n</form>\n<form id=\"form-YuningJiangRepulsionLossDetecting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuning Jiang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuningJiangRepulsionLossDetecting').submit();\">Yuning Jiang</a>,\n</form>\n<form id=\"form-ShuaiShaoRepulsionLossDetecting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuai Shao\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuaiShaoRepulsionLossDetecting').submit();\">Shuai Shao</a>,\n</form>\n<form id=\"form-JianSunRepulsionLossDetecting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jian Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianSunRepulsionLossDetecting').submit();\">Jian Sun</a>,\n</form>\n<form id=\"form-ChunhuaShenRepulsionLossDetecting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chunhua Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChunhuaShenRepulsionLossDetecting').submit();\">Chunhua Shen</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Repulsion_Loss_Detecting_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1247-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.07752\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Xinlong and Xiao, Tete and Jiang, Yuning and Shao, Shuai and Sun, Jian and Shen, Chunhua},<br>\ntitle = {Repulsion Loss: Detecting Pedestrians in a Crowd},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Camgoz_Neural_Sign_Language_CVPR_2018_paper.html\">Neural Sign Language Translation</a></dt>\n<dd>\n<form id=\"form-NecatiCihanNeuralSignLanguage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Necati Cihan Camgoz\">\n<a href=\"#\" onclick=\"document.getElementById('form-NecatiCihanNeuralSignLanguage').submit();\">Necati Cihan Camgoz</a>,\n</form>\n<form id=\"form-SimonHadfieldNeuralSignLanguage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Simon Hadfield\">\n<a href=\"#\" onclick=\"document.getElementById('form-SimonHadfieldNeuralSignLanguage').submit();\">Simon Hadfield</a>,\n</form>\n<form id=\"form-OscarKollerNeuralSignLanguage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Oscar Koller\">\n<a href=\"#\" onclick=\"document.getElementById('form-OscarKollerNeuralSignLanguage').submit();\">Oscar Koller</a>,\n</form>\n<form id=\"form-HermannNeyNeuralSignLanguage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hermann Ney\">\n<a href=\"#\" onclick=\"document.getElementById('form-HermannNeyNeuralSignLanguage').submit();\">Hermann Ney</a>,\n</form>\n<form id=\"form-RichardBowdenNeuralSignLanguage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Richard Bowden\">\n<a href=\"#\" onclick=\"document.getElementById('form-RichardBowdenNeuralSignLanguage').submit();\">Richard Bowden</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Camgoz_Neural_Sign_Language_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Camgoz_2018_CVPR,<br>\nauthor = {Cihan Camgoz, Necati and Hadfield, Simon and Koller, Oscar and Ney, Hermann and Bowden, Richard},<br>\ntitle = {Neural Sign Language Translation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Non-Local_Neural_Networks_CVPR_2018_paper.html\">Non-Local Neural Networks</a></dt>\n<dd>\n<form id=\"form-XiaolongWangNonLocalNeuralNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaolong Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaolongWangNonLocalNeuralNetworks').submit();\">Xiaolong Wang</a>,\n</form>\n<form id=\"form-RossGirshickNonLocalNeuralNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ross Girshick\">\n<a href=\"#\" onclick=\"document.getElementById('form-RossGirshickNonLocalNeuralNetworks').submit();\">Ross Girshick</a>,\n</form>\n<form id=\"form-AbhinavGuptaNonLocalNeuralNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Abhinav Gupta\">\n<a href=\"#\" onclick=\"document.getElementById('form-AbhinavGuptaNonLocalNeuralNetworks').submit();\">Abhinav Gupta</a>,\n</form>\n<form id=\"form-KaimingHeNonLocalNeuralNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kaiming He\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaimingHeNonLocalNeuralNetworks').submit();\">Kaiming He</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Non-Local_Neural_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.10158\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Xiaolong and Girshick, Ross and Gupta, Abhinav and He, Kaiming},<br>\ntitle = {Non-Local Neural Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Baraldi_LAMV_Learning_to_CVPR_2018_paper.html\">LAMV: Learning to Align and Match Videos With Kernelized Temporal Layers</a></dt>\n<dd>\n<form id=\"form-LorenzoBaraldiLAMVLearningto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lorenzo Baraldi\">\n<a href=\"#\" onclick=\"document.getElementById('form-LorenzoBaraldiLAMVLearningto').submit();\">Lorenzo Baraldi</a>,\n</form>\n<form id=\"form-MatthijsDouzeLAMVLearningto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Matthijs Douze\">\n<a href=\"#\" onclick=\"document.getElementById('form-MatthijsDouzeLAMVLearningto').submit();\">Matthijs Douze</a>,\n</form>\n<form id=\"form-RitaCucchiaraLAMVLearningto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rita Cucchiara\">\n<a href=\"#\" onclick=\"document.getElementById('form-RitaCucchiaraLAMVLearningto').submit();\">Rita Cucchiara</a>,\n</form>\n<form id=\"form-Herv\u00c3\u00a9J\u00c3\u00a9gouLAMVLearningto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Herv\u00c3\u00a9 J\u00c3\u00a9gou\">\n<a href=\"#\" onclick=\"document.getElementById('form-Herv\u00c3\u00a9J\u00c3\u00a9gouLAMVLearningto').submit();\">Herv\u00c3\u00a9 J\u00c3\u00a9gou</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Baraldi_LAMV_Learning_to_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Baraldi_2018_CVPR,<br>\nauthor = {Baraldi, Lorenzo and Douze, Matthijs and Cucchiara, Rita and J\u00c3\u00a9gou, Herv\u00c3\u00a9},<br>\ntitle = {LAMV: Learning to Align and Match Videos With Kernelized Temporal Layers},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_Optimizing_Video_Object_CVPR_2018_paper.html\">Optimizing Video Object Detection via a Scale-Time Lattice</a></dt>\n<dd>\n<form id=\"form-KaiChenOptimizingVideoObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kai Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaiChenOptimizingVideoObject').submit();\">Kai Chen</a>,\n</form>\n<form id=\"form-JiaqiWangOptimizingVideoObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiaqi Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiaqiWangOptimizingVideoObject').submit();\">Jiaqi Wang</a>,\n</form>\n<form id=\"form-ShuoYangOptimizingVideoObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuo Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuoYangOptimizingVideoObject').submit();\">Shuo Yang</a>,\n</form>\n<form id=\"form-XingchengZhangOptimizingVideoObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xingcheng Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XingchengZhangOptimizingVideoObject').submit();\">Xingcheng Zhang</a>,\n</form>\n<form id=\"form-YuanjunXiongOptimizingVideoObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuanjun Xiong\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuanjunXiongOptimizingVideoObject').submit();\">Yuanjun Xiong</a>,\n</form>\n<form id=\"form-ChenChangeOptimizingVideoObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chen Change Loy\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenChangeOptimizingVideoObject').submit();\">Chen Change Loy</a>,\n</form>\n<form id=\"form-DahuaLinOptimizingVideoObject\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dahua Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-DahuaLinOptimizingVideoObject').submit();\">Dahua Lin</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_Optimizing_Video_Object_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.05472\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Kai and Wang, Jiaqi and Yang, Shuo and Zhang, Xingcheng and Xiong, Yuanjun and Change Loy, Chen and Lin, Dahua},<br>\ntitle = {Optimizing Video Object Detection via a Scale-Time Lattice},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Su_Learning_Compressible_360deg_CVPR_2018_paper.html\">Learning Compressible 360\u00c2\u00b0 Video Isomers</a></dt>\n<dd>\n<form id=\"form-Yu-ChuanSuLearningCompressible360\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu-Chuan Su\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yu-ChuanSuLearningCompressible360').submit();\">Yu-Chuan Su</a>,\n</form>\n<form id=\"form-KristenGraumanLearningCompressible360\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kristen Grauman\">\n<a href=\"#\" onclick=\"document.getElementById('form-KristenGraumanLearningCompressible360').submit();\">Kristen Grauman</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Su_Learning_Compressible_360deg_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2839-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Su_2018_CVPR,<br>\nauthor = {Su, Yu-Chuan and Grauman, Kristen},<br>\ntitle = {Learning Compressible 360\u00c2\u00b0 Video Isomers},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Long_Attention_Clusters_Purely_CVPR_2018_paper.html\">Attention Clusters: Purely Attention Based Local Feature Integration for Video Classification</a></dt>\n<dd>\n<form id=\"form-XiangLongAttentionClustersPurely\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiang Long\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiangLongAttentionClustersPurely').submit();\">Xiang Long</a>,\n</form>\n<form id=\"form-ChuangGanAttentionClustersPurely\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chuang Gan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChuangGanAttentionClustersPurely').submit();\">Chuang Gan</a>,\n</form>\n<form id=\"form-GerarddeAttentionClustersPurely\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gerard de Melo\">\n<a href=\"#\" onclick=\"document.getElementById('form-GerarddeAttentionClustersPurely').submit();\">Gerard de Melo</a>,\n</form>\n<form id=\"form-JiajunWuAttentionClustersPurely\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiajun Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiajunWuAttentionClustersPurely').submit();\">Jiajun Wu</a>,\n</form>\n<form id=\"form-XiaoLiuAttentionClustersPurely\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiao Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaoLiuAttentionClustersPurely').submit();\">Xiao Liu</a>,\n</form>\n<form id=\"form-ShileiWenAttentionClustersPurely\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shilei Wen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShileiWenAttentionClustersPurely').submit();\">Shilei Wen</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Long_Attention_Clusters_Purely_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2195-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.09550\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Long_2018_CVPR,<br>\nauthor = {Long, Xiang and Gan, Chuang and de Melo, Gerard and Wu, Jiajun and Liu, Xiao and Wen, Shilei},<br>\ntitle = {Attention Clusters: Purely Attention Based Local Feature Integration for Video Classification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Feichtenhofer_What_Have_We_CVPR_2018_paper.html\">What Have We Learned From Deep Representations for Action Recognition?</a></dt>\n<dd>\n<form id=\"form-ChristophFeichtenhoferWhatHaveWe\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Christoph Feichtenhofer\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChristophFeichtenhoferWhatHaveWe').submit();\">Christoph Feichtenhofer</a>,\n</form>\n<form id=\"form-AxelPinzWhatHaveWe\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Axel Pinz\">\n<a href=\"#\" onclick=\"document.getElementById('form-AxelPinzWhatHaveWe').submit();\">Axel Pinz</a>,\n</form>\n<form id=\"form-RichardP.WhatHaveWe\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Richard P. Wildes\">\n<a href=\"#\" onclick=\"document.getElementById('form-RichardP.WhatHaveWe').submit();\">Richard P. Wildes</a>,\n</form>\n<form id=\"form-AndrewZissermanWhatHaveWe\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrew Zisserman\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndrewZissermanWhatHaveWe').submit();\">Andrew Zisserman</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Feichtenhofer_What_Have_We_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Feichtenhofer_2018_CVPR,<br>\nauthor = {Feichtenhofer, Christoph and Pinz, Axel and Wildes, Richard P. and Zisserman, Andrew},<br>\ntitle = {What Have We Learned From Deep Representations for Action Recognition?},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hao_Controllable_Video_Generation_CVPR_2018_paper.html\">Controllable Video Generation With Sparse Trajectories</a></dt>\n<dd>\n<form id=\"form-ZekunHaoControllableVideoGeneration\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zekun Hao\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZekunHaoControllableVideoGeneration').submit();\">Zekun Hao</a>,\n</form>\n<form id=\"form-XunHuangControllableVideoGeneration\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xun Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XunHuangControllableVideoGeneration').submit();\">Xun Huang</a>,\n</form>\n<form id=\"form-SergeBelongieControllableVideoGeneration\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Serge Belongie\">\n<a href=\"#\" onclick=\"document.getElementById('form-SergeBelongieControllableVideoGeneration').submit();\">Serge Belongie</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hao_Controllable_Video_Generation_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hao_2018_CVPR,<br>\nauthor = {Hao, Zekun and Huang, Xun and Belongie, Serge},<br>\ntitle = {Controllable Video Generation With Sparse Trajectories},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Park_Representing_and_Learning_CVPR_2018_paper.html\">Representing and Learning High Dimensional Data With the Optimal Transport Map From a Probabilistic Viewpoint</a></dt>\n<dd>\n<form id=\"form-SerimParkRepresentingandLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Serim Park\">\n<a href=\"#\" onclick=\"document.getElementById('form-SerimParkRepresentingandLearning').submit();\">Serim Park</a>,\n</form>\n<form id=\"form-MatthewThorpeRepresentingandLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Matthew Thorpe\">\n<a href=\"#\" onclick=\"document.getElementById('form-MatthewThorpeRepresentingandLearning').submit();\">Matthew Thorpe</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Park_Representing_and_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Park_2018_CVPR,<br>\nauthor = {Park, Serim and Thorpe, Matthew},<br>\ntitle = {Representing and Learning High Dimensional Data With the Optimal Transport Map From a Probabilistic Viewpoint},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tung_CLIP-Q_Deep_Network_CVPR_2018_paper.html\">CLIP-Q: Deep Network Compression Learning by In-Parallel Pruning-Quantization</a></dt>\n<dd>\n<form id=\"form-FrederickTungCLIPQDeepNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Frederick Tung\">\n<a href=\"#\" onclick=\"document.getElementById('form-FrederickTungCLIPQDeepNetwork').submit();\">Frederick Tung</a>,\n</form>\n<form id=\"form-GregMoriCLIPQDeepNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Greg Mori\">\n<a href=\"#\" onclick=\"document.getElementById('form-GregMoriCLIPQDeepNetwork').submit();\">Greg Mori</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tung_CLIP-Q_Deep_Network_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tung_2018_CVPR,<br>\nauthor = {Tung, Frederick and Mori, Greg},<br>\ntitle = {CLIP-Q: Deep Network Compression Learning by In-Parallel Pruning-Quantization},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Shanu_Inference_in_Higher_CVPR_2018_paper.html\">Inference in Higher Order MRF-MAP Problems With Small and Large Cliques</a></dt>\n<dd>\n<form id=\"form-IshantShanuInferenceinHigher\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ishant Shanu\">\n<a href=\"#\" onclick=\"document.getElementById('form-IshantShanuInferenceinHigher').submit();\">Ishant Shanu</a>,\n</form>\n<form id=\"form-ChetanAroraInferenceinHigher\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chetan Arora\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChetanAroraInferenceinHigher').submit();\">Chetan Arora</a>,\n</form>\n<form id=\"form-S.N.MaheshwariInferenceinHigher\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"S.N. Maheshwari\">\n<a href=\"#\" onclick=\"document.getElementById('form-S.N.MaheshwariInferenceinHigher').submit();\">S.N. Maheshwari</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Shanu_Inference_in_Higher_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Shanu_2018_CVPR,<br>\nauthor = {Shanu, Ishant and Arora, Chetan and Maheshwari, S.N.},<br>\ntitle = {Inference in Higher Order MRF-MAP Problems With Small and Large Cliques},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_ROAD_Reality_Oriented_CVPR_2018_paper.html\">ROAD: Reality Oriented Adaptation for Semantic Segmentation of Urban Scenes</a></dt>\n<dd>\n<form id=\"form-YuhuaChenROADRealityOriented\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuhua Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuhuaChenROADRealityOriented').submit();\">Yuhua Chen</a>,\n</form>\n<form id=\"form-WenLiROADRealityOriented\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wen Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenLiROADRealityOriented').submit();\">Wen Li</a>,\n</form>\n<form id=\"form-LucVanROADRealityOriented\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Luc Van Gool\">\n<a href=\"#\" onclick=\"document.getElementById('form-LucVanROADRealityOriented').submit();\">Luc Van Gool</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_ROAD_Reality_Oriented_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.11556\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Yuhua and Li, Wen and Van Gool, Luc},<br>\ntitle = {ROAD: Reality Oriented Adaptation for Semantic Segmentation of Urban Scenes},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Dolhansky_Eye_In-Painting_With_CVPR_2018_paper.html\">Eye In-Painting With Exemplar Generative Adversarial Networks</a></dt>\n<dd>\n<form id=\"form-BrianDolhanskyEyeInPaintingWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Brian Dolhansky\">\n<a href=\"#\" onclick=\"document.getElementById('form-BrianDolhanskyEyeInPaintingWith').submit();\">Brian Dolhansky</a>,\n</form>\n<form id=\"form-CristianCantonEyeInPaintingWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cristian Canton Ferrer\">\n<a href=\"#\" onclick=\"document.getElementById('form-CristianCantonEyeInPaintingWith').submit();\">Cristian Canton Ferrer</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Dolhansky_Eye_In-Painting_With_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.03999\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Dolhansky_2018_CVPR,<br>\nauthor = {Dolhansky, Brian and Canton Ferrer, Cristian},<br>\ntitle = {Eye In-Painting With Exemplar Generative Adversarial Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_ClcNet_Improving_the_CVPR_2018_paper.html\">ClcNet: Improving the Efficiency of Convolutional Neural Network Using Channel Local Convolutions</a></dt>\n<dd>\n<form id=\"form-Dong-QingZhangClcNetImprovingthe\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dong-Qing Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Dong-QingZhangClcNetImprovingthe').submit();\">Dong-Qing Zhang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_ClcNet_Improving_the_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.06145\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Dong-Qing},<br>\ntitle = {ClcNet: Improving the Efficiency of Convolutional Neural Network Using Channel Local Convolutions},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhuang_Towards_Effective_Low-Bitwidth_CVPR_2018_paper.html\">Towards Effective Low-Bitwidth Convolutional Neural Networks</a></dt>\n<dd>\n<form id=\"form-BohanZhuangTowardsEffectiveLowBitwidth\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bohan Zhuang\">\n<a href=\"#\" onclick=\"document.getElementById('form-BohanZhuangTowardsEffectiveLowBitwidth').submit();\">Bohan Zhuang</a>,\n</form>\n<form id=\"form-ChunhuaShenTowardsEffectiveLowBitwidth\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chunhua Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChunhuaShenTowardsEffectiveLowBitwidth').submit();\">Chunhua Shen</a>,\n</form>\n<form id=\"form-MingkuiTanTowardsEffectiveLowBitwidth\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mingkui Tan\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingkuiTanTowardsEffectiveLowBitwidth').submit();\">Mingkui Tan</a>,\n</form>\n<form id=\"form-LingqiaoLiuTowardsEffectiveLowBitwidth\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lingqiao Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-LingqiaoLiuTowardsEffectiveLowBitwidth').submit();\">Lingqiao Liu</a>,\n</form>\n<form id=\"form-IanReidTowardsEffectiveLowBitwidth\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ian Reid\">\n<a href=\"#\" onclick=\"document.getElementById('form-IanReidTowardsEffectiveLowBitwidth').submit();\">Ian Reid</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhuang_Towards_Effective_Low-Bitwidth_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.00205\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhuang_2018_CVPR,<br>\nauthor = {Zhuang, Bohan and Shen, Chunhua and Tan, Mingkui and Liu, Lingqiao and Reid, Ian},<br>\ntitle = {Towards Effective Low-Bitwidth Convolutional Neural Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kuen_Stochastic_Downsampling_for_CVPR_2018_paper.html\">Stochastic Downsampling for Cost-Adjustable Inference and Improved Regularization in Convolutional Networks</a></dt>\n<dd>\n<form id=\"form-JasonKuenStochasticDownsamplingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jason Kuen\">\n<a href=\"#\" onclick=\"document.getElementById('form-JasonKuenStochasticDownsamplingfor').submit();\">Jason Kuen</a>,\n</form>\n<form id=\"form-XiangfeiKongStochasticDownsamplingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiangfei Kong\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiangfeiKongStochasticDownsamplingfor').submit();\">Xiangfei Kong</a>,\n</form>\n<form id=\"form-ZheLinStochasticDownsamplingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhe Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZheLinStochasticDownsamplingfor').submit();\">Zhe Lin</a>,\n</form>\n<form id=\"form-GangWangStochasticDownsamplingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-GangWangStochasticDownsamplingfor').submit();\">Gang Wang</a>,\n</form>\n<form id=\"form-JianxiongYinStochasticDownsamplingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianxiong Yin\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianxiongYinStochasticDownsamplingfor').submit();\">Jianxiong Yin</a>,\n</form>\n<form id=\"form-SimonSeeStochasticDownsamplingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Simon See\">\n<a href=\"#\" onclick=\"document.getElementById('form-SimonSeeStochasticDownsamplingfor').submit();\">Simon See</a>,\n</form>\n<form id=\"form-Yap-PengTanStochasticDownsamplingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yap-Peng Tan\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yap-PengTanStochasticDownsamplingfor').submit();\">Yap-Peng Tan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kuen_Stochastic_Downsampling_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.09335\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kuen_2018_CVPR,<br>\nauthor = {Kuen, Jason and Kong, Xiangfei and Lin, Zhe and Wang, Gang and Yin, Jianxiong and See, Simon and Tan, Yap-Peng},<br>\ntitle = {Stochastic Downsampling for Cost-Adjustable Inference and Improved Regularization in Convolutional Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Face_Aging_With_CVPR_2018_paper.html\">Face Aging With Identity-Preserved Conditional Generative Adversarial Networks</a></dt>\n<dd>\n<form id=\"form-ZongweiWangFaceAgingWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zongwei Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZongweiWangFaceAgingWith').submit();\">Zongwei Wang</a>,\n</form>\n<form id=\"form-XuTangFaceAgingWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xu Tang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XuTangFaceAgingWith').submit();\">Xu Tang</a>,\n</form>\n<form id=\"form-WeixinLuoFaceAgingWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weixin Luo\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeixinLuoFaceAgingWith').submit();\">Weixin Luo</a>,\n</form>\n<form id=\"form-ShenghuaGaoFaceAgingWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shenghua Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShenghuaGaoFaceAgingWith').submit();\">Shenghua Gao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Face_Aging_With_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Zongwei and Tang, Xu and Luo, Weixin and Gao, Shenghua},<br>\ntitle = {Face Aging With Identity-Preserved Conditional Generative Adversarial Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lv_Unsupervised_Cross-Dataset_Person_CVPR_2018_paper.html\">Unsupervised Cross-Dataset Person Re-Identification by Transfer Learning of Spatial-Temporal Patterns</a></dt>\n<dd>\n<form id=\"form-JianmingLvUnsupervisedCrossDatasetPerson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianming Lv\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianmingLvUnsupervisedCrossDatasetPerson').submit();\">Jianming Lv</a>,\n</form>\n<form id=\"form-WeihangChenUnsupervisedCrossDatasetPerson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weihang Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeihangChenUnsupervisedCrossDatasetPerson').submit();\">Weihang Chen</a>,\n</form>\n<form id=\"form-QingLiUnsupervisedCrossDatasetPerson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qing Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-QingLiUnsupervisedCrossDatasetPerson').submit();\">Qing Li</a>,\n</form>\n<form id=\"form-CanYangUnsupervisedCrossDatasetPerson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Can Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-CanYangUnsupervisedCrossDatasetPerson').submit();\">Can Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lv_Unsupervised_Cross-Dataset_Person_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0779-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.07293\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lv_2018_CVPR,<br>\nauthor = {Lv, Jianming and Chen, Weihang and Li, Qing and Yang, Can},<br>\ntitle = {Unsupervised Cross-Dataset Person Re-Identification by Transfer Learning of Spatial-Temporal Patterns},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sun_Feature_Quantization_for_CVPR_2018_paper.html\">Feature Quantization for Defending Against Distortion of Images</a></dt>\n<dd>\n<form id=\"form-ZhunSunFeatureQuantizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhun Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhunSunFeatureQuantizationfor').submit();\">Zhun Sun</a>,\n</form>\n<form id=\"form-MeteOzayFeatureQuantizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mete Ozay\">\n<a href=\"#\" onclick=\"document.getElementById('form-MeteOzayFeatureQuantizationfor').submit();\">Mete Ozay</a>,\n</form>\n<form id=\"form-YanZhangFeatureQuantizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yan Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanZhangFeatureQuantizationfor').submit();\">Yan Zhang</a>,\n</form>\n<form id=\"form-XingLiuFeatureQuantizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xing Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XingLiuFeatureQuantizationfor').submit();\">Xing Liu</a>,\n</form>\n<form id=\"form-TakayukiOkataniFeatureQuantizationfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Takayuki Okatani\">\n<a href=\"#\" onclick=\"document.getElementById('form-TakayukiOkataniFeatureQuantizationfor').submit();\">Takayuki Okatani</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sun_Feature_Quantization_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1001-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sun_2018_CVPR,<br>\nauthor = {Sun, Zhun and Ozay, Mete and Zhang, Yan and Liu, Xing and Okatani, Takayuki},<br>\ntitle = {Feature Quantization for Defending Against Distortion of Images},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wu_Tagging_Like_Humans_CVPR_2018_paper.html\">Tagging Like Humans: Diverse and Distinct Image Annotation</a></dt>\n<dd>\n<form id=\"form-BaoyuanWuTaggingLikeHumans\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Baoyuan Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-BaoyuanWuTaggingLikeHumans').submit();\">Baoyuan Wu</a>,\n</form>\n<form id=\"form-WeidongChenTaggingLikeHumans\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weidong Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeidongChenTaggingLikeHumans').submit();\">Weidong Chen</a>,\n</form>\n<form id=\"form-PengSunTaggingLikeHumans\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peng Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-PengSunTaggingLikeHumans').submit();\">Peng Sun</a>,\n</form>\n<form id=\"form-WeiLiuTaggingLikeHumans\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiLiuTaggingLikeHumans').submit();\">Wei Liu</a>,\n</form>\n<form id=\"form-BernardGhanemTaggingLikeHumans\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bernard Ghanem\">\n<a href=\"#\" onclick=\"document.getElementById('form-BernardGhanemTaggingLikeHumans').submit();\">Bernard Ghanem</a>,\n</form>\n<form id=\"form-SiweiLyuTaggingLikeHumans\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Siwei Lyu\">\n<a href=\"#\" onclick=\"document.getElementById('form-SiweiLyuTaggingLikeHumans').submit();\">Siwei Lyu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wu_Tagging_Like_Humans_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1182-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00113\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wu_2018_CVPR,<br>\nauthor = {Wu, Baoyuan and Chen, Weidong and Sun, Peng and Liu, Wei and Ghanem, Bernard and Lyu, Siwei},<br>\ntitle = {Tagging Like Humans: Diverse and Distinct Image Annotation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_Re-Weighted_Adversarial_Adaptation_CVPR_2018_paper.html\">Re-Weighted Adversarial Adaptation Network for Unsupervised Domain Adaptation</a></dt>\n<dd>\n<form id=\"form-QingchaoChenReWeightedAdversarialAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qingchao Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-QingchaoChenReWeightedAdversarialAdaptation').submit();\">Qingchao Chen</a>,\n</form>\n<form id=\"form-YangLiuReWeightedAdversarialAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yang Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YangLiuReWeightedAdversarialAdaptation').submit();\">Yang Liu</a>,\n</form>\n<form id=\"form-ZhaowenWangReWeightedAdversarialAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhaowen Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhaowenWangReWeightedAdversarialAdaptation').submit();\">Zhaowen Wang</a>,\n</form>\n<form id=\"form-IanWassellReWeightedAdversarialAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ian Wassell\">\n<a href=\"#\" onclick=\"document.getElementById('form-IanWassellReWeightedAdversarialAdaptation').submit();\">Ian Wassell</a>,\n</form>\n<form id=\"form-KevinChettyReWeightedAdversarialAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kevin Chetty\">\n<a href=\"#\" onclick=\"document.getElementById('form-KevinChettyReWeightedAdversarialAdaptation').submit();\">Kevin Chetty</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_Re-Weighted_Adversarial_Adaptation_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Qingchao and Liu, Yang and Wang, Zhaowen and Wassell, Ian and Chetty, Kevin},<br>\ntitle = {Re-Weighted Adversarial Adaptation Network for Unsupervised Domain Adaptation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hong_Inferring_Semantic_Layout_CVPR_2018_paper.html\">Inferring Semantic Layout for Hierarchical Text-to-Image Synthesis</a></dt>\n<dd>\n<form id=\"form-SeunghoonHongInferringSemanticLayout\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Seunghoon Hong\">\n<a href=\"#\" onclick=\"document.getElementById('form-SeunghoonHongInferringSemanticLayout').submit();\">Seunghoon Hong</a>,\n</form>\n<form id=\"form-DingdongYangInferringSemanticLayout\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dingdong Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-DingdongYangInferringSemanticLayout').submit();\">Dingdong Yang</a>,\n</form>\n<form id=\"form-JongwookChoiInferringSemanticLayout\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jongwook Choi\">\n<a href=\"#\" onclick=\"document.getElementById('form-JongwookChoiInferringSemanticLayout').submit();\">Jongwook Choi</a>,\n</form>\n<form id=\"form-HonglakLeeInferringSemanticLayout\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Honglak Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-HonglakLeeInferringSemanticLayout').submit();\">Honglak Lee</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hong_Inferring_Semantic_Layout_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.05091\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hong_2018_CVPR,<br>\nauthor = {Hong, Seunghoon and Yang, Dingdong and Choi, Jongwook and Lee, Honglak},<br>\ntitle = {Inferring Semantic Layout for Hierarchical Text-to-Image Synthesis},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_Regularizing_RNNs_for_CVPR_2018_paper.html\">Regularizing RNNs for Caption Generation by Reconstructing the Past With the Present</a></dt>\n<dd>\n<form id=\"form-XinpengChenRegularizingRNNsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xinpeng Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinpengChenRegularizingRNNsfor').submit();\">Xinpeng Chen</a>,\n</form>\n<form id=\"form-LinMaRegularizingRNNsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lin Ma\">\n<a href=\"#\" onclick=\"document.getElementById('form-LinMaRegularizingRNNsfor').submit();\">Lin Ma</a>,\n</form>\n<form id=\"form-WenhaoJiangRegularizingRNNsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenhao Jiang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenhaoJiangRegularizingRNNsfor').submit();\">Wenhao Jiang</a>,\n</form>\n<form id=\"form-JianYaoRegularizingRNNsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jian Yao\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianYaoRegularizingRNNsfor').submit();\">Jian Yao</a>,\n</form>\n<form id=\"form-WeiLiuRegularizingRNNsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiLiuRegularizingRNNsfor').submit();\">Wei Liu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_Regularizing_RNNs_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.11439\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Xinpeng and Ma, Lin and Jiang, Wenhao and Yao, Jian and Liu, Wei},<br>\ntitle = {Regularizing RNNs for Caption Generation by Reconstructing the Past With the Present},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Pinheiro_Unsupervised_Domain_Adaptation_CVPR_2018_paper.html\">Unsupervised Domain Adaptation With Similarity Learning</a></dt>\n<dd>\n<form id=\"form-PedroO.UnsupervisedDomainAdaptation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pedro O. Pinheiro\">\n<a href=\"#\" onclick=\"document.getElementById('form-PedroO.UnsupervisedDomainAdaptation').submit();\">Pedro O. Pinheiro</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Pinheiro_Unsupervised_Domain_Adaptation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.08995\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Pinheiro_2018_CVPR,<br>\nauthor = {Pinheiro, Pedro O.},<br>\ntitle = {Unsupervised Domain Adaptation With Similarity Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Muhammad_Learning_Deep_Sketch_CVPR_2018_paper.html\">Learning Deep Sketch Abstraction</a></dt>\n<dd>\n<form id=\"form-UmarRiazLearningDeepSketch\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Umar Riaz Muhammad\">\n<a href=\"#\" onclick=\"document.getElementById('form-UmarRiazLearningDeepSketch').submit();\">Umar Riaz Muhammad</a>,\n</form>\n<form id=\"form-YongxinYangLearningDeepSketch\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yongxin Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YongxinYangLearningDeepSketch').submit();\">Yongxin Yang</a>,\n</form>\n<form id=\"form-Yi-ZheSongLearningDeepSketch\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi-Zhe Song\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yi-ZheSongLearningDeepSketch').submit();\">Yi-Zhe Song</a>,\n</form>\n<form id=\"form-TaoXiangLearningDeepSketch\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tao Xiang\">\n<a href=\"#\" onclick=\"document.getElementById('form-TaoXiangLearningDeepSketch').submit();\">Tao Xiang</a>,\n</form>\n<form id=\"form-TimothyM.LearningDeepSketch\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Timothy M. Hospedales\">\n<a href=\"#\" onclick=\"document.getElementById('form-TimothyM.LearningDeepSketch').submit();\">Timothy M. Hospedales</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Muhammad_Learning_Deep_Sketch_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.04804\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Muhammad_2018_CVPR,<br>\nauthor = {Riaz Muhammad, Umar and Yang, Yongxin and Song, Yi-Zhe and Xiang, Tao and Hospedales, Timothy M.},<br>\ntitle = {Learning Deep Sketch Abstraction},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Mattyus_Matching_Adversarial_Networks_CVPR_2018_paper.html\">Matching Adversarial Networks</a></dt>\n<dd>\n<form id=\"form-Gell\u00c3\u00a9rtM\u00c3\u00a1ttyusMatchingAdversarialNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gell\u00c3\u00a9rt M\u00c3\u00a1ttyus\">\n<a href=\"#\" onclick=\"document.getElementById('form-Gell\u00c3\u00a9rtM\u00c3\u00a1ttyusMatchingAdversarialNetworks').submit();\">Gell\u00c3\u00a9rt M\u00c3\u00a1ttyus</a>,\n</form>\n<form id=\"form-RaquelUrtasunMatchingAdversarialNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Raquel Urtasun\">\n<a href=\"#\" onclick=\"document.getElementById('form-RaquelUrtasunMatchingAdversarialNetworks').submit();\">Raquel Urtasun</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Mattyus_Matching_Adversarial_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1707.08273\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{M\u00c3\u00a1ttyus_2018_CVPR,<br>\nauthor = {M\u00c3\u00a1ttyus, Gell\u00c3\u00a9rt and Urtasun, Raquel},<br>\ntitle = {Matching Adversarial Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sznaier_SoS-RSC_A_Sum-of-Squares_CVPR_2018_paper.html\">SoS-RSC: A Sum-of-Squares Polynomial Approach to Robustifying Subspace Clustering Algorithms</a></dt>\n<dd>\n<form id=\"form-MarioSznaierSoSRSCASumofSquares\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mario Sznaier\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarioSznaierSoSRSCASumofSquares').submit();\">Mario Sznaier</a>,\n</form>\n<form id=\"form-OctaviaCampsSoSRSCASumofSquares\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Octavia Camps\">\n<a href=\"#\" onclick=\"document.getElementById('form-OctaviaCampsSoSRSCASumofSquares').submit();\">Octavia Camps</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sznaier_SoS-RSC_A_Sum-of-Squares_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sznaier_2018_CVPR,<br>\nauthor = {Sznaier, Mario and Camps, Octavia},<br>\ntitle = {SoS-RSC: A Sum-of-Squares Polynomial Approach to Robustifying Subspace Clustering Algorithms},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Resource_Aware_Person_CVPR_2018_paper.html\">Resource Aware Person Re-Identification Across Multiple Resolutions</a></dt>\n<dd>\n<form id=\"form-YanWangResourceAwarePerson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yan Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanWangResourceAwarePerson').submit();\">Yan Wang</a>,\n</form>\n<form id=\"form-LequnWangResourceAwarePerson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lequn Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LequnWangResourceAwarePerson').submit();\">Lequn Wang</a>,\n</form>\n<form id=\"form-YurongYouResourceAwarePerson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yurong You\">\n<a href=\"#\" onclick=\"document.getElementById('form-YurongYouResourceAwarePerson').submit();\">Yurong You</a>,\n</form>\n<form id=\"form-XuZouResourceAwarePerson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xu Zou\">\n<a href=\"#\" onclick=\"document.getElementById('form-XuZouResourceAwarePerson').submit();\">Xu Zou</a>,\n</form>\n<form id=\"form-VincentChenResourceAwarePerson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vincent Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-VincentChenResourceAwarePerson').submit();\">Vincent Chen</a>,\n</form>\n<form id=\"form-SerenaLiResourceAwarePerson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Serena Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-SerenaLiResourceAwarePerson').submit();\">Serena Li</a>,\n</form>\n<form id=\"form-GaoHuangResourceAwarePerson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gao Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-GaoHuangResourceAwarePerson').submit();\">Gao Huang</a>,\n</form>\n<form id=\"form-BharathHariharanResourceAwarePerson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bharath Hariharan\">\n<a href=\"#\" onclick=\"document.getElementById('form-BharathHariharanResourceAwarePerson').submit();\">Bharath Hariharan</a>,\n</form>\n<form id=\"form-KilianQ.ResourceAwarePerson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kilian Q. Weinberger\">\n<a href=\"#\" onclick=\"document.getElementById('form-KilianQ.ResourceAwarePerson').submit();\">Kilian Q. Weinberger</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Resource_Aware_Person_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.08805\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Yan and Wang, Lequn and You, Yurong and Zou, Xu and Chen, Vincent and Li, Serena and Huang, Gao and Hariharan, Bharath and Weinberger, Kilian Q.},<br>\ntitle = {Resource Aware Person Re-Identification Across Multiple Resolutions},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wei_Learning_and_Using_CVPR_2018_paper.html\">Learning and Using the Arrow of Time</a></dt>\n<dd>\n<form id=\"form-DonglaiWeiLearningandUsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Donglai Wei\">\n<a href=\"#\" onclick=\"document.getElementById('form-DonglaiWeiLearningandUsing').submit();\">Donglai Wei</a>,\n</form>\n<form id=\"form-JosephJ.LearningandUsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Joseph J. Lim\">\n<a href=\"#\" onclick=\"document.getElementById('form-JosephJ.LearningandUsing').submit();\">Joseph J. Lim</a>,\n</form>\n<form id=\"form-AndrewZissermanLearningandUsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrew Zisserman\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndrewZissermanLearningandUsing').submit();\">Andrew Zisserman</a>,\n</form>\n<form id=\"form-WilliamT.LearningandUsing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"William T. Freeman\">\n<a href=\"#\" onclick=\"document.getElementById('form-WilliamT.LearningandUsing').submit();\">William T. Freeman</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wei_Learning_and_Using_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wei_2018_CVPR,<br>\nauthor = {Wei, Donglai and Lim, Joseph J. and Zisserman, Andrew and Freeman, William T.},<br>\ntitle = {Learning and Using the Arrow of Time},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Shen_Neural_Style_Transfer_CVPR_2018_paper.html\">Neural Style Transfer via Meta Networks</a></dt>\n<dd>\n<form id=\"form-FalongShenNeuralStyleTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Falong Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-FalongShenNeuralStyleTransfer').submit();\">Falong Shen</a>,\n</form>\n<form id=\"form-ShuichengYanNeuralStyleTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuicheng Yan\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuichengYanNeuralStyleTransfer').submit();\">Shuicheng Yan</a>,\n</form>\n<form id=\"form-GangZengNeuralStyleTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gang Zeng\">\n<a href=\"#\" onclick=\"document.getElementById('form-GangZengNeuralStyleTransfer').submit();\">Gang Zeng</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Shen_Neural_Style_Transfer_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Shen_2018_CVPR,<br>\nauthor = {Shen, Falong and Yan, Shuicheng and Zeng, Gang},<br>\ntitle = {Neural Style Transfer via Meta Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Marsden_People_Penguins_and_CVPR_2018_paper.html\">People, Penguins and Petri Dishes: Adapting Object Counting Models to New Visual Domains and Object Types Without Forgetting</a></dt>\n<dd>\n<form id=\"form-MarkMarsdenPeoplePenguinsand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mark Marsden\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarkMarsdenPeoplePenguinsand').submit();\">Mark Marsden</a>,\n</form>\n<form id=\"form-KevinMcGuinnessPeoplePenguinsand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kevin McGuinness\">\n<a href=\"#\" onclick=\"document.getElementById('form-KevinMcGuinnessPeoplePenguinsand').submit();\">Kevin McGuinness</a>,\n</form>\n<form id=\"form-SuzanneLittlePeoplePenguinsand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Suzanne Little\">\n<a href=\"#\" onclick=\"document.getElementById('form-SuzanneLittlePeoplePenguinsand').submit();\">Suzanne Little</a>,\n</form>\n<form id=\"form-CiaraE.PeoplePenguinsand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ciara E. Keogh\">\n<a href=\"#\" onclick=\"document.getElementById('form-CiaraE.PeoplePenguinsand').submit();\">Ciara E. Keogh</a>,\n</form>\n<form id=\"form-NoelE.PeoplePenguinsand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Noel E. O'Connor\">\n<a href=\"#\" onclick=\"document.getElementById('form-NoelE.PeoplePenguinsand').submit();\">Noel E. O'Connor</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Marsden_People_Penguins_and_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Marsden_2018_CVPR,<br>\nauthor = {Marsden, Mark and McGuinness, Kevin and Little, Suzanne and Keogh, Ciara E. and O'Connor, Noel E.},<br>\ntitle = {People, Penguins and Petri Dishes: Adapting Object Counting Models to New Visual Domains and Object Types Without Forgetting},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Mullapudi_HydraNets_Specialized_Dynamic_CVPR_2018_paper.html\">HydraNets: Specialized Dynamic Architectures for Efficient Inference</a></dt>\n<dd>\n<form id=\"form-RaviTejaHydraNetsSpecializedDynamic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ravi Teja Mullapudi\">\n<a href=\"#\" onclick=\"document.getElementById('form-RaviTejaHydraNetsSpecializedDynamic').submit();\">Ravi Teja Mullapudi</a>,\n</form>\n<form id=\"form-WilliamR.HydraNetsSpecializedDynamic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"William R. Mark\">\n<a href=\"#\" onclick=\"document.getElementById('form-WilliamR.HydraNetsSpecializedDynamic').submit();\">William R. Mark</a>,\n</form>\n<form id=\"form-NoamShazeerHydraNetsSpecializedDynamic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Noam Shazeer\">\n<a href=\"#\" onclick=\"document.getElementById('form-NoamShazeerHydraNetsSpecializedDynamic').submit();\">Noam Shazeer</a>,\n</form>\n<form id=\"form-KayvonFatahalianHydraNetsSpecializedDynamic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kayvon Fatahalian\">\n<a href=\"#\" onclick=\"document.getElementById('form-KayvonFatahalianHydraNetsSpecializedDynamic').submit();\">Kayvon Fatahalian</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Mullapudi_HydraNets_Specialized_Dynamic_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Mullapudi_2018_CVPR,<br>\nauthor = {Teja Mullapudi, Ravi and Mark, William R. and Shazeer, Noam and Fatahalian, Kayvon},<br>\ntitle = {HydraNets: Specialized Dynamic Architectures for Efficient Inference},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xu_SketchMate_Deep_Hashing_CVPR_2018_paper.html\">SketchMate: Deep Hashing for Million-Scale Human Sketch Retrieval</a></dt>\n<dd>\n<form id=\"form-PengXuSketchMateDeepHashing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peng Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-PengXuSketchMateDeepHashing').submit();\">Peng Xu</a>,\n</form>\n<form id=\"form-YongyeHuangSketchMateDeepHashing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yongye Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YongyeHuangSketchMateDeepHashing').submit();\">Yongye Huang</a>,\n</form>\n<form id=\"form-TongtongYuanSketchMateDeepHashing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tongtong Yuan\">\n<a href=\"#\" onclick=\"document.getElementById('form-TongtongYuanSketchMateDeepHashing').submit();\">Tongtong Yuan</a>,\n</form>\n<form id=\"form-KaiyuePangSketchMateDeepHashing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kaiyue Pang\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaiyuePangSketchMateDeepHashing').submit();\">Kaiyue Pang</a>,\n</form>\n<form id=\"form-Yi-ZheSongSketchMateDeepHashing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi-Zhe Song\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yi-ZheSongSketchMateDeepHashing').submit();\">Yi-Zhe Song</a>,\n</form>\n<form id=\"form-TaoXiangSketchMateDeepHashing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tao Xiang\">\n<a href=\"#\" onclick=\"document.getElementById('form-TaoXiangSketchMateDeepHashing').submit();\">Tao Xiang</a>,\n</form>\n<form id=\"form-TimothyM.SketchMateDeepHashing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Timothy M. Hospedales\">\n<a href=\"#\" onclick=\"document.getElementById('form-TimothyM.SketchMateDeepHashing').submit();\">Timothy M. Hospedales</a>,\n</form>\n<form id=\"form-ZhanyuMaSketchMateDeepHashing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhanyu Ma\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhanyuMaSketchMateDeepHashing').submit();\">Zhanyu Ma</a>,\n</form>\n<form id=\"form-JunGuoSketchMateDeepHashing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jun Guo\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunGuoSketchMateDeepHashing').submit();\">Jun Guo</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xu_SketchMate_Deep_Hashing_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.01401\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xu_2018_CVPR,<br>\nauthor = {Xu, Peng and Huang, Yongye and Yuan, Tongtong and Pang, Kaiyue and Song, Yi-Zhe and Xiang, Tao and Hospedales, Timothy M. and Ma, Zhanyu and Guo, Jun},<br>\ntitle = {SketchMate: Deep Hashing for Million-Scale Human Sketch Retrieval},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Russo_From_Source_to_CVPR_2018_paper.html\">From Source to Target and Back: Symmetric Bi-Directional Adaptive GAN</a></dt>\n<dd>\n<form id=\"form-PaoloRussoFromSourceto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Paolo Russo\">\n<a href=\"#\" onclick=\"document.getElementById('form-PaoloRussoFromSourceto').submit();\">Paolo Russo</a>,\n</form>\n<form id=\"form-FabioM.FromSourceto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fabio M. Carlucci\">\n<a href=\"#\" onclick=\"document.getElementById('form-FabioM.FromSourceto').submit();\">Fabio M. Carlucci</a>,\n</form>\n<form id=\"form-TatianaTommasiFromSourceto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tatiana Tommasi\">\n<a href=\"#\" onclick=\"document.getElementById('form-TatianaTommasiFromSourceto').submit();\">Tatiana Tommasi</a>,\n</form>\n<form id=\"form-BarbaraCaputoFromSourceto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Barbara Caputo\">\n<a href=\"#\" onclick=\"document.getElementById('form-BarbaraCaputoFromSourceto').submit();\">Barbara Caputo</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Russo_From_Source_to_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2781-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1705.08824\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Russo_2018_CVPR,<br>\nauthor = {Russo, Paolo and Carlucci, Fabio M. and Tommasi, Tatiana and Caputo, Barbara},<br>\ntitle = {From Source to Target and Back: Symmetric Bi-Directional Adaptive GAN},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lezama_OLE_Orthogonal_Low-Rank_CVPR_2018_paper.html\">OL\u00c3\u0089: Orthogonal Low-Rank Embedding - A Plug and Play Geometric Loss for Deep Learning</a></dt>\n<dd>\n<form id=\"form-Jos\u00c3\u00a9LezamaOLOrthogonalLowRank\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jos\u00c3\u00a9 Lezama\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jos\u00c3\u00a9LezamaOLOrthogonalLowRank').submit();\">Jos\u00c3\u00a9 Lezama</a>,\n</form>\n<form id=\"form-QiangQiuOLOrthogonalLowRank\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qiang Qiu\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiangQiuOLOrthogonalLowRank').submit();\">Qiang Qiu</a>,\n</form>\n<form id=\"form-PabloMus\u00c3\u00a9OLOrthogonalLowRank\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pablo Mus\u00c3\u00a9\">\n<a href=\"#\" onclick=\"document.getElementById('form-PabloMus\u00c3\u00a9OLOrthogonalLowRank').submit();\">Pablo Mus\u00c3\u00a9</a>,\n</form>\n<form id=\"form-GuillermoSapiroOLOrthogonalLowRank\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guillermo Sapiro\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuillermoSapiroOLOrthogonalLowRank').submit();\">Guillermo Sapiro</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lezama_OLE_Orthogonal_Low-Rank_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lezama_2018_CVPR,<br>\nauthor = {Lezama, Jos\u00c3\u00a9 and Qiu, Qiang and Mus\u00c3\u00a9, Pablo and Sapiro, Guillermo},<br>\ntitle = {OL\u00c3\u0089: Orthogonal Low-Rank Embedding - A Plug and Play Geometric Loss for Deep Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Rebuffi_Efficient_Parametrization_of_CVPR_2018_paper.html\">Efficient Parametrization of Multi-Domain Deep Neural Networks</a></dt>\n<dd>\n<form id=\"form-Sylvestre-AlviseRebuffiEfficientParametrizationof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sylvestre-Alvise Rebuffi\">\n<a href=\"#\" onclick=\"document.getElementById('form-Sylvestre-AlviseRebuffiEfficientParametrizationof').submit();\">Sylvestre-Alvise Rebuffi</a>,\n</form>\n<form id=\"form-HakanBilenEfficientParametrizationof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hakan Bilen\">\n<a href=\"#\" onclick=\"document.getElementById('form-HakanBilenEfficientParametrizationof').submit();\">Hakan Bilen</a>,\n</form>\n<form id=\"form-AndreaVedaldiEfficientParametrizationof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrea Vedaldi\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndreaVedaldiEfficientParametrizationof').submit();\">Andrea Vedaldi</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Rebuffi_Efficient_Parametrization_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.10082\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Rebuffi_2018_CVPR,<br>\nauthor = {Rebuffi, Sylvestre-Alvise and Bilen, Hakan and Vedaldi, Andrea},<br>\ntitle = {Efficient Parametrization of Multi-Domain Deep Neural Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lin_Deep_Density_Clustering_CVPR_2018_paper.html\">Deep Density Clustering of Unconstrained Faces</a></dt>\n<dd>\n<form id=\"form-Wei-AnLinDeepDensityClustering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei-An Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-Wei-AnLinDeepDensityClustering').submit();\">Wei-An Lin</a>,\n</form>\n<form id=\"form-Jun-ChengChenDeepDensityClustering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jun-Cheng Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jun-ChengChenDeepDensityClustering').submit();\">Jun-Cheng Chen</a>,\n</form>\n<form id=\"form-CarlosD.DeepDensityClustering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Carlos D. Castillo\">\n<a href=\"#\" onclick=\"document.getElementById('form-CarlosD.DeepDensityClustering').submit();\">Carlos D. Castillo</a>,\n</form>\n<form id=\"form-RamaChellappaDeepDensityClustering\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rama Chellappa\">\n<a href=\"#\" onclick=\"document.getElementById('form-RamaChellappaDeepDensityClustering').submit();\">Rama Chellappa</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lin_Deep_Density_Clustering_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3208-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lin_2018_CVPR,<br>\nauthor = {Lin, Wei-An and Chen, Jun-Cheng and Castillo, Carlos D. and Chellappa, Rama},<br>\ntitle = {Deep Density Clustering of Unconstrained Faces},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Amayo_Geometric_Multi-Model_Fitting_CVPR_2018_paper.html\">Geometric Multi-Model Fitting With a Convex Relaxation Algorithm</a></dt>\n<dd>\n<form id=\"form-PaulAmayoGeometricMultiModelFitting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Paul Amayo\">\n<a href=\"#\" onclick=\"document.getElementById('form-PaulAmayoGeometricMultiModelFitting').submit();\">Paul Amayo</a>,\n</form>\n<form id=\"form-PedroPini\u00c3\u00a9sGeometricMultiModelFitting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pedro Pini\u00c3\u00a9s\">\n<a href=\"#\" onclick=\"document.getElementById('form-PedroPini\u00c3\u00a9sGeometricMultiModelFitting').submit();\">Pedro Pini\u00c3\u00a9s</a>,\n</form>\n<form id=\"form-LinaM.GeometricMultiModelFitting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lina M. Paz\">\n<a href=\"#\" onclick=\"document.getElementById('form-LinaM.GeometricMultiModelFitting').submit();\">Lina M. Paz</a>,\n</form>\n<form id=\"form-PaulNewmanGeometricMultiModelFitting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Paul Newman\">\n<a href=\"#\" onclick=\"document.getElementById('form-PaulNewmanGeometricMultiModelFitting').submit();\">Paul Newman</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Amayo_Geometric_Multi-Model_Fitting_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3327-supp.zip\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1706.01553\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Amayo_2018_CVPR,<br>\nauthor = {Amayo, Paul and Pini\u00c3\u00a9s, Pedro and Paz, Lina M. and Newman, Paul},<br>\ntitle = {Geometric Multi-Model Fitting With a Convex Relaxation Algorithm},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ikami_Fast_and_Robust_CVPR_2018_paper.html\">Fast and Robust Estimation for Unit-Norm Constrained Linear Fitting Problems</a></dt>\n<dd>\n<form id=\"form-DaikiIkamiFastandRobust\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daiki Ikami\">\n<a href=\"#\" onclick=\"document.getElementById('form-DaikiIkamiFastandRobust').submit();\">Daiki Ikami</a>,\n</form>\n<form id=\"form-ToshihikoYamasakiFastandRobust\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Toshihiko Yamasaki\">\n<a href=\"#\" onclick=\"document.getElementById('form-ToshihikoYamasakiFastandRobust').submit();\">Toshihiko Yamasaki</a>,\n</form>\n<form id=\"form-KiyoharuAizawaFastandRobust\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kiyoharu Aizawa\">\n<a href=\"#\" onclick=\"document.getElementById('form-KiyoharuAizawaFastandRobust').submit();\">Kiyoharu Aizawa</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ikami_Fast_and_Robust_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ikami_2018_CVPR,<br>\nauthor = {Ikami, Daiki and Yamasaki, Toshihiko and Aizawa, Kiyoharu},<br>\ntitle = {Fast and Robust Estimation for Unit-Norm Constrained Linear Fitting Problems},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Importance_Weighted_Adversarial_CVPR_2018_paper.html\">Importance Weighted Adversarial Nets for Partial Domain Adaptation</a></dt>\n<dd>\n<form id=\"form-JingZhangImportanceWeightedAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jing Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingZhangImportanceWeightedAdversarial').submit();\">Jing Zhang</a>,\n</form>\n<form id=\"form-ZeweiDingImportanceWeightedAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zewei Ding\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZeweiDingImportanceWeightedAdversarial').submit();\">Zewei Ding</a>,\n</form>\n<form id=\"form-WanqingLiImportanceWeightedAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wanqing Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-WanqingLiImportanceWeightedAdversarial').submit();\">Wanqing Li</a>,\n</form>\n<form id=\"form-PhilipOgunbonaImportanceWeightedAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Philip Ogunbona\">\n<a href=\"#\" onclick=\"document.getElementById('form-PhilipOgunbonaImportanceWeightedAdversarial').submit();\">Philip Ogunbona</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Importance_Weighted_Adversarial_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.09210\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Jing and Ding, Zewei and Li, Wanqing and Ogunbona, Philip},<br>\ntitle = {Importance Weighted Adversarial Nets for Partial Domain Adaptation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lui_Efficient_Subpixel_Refinement_CVPR_2018_paper.html\">Efficient Subpixel Refinement With Symbolic Linear Predictors</a></dt>\n<dd>\n<form id=\"form-VincentLuiEfficientSubpixelRefinement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vincent Lui\">\n<a href=\"#\" onclick=\"document.getElementById('form-VincentLuiEfficientSubpixelRefinement').submit();\">Vincent Lui</a>,\n</form>\n<form id=\"form-JonathonGeevesEfficientSubpixelRefinement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jonathon Geeves\">\n<a href=\"#\" onclick=\"document.getElementById('form-JonathonGeevesEfficientSubpixelRefinement').submit();\">Jonathon Geeves</a>,\n</form>\n<form id=\"form-WinstonYiiEfficientSubpixelRefinement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Winston Yii\">\n<a href=\"#\" onclick=\"document.getElementById('form-WinstonYiiEfficientSubpixelRefinement').submit();\">Winston Yii</a>,\n</form>\n<form id=\"form-TomDrummondEfficientSubpixelRefinement\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tom Drummond\">\n<a href=\"#\" onclick=\"document.getElementById('form-TomDrummondEfficientSubpixelRefinement').submit();\">Tom Drummond</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lui_Efficient_Subpixel_Refinement_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1052-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.10750\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lui_2018_CVPR,<br>\nauthor = {Lui, Vincent and Geeves, Jonathon and Yii, Winston and Drummond, Tom},<br>\ntitle = {Efficient Subpixel Refinement With Symbolic Linear Predictors},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tao_Scale-Recurrent_Network_for_CVPR_2018_paper.html\">Scale-Recurrent Network for Deep Image Deblurring</a></dt>\n<dd>\n<form id=\"form-XinTaoScaleRecurrentNetworkfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xin Tao\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinTaoScaleRecurrentNetworkfor').submit();\">Xin Tao</a>,\n</form>\n<form id=\"form-HongyunGaoScaleRecurrentNetworkfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hongyun Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-HongyunGaoScaleRecurrentNetworkfor').submit();\">Hongyun Gao</a>,\n</form>\n<form id=\"form-XiaoyongShenScaleRecurrentNetworkfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaoyong Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaoyongShenScaleRecurrentNetworkfor').submit();\">Xiaoyong Shen</a>,\n</form>\n<form id=\"form-JueWangScaleRecurrentNetworkfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jue Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JueWangScaleRecurrentNetworkfor').submit();\">Jue Wang</a>,\n</form>\n<form id=\"form-JiayaJiaScaleRecurrentNetworkfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiaya Jia\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiayaJiaScaleRecurrentNetworkfor').submit();\">Jiaya Jia</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tao_Scale-Recurrent_Network_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.01770\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tao_2018_CVPR,<br>\nauthor = {Tao, Xin and Gao, Hongyun and Shen, Xiaoyong and Wang, Jue and Jia, Jiaya},<br>\ntitle = {Scale-Recurrent Network for Deep Image Deblurring},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kupyn_DeblurGAN_Blind_Motion_CVPR_2018_paper.html\">DeblurGAN: Blind Motion Deblurring Using Conditional Adversarial Networks</a></dt>\n<dd>\n<form id=\"form-OrestKupynDeblurGANBlindMotion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Orest Kupyn\">\n<a href=\"#\" onclick=\"document.getElementById('form-OrestKupynDeblurGANBlindMotion').submit();\">Orest Kupyn</a>,\n</form>\n<form id=\"form-VolodymyrBudzanDeblurGANBlindMotion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Volodymyr Budzan\">\n<a href=\"#\" onclick=\"document.getElementById('form-VolodymyrBudzanDeblurGANBlindMotion').submit();\">Volodymyr Budzan</a>,\n</form>\n<form id=\"form-MykolaMykhailychDeblurGANBlindMotion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mykola Mykhailych\">\n<a href=\"#\" onclick=\"document.getElementById('form-MykolaMykhailychDeblurGANBlindMotion').submit();\">Mykola Mykhailych</a>,\n</form>\n<form id=\"form-DmytroMishkinDeblurGANBlindMotion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dmytro Mishkin\">\n<a href=\"#\" onclick=\"document.getElementById('form-DmytroMishkinDeblurGANBlindMotion').submit();\">Dmytro Mishkin</a>,\n</form>\n<form id=\"form-Ji\u00c5\u0099\u00c3\u00adMatasDeblurGANBlindMotion\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ji\u00c5\u0099\u00c3\u00ad Matas\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ji\u00c5\u0099\u00c3\u00adMatasDeblurGANBlindMotion').submit();\">Ji\u00c5\u0099\u00c3\u00ad Matas</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kupyn_DeblurGAN_Blind_Motion_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.07064\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kupyn_2018_CVPR,<br>\nauthor = {Kupyn, Orest and Budzan, Volodymyr and Mykhailych, Mykola and Mishkin, Dmytro and Matas, Ji\u00c5\u0099\u00c3\u00ad},<br>\ntitle = {DeblurGAN: Blind Motion Deblurring Using Conditional Adversarial Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_A2-RL_Aesthetics_Aware_CVPR_2018_paper.html\">A2-RL: Aesthetics Aware Reinforcement Learning for Image Cropping</a></dt>\n<dd>\n<form id=\"form-DebangLiA2RLAestheticsAware\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Debang Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-DebangLiA2RLAestheticsAware').submit();\">Debang Li</a>,\n</form>\n<form id=\"form-HuikaiWuA2RLAestheticsAware\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huikai Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuikaiWuA2RLAestheticsAware').submit();\">Huikai Wu</a>,\n</form>\n<form id=\"form-JungeZhangA2RLAestheticsAware\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junge Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JungeZhangA2RLAestheticsAware').submit();\">Junge Zhang</a>,\n</form>\n<form id=\"form-KaiqiHuangA2RLAestheticsAware\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kaiqi Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaiqiHuangA2RLAestheticsAware').submit();\">Kaiqi Huang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_A2-RL_Aesthetics_Aware_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1709.04595\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Debang and Wu, Huikai and Zhang, Junge and Huang, Kaiqi},<br>\ntitle = {A2-RL: Aesthetics Aware Reinforcement Learning for Image Cropping},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Single_Image_Dehazing_CVPR_2018_paper.html\">Single Image Dehazing via Conditional Generative Adversarial Network</a></dt>\n<dd>\n<form id=\"form-RundeLiSingleImageDehazing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Runde Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-RundeLiSingleImageDehazing').submit();\">Runde Li</a>,\n</form>\n<form id=\"form-JinshanPanSingleImageDehazing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jinshan Pan\">\n<a href=\"#\" onclick=\"document.getElementById('form-JinshanPanSingleImageDehazing').submit();\">Jinshan Pan</a>,\n</form>\n<form id=\"form-ZechaoLiSingleImageDehazing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zechao Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZechaoLiSingleImageDehazing').submit();\">Zechao Li</a>,\n</form>\n<form id=\"form-JinhuiTangSingleImageDehazing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jinhui Tang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JinhuiTangSingleImageDehazing').submit();\">Jinhui Tang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Single_Image_Dehazing_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2260-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Runde and Pan, Jinshan and Li, Zechao and Tang, Jinhui},<br>\ntitle = {Single Image Dehazing via Conditional Generative Adversarial Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Galdran_On_the_Duality_CVPR_2018_paper.html\">On the Duality Between Retinex and Image Dehazing</a></dt>\n<dd>\n<form id=\"form-AdrianGaldranOntheDuality\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Adrian Galdran\">\n<a href=\"#\" onclick=\"document.getElementById('form-AdrianGaldranOntheDuality').submit();\">Adrian Galdran</a>,\n</form>\n<form id=\"form-AitorAlvarez-GilaOntheDuality\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Aitor Alvarez-Gila\">\n<a href=\"#\" onclick=\"document.getElementById('form-AitorAlvarez-GilaOntheDuality').submit();\">Aitor Alvarez-Gila</a>,\n</form>\n<form id=\"form-AlessandroBriaOntheDuality\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alessandro Bria\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlessandroBriaOntheDuality').submit();\">Alessandro Bria</a>,\n</form>\n<form id=\"form-JavierVazquez-CorralOntheDuality\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Javier Vazquez-Corral\">\n<a href=\"#\" onclick=\"document.getElementById('form-JavierVazquez-CorralOntheDuality').submit();\">Javier Vazquez-Corral</a>,\n</form>\n<form id=\"form-MarceloBertalm\u00c3\u00adoOntheDuality\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Marcelo Bertalm\u00c3\u00ado\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarceloBertalm\u00c3\u00adoOntheDuality').submit();\">Marcelo Bertalm\u00c3\u00ado</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Galdran_On_the_Duality_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.02754\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Galdran_2018_CVPR,<br>\nauthor = {Galdran, Adrian and Alvarez-Gila, Aitor and Bria, Alessandro and Vazquez-Corral, Javier and Bertalm\u00c3\u00ado, Marcelo},<br>\ntitle = {On the Duality Between Retinex and Image Dehazing},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Gu_Arbitrary_Style_Transfer_CVPR_2018_paper.html\">Arbitrary Style Transfer With Deep Feature Reshuffle</a></dt>\n<dd>\n<form id=\"form-ShuyangGuArbitraryStyleTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shuyang Gu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuyangGuArbitraryStyleTransfer').submit();\">Shuyang Gu</a>,\n</form>\n<form id=\"form-CongliangChenArbitraryStyleTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Congliang Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-CongliangChenArbitraryStyleTransfer').submit();\">Congliang Chen</a>,\n</form>\n<form id=\"form-JingLiaoArbitraryStyleTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jing Liao\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingLiaoArbitraryStyleTransfer').submit();\">Jing Liao</a>,\n</form>\n<form id=\"form-LuYuanArbitraryStyleTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lu Yuan\">\n<a href=\"#\" onclick=\"document.getElementById('form-LuYuanArbitraryStyleTransfer').submit();\">Lu Yuan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Gu_Arbitrary_Style_Transfer_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.04103\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Gu_2018_CVPR,<br>\nauthor = {Gu, Shuyang and Chen, Congliang and Liao, Jing and Yuan, Lu},<br>\ntitle = {Arbitrary Style Transfer With Deep Feature Reshuffle},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Nonlocal_Low-Rank_Tensor_CVPR_2018_paper.html\">Nonlocal Low-Rank Tensor Factor Analysis for Image Restoration</a></dt>\n<dd>\n<form id=\"form-XinyuanZhangNonlocalLowRankTensor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xinyuan Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinyuanZhangNonlocalLowRankTensor').submit();\">Xinyuan Zhang</a>,\n</form>\n<form id=\"form-XinYuanNonlocalLowRankTensor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xin Yuan\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinYuanNonlocalLowRankTensor').submit();\">Xin Yuan</a>,\n</form>\n<form id=\"form-LawrenceCarinNonlocalLowRankTensor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lawrence Carin\">\n<a href=\"#\" onclick=\"document.getElementById('form-LawrenceCarinNonlocalLowRankTensor').submit();\">Lawrence Carin</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Nonlocal_Low-Rank_Tensor_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.06795\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Xinyuan and Yuan, Xin and Carin, Lawrence},<br>\ntitle = {Nonlocal Low-Rank Tensor Factor Analysis for Image Restoration},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper.html\">Avatar-Net: Multi-Scale Zero-Shot Style Transfer by Feature Decoration</a></dt>\n<dd>\n<form id=\"form-LuShengAvatarNetMultiScaleZeroShot\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lu Sheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-LuShengAvatarNetMultiScaleZeroShot').submit();\">Lu Sheng</a>,\n</form>\n<form id=\"form-ZiyiLinAvatarNetMultiScaleZeroShot\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ziyi Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZiyiLinAvatarNetMultiScaleZeroShot').submit();\">Ziyi Lin</a>,\n</form>\n<form id=\"form-JingShaoAvatarNetMultiScaleZeroShot\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jing Shao\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingShaoAvatarNetMultiScaleZeroShot').submit();\">Jing Shao</a>,\n</form>\n<form id=\"form-XiaogangWangAvatarNetMultiScaleZeroShot\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaogang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaogangWangAvatarNetMultiScaleZeroShot').submit();\">Xiaogang Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sheng_Avatar-Net_Multi-Scale_Zero-Shot_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.03857\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sheng_2018_CVPR,<br>\nauthor = {Sheng, Lu and Lin, Ziyi and Shao, Jing and Wang, Xiaogang},<br>\ntitle = {Avatar-Net: Multi-Scale Zero-Shot Style Transfer by Feature Decoration},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yokota_Missing_Slice_Recovery_CVPR_2018_paper.html\">Missing Slice Recovery for Tensors Using a Low-Rank Model in Embedded Space</a></dt>\n<dd>\n<form id=\"form-TatsuyaYokotaMissingSliceRecovery\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tatsuya Yokota\">\n<a href=\"#\" onclick=\"document.getElementById('form-TatsuyaYokotaMissingSliceRecovery').submit();\">Tatsuya Yokota</a>,\n</form>\n<form id=\"form-BurakEremMissingSliceRecovery\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Burak Erem\">\n<a href=\"#\" onclick=\"document.getElementById('form-BurakEremMissingSliceRecovery').submit();\">Burak Erem</a>,\n</form>\n<form id=\"form-SeyhmusGulerMissingSliceRecovery\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Seyhmus Guler\">\n<a href=\"#\" onclick=\"document.getElementById('form-SeyhmusGulerMissingSliceRecovery').submit();\">Seyhmus Guler</a>,\n</form>\n<form id=\"form-SimonK.MissingSliceRecovery\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Simon K. Warfield\">\n<a href=\"#\" onclick=\"document.getElementById('form-SimonK.MissingSliceRecovery').submit();\">Simon K. Warfield</a>,\n</form>\n<form id=\"form-HidekataHontaniMissingSliceRecovery\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hidekata Hontani\">\n<a href=\"#\" onclick=\"document.getElementById('form-HidekataHontaniMissingSliceRecovery').submit();\">Hidekata Hontani</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yokota_Missing_Slice_Recovery_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0672-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.01736\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yokota_2018_CVPR,<br>\nauthor = {Yokota, Tatsuya and Erem, Burak and Guler, Seyhmus and Warfield, Simon K. and Hontani, Hidekata},<br>\ntitle = {Missing Slice Recovery for Tensors Using a Low-Rank Model in Embedded Space},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Shen_Deep_Semantic_Face_CVPR_2018_paper.html\">Deep Semantic Face Deblurring</a></dt>\n<dd>\n<form id=\"form-ZiyiShenDeepSemanticFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ziyi Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZiyiShenDeepSemanticFace').submit();\">Ziyi Shen</a>,\n</form>\n<form id=\"form-Wei-ShengLaiDeepSemanticFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei-Sheng Lai\">\n<a href=\"#\" onclick=\"document.getElementById('form-Wei-ShengLaiDeepSemanticFace').submit();\">Wei-Sheng Lai</a>,\n</form>\n<form id=\"form-TingfaXuDeepSemanticFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tingfa Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-TingfaXuDeepSemanticFace').submit();\">Tingfa Xu</a>,\n</form>\n<form id=\"form-JanKautzDeepSemanticFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jan Kautz\">\n<a href=\"#\" onclick=\"document.getElementById('form-JanKautzDeepSemanticFace').submit();\">Jan Kautz</a>,\n</form>\n<form id=\"form-Ming-HsuanYangDeepSemanticFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming-Hsuan Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ming-HsuanYangDeepSemanticFace').submit();\">Ming-Hsuan Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Shen_Deep_Semantic_Face_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1531-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.03345\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Shen_2018_CVPR,<br>\nauthor = {Shen, Ziyi and Lai, Wei-Sheng and Xu, Tingfa and Kautz, Jan and Yang, Ming-Hsuan},<br>\ntitle = {Deep Semantic Face Deblurring},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Duan_GraphBit_Bitwise_Interaction_CVPR_2018_paper.html\">GraphBit: Bitwise Interaction Mining via Deep Reinforcement Learning</a></dt>\n<dd>\n<form id=\"form-YueqiDuanGraphBitBitwiseInteraction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yueqi Duan\">\n<a href=\"#\" onclick=\"document.getElementById('form-YueqiDuanGraphBitBitwiseInteraction').submit();\">Yueqi Duan</a>,\n</form>\n<form id=\"form-ZiweiWangGraphBitBitwiseInteraction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ziwei Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZiweiWangGraphBitBitwiseInteraction').submit();\">Ziwei Wang</a>,\n</form>\n<form id=\"form-JiwenLuGraphBitBitwiseInteraction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiwen Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiwenLuGraphBitBitwiseInteraction').submit();\">Jiwen Lu</a>,\n</form>\n<form id=\"form-XudongLinGraphBitBitwiseInteraction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xudong Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-XudongLinGraphBitBitwiseInteraction').submit();\">Xudong Lin</a>,\n</form>\n<form id=\"form-JieZhouGraphBitBitwiseInteraction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jie Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-JieZhouGraphBitBitwiseInteraction').submit();\">Jie Zhou</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Duan_GraphBit_Bitwise_Interaction_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Duan_2018_CVPR,<br>\nauthor = {Duan, Yueqi and Wang, Ziwei and Lu, Jiwen and Lin, Xudong and Zhou, Jie},<br>\ntitle = {GraphBit: Bitwise Interaction Mining via Deep Reinforcement Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yu_Recurrent_Saliency_Transformation_CVPR_2018_paper.html\">Recurrent Saliency Transformation Network: Incorporating Multi-Stage Visual Cues for Small Organ Segmentation</a></dt>\n<dd>\n<form id=\"form-QihangYuRecurrentSaliencyTransformation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qihang Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-QihangYuRecurrentSaliencyTransformation').submit();\">Qihang Yu</a>,\n</form>\n<form id=\"form-LingxiXieRecurrentSaliencyTransformation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lingxi Xie\">\n<a href=\"#\" onclick=\"document.getElementById('form-LingxiXieRecurrentSaliencyTransformation').submit();\">Lingxi Xie</a>,\n</form>\n<form id=\"form-YanWangRecurrentSaliencyTransformation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yan Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YanWangRecurrentSaliencyTransformation').submit();\">Yan Wang</a>,\n</form>\n<form id=\"form-YuyinZhouRecurrentSaliencyTransformation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuyin Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuyinZhouRecurrentSaliencyTransformation').submit();\">Yuyin Zhou</a>,\n</form>\n<form id=\"form-ElliotK.RecurrentSaliencyTransformation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Elliot K. Fishman\">\n<a href=\"#\" onclick=\"document.getElementById('form-ElliotK.RecurrentSaliencyTransformation').submit();\">Elliot K. Fishman</a>,\n</form>\n<form id=\"form-AlanL.RecurrentSaliencyTransformation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alan L. Yuille\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlanL.RecurrentSaliencyTransformation').submit();\">Alan L. Yuille</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yu_Recurrent_Saliency_Transformation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1709.04518\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yu_2018_CVPR,<br>\nauthor = {Yu, Qihang and Xie, Lingxi and Wang, Yan and Zhou, Yuyin and Fishman, Elliot K. and Yuille, Alan L.},<br>\ntitle = {Recurrent Saliency Transformation Network: Incorporating Multi-Stage Visual Cues for Small Organ Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Thoracic_Disease_Identification_CVPR_2018_paper.html\">Thoracic Disease Identification and Localization With Limited Supervision</a></dt>\n<dd>\n<form id=\"form-ZheLiThoracicDiseaseIdentification\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhe Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZheLiThoracicDiseaseIdentification').submit();\">Zhe Li</a>,\n</form>\n<form id=\"form-ChongWangThoracicDiseaseIdentification\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chong Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChongWangThoracicDiseaseIdentification').submit();\">Chong Wang</a>,\n</form>\n<form id=\"form-MeiHanThoracicDiseaseIdentification\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mei Han\">\n<a href=\"#\" onclick=\"document.getElementById('form-MeiHanThoracicDiseaseIdentification').submit();\">Mei Han</a>,\n</form>\n<form id=\"form-YuanXueThoracicDiseaseIdentification\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuan Xue\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuanXueThoracicDiseaseIdentification').submit();\">Yuan Xue</a>,\n</form>\n<form id=\"form-WeiWeiThoracicDiseaseIdentification\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Wei\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiWeiThoracicDiseaseIdentification').submit();\">Wei Wei</a>,\n</form>\n<form id=\"form-Li-JiaLiThoracicDiseaseIdentification\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Li-Jia Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-Li-JiaLiThoracicDiseaseIdentification').submit();\">Li-Jia Li</a>,\n</form>\n<form id=\"form-LiFei-FeiThoracicDiseaseIdentification\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Li Fei-Fei\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiFei-FeiThoracicDiseaseIdentification').submit();\">Li Fei-Fei</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Thoracic_Disease_Identification_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0418-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.06373\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Zhe and Wang, Chong and Han, Mei and Xue, Yuan and Wei, Wei and Li, Li-Jia and Fei-Fei, Li},<br>\ntitle = {Thoracic Disease Identification and Localization With Limited Supervision},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xu_Quantization_of_Fully_CVPR_2018_paper.html\">Quantization of Fully Convolutional Networks for Accurate Biomedical Image Segmentation</a></dt>\n<dd>\n<form id=\"form-XiaoweiXuQuantizationofFully\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaowei Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaoweiXuQuantizationofFully').submit();\">Xiaowei Xu</a>,\n</form>\n<form id=\"form-QingLuQuantizationofFully\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qing Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-QingLuQuantizationofFully').submit();\">Qing Lu</a>,\n</form>\n<form id=\"form-LinYangQuantizationofFully\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lin Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LinYangQuantizationofFully').submit();\">Lin Yang</a>,\n</form>\n<form id=\"form-SharonHuQuantizationofFully\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sharon Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-SharonHuQuantizationofFully').submit();\">Sharon Hu</a>,\n</form>\n<form id=\"form-DannyChenQuantizationofFully\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Danny Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-DannyChenQuantizationofFully').submit();\">Danny Chen</a>,\n</form>\n<form id=\"form-YuHuQuantizationofFully\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuHuQuantizationofFully').submit();\">Yu Hu</a>,\n</form>\n<form id=\"form-YiyuShiQuantizationofFully\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yiyu Shi\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiyuShiQuantizationofFully').submit();\">Yiyu Shi</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xu_Quantization_of_Fully_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.04907\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xu_2018_CVPR,<br>\nauthor = {Xu, Xiaowei and Lu, Qing and Yang, Lin and Hu, Sharon and Chen, Danny and Hu, Yu and Shi, Yiyu},<br>\ntitle = {Quantization of Fully Convolutional Networks for Accurate Biomedical Image Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Baumgartner_Visual_Feature_Attribution_CVPR_2018_paper.html\">Visual Feature Attribution Using Wasserstein GANs</a></dt>\n<dd>\n<form id=\"form-ChristianF.VisualFeatureAttribution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Christian F. Baumgartner\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChristianF.VisualFeatureAttribution').submit();\">Christian F. Baumgartner</a>,\n</form>\n<form id=\"form-LisaM.VisualFeatureAttribution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lisa M. Koch\">\n<a href=\"#\" onclick=\"document.getElementById('form-LisaM.VisualFeatureAttribution').submit();\">Lisa M. Koch</a>,\n</form>\n<form id=\"form-KeremCanVisualFeatureAttribution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kerem Can Tezcan\">\n<a href=\"#\" onclick=\"document.getElementById('form-KeremCanVisualFeatureAttribution').submit();\">Kerem Can Tezcan</a>,\n</form>\n<form id=\"form-JiaXiVisualFeatureAttribution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jia Xi Ang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiaXiVisualFeatureAttribution').submit();\">Jia Xi Ang</a>,\n</form>\n<form id=\"form-EnderKonukogluVisualFeatureAttribution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ender Konukoglu\">\n<a href=\"#\" onclick=\"document.getElementById('form-EnderKonukogluVisualFeatureAttribution').submit();\">Ender Konukoglu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Baumgartner_Visual_Feature_Attribution_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3918-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.08998\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Baumgartner_2018_CVPR,<br>\nauthor = {Baumgartner, Christian F. and Koch, Lisa M. and Can Tezcan, Kerem and Xi Ang, Jia and Konukoglu, Ender},<br>\ntitle = {Visual Feature Attribution Using Wasserstein GANs},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Joo_Total_Capture_A_CVPR_2018_paper.html\">Total Capture: A 3D Deformation Model for Tracking Faces, Hands, and Bodies</a></dt>\n<dd>\n<form id=\"form-HanbyulJooTotalCaptureA\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hanbyul Joo\">\n<a href=\"#\" onclick=\"document.getElementById('form-HanbyulJooTotalCaptureA').submit();\">Hanbyul Joo</a>,\n</form>\n<form id=\"form-TomasSimonTotalCaptureA\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tomas Simon\">\n<a href=\"#\" onclick=\"document.getElementById('form-TomasSimonTotalCaptureA').submit();\">Tomas Simon</a>,\n</form>\n<form id=\"form-YaserSheikhTotalCaptureA\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yaser Sheikh\">\n<a href=\"#\" onclick=\"document.getElementById('form-YaserSheikhTotalCaptureA').submit();\">Yaser Sheikh</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Joo_Total_Capture_A_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Joo_2018_CVPR,<br>\nauthor = {Joo, Hanbyul and Simon, Tomas and Sheikh, Yaser},<br>\ntitle = {Total Capture: A 3D Deformation Model for Tracking Faces, Hands, and Bodies},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Baek_Augmented_Skeleton_Space_CVPR_2018_paper.html\">Augmented Skeleton Space Transfer for Depth-Based Hand Pose Estimation</a></dt>\n<dd>\n<form id=\"form-SeungryulBaekAugmentedSkeletonSpace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Seungryul Baek\">\n<a href=\"#\" onclick=\"document.getElementById('form-SeungryulBaekAugmentedSkeletonSpace').submit();\">Seungryul Baek</a>,\n</form>\n<form id=\"form-KwangInAugmentedSkeletonSpace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kwang In Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-KwangInAugmentedSkeletonSpace').submit();\">Kwang In Kim</a>,\n</form>\n<form id=\"form-Tae-KyunKimAugmentedSkeletonSpace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tae-Kyun Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-Tae-KyunKimAugmentedSkeletonSpace').submit();\">Tae-Kyun Kim</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Baek_Augmented_Skeleton_Space_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.04497\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Baek_2018_CVPR,<br>\nauthor = {Baek, Seungryul and In Kim, Kwang and Kim, Tae-Kyun},<br>\ntitle = {Augmented Skeleton Space Transfer for Depth-Based Hand Pose Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Balakrishnan_Synthesizing_Images_of_CVPR_2018_paper.html\">Synthesizing Images of Humans in Unseen Poses</a></dt>\n<dd>\n<form id=\"form-GuhaBalakrishnanSynthesizingImagesof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guha Balakrishnan\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuhaBalakrishnanSynthesizingImagesof').submit();\">Guha Balakrishnan</a>,\n</form>\n<form id=\"form-AmyZhaoSynthesizingImagesof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Amy Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-AmyZhaoSynthesizingImagesof').submit();\">Amy Zhao</a>,\n</form>\n<form id=\"form-AdrianV.SynthesizingImagesof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Adrian V. Dalca\">\n<a href=\"#\" onclick=\"document.getElementById('form-AdrianV.SynthesizingImagesof').submit();\">Adrian V. Dalca</a>,\n</form>\n<form id=\"form-Fr\u00c3\u00a9doDurandSynthesizingImagesof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fr\u00c3\u00a9do Durand\">\n<a href=\"#\" onclick=\"document.getElementById('form-Fr\u00c3\u00a9doDurandSynthesizingImagesof').submit();\">Fr\u00c3\u00a9do Durand</a>,\n</form>\n<form id=\"form-JohnGuttagSynthesizingImagesof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"John Guttag\">\n<a href=\"#\" onclick=\"document.getElementById('form-JohnGuttagSynthesizingImagesof').submit();\">John Guttag</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Balakrishnan_Synthesizing_Images_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1978-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.07739\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Balakrishnan_2018_CVPR,<br>\nauthor = {Balakrishnan, Guha and Zhao, Amy and Dalca, Adrian V. and Durand, Fr\u00c3\u00a9do and Guttag, John},<br>\ntitle = {Synthesizing Images of Humans in Unseen Poses},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_SSNet_Scale_Selection_CVPR_2018_paper.html\">SSNet: Scale Selection Network for Online 3D Action Prediction</a></dt>\n<dd>\n<form id=\"form-JunLiuSSNetScaleSelection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jun Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunLiuSSNetScaleSelection').submit();\">Jun Liu</a>,\n</form>\n<form id=\"form-AmirShahroudySSNetScaleSelection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Amir Shahroudy\">\n<a href=\"#\" onclick=\"document.getElementById('form-AmirShahroudySSNetScaleSelection').submit();\">Amir Shahroudy</a>,\n</form>\n<form id=\"form-GangWangSSNetScaleSelection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-GangWangSSNetScaleSelection').submit();\">Gang Wang</a>,\n</form>\n<form id=\"form-Ling-YuDuanSSNetScaleSelection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ling-Yu Duan\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ling-YuDuanSSNetScaleSelection').submit();\">Ling-Yu Duan</a>,\n</form>\n<form id=\"form-AlexC.SSNetScaleSelection\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alex C. Kot\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexC.SSNetScaleSelection').submit();\">Alex C. Kot</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_SSNet_Scale_Selection_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Jun and Shahroudy, Amir and Wang, Gang and Duan, Ling-Yu and Kot, Alex C.},<br>\ntitle = {SSNet: Scale Selection Network for Online 3D Action Prediction},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Gkioxari_Detecting_and_Recognizing_CVPR_2018_paper.html\">Detecting and Recognizing Human-Object Interactions</a></dt>\n<dd>\n<form id=\"form-GeorgiaGkioxariDetectingandRecognizing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Georgia Gkioxari\">\n<a href=\"#\" onclick=\"document.getElementById('form-GeorgiaGkioxariDetectingandRecognizing').submit();\">Georgia Gkioxari</a>,\n</form>\n<form id=\"form-RossGirshickDetectingandRecognizing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ross Girshick\">\n<a href=\"#\" onclick=\"document.getElementById('form-RossGirshickDetectingandRecognizing').submit();\">Ross Girshick</a>,\n</form>\n<form id=\"form-PiotrDoll\u00c3\u00a1rDetectingandRecognizing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Piotr Doll\u00c3\u00a1r\">\n<a href=\"#\" onclick=\"document.getElementById('form-PiotrDoll\u00c3\u00a1rDetectingandRecognizing').submit();\">Piotr Doll\u00c3\u00a1r</a>,\n</form>\n<form id=\"form-KaimingHeDetectingandRecognizing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kaiming He\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaimingHeDetectingandRecognizing').submit();\">Kaiming He</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Gkioxari_Detecting_and_Recognizing_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1704.07333\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Gkioxari_2018_CVPR,<br>\nauthor = {Gkioxari, Georgia and Girshick, Ross and Doll\u00c3\u00a1r, Piotr and He, Kaiming},<br>\ntitle = {Detecting and Recognizing Human-Object Interactions},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sener_Unsupervised_Learning_and_CVPR_2018_paper.html\">Unsupervised Learning and Segmentation of Complex Activities From Video</a></dt>\n<dd>\n<form id=\"form-FadimeSenerUnsupervisedLearningand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fadime Sener\">\n<a href=\"#\" onclick=\"document.getElementById('form-FadimeSenerUnsupervisedLearningand').submit();\">Fadime Sener</a>,\n</form>\n<form id=\"form-AngelaYaoUnsupervisedLearningand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Angela Yao\">\n<a href=\"#\" onclick=\"document.getElementById('form-AngelaYaoUnsupervisedLearningand').submit();\">Angela Yao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sener_Unsupervised_Learning_and_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.09490\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sener_2018_CVPR,<br>\nauthor = {Sener, Fadime and Yao, Angela},<br>\ntitle = {Unsupervised Learning and Segmentation of Complex Activities From Video},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Genova_Unsupervised_Training_for_CVPR_2018_paper.html\">Unsupervised Training for 3D Morphable Model Regression</a></dt>\n<dd>\n<form id=\"form-KyleGenovaUnsupervisedTrainingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kyle Genova\">\n<a href=\"#\" onclick=\"document.getElementById('form-KyleGenovaUnsupervisedTrainingfor').submit();\">Kyle Genova</a>,\n</form>\n<form id=\"form-ForresterColeUnsupervisedTrainingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Forrester Cole\">\n<a href=\"#\" onclick=\"document.getElementById('form-ForresterColeUnsupervisedTrainingfor').submit();\">Forrester Cole</a>,\n</form>\n<form id=\"form-AaronMaschinotUnsupervisedTrainingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Aaron Maschinot\">\n<a href=\"#\" onclick=\"document.getElementById('form-AaronMaschinotUnsupervisedTrainingfor').submit();\">Aaron Maschinot</a>,\n</form>\n<form id=\"form-AaronSarnaUnsupervisedTrainingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Aaron Sarna\">\n<a href=\"#\" onclick=\"document.getElementById('form-AaronSarnaUnsupervisedTrainingfor').submit();\">Aaron Sarna</a>,\n</form>\n<form id=\"form-DanielVlasicUnsupervisedTrainingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daniel Vlasic\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanielVlasicUnsupervisedTrainingfor').submit();\">Daniel Vlasic</a>,\n</form>\n<form id=\"form-WilliamT.UnsupervisedTrainingfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"William T. Freeman\">\n<a href=\"#\" onclick=\"document.getElementById('form-WilliamT.UnsupervisedTrainingfor').submit();\">William T. Freeman</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Genova_Unsupervised_Training_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1806.06098\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Genova_2018_CVPR,<br>\nauthor = {Genova, Kyle and Cole, Forrester and Maschinot, Aaron and Sarna, Aaron and Vlasic, Daniel and Freeman, William T.},<br>\ntitle = {Unsupervised Training for 3D Morphable Model Regression},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Alldieck_Video_Based_Reconstruction_CVPR_2018_paper.html\">Video Based Reconstruction of 3D People Models</a></dt>\n<dd>\n<form id=\"form-ThiemoAlldieckVideoBasedReconstruction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Thiemo Alldieck\">\n<a href=\"#\" onclick=\"document.getElementById('form-ThiemoAlldieckVideoBasedReconstruction').submit();\">Thiemo Alldieck</a>,\n</form>\n<form id=\"form-MarcusMagnorVideoBasedReconstruction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Marcus Magnor\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarcusMagnorVideoBasedReconstruction').submit();\">Marcus Magnor</a>,\n</form>\n<form id=\"form-WeipengXuVideoBasedReconstruction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weipeng Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeipengXuVideoBasedReconstruction').submit();\">Weipeng Xu</a>,\n</form>\n<form id=\"form-ChristianTheobaltVideoBasedReconstruction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Christian Theobalt\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChristianTheobaltVideoBasedReconstruction').submit();\">Christian Theobalt</a>,\n</form>\n<form id=\"form-GerardPons-MollVideoBasedReconstruction\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gerard Pons-Moll\">\n<a href=\"#\" onclick=\"document.getElementById('form-GerardPons-MollVideoBasedReconstruction').submit();\">Gerard Pons-Moll</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Alldieck_Video_Based_Reconstruction_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2769-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.04758\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Alldieck_2018_CVPR,<br>\nauthor = {Alldieck, Thiemo and Magnor, Marcus and Xu, Weipeng and Theobalt, Christian and Pons-Moll, Gerard},<br>\ntitle = {Video Based Reconstruction of 3D People Models},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hu_Pose-Guided_Photorealistic_Face_CVPR_2018_paper.html\">Pose-Guided Photorealistic Face Rotation</a></dt>\n<dd>\n<form id=\"form-YiboHuPoseGuidedPhotorealisticFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yibo Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiboHuPoseGuidedPhotorealisticFace').submit();\">Yibo Hu</a>,\n</form>\n<form id=\"form-XiangWuPoseGuidedPhotorealisticFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiang Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiangWuPoseGuidedPhotorealisticFace').submit();\">Xiang Wu</a>,\n</form>\n<form id=\"form-BingYuPoseGuidedPhotorealisticFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bing Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-BingYuPoseGuidedPhotorealisticFace').submit();\">Bing Yu</a>,\n</form>\n<form id=\"form-RanHePoseGuidedPhotorealisticFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ran He\">\n<a href=\"#\" onclick=\"document.getElementById('form-RanHePoseGuidedPhotorealisticFace').submit();\">Ran He</a>,\n</form>\n<form id=\"form-ZhenanSunPoseGuidedPhotorealisticFace\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhenan Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhenanSunPoseGuidedPhotorealisticFace').submit();\">Zhenan Sun</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hu_Pose-Guided_Photorealistic_Face_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1097-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hu_2018_CVPR,<br>\nauthor = {Hu, Yibo and Wu, Xiang and Yu, Bing and He, Ran and Sun, Zhenan},<br>\ntitle = {Pose-Guided Photorealistic Face Rotation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Huynh_Mesoscopic_Facial_Geometry_CVPR_2018_paper.html\">Mesoscopic Facial Geometry Inference Using Deep Neural Networks</a></dt>\n<dd>\n<form id=\"form-LocHuynhMesoscopicFacialGeometry\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Loc Huynh\">\n<a href=\"#\" onclick=\"document.getElementById('form-LocHuynhMesoscopicFacialGeometry').submit();\">Loc Huynh</a>,\n</form>\n<form id=\"form-WeikaiChenMesoscopicFacialGeometry\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weikai Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeikaiChenMesoscopicFacialGeometry').submit();\">Weikai Chen</a>,\n</form>\n<form id=\"form-ShunsukeSaitoMesoscopicFacialGeometry\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shunsuke Saito\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShunsukeSaitoMesoscopicFacialGeometry').submit();\">Shunsuke Saito</a>,\n</form>\n<form id=\"form-JunXingMesoscopicFacialGeometry\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jun Xing\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunXingMesoscopicFacialGeometry').submit();\">Jun Xing</a>,\n</form>\n<form id=\"form-KokiNaganoMesoscopicFacialGeometry\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Koki Nagano\">\n<a href=\"#\" onclick=\"document.getElementById('form-KokiNaganoMesoscopicFacialGeometry').submit();\">Koki Nagano</a>,\n</form>\n<form id=\"form-AndrewJonesMesoscopicFacialGeometry\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrew Jones\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndrewJonesMesoscopicFacialGeometry').submit();\">Andrew Jones</a>,\n</form>\n<form id=\"form-PaulDebevecMesoscopicFacialGeometry\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Paul Debevec\">\n<a href=\"#\" onclick=\"document.getElementById('form-PaulDebevecMesoscopicFacialGeometry').submit();\">Paul Debevec</a>,\n</form>\n<form id=\"form-HaoLiMesoscopicFacialGeometry\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hao Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaoLiMesoscopicFacialGeometry').submit();\">Hao Li</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Huynh_Mesoscopic_Facial_Geometry_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2496-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Huynh_2018_CVPR,<br>\nauthor = {Huynh, Loc and Chen, Weikai and Saito, Shunsuke and Xing, Jun and Nagano, Koki and Jones, Andrew and Debevec, Paul and Li, Hao},<br>\ntitle = {Mesoscopic Facial Geometry Inference Using Deep Neural Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ge_Hand_PointNet_3D_CVPR_2018_paper.html\">Hand PointNet: 3D Hand Pose Estimation Using Point Sets</a></dt>\n<dd>\n<form id=\"form-LiuhaoGeHandPointNet3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Liuhao Ge\">\n<a href=\"#\" onclick=\"document.getElementById('form-LiuhaoGeHandPointNet3D').submit();\">Liuhao Ge</a>,\n</form>\n<form id=\"form-YujunCaiHandPointNet3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yujun Cai\">\n<a href=\"#\" onclick=\"document.getElementById('form-YujunCaiHandPointNet3D').submit();\">Yujun Cai</a>,\n</form>\n<form id=\"form-JunwuWengHandPointNet3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junwu Weng\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunwuWengHandPointNet3D').submit();\">Junwu Weng</a>,\n</form>\n<form id=\"form-JunsongYuanHandPointNet3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junsong Yuan\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunsongYuanHandPointNet3D').submit();\">Junsong Yuan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ge_Hand_PointNet_3D_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0687-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ge_2018_CVPR,<br>\nauthor = {Ge, Liuhao and Cai, Yujun and Weng, Junwu and Yuan, Junsong},<br>\ntitle = {Hand PointNet: 3D Hand Pose Estimation Using Point Sets},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Nagrani_Seeing_Voices_and_CVPR_2018_paper.html\">Seeing Voices and Hearing Faces: Cross-Modal Biometric Matching</a></dt>\n<dd>\n<form id=\"form-ArshaNagraniSeeingVoicesand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Arsha Nagrani\">\n<a href=\"#\" onclick=\"document.getElementById('form-ArshaNagraniSeeingVoicesand').submit();\">Arsha Nagrani</a>,\n</form>\n<form id=\"form-SamuelAlbanieSeeingVoicesand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Samuel Albanie\">\n<a href=\"#\" onclick=\"document.getElementById('form-SamuelAlbanieSeeingVoicesand').submit();\">Samuel Albanie</a>,\n</form>\n<form id=\"form-AndrewZissermanSeeingVoicesand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrew Zisserman\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndrewZissermanSeeingVoicesand').submit();\">Andrew Zisserman</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Nagrani_Seeing_Voices_and_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3001-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00326\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Nagrani_2018_CVPR,<br>\nauthor = {Nagrani, Arsha and Albanie, Samuel and Zisserman, Andrew},<br>\ntitle = {Seeing Voices and Hearing Faces: Cross-Modal Biometric Matching},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Rhodin_Learning_Monocular_3D_CVPR_2018_paper.html\">Learning Monocular 3D Human Pose Estimation From Multi-View Images</a></dt>\n<dd>\n<form id=\"form-HelgeRhodinLearningMonocular3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Helge Rhodin\">\n<a href=\"#\" onclick=\"document.getElementById('form-HelgeRhodinLearningMonocular3D').submit();\">Helge Rhodin</a>,\n</form>\n<form id=\"form-J\u00c3\u00b6rgSp\u00c3\u00b6rriLearningMonocular3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"J\u00c3\u00b6rg Sp\u00c3\u00b6rri\">\n<a href=\"#\" onclick=\"document.getElementById('form-J\u00c3\u00b6rgSp\u00c3\u00b6rriLearningMonocular3D').submit();\">J\u00c3\u00b6rg Sp\u00c3\u00b6rri</a>,\n</form>\n<form id=\"form-IsinsuKatirciogluLearningMonocular3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Isinsu Katircioglu\">\n<a href=\"#\" onclick=\"document.getElementById('form-IsinsuKatirciogluLearningMonocular3D').submit();\">Isinsu Katircioglu</a>,\n</form>\n<form id=\"form-VictorConstantinLearningMonocular3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Victor Constantin\">\n<a href=\"#\" onclick=\"document.getElementById('form-VictorConstantinLearningMonocular3D').submit();\">Victor Constantin</a>,\n</form>\n<form id=\"form-Fr\u00c3\u00a9d\u00c3\u00a9ricMeyerLearningMonocular3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fr\u00c3\u00a9d\u00c3\u00a9ric Meyer\">\n<a href=\"#\" onclick=\"document.getElementById('form-Fr\u00c3\u00a9d\u00c3\u00a9ricMeyerLearningMonocular3D').submit();\">Fr\u00c3\u00a9d\u00c3\u00a9ric Meyer</a>,\n</form>\n<form id=\"form-ErichM\u00c3\u00bcllerLearningMonocular3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Erich M\u00c3\u00bcller\">\n<a href=\"#\" onclick=\"document.getElementById('form-ErichM\u00c3\u00bcllerLearningMonocular3D').submit();\">Erich M\u00c3\u00bcller</a>,\n</form>\n<form id=\"form-MathieuSalzmannLearningMonocular3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mathieu Salzmann\">\n<a href=\"#\" onclick=\"document.getElementById('form-MathieuSalzmannLearningMonocular3D').submit();\">Mathieu Salzmann</a>,\n</form>\n<form id=\"form-PascalFuaLearningMonocular3D\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pascal Fua\">\n<a href=\"#\" onclick=\"document.getElementById('form-PascalFuaLearningMonocular3D').submit();\">Pascal Fua</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Rhodin_Learning_Monocular_3D_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2355-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.04775\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Rhodin_2018_CVPR,<br>\nauthor = {Rhodin, Helge and Sp\u00c3\u00b6rri, J\u00c3\u00b6rg and Katircioglu, Isinsu and Constantin, Victor and Meyer, Fr\u00c3\u00a9d\u00c3\u00a9ric and M\u00c3\u00bcller, Erich and Salzmann, Mathieu and Fua, Pascal},<br>\ntitle = {Learning Monocular 3D Human Pose Estimation From Multi-View Images},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Separating_Style_and_CVPR_2018_paper.html\">Separating Style and Content for Generalized Style Transfer</a></dt>\n<dd>\n<form id=\"form-YexunZhangSeparatingStyleand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yexun Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YexunZhangSeparatingStyleand').submit();\">Yexun Zhang</a>,\n</form>\n<form id=\"form-YaZhangSeparatingStyleand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ya Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YaZhangSeparatingStyleand').submit();\">Ya Zhang</a>,\n</form>\n<form id=\"form-WenbinCaiSeparatingStyleand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenbin Cai\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenbinCaiSeparatingStyleand').submit();\">Wenbin Cai</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Separating_Style_and_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1644-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.06454\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Yexun and Zhang, Ya and Cai, Wenbin},<br>\ntitle = {Separating Style and Content for Generalized Style Transfer},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xian_TextureGAN_Controlling_Deep_CVPR_2018_paper.html\">TextureGAN: Controlling Deep Image Synthesis With Texture Patches</a></dt>\n<dd>\n<form id=\"form-WenqiXianTextureGANControllingDeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenqi Xian\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenqiXianTextureGANControllingDeep').submit();\">Wenqi Xian</a>,\n</form>\n<form id=\"form-PatsornSangkloyTextureGANControllingDeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Patsorn Sangkloy\">\n<a href=\"#\" onclick=\"document.getElementById('form-PatsornSangkloyTextureGANControllingDeep').submit();\">Patsorn Sangkloy</a>,\n</form>\n<form id=\"form-VarunAgrawalTextureGANControllingDeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Varun Agrawal\">\n<a href=\"#\" onclick=\"document.getElementById('form-VarunAgrawalTextureGANControllingDeep').submit();\">Varun Agrawal</a>,\n</form>\n<form id=\"form-AmitRajTextureGANControllingDeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Amit Raj\">\n<a href=\"#\" onclick=\"document.getElementById('form-AmitRajTextureGANControllingDeep').submit();\">Amit Raj</a>,\n</form>\n<form id=\"form-JingwanLuTextureGANControllingDeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jingwan Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingwanLuTextureGANControllingDeep').submit();\">Jingwan Lu</a>,\n</form>\n<form id=\"form-ChenFangTextureGANControllingDeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chen Fang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenFangTextureGANControllingDeep').submit();\">Chen Fang</a>,\n</form>\n<form id=\"form-FisherYuTextureGANControllingDeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fisher Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-FisherYuTextureGANControllingDeep').submit();\">Fisher Yu</a>,\n</form>\n<form id=\"form-JamesHaysTextureGANControllingDeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"James Hays\">\n<a href=\"#\" onclick=\"document.getElementById('form-JamesHaysTextureGANControllingDeep').submit();\">James Hays</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xian_TextureGAN_Controlling_Deep_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3523-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1706.02823\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xian_2018_CVPR,<br>\nauthor = {Xian, Wenqi and Sangkloy, Patsorn and Agrawal, Varun and Raj, Amit and Lu, Jingwan and Fang, Chen and Yu, Fisher and Hays, James},<br>\ntitle = {TextureGAN: Controlling Deep Image Synthesis With Texture Patches},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Orekondy_Connecting_Pixels_to_CVPR_2018_paper.html\">Connecting Pixels to Privacy and Utility: Automatic Redaction of Private Information in Images</a></dt>\n<dd>\n<form id=\"form-TribhuvaneshOrekondyConnectingPixelsto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tribhuvanesh Orekondy\">\n<a href=\"#\" onclick=\"document.getElementById('form-TribhuvaneshOrekondyConnectingPixelsto').submit();\">Tribhuvanesh Orekondy</a>,\n</form>\n<form id=\"form-MarioFritzConnectingPixelsto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mario Fritz\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarioFritzConnectingPixelsto').submit();\">Mario Fritz</a>,\n</form>\n<form id=\"form-BerntSchieleConnectingPixelsto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bernt Schiele\">\n<a href=\"#\" onclick=\"document.getElementById('form-BerntSchieleConnectingPixelsto').submit();\">Bernt Schiele</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Orekondy_Connecting_Pixels_to_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3536-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.01066\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Orekondy_2018_CVPR,<br>\nauthor = {Orekondy, Tribhuvanesh and Fritz, Mario and Schiele, Bernt},<br>\ntitle = {Connecting Pixels to Privacy and Utility: Automatic Redaction of Private Information in Images},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Henriques_MapNet_An_Allocentric_CVPR_2018_paper.html\">MapNet: An Allocentric Spatial Memory for Mapping Environments</a></dt>\n<dd>\n<form id=\"form-Jo\u00c3\u00a3oF.MapNetAnAllocentric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jo\u00c3\u00a3o F. Henriques\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jo\u00c3\u00a3oF.MapNetAnAllocentric').submit();\">Jo\u00c3\u00a3o F. Henriques</a>,\n</form>\n<form id=\"form-AndreaVedaldiMapNetAnAllocentric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrea Vedaldi\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndreaVedaldiMapNetAnAllocentric').submit();\">Andrea Vedaldi</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Henriques_MapNet_An_Allocentric_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Henriques_2018_CVPR,<br>\nauthor = {Henriques, Jo\u00c3\u00a3o F. and Vedaldi, Andrea},<br>\ntitle = {MapNet: An Allocentric Spatial Memory for Mapping Environments},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Bhattacharyya_Accurate_and_Diverse_CVPR_2018_paper.html\">Accurate and Diverse Sampling of Sequences Based on a \u00e2\u0080\u009cBest of Many\u00e2\u0080\u009d Sample Objective</a></dt>\n<dd>\n<form id=\"form-ApratimBhattacharyyaAccurateandDiverse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Apratim Bhattacharyya\">\n<a href=\"#\" onclick=\"document.getElementById('form-ApratimBhattacharyyaAccurateandDiverse').submit();\">Apratim Bhattacharyya</a>,\n</form>\n<form id=\"form-BerntSchieleAccurateandDiverse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bernt Schiele\">\n<a href=\"#\" onclick=\"document.getElementById('form-BerntSchieleAccurateandDiverse').submit();\">Bernt Schiele</a>,\n</form>\n<form id=\"form-MarioFritzAccurateandDiverse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mario Fritz\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarioFritzAccurateandDiverse').submit();\">Mario Fritz</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Bhattacharyya_Accurate_and_Diverse_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3890-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Bhattacharyya_2018_CVPR,<br>\nauthor = {Bhattacharyya, Apratim and Schiele, Bernt and Fritz, Mario},<br>\ntitle = {Accurate and Diverse Sampling of Sequences Based on a \u00e2\u0080\u009cBest of Many\u00e2\u0080\u009d Sample Objective},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Puig_VirtualHome_Simulating_Household_CVPR_2018_paper.html\">VirtualHome: Simulating Household Activities via Programs</a></dt>\n<dd>\n<form id=\"form-XavierPuigVirtualHomeSimulatingHousehold\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xavier Puig\">\n<a href=\"#\" onclick=\"document.getElementById('form-XavierPuigVirtualHomeSimulatingHousehold').submit();\">Xavier Puig</a>,\n</form>\n<form id=\"form-KevinRaVirtualHomeSimulatingHousehold\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kevin Ra\">\n<a href=\"#\" onclick=\"document.getElementById('form-KevinRaVirtualHomeSimulatingHousehold').submit();\">Kevin Ra</a>,\n</form>\n<form id=\"form-MarkoBobenVirtualHomeSimulatingHousehold\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Marko Boben\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarkoBobenVirtualHomeSimulatingHousehold').submit();\">Marko Boben</a>,\n</form>\n<form id=\"form-JiamanLiVirtualHomeSimulatingHousehold\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiaman Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiamanLiVirtualHomeSimulatingHousehold').submit();\">Jiaman Li</a>,\n</form>\n<form id=\"form-TingwuWangVirtualHomeSimulatingHousehold\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tingwu Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-TingwuWangVirtualHomeSimulatingHousehold').submit();\">Tingwu Wang</a>,\n</form>\n<form id=\"form-SanjaFidlerVirtualHomeSimulatingHousehold\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sanja Fidler\">\n<a href=\"#\" onclick=\"document.getElementById('form-SanjaFidlerVirtualHomeSimulatingHousehold').submit();\">Sanja Fidler</a>,\n</form>\n<form id=\"form-AntonioTorralbaVirtualHomeSimulatingHousehold\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Antonio Torralba\">\n<a href=\"#\" onclick=\"document.getElementById('form-AntonioTorralbaVirtualHomeSimulatingHousehold').submit();\">Antonio Torralba</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Puig_VirtualHome_Simulating_Household_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1806.07011\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Puig_2018_CVPR,<br>\nauthor = {Puig, Xavier and Ra, Kevin and Boben, Marko and Li, Jiaman and Wang, Tingwu and Fidler, Sanja and Torralba, Antonio},<br>\ntitle = {VirtualHome: Simulating Household Activities via Programs},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sankaranarayanan_Generate_to_Adapt_CVPR_2018_paper.html\">Generate to Adapt: Aligning Domains Using Generative Adversarial Networks</a></dt>\n<dd>\n<form id=\"form-SwamiSankaranarayananGeneratetoAdapt\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Swami Sankaranarayanan\">\n<a href=\"#\" onclick=\"document.getElementById('form-SwamiSankaranarayananGeneratetoAdapt').submit();\">Swami Sankaranarayanan</a>,\n</form>\n<form id=\"form-YogeshBalajiGeneratetoAdapt\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yogesh Balaji\">\n<a href=\"#\" onclick=\"document.getElementById('form-YogeshBalajiGeneratetoAdapt').submit();\">Yogesh Balaji</a>,\n</form>\n<form id=\"form-CarlosD.GeneratetoAdapt\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Carlos D. Castillo\">\n<a href=\"#\" onclick=\"document.getElementById('form-CarlosD.GeneratetoAdapt').submit();\">Carlos D. Castillo</a>,\n</form>\n<form id=\"form-RamaChellappaGeneratetoAdapt\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rama Chellappa\">\n<a href=\"#\" onclick=\"document.getElementById('form-RamaChellappaGeneratetoAdapt').submit();\">Rama Chellappa</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sankaranarayanan_Generate_to_Adapt_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2082-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1704.01705\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sankaranarayanan_2018_CVPR,<br>\nauthor = {Sankaranarayanan, Swami and Balaji, Yogesh and Castillo, Carlos D. and Chellappa, Rama},<br>\ntitle = {Generate to Adapt: Aligning Domains Using Generative Adversarial Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ghosh_Multi-Agent_Diverse_Generative_CVPR_2018_paper.html\">Multi-Agent Diverse Generative Adversarial Networks</a></dt>\n<dd>\n<form id=\"form-ArnabGhoshMultiAgentDiverseGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Arnab Ghosh\">\n<a href=\"#\" onclick=\"document.getElementById('form-ArnabGhoshMultiAgentDiverseGenerative').submit();\">Arnab Ghosh</a>,\n</form>\n<form id=\"form-VivekaKulhariaMultiAgentDiverseGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Viveka Kulharia\">\n<a href=\"#\" onclick=\"document.getElementById('form-VivekaKulhariaMultiAgentDiverseGenerative').submit();\">Viveka Kulharia</a>,\n</form>\n<form id=\"form-VinayP.MultiAgentDiverseGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vinay P. Namboodiri\">\n<a href=\"#\" onclick=\"document.getElementById('form-VinayP.MultiAgentDiverseGenerative').submit();\">Vinay P. Namboodiri</a>,\n</form>\n<form id=\"form-PhilipH.S.MultiAgentDiverseGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Philip H.S. Torr\">\n<a href=\"#\" onclick=\"document.getElementById('form-PhilipH.S.MultiAgentDiverseGenerative').submit();\">Philip H.S. Torr</a>,\n</form>\n<form id=\"form-PuneetK.MultiAgentDiverseGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Puneet K. Dokania\">\n<a href=\"#\" onclick=\"document.getElementById('form-PuneetK.MultiAgentDiverseGenerative').submit();\">Puneet K. Dokania</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ghosh_Multi-Agent_Diverse_Generative_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2347-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1704.02906\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ghosh_2018_CVPR,<br>\nauthor = {Ghosh, Arnab and Kulharia, Viveka and Namboodiri, Vinay P. and Torr, Philip H.S. and Dokania, Puneet K.},<br>\ntitle = {Multi-Agent Diverse Generative Adversarial Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/An_A_PID_Controller_CVPR_2018_paper.html\">A PID Controller Approach for Stochastic Optimization of Deep Networks</a></dt>\n<dd>\n<form id=\"form-WangpengAnAPIDController\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wangpeng An\">\n<a href=\"#\" onclick=\"document.getElementById('form-WangpengAnAPIDController').submit();\">Wangpeng An</a>,\n</form>\n<form id=\"form-HaoqianWangAPIDController\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Haoqian Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaoqianWangAPIDController').submit();\">Haoqian Wang</a>,\n</form>\n<form id=\"form-QingyunSunAPIDController\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qingyun Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-QingyunSunAPIDController').submit();\">Qingyun Sun</a>,\n</form>\n<form id=\"form-JunXuAPIDController\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jun Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunXuAPIDController').submit();\">Jun Xu</a>,\n</form>\n<form id=\"form-QionghaiDaiAPIDController\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qionghai Dai\">\n<a href=\"#\" onclick=\"document.getElementById('form-QionghaiDaiAPIDController').submit();\">Qionghai Dai</a>,\n</form>\n<form id=\"form-LeiZhangAPIDController\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lei Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeiZhangAPIDController').submit();\">Lei Zhang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/An_A_PID_Controller_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2918-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{An_2018_CVPR,<br>\nauthor = {An, Wangpeng and Wang, Haoqian and Sun, Qingyun and Xu, Jun and Dai, Qionghai and Zhang, Lei},<br>\ntitle = {A PID Controller Approach for Stochastic Optimization of Deep Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Carreira-Perpinan_Learning-Compression_Algorithms_for_CVPR_2018_paper.html\">\u00e2\u0080\u009cLearning-Compression\u00e2\u0080\u009d Algorithms for Neural Net Pruning</a></dt>\n<dd>\n<form id=\"form-Miguel\u00c3\u0081.LearningCompressionAlgorithmsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Miguel \u00c3\u0081. Carreira-Perpi\u00c3\u00b1\u00c3\u00a1n\">\n<a href=\"#\" onclick=\"document.getElementById('form-Miguel\u00c3\u0081.LearningCompressionAlgorithmsfor').submit();\">Miguel \u00c3\u0081. Carreira-Perpi\u00c3\u00b1\u00c3\u00a1n</a>,\n</form>\n<form id=\"form-YerlanIdelbayevLearningCompressionAlgorithmsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yerlan Idelbayev\">\n<a href=\"#\" onclick=\"document.getElementById('form-YerlanIdelbayevLearningCompressionAlgorithmsfor').submit();\">Yerlan Idelbayev</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Carreira-Perpinan_Learning-Compression_Algorithms_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3340-supp.zip\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Carreira-Perpi\u00c3\u00b1\u00c3\u00a1n_2018_CVPR,<br>\nauthor = {Carreira-Perpi\u00c3\u00b1\u00c3\u00a1n, Miguel \u00c3\u0081. and Idelbayev, Yerlan},<br>\ntitle = {\u00e2\u0080\u009cLearning-Compression\u00e2\u0080\u009d Algorithms for Neural Net Pruning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Qian_Large-Scale_Distance_Metric_CVPR_2018_paper.html\">Large-Scale Distance Metric Learning With Uncertainty</a></dt>\n<dd>\n<form id=\"form-QiQianLargeScaleDistanceMetric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qi Qian\">\n<a href=\"#\" onclick=\"document.getElementById('form-QiQianLargeScaleDistanceMetric').submit();\">Qi Qian</a>,\n</form>\n<form id=\"form-JiashengTangLargeScaleDistanceMetric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiasheng Tang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiashengTangLargeScaleDistanceMetric').submit();\">Jiasheng Tang</a>,\n</form>\n<form id=\"form-HaoLiLargeScaleDistanceMetric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hao Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaoLiLargeScaleDistanceMetric').submit();\">Hao Li</a>,\n</form>\n<form id=\"form-ShenghuoZhuLargeScaleDistanceMetric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shenghuo Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShenghuoZhuLargeScaleDistanceMetric').submit();\">Shenghuo Zhu</a>,\n</form>\n<form id=\"form-RongJinLargeScaleDistanceMetric\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rong Jin\">\n<a href=\"#\" onclick=\"document.getElementById('form-RongJinLargeScaleDistanceMetric').submit();\">Rong Jin</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Qian_Large-Scale_Distance_Metric_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.10384\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Qian_2018_CVPR,<br>\nauthor = {Qian, Qi and Tang, Jiasheng and Li, Hao and Zhu, Shenghuo and Jin, Rong},<br>\ntitle = {Large-Scale Distance Metric Learning With Uncertainty},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Rupprecht_Guide_Me_Interacting_CVPR_2018_paper.html\">Guide Me: Interacting With Deep Networks</a></dt>\n<dd>\n<form id=\"form-ChristianRupprechtGuideMeInteracting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Christian Rupprecht\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChristianRupprechtGuideMeInteracting').submit();\">Christian Rupprecht</a>,\n</form>\n<form id=\"form-IroLainaGuideMeInteracting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Iro Laina\">\n<a href=\"#\" onclick=\"document.getElementById('form-IroLainaGuideMeInteracting').submit();\">Iro Laina</a>,\n</form>\n<form id=\"form-NassirNavabGuideMeInteracting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nassir Navab\">\n<a href=\"#\" onclick=\"document.getElementById('form-NassirNavabGuideMeInteracting').submit();\">Nassir Navab</a>,\n</form>\n<form id=\"form-GregoryD.GuideMeInteracting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gregory D. Hager\">\n<a href=\"#\" onclick=\"document.getElementById('form-GregoryD.GuideMeInteracting').submit();\">Gregory D. Hager</a>,\n</form>\n<form id=\"form-FedericoTombariGuideMeInteracting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Federico Tombari\">\n<a href=\"#\" onclick=\"document.getElementById('form-FedericoTombariGuideMeInteracting').submit();\">Federico Tombari</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Rupprecht_Guide_Me_Interacting_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.11544\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Rupprecht_2018_CVPR,<br>\nauthor = {Rupprecht, Christian and Laina, Iro and Navab, Nassir and Hager, Gregory D. and Tombari, Federico},<br>\ntitle = {Guide Me: Interacting With Deep Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Khrulkov_Art_of_Singular_CVPR_2018_paper.html\">Art of Singular Vectors and Universal Adversarial Perturbations</a></dt>\n<dd>\n<form id=\"form-ValentinKhrulkovArtofSingular\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Valentin Khrulkov\">\n<a href=\"#\" onclick=\"document.getElementById('form-ValentinKhrulkovArtofSingular').submit();\">Valentin Khrulkov</a>,\n</form>\n<form id=\"form-IvanOseledetsArtofSingular\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ivan Oseledets\">\n<a href=\"#\" onclick=\"document.getElementById('form-IvanOseledetsArtofSingular').submit();\">Ivan Oseledets</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Khrulkov_Art_of_Singular_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1709.03582\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Khrulkov_2018_CVPR,<br>\nauthor = {Khrulkov, Valentin and Oseledets, Ivan},<br>\ntitle = {Art of Singular Vectors and Universal Adversarial Perturbations},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Prakash_Deflecting_Adversarial_Attacks_CVPR_2018_paper.html\">Deflecting Adversarial Attacks With Pixel Deflection</a></dt>\n<dd>\n<form id=\"form-AadityaPrakashDeflectingAdversarialAttacks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Aaditya Prakash\">\n<a href=\"#\" onclick=\"document.getElementById('form-AadityaPrakashDeflectingAdversarialAttacks').submit();\">Aaditya Prakash</a>,\n</form>\n<form id=\"form-NickMoranDeflectingAdversarialAttacks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nick Moran\">\n<a href=\"#\" onclick=\"document.getElementById('form-NickMoranDeflectingAdversarialAttacks').submit();\">Nick Moran</a>,\n</form>\n<form id=\"form-SolomonGarberDeflectingAdversarialAttacks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Solomon Garber\">\n<a href=\"#\" onclick=\"document.getElementById('form-SolomonGarberDeflectingAdversarialAttacks').submit();\">Solomon Garber</a>,\n</form>\n<form id=\"form-AntonellaDiLilloDeflectingAdversarialAttacks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Antonella DiLillo\">\n<a href=\"#\" onclick=\"document.getElementById('form-AntonellaDiLilloDeflectingAdversarialAttacks').submit();\">Antonella DiLillo</a>,\n</form>\n<form id=\"form-JamesStorerDeflectingAdversarialAttacks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"James Storer\">\n<a href=\"#\" onclick=\"document.getElementById('form-JamesStorerDeflectingAdversarialAttacks').submit();\">James Storer</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Prakash_Deflecting_Adversarial_Attacks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/4093-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.08926\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Prakash_2018_CVPR,<br>\nauthor = {Prakash, Aaditya and Moran, Nick and Garber, Solomon and DiLillo, Antonella and Storer, James},<br>\ntitle = {Deflecting Adversarial Attacks With Pixel Deflection},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Vicol_MovieGraphs_Towards_Understanding_CVPR_2018_paper.html\">MovieGraphs: Towards Understanding Human-Centric Situations From Videos</a></dt>\n<dd>\n<form id=\"form-PaulVicolMovieGraphsTowardsUnderstanding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Paul Vicol\">\n<a href=\"#\" onclick=\"document.getElementById('form-PaulVicolMovieGraphsTowardsUnderstanding').submit();\">Paul Vicol</a>,\n</form>\n<form id=\"form-MakarandTapaswiMovieGraphsTowardsUnderstanding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Makarand Tapaswi\">\n<a href=\"#\" onclick=\"document.getElementById('form-MakarandTapaswiMovieGraphsTowardsUnderstanding').submit();\">Makarand Tapaswi</a>,\n</form>\n<form id=\"form-Llu\u00c3\u00adsCastrej\u00c3\u00b3nMovieGraphsTowardsUnderstanding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Llu\u00c3\u00ads Castrej\u00c3\u00b3n\">\n<a href=\"#\" onclick=\"document.getElementById('form-Llu\u00c3\u00adsCastrej\u00c3\u00b3nMovieGraphsTowardsUnderstanding').submit();\">Llu\u00c3\u00ads Castrej\u00c3\u00b3n</a>,\n</form>\n<form id=\"form-SanjaFidlerMovieGraphsTowardsUnderstanding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sanja Fidler\">\n<a href=\"#\" onclick=\"document.getElementById('form-SanjaFidlerMovieGraphsTowardsUnderstanding').submit();\">Sanja Fidler</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Vicol_MovieGraphs_Towards_Understanding_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3308-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.06761\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Vicol_2018_CVPR,<br>\nauthor = {Vicol, Paul and Tapaswi, Makarand and Castrej\u00c3\u00b3n, Llu\u00c3\u00ads and Fidler, Sanja},<br>\ntitle = {MovieGraphs: Towards Understanding Human-Centric Situations From Videos},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Mathews_SemStyle_Learning_to_CVPR_2018_paper.html\">SemStyle: Learning to Generate Stylised Image Captions Using Unaligned Text</a></dt>\n<dd>\n<form id=\"form-AlexanderMathewsSemStyleLearningto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexander Mathews\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexanderMathewsSemStyleLearningto').submit();\">Alexander Mathews</a>,\n</form>\n<form id=\"form-LexingXieSemStyleLearningto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lexing Xie\">\n<a href=\"#\" onclick=\"document.getElementById('form-LexingXieSemStyleLearningto').submit();\">Lexing Xie</a>,\n</form>\n<form id=\"form-XumingHeSemStyleLearningto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xuming He\">\n<a href=\"#\" onclick=\"document.getElementById('form-XumingHeSemStyleLearningto').submit();\">Xuming He</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Mathews_SemStyle_Learning_to_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/4057-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.07030\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Mathews_2018_CVPR,<br>\nauthor = {Mathews, Alexander and Xie, Lexing and He, Xuming},<br>\ntitle = {SemStyle: Learning to Generate Stylised Image Captions Using Unaligned Text},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sattler_Benchmarking_6DOF_Outdoor_CVPR_2018_paper.html\">Benchmarking 6DOF Outdoor Visual Localization in Changing Conditions</a></dt>\n<dd>\n<form id=\"form-TorstenSattlerBenchmarking6DOFOutdoor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Torsten Sattler\">\n<a href=\"#\" onclick=\"document.getElementById('form-TorstenSattlerBenchmarking6DOFOutdoor').submit();\">Torsten Sattler</a>,\n</form>\n<form id=\"form-WillMaddernBenchmarking6DOFOutdoor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Will Maddern\">\n<a href=\"#\" onclick=\"document.getElementById('form-WillMaddernBenchmarking6DOFOutdoor').submit();\">Will Maddern</a>,\n</form>\n<form id=\"form-CarlToftBenchmarking6DOFOutdoor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Carl Toft\">\n<a href=\"#\" onclick=\"document.getElementById('form-CarlToftBenchmarking6DOFOutdoor').submit();\">Carl Toft</a>,\n</form>\n<form id=\"form-AkihikoToriiBenchmarking6DOFOutdoor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Akihiko Torii\">\n<a href=\"#\" onclick=\"document.getElementById('form-AkihikoToriiBenchmarking6DOFOutdoor').submit();\">Akihiko Torii</a>,\n</form>\n<form id=\"form-LarsHammarstrandBenchmarking6DOFOutdoor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lars Hammarstrand\">\n<a href=\"#\" onclick=\"document.getElementById('form-LarsHammarstrandBenchmarking6DOFOutdoor').submit();\">Lars Hammarstrand</a>,\n</form>\n<form id=\"form-ErikStenborgBenchmarking6DOFOutdoor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Erik Stenborg\">\n<a href=\"#\" onclick=\"document.getElementById('form-ErikStenborgBenchmarking6DOFOutdoor').submit();\">Erik Stenborg</a>,\n</form>\n<form id=\"form-DanielSafariBenchmarking6DOFOutdoor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daniel Safari\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanielSafariBenchmarking6DOFOutdoor').submit();\">Daniel Safari</a>,\n</form>\n<form id=\"form-MasatoshiOkutomiBenchmarking6DOFOutdoor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Masatoshi Okutomi\">\n<a href=\"#\" onclick=\"document.getElementById('form-MasatoshiOkutomiBenchmarking6DOFOutdoor').submit();\">Masatoshi Okutomi</a>,\n</form>\n<form id=\"form-MarcPollefeysBenchmarking6DOFOutdoor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Marc Pollefeys\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarcPollefeysBenchmarking6DOFOutdoor').submit();\">Marc Pollefeys</a>,\n</form>\n<form id=\"form-JosefSivicBenchmarking6DOFOutdoor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Josef Sivic\">\n<a href=\"#\" onclick=\"document.getElementById('form-JosefSivicBenchmarking6DOFOutdoor').submit();\">Josef Sivic</a>,\n</form>\n<form id=\"form-FredrikKahlBenchmarking6DOFOutdoor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fredrik Kahl\">\n<a href=\"#\" onclick=\"document.getElementById('form-FredrikKahlBenchmarking6DOFOutdoor').submit();\">Fredrik Kahl</a>,\n</form>\n<form id=\"form-TomasPajdlaBenchmarking6DOFOutdoor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tomas Pajdla\">\n<a href=\"#\" onclick=\"document.getElementById('form-TomasPajdlaBenchmarking6DOFOutdoor').submit();\">Tomas Pajdla</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sattler_Benchmarking_6DOF_Outdoor_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1707.09092\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sattler_2018_CVPR,<br>\nauthor = {Sattler, Torsten and Maddern, Will and Toft, Carl and Torii, Akihiko and Hammarstrand, Lars and Stenborg, Erik and Safari, Daniel and Okutomi, Masatoshi and Pollefeys, Marc and Sivic, Josef and Kahl, Fredrik and Pajdla, Tomas},<br>\ntitle = {Benchmarking 6DOF Outdoor Visual Localization in Changing Conditions},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_IVQA_Inverse_Visual_CVPR_2018_paper.html\">IVQA: Inverse Visual Question Answering</a></dt>\n<dd>\n<form id=\"form-FengLiuIVQAInverseVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Feng Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-FengLiuIVQAInverseVisual').submit();\">Feng Liu</a>,\n</form>\n<form id=\"form-TaoXiangIVQAInverseVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tao Xiang\">\n<a href=\"#\" onclick=\"document.getElementById('form-TaoXiangIVQAInverseVisual').submit();\">Tao Xiang</a>,\n</form>\n<form id=\"form-TimothyM.IVQAInverseVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Timothy M. Hospedales\">\n<a href=\"#\" onclick=\"document.getElementById('form-TimothyM.IVQAInverseVisual').submit();\">Timothy M. Hospedales</a>,\n</form>\n<form id=\"form-WankouYangIVQAInverseVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wankou Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WankouYangIVQAInverseVisual').submit();\">Wankou Yang</a>,\n</form>\n<form id=\"form-ChangyinSunIVQAInverseVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Changyin Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChangyinSunIVQAInverseVisual').submit();\">Changyin Sun</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_IVQA_Inverse_Visual_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1710.03370\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Feng and Xiang, Tao and Hospedales, Timothy M. and Yang, Wankou and Sun, Changyin},<br>\ntitle = {IVQA: Inverse Visual Question Answering},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Pumarola_Unsupervised_Person_Image_CVPR_2018_paper.html\">Unsupervised Person Image Synthesis in Arbitrary Poses</a></dt>\n<dd>\n<form id=\"form-AlbertPumarolaUnsupervisedPersonImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Albert Pumarola\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlbertPumarolaUnsupervisedPersonImage').submit();\">Albert Pumarola</a>,\n</form>\n<form id=\"form-AntonioAgudoUnsupervisedPersonImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Antonio Agudo\">\n<a href=\"#\" onclick=\"document.getElementById('form-AntonioAgudoUnsupervisedPersonImage').submit();\">Antonio Agudo</a>,\n</form>\n<form id=\"form-AlbertoSanfeliuUnsupervisedPersonImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alberto Sanfeliu\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlbertoSanfeliuUnsupervisedPersonImage').submit();\">Alberto Sanfeliu</a>,\n</form>\n<form id=\"form-FrancescMoreno-NoguerUnsupervisedPersonImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Francesc Moreno-Noguer\">\n<a href=\"#\" onclick=\"document.getElementById('form-FrancescMoreno-NoguerUnsupervisedPersonImage').submit();\">Francesc Moreno-Noguer</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Pumarola_Unsupervised_Person_Image_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Pumarola_2018_CVPR,<br>\nauthor = {Pumarola, Albert and Agudo, Antonio and Sanfeliu, Alberto and Moreno-Noguer, Francesc},<br>\ntitle = {Unsupervised Person Image Synthesis in Arbitrary Poses},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xie_Learning_Descriptor_Networks_CVPR_2018_paper.html\">Learning Descriptor Networks for 3D Shape Synthesis and Analysis</a></dt>\n<dd>\n<form id=\"form-JianwenXieLearningDescriptorNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianwen Xie\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianwenXieLearningDescriptorNetworks').submit();\">Jianwen Xie</a>,\n</form>\n<form id=\"form-ZilongZhengLearningDescriptorNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zilong Zheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZilongZhengLearningDescriptorNetworks').submit();\">Zilong Zheng</a>,\n</form>\n<form id=\"form-RuiqiGaoLearningDescriptorNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ruiqi Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-RuiqiGaoLearningDescriptorNetworks').submit();\">Ruiqi Gao</a>,\n</form>\n<form id=\"form-WenguanWangLearningDescriptorNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenguan Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenguanWangLearningDescriptorNetworks').submit();\">Wenguan Wang</a>,\n</form>\n<form id=\"form-Song-ChunZhuLearningDescriptorNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Song-Chun Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Song-ChunZhuLearningDescriptorNetworks').submit();\">Song-Chun Zhu</a>,\n</form>\n<form id=\"form-YingNianLearningDescriptorNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ying Nian Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YingNianLearningDescriptorNetworks').submit();\">Ying Nian Wu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xie_Learning_Descriptor_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00586\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xie_2018_CVPR,<br>\nauthor = {Xie, Jianwen and Zheng, Zilong and Gao, Ruiqi and Wang, Wenguan and Zhu, Song-Chun and Nian Wu, Ying},<br>\ntitle = {Learning Descriptor Networks for 3D Shape Synthesis and Analysis},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Villegas_Neural_Kinematic_Networks_CVPR_2018_paper.html\">Neural Kinematic Networks for Unsupervised Motion Retargetting</a></dt>\n<dd>\n<form id=\"form-RubenVillegasNeuralKinematicNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ruben Villegas\">\n<a href=\"#\" onclick=\"document.getElementById('form-RubenVillegasNeuralKinematicNetworks').submit();\">Ruben Villegas</a>,\n</form>\n<form id=\"form-JimeiYangNeuralKinematicNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jimei Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JimeiYangNeuralKinematicNetworks').submit();\">Jimei Yang</a>,\n</form>\n<form id=\"form-DuyguCeylanNeuralKinematicNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Duygu Ceylan\">\n<a href=\"#\" onclick=\"document.getElementById('form-DuyguCeylanNeuralKinematicNetworks').submit();\">Duygu Ceylan</a>,\n</form>\n<form id=\"form-HonglakLeeNeuralKinematicNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Honglak Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-HonglakLeeNeuralKinematicNetworks').submit();\">Honglak Lee</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Villegas_Neural_Kinematic_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1988-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.05653\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Villegas_2018_CVPR,<br>\nauthor = {Villegas, Ruben and Yang, Jimei and Ceylan, Duygu and Lee, Honglak},<br>\ntitle = {Neural Kinematic Networks for Unsupervised Motion Retargetting},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_Group_Consistent_Similarity_CVPR_2018_paper.html\">Group Consistent Similarity Learning via Deep CRF for Person Re-Identification</a></dt>\n<dd>\n<form id=\"form-DapengChenGroupConsistentSimilarity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dapeng Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-DapengChenGroupConsistentSimilarity').submit();\">Dapeng Chen</a>,\n</form>\n<form id=\"form-DanXuGroupConsistentSimilarity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dan Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanXuGroupConsistentSimilarity').submit();\">Dan Xu</a>,\n</form>\n<form id=\"form-HongshengLiGroupConsistentSimilarity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hongsheng Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-HongshengLiGroupConsistentSimilarity').submit();\">Hongsheng Li</a>,\n</form>\n<form id=\"form-NicuSebeGroupConsistentSimilarity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nicu Sebe\">\n<a href=\"#\" onclick=\"document.getElementById('form-NicuSebeGroupConsistentSimilarity').submit();\">Nicu Sebe</a>,\n</form>\n<form id=\"form-XiaogangWangGroupConsistentSimilarity\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaogang Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaogangWangGroupConsistentSimilarity').submit();\">Xiaogang Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_Group_Consistent_Similarity_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Dapeng and Xu, Dan and Li, Hongsheng and Sebe, Nicu and Wang, Xiaogang},<br>\ntitle = {Group Consistent Similarity Learning via Deep CRF for Person Re-Identification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Gong_Learning_Compositional_Visual_CVPR_2018_paper.html\">Learning Compositional Visual Concepts With Mutual Consistency</a></dt>\n<dd>\n<form id=\"form-YunyeGongLearningCompositionalVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yunye Gong\">\n<a href=\"#\" onclick=\"document.getElementById('form-YunyeGongLearningCompositionalVisual').submit();\">Yunye Gong</a>,\n</form>\n<form id=\"form-SrikrishnaKaranamLearningCompositionalVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Srikrishna Karanam\">\n<a href=\"#\" onclick=\"document.getElementById('form-SrikrishnaKaranamLearningCompositionalVisual').submit();\">Srikrishna Karanam</a>,\n</form>\n<form id=\"form-ZiyanWuLearningCompositionalVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ziyan Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZiyanWuLearningCompositionalVisual').submit();\">Ziyan Wu</a>,\n</form>\n<form id=\"form-Kuan-ChuanPengLearningCompositionalVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kuan-Chuan Peng\">\n<a href=\"#\" onclick=\"document.getElementById('form-Kuan-ChuanPengLearningCompositionalVisual').submit();\">Kuan-Chuan Peng</a>,\n</form>\n<form id=\"form-JanErnstLearningCompositionalVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jan Ernst\">\n<a href=\"#\" onclick=\"document.getElementById('form-JanErnstLearningCompositionalVisual').submit();\">Jan Ernst</a>,\n</form>\n<form id=\"form-PeterC.LearningCompositionalVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peter C. Doerschuk\">\n<a href=\"#\" onclick=\"document.getElementById('form-PeterC.LearningCompositionalVisual').submit();\">Peter C. Doerschuk</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Gong_Learning_Compositional_Visual_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1959-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.06148\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Gong_2018_CVPR,<br>\nauthor = {Gong, Yunye and Karanam, Srikrishna and Wu, Ziyan and Peng, Kuan-Chuan and Ernst, Jan and Doerschuk, Peter C.},<br>\ntitle = {Learning Compositional Visual Concepts With Mutual Consistency},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kim_NestedNet_Learning_Nested_CVPR_2018_paper.html\">NestedNet: Learning Nested Sparse Structures in Deep Neural Networks</a></dt>\n<dd>\n<form id=\"form-EunwooKimNestedNetLearningNested\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Eunwoo Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-EunwooKimNestedNetLearningNested').submit();\">Eunwoo Kim</a>,\n</form>\n<form id=\"form-ChanhoAhnNestedNetLearningNested\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chanho Ahn\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChanhoAhnNestedNetLearningNested').submit();\">Chanho Ahn</a>,\n</form>\n<form id=\"form-SonghwaiOhNestedNetLearningNested\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Songhwai Oh\">\n<a href=\"#\" onclick=\"document.getElementById('form-SonghwaiOhNestedNetLearningNested').submit();\">Songhwai Oh</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kim_NestedNet_Learning_Nested_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3430-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.03781\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kim_2018_CVPR,<br>\nauthor = {Kim, Eunwoo and Ahn, Chanho and Oh, Songhwai},<br>\ntitle = {NestedNet: Learning Nested Sparse Structures in Deep Neural Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kim_Context_Embedding_Networks_CVPR_2018_paper.html\">Context Embedding Networks</a></dt>\n<dd>\n<form id=\"form-KunHoContextEmbeddingNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kun Ho Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-KunHoContextEmbeddingNetworks').submit();\">Kun Ho Kim</a>,\n</form>\n<form id=\"form-OisinMacContextEmbeddingNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Oisin Mac Aodha\">\n<a href=\"#\" onclick=\"document.getElementById('form-OisinMacContextEmbeddingNetworks').submit();\">Oisin Mac Aodha</a>,\n</form>\n<form id=\"form-PietroPeronaContextEmbeddingNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pietro Perona\">\n<a href=\"#\" onclick=\"document.getElementById('form-PietroPeronaContextEmbeddingNetworks').submit();\">Pietro Perona</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kim_Context_Embedding_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1580-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.00227\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kim_2018_CVPR,<br>\nauthor = {Ho Kim, Kun and Mac Aodha, Oisin and Perona, Pietro},<br>\ntitle = {Context Embedding Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Iterative_Learning_With_CVPR_2018_paper.html\">Iterative Learning With Open-Set Noisy Labels</a></dt>\n<dd>\n<form id=\"form-YisenWangIterativeLearningWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yisen Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YisenWangIterativeLearningWith').submit();\">Yisen Wang</a>,\n</form>\n<form id=\"form-WeiyangLiuIterativeLearningWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weiyang Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiyangLiuIterativeLearningWith').submit();\">Weiyang Liu</a>,\n</form>\n<form id=\"form-XingjunMaIterativeLearningWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xingjun Ma\">\n<a href=\"#\" onclick=\"document.getElementById('form-XingjunMaIterativeLearningWith').submit();\">Xingjun Ma</a>,\n</form>\n<form id=\"form-JamesBaileyIterativeLearningWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"James Bailey\">\n<a href=\"#\" onclick=\"document.getElementById('form-JamesBaileyIterativeLearningWith').submit();\">James Bailey</a>,\n</form>\n<form id=\"form-HongyuanZhaIterativeLearningWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hongyuan Zha\">\n<a href=\"#\" onclick=\"document.getElementById('form-HongyuanZhaIterativeLearningWith').submit();\">Hongyuan Zha</a>,\n</form>\n<form id=\"form-LeSongIterativeLearningWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Le Song\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeSongIterativeLearningWith').submit();\">Le Song</a>,\n</form>\n<form id=\"form-Shu-TaoXiaIterativeLearningWith\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shu-Tao Xia\">\n<a href=\"#\" onclick=\"document.getElementById('form-Shu-TaoXiaIterativeLearningWith').submit();\">Shu-Tao Xia</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Iterative_Learning_With_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00092\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Yisen and Liu, Weiyang and Ma, Xingjun and Bailey, James and Zha, Hongyuan and Song, Le and Xia, Shu-Tao},<br>\ntitle = {Iterative Learning With Open-Set Noisy Labels},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zoph_Learning_Transferable_Architectures_CVPR_2018_paper.html\">Learning Transferable Architectures for Scalable Image Recognition</a></dt>\n<dd>\n<form id=\"form-BarretZophLearningTransferableArchitectures\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Barret Zoph\">\n<a href=\"#\" onclick=\"document.getElementById('form-BarretZophLearningTransferableArchitectures').submit();\">Barret Zoph</a>,\n</form>\n<form id=\"form-VijayVasudevanLearningTransferableArchitectures\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vijay Vasudevan\">\n<a href=\"#\" onclick=\"document.getElementById('form-VijayVasudevanLearningTransferableArchitectures').submit();\">Vijay Vasudevan</a>,\n</form>\n<form id=\"form-JonathonShlensLearningTransferableArchitectures\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jonathon Shlens\">\n<a href=\"#\" onclick=\"document.getElementById('form-JonathonShlensLearningTransferableArchitectures').submit();\">Jonathon Shlens</a>,\n</form>\n<form id=\"form-QuocV.LearningTransferableArchitectures\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Quoc V. Le\">\n<a href=\"#\" onclick=\"document.getElementById('form-QuocV.LearningTransferableArchitectures').submit();\">Quoc V. Le</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zoph_Learning_Transferable_Architectures_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1707.07012\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zoph_2018_CVPR,<br>\nauthor = {Zoph, Barret and Vasudevan, Vijay and Shlens, Jonathon and Le, Quoc V.},<br>\ntitle = {Learning Transferable Architectures for Scalable Image Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ren_SBNet_Sparse_Blocks_CVPR_2018_paper.html\">SBNet: Sparse Blocks Network for Fast Inference</a></dt>\n<dd>\n<form id=\"form-MengyeRenSBNetSparseBlocks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mengye Ren\">\n<a href=\"#\" onclick=\"document.getElementById('form-MengyeRenSBNetSparseBlocks').submit();\">Mengye Ren</a>,\n</form>\n<form id=\"form-AndreiPokrovskySBNetSparseBlocks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrei Pokrovsky\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndreiPokrovskySBNetSparseBlocks').submit();\">Andrei Pokrovsky</a>,\n</form>\n<form id=\"form-BinYangSBNetSparseBlocks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bin Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-BinYangSBNetSparseBlocks').submit();\">Bin Yang</a>,\n</form>\n<form id=\"form-RaquelUrtasunSBNetSparseBlocks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Raquel Urtasun\">\n<a href=\"#\" onclick=\"document.getElementById('form-RaquelUrtasunSBNetSparseBlocks').submit();\">Raquel Urtasun</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ren_SBNet_Sparse_Blocks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.02108\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ren_2018_CVPR,<br>\nauthor = {Ren, Mengye and Pokrovsky, Andrei and Yang, Bin and Urtasun, Raquel},<br>\ntitle = {SBNet: Sparse Blocks Network for Fast Inference},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_Language-Based_Image_Editing_CVPR_2018_paper.html\">Language-Based Image Editing With Recurrent Attentive Models</a></dt>\n<dd>\n<form id=\"form-JianboChenLanguageBasedImageEditing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianbo Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianboChenLanguageBasedImageEditing').submit();\">Jianbo Chen</a>,\n</form>\n<form id=\"form-YelongShenLanguageBasedImageEditing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yelong Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-YelongShenLanguageBasedImageEditing').submit();\">Yelong Shen</a>,\n</form>\n<form id=\"form-JianfengGaoLanguageBasedImageEditing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianfeng Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianfengGaoLanguageBasedImageEditing').submit();\">Jianfeng Gao</a>,\n</form>\n<form id=\"form-JingjingLiuLanguageBasedImageEditing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jingjing Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingjingLiuLanguageBasedImageEditing').submit();\">Jingjing Liu</a>,\n</form>\n<form id=\"form-XiaodongLiuLanguageBasedImageEditing\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaodong Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaodongLiuLanguageBasedImageEditing').submit();\">Xiaodong Liu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_Language-Based_Image_Editing_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1956-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.06288\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Jianbo and Shen, Yelong and Gao, Jianfeng and Liu, Jingjing and Liu, Xiaodong},<br>\ntitle = {Language-Based Image Editing With Recurrent Attentive Models},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Fong_Net2Vec_Quantifying_and_CVPR_2018_paper.html\">Net2Vec: Quantifying and Explaining How Concepts Are Encoded by Filters in Deep Neural Networks</a></dt>\n<dd>\n<form id=\"form-RuthFongNet2VecQuantifyingand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ruth Fong\">\n<a href=\"#\" onclick=\"document.getElementById('form-RuthFongNet2VecQuantifyingand').submit();\">Ruth Fong</a>,\n</form>\n<form id=\"form-AndreaVedaldiNet2VecQuantifyingand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrea Vedaldi\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndreaVedaldiNet2VecQuantifyingand').submit();\">Andrea Vedaldi</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Fong_Net2Vec_Quantifying_and_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/4217-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.03454\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Fong_2018_CVPR,<br>\nauthor = {Fong, Ruth and Vedaldi, Andrea},<br>\ntitle = {Net2Vec: Quantifying and Explaining How Concepts Are Encoded by Filters in Deep Neural Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhou_End-to-End_Dense_Video_CVPR_2018_paper.html\">End-to-End Dense Video Captioning With Masked Transformer</a></dt>\n<dd>\n<form id=\"form-LuoweiZhouEndtoEndDenseVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Luowei Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-LuoweiZhouEndtoEndDenseVideo').submit();\">Luowei Zhou</a>,\n</form>\n<form id=\"form-YingboZhouEndtoEndDenseVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yingbo Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-YingboZhouEndtoEndDenseVideo').submit();\">Yingbo Zhou</a>,\n</form>\n<form id=\"form-JasonJ.EndtoEndDenseVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jason J. Corso\">\n<a href=\"#\" onclick=\"document.getElementById('form-JasonJ.EndtoEndDenseVideo').submit();\">Jason J. Corso</a>,\n</form>\n<form id=\"form-RichardSocherEndtoEndDenseVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Richard Socher\">\n<a href=\"#\" onclick=\"document.getElementById('form-RichardSocherEndtoEndDenseVideo').submit();\">Richard Socher</a>,\n</form>\n<form id=\"form-CaimingXiongEndtoEndDenseVideo\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Caiming Xiong\">\n<a href=\"#\" onclick=\"document.getElementById('form-CaimingXiongEndtoEndDenseVideo').submit();\">Caiming Xiong</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhou_End-to-End_Dense_Video_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0037-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00819\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhou_2018_CVPR,<br>\nauthor = {Zhou, Luowei and Zhou, Yingbo and Corso, Jason J. and Socher, Richard and Xiong, Caiming},<br>\ntitle = {End-to-End Dense Video Captioning With Masked Transformer},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Dogan_A_Neural_Multi-Sequence_CVPR_2018_paper.html\">A Neural Multi-Sequence Alignment TeCHnique (NeuMATCH)</a></dt>\n<dd>\n<form id=\"form-PelinDoganANeuralMultiSequence\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pelin Dogan\">\n<a href=\"#\" onclick=\"document.getElementById('form-PelinDoganANeuralMultiSequence').submit();\">Pelin Dogan</a>,\n</form>\n<form id=\"form-BoyangLiANeuralMultiSequence\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Boyang Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoyangLiANeuralMultiSequence').submit();\">Boyang Li</a>,\n</form>\n<form id=\"form-LeonidSigalANeuralMultiSequence\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Leonid Sigal\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeonidSigalANeuralMultiSequence').submit();\">Leonid Sigal</a>,\n</form>\n<form id=\"form-MarkusGrossANeuralMultiSequence\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Markus Gross\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarkusGrossANeuralMultiSequence').submit();\">Markus Gross</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Dogan_A_Neural_Multi-Sequence_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0914-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.00057\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Dogan_2018_CVPR,<br>\nauthor = {Dogan, Pelin and Li, Boyang and Sigal, Leonid and Gross, Markus},<br>\ntitle = {A Neural Multi-Sequence Alignment TeCHnique (NeuMATCH)},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_Path_Aggregation_Network_CVPR_2018_paper.html\">Path Aggregation Network for Instance Segmentation</a></dt>\n<dd>\n<form id=\"form-ShuLiuPathAggregationNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shu Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuLiuPathAggregationNetwork').submit();\">Shu Liu</a>,\n</form>\n<form id=\"form-LuQiPathAggregationNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lu Qi\">\n<a href=\"#\" onclick=\"document.getElementById('form-LuQiPathAggregationNetwork').submit();\">Lu Qi</a>,\n</form>\n<form id=\"form-HaifangQinPathAggregationNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Haifang Qin\">\n<a href=\"#\" onclick=\"document.getElementById('form-HaifangQinPathAggregationNetwork').submit();\">Haifang Qin</a>,\n</form>\n<form id=\"form-JianpingShiPathAggregationNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianping Shi\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianpingShiPathAggregationNetwork').submit();\">Jianping Shi</a>,\n</form>\n<form id=\"form-JiayaJiaPathAggregationNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiaya Jia\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiayaJiaPathAggregationNetwork').submit();\">Jiaya Jia</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_Path_Aggregation_Network_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.01534\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Shu and Qi, Lu and Qin, Haifang and Shi, Jianping and Jia, Jiaya},<br>\ntitle = {Path Aggregation Network for Instance Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Van_Horn_The_INaturalist_Species_CVPR_2018_paper.html\">The INaturalist Species Classification and Detection Dataset</a></dt>\n<dd>\n<form id=\"form-GrantVanTheINaturalistSpecies\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Grant Van Horn\">\n<a href=\"#\" onclick=\"document.getElementById('form-GrantVanTheINaturalistSpecies').submit();\">Grant Van Horn</a>,\n</form>\n<form id=\"form-OisinMacTheINaturalistSpecies\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Oisin Mac Aodha\">\n<a href=\"#\" onclick=\"document.getElementById('form-OisinMacTheINaturalistSpecies').submit();\">Oisin Mac Aodha</a>,\n</form>\n<form id=\"form-YangSongTheINaturalistSpecies\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yang Song\">\n<a href=\"#\" onclick=\"document.getElementById('form-YangSongTheINaturalistSpecies').submit();\">Yang Song</a>,\n</form>\n<form id=\"form-YinCuiTheINaturalistSpecies\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yin Cui\">\n<a href=\"#\" onclick=\"document.getElementById('form-YinCuiTheINaturalistSpecies').submit();\">Yin Cui</a>,\n</form>\n<form id=\"form-ChenSunTheINaturalistSpecies\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chen Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenSunTheINaturalistSpecies').submit();\">Chen Sun</a>,\n</form>\n<form id=\"form-AlexShepardTheINaturalistSpecies\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alex Shepard\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexShepardTheINaturalistSpecies').submit();\">Alex Shepard</a>,\n</form>\n<form id=\"form-HartwigAdamTheINaturalistSpecies\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hartwig Adam\">\n<a href=\"#\" onclick=\"document.getElementById('form-HartwigAdamTheINaturalistSpecies').submit();\">Hartwig Adam</a>,\n</form>\n<form id=\"form-PietroPeronaTheINaturalistSpecies\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pietro Perona\">\n<a href=\"#\" onclick=\"document.getElementById('form-PietroPeronaTheINaturalistSpecies').submit();\">Pietro Perona</a>,\n</form>\n<form id=\"form-SergeBelongieTheINaturalistSpecies\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Serge Belongie\">\n<a href=\"#\" onclick=\"document.getElementById('form-SergeBelongieTheINaturalistSpecies').submit();\">Serge Belongie</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Van_Horn_The_INaturalist_Species_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1916-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1707.06642\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Horn_2018_CVPR,<br>\nauthor = {Van Horn, Grant and Mac Aodha, Oisin and Song, Yang and Cui, Yin and Sun, Chen and Shepard, Alex and Adam, Hartwig and Perona, Pietro and Belongie, Serge},<br>\ntitle = {The INaturalist Species Classification and Detection Dataset},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Park_Multimodal_Explanations_Justifying_CVPR_2018_paper.html\">Multimodal Explanations: Justifying Decisions and Pointing to the Evidence</a></dt>\n<dd>\n<form id=\"form-DongHukMultimodalExplanationsJustifying\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dong Huk Park\">\n<a href=\"#\" onclick=\"document.getElementById('form-DongHukMultimodalExplanationsJustifying').submit();\">Dong Huk Park</a>,\n</form>\n<form id=\"form-LisaAnneMultimodalExplanationsJustifying\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lisa Anne Hendricks\">\n<a href=\"#\" onclick=\"document.getElementById('form-LisaAnneMultimodalExplanationsJustifying').submit();\">Lisa Anne Hendricks</a>,\n</form>\n<form id=\"form-ZeynepAkataMultimodalExplanationsJustifying\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zeynep Akata\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZeynepAkataMultimodalExplanationsJustifying').submit();\">Zeynep Akata</a>,\n</form>\n<form id=\"form-AnnaRohrbachMultimodalExplanationsJustifying\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anna Rohrbach\">\n<a href=\"#\" onclick=\"document.getElementById('form-AnnaRohrbachMultimodalExplanationsJustifying').submit();\">Anna Rohrbach</a>,\n</form>\n<form id=\"form-BerntSchieleMultimodalExplanationsJustifying\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bernt Schiele\">\n<a href=\"#\" onclick=\"document.getElementById('form-BerntSchieleMultimodalExplanationsJustifying').submit();\">Bernt Schiele</a>,\n</form>\n<form id=\"form-TrevorDarrellMultimodalExplanationsJustifying\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Trevor Darrell\">\n<a href=\"#\" onclick=\"document.getElementById('form-TrevorDarrellMultimodalExplanationsJustifying').submit();\">Trevor Darrell</a>,\n</form>\n<form id=\"form-MarcusRohrbachMultimodalExplanationsJustifying\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Marcus Rohrbach\">\n<a href=\"#\" onclick=\"document.getElementById('form-MarcusRohrbachMultimodalExplanationsJustifying').submit();\">Marcus Rohrbach</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Park_Multimodal_Explanations_Justifying_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2708-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.08129\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Park_2018_CVPR,<br>\nauthor = {Huk Park, Dong and Anne Hendricks, Lisa and Akata, Zeynep and Rohrbach, Anna and Schiele, Bernt and Darrell, Trevor and Rohrbach, Marcus},<br>\ntitle = {Multimodal Explanations: Justifying Decisions and Pointing to the Evidence},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Choi_StarGAN_Unified_Generative_CVPR_2018_paper.html\">StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation</a></dt>\n<dd>\n<form id=\"form-YunjeyChoiStarGANUnifiedGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yunjey Choi\">\n<a href=\"#\" onclick=\"document.getElementById('form-YunjeyChoiStarGANUnifiedGenerative').submit();\">Yunjey Choi</a>,\n</form>\n<form id=\"form-MinjeChoiStarGANUnifiedGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Minje Choi\">\n<a href=\"#\" onclick=\"document.getElementById('form-MinjeChoiStarGANUnifiedGenerative').submit();\">Minje Choi</a>,\n</form>\n<form id=\"form-MunyoungKimStarGANUnifiedGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Munyoung Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-MunyoungKimStarGANUnifiedGenerative').submit();\">Munyoung Kim</a>,\n</form>\n<form id=\"form-Jung-WooHaStarGANUnifiedGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jung-Woo Ha\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jung-WooHaStarGANUnifiedGenerative').submit();\">Jung-Woo Ha</a>,\n</form>\n<form id=\"form-SunghunKimStarGANUnifiedGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sunghun Kim\">\n<a href=\"#\" onclick=\"document.getElementById('form-SunghunKimStarGANUnifiedGenerative').submit();\">Sunghun Kim</a>,\n</form>\n<form id=\"form-JaegulChooStarGANUnifiedGenerative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jaegul Choo\">\n<a href=\"#\" onclick=\"document.getElementById('form-JaegulChooStarGANUnifiedGenerative').submit();\">Jaegul Choo</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Choi_StarGAN_Unified_Generative_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3662-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.09020\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Choi_2018_CVPR,<br>\nauthor = {Choi, Yunjey and Choi, Minje and Kim, Munyoung and Ha, Jung-Woo and Kim, Sunghun and Choo, Jaegul},<br>\ntitle = {StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_High-Resolution_Image_Synthesis_CVPR_2018_paper.html\">High-Resolution Image Synthesis and Semantic Manipulation With Conditional GANs</a></dt>\n<dd>\n<form id=\"form-Ting-ChunWangHighResolutionImageSynthesis\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ting-Chun Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ting-ChunWangHighResolutionImageSynthesis').submit();\">Ting-Chun Wang</a>,\n</form>\n<form id=\"form-Ming-YuLiuHighResolutionImageSynthesis\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming-Yu Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ming-YuLiuHighResolutionImageSynthesis').submit();\">Ming-Yu Liu</a>,\n</form>\n<form id=\"form-Jun-YanZhuHighResolutionImageSynthesis\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jun-Yan Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jun-YanZhuHighResolutionImageSynthesis').submit();\">Jun-Yan Zhu</a>,\n</form>\n<form id=\"form-AndrewTaoHighResolutionImageSynthesis\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrew Tao\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndrewTaoHighResolutionImageSynthesis').submit();\">Andrew Tao</a>,\n</form>\n<form id=\"form-JanKautzHighResolutionImageSynthesis\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jan Kautz\">\n<a href=\"#\" onclick=\"document.getElementById('form-JanKautzHighResolutionImageSynthesis').submit();\">Jan Kautz</a>,\n</form>\n<form id=\"form-BryanCatanzaroHighResolutionImageSynthesis\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bryan Catanzaro\">\n<a href=\"#\" onclick=\"document.getElementById('form-BryanCatanzaroHighResolutionImageSynthesis').submit();\">Bryan Catanzaro</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_High-Resolution_Image_Synthesis_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.11585\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Ting-Chun and Liu, Ming-Yu and Zhu, Jun-Yan and Tao, Andrew and Kautz, Jan and Catanzaro, Bryan},<br>\ntitle = {High-Resolution Image Synthesis and Semantic Manipulation With Conditional GANs},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Qi_Semi-Parametric_Image_Synthesis_CVPR_2018_paper.html\">Semi-Parametric Image Synthesis</a></dt>\n<dd>\n<form id=\"form-XiaojuanQiSemiParametricImageSynthesis\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaojuan Qi\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaojuanQiSemiParametricImageSynthesis').submit();\">Xiaojuan Qi</a>,\n</form>\n<form id=\"form-QifengChenSemiParametricImageSynthesis\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qifeng Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-QifengChenSemiParametricImageSynthesis').submit();\">Qifeng Chen</a>,\n</form>\n<form id=\"form-JiayaJiaSemiParametricImageSynthesis\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiaya Jia\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiayaJiaSemiParametricImageSynthesis').submit();\">Jiaya Jia</a>,\n</form>\n<form id=\"form-VladlenKoltunSemiParametricImageSynthesis\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vladlen Koltun\">\n<a href=\"#\" onclick=\"document.getElementById('form-VladlenKoltunSemiParametricImageSynthesis').submit();\">Vladlen Koltun</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Qi_Semi-Parametric_Image_Synthesis_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.10992\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Qi_2018_CVPR,<br>\nauthor = {Qi, Xiaojuan and Chen, Qifeng and Jia, Jiaya and Koltun, Vladlen},<br>\ntitle = {Semi-Parametric Image Synthesis},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wu_BlockDrop_Dynamic_Inference_CVPR_2018_paper.html\">BlockDrop: Dynamic Inference Paths in Residual Networks</a></dt>\n<dd>\n<form id=\"form-ZuxuanWuBlockDropDynamicInference\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zuxuan Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZuxuanWuBlockDropDynamicInference').submit();\">Zuxuan Wu</a>,\n</form>\n<form id=\"form-TusharNagarajanBlockDropDynamicInference\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tushar Nagarajan\">\n<a href=\"#\" onclick=\"document.getElementById('form-TusharNagarajanBlockDropDynamicInference').submit();\">Tushar Nagarajan</a>,\n</form>\n<form id=\"form-AbhishekKumarBlockDropDynamicInference\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Abhishek Kumar\">\n<a href=\"#\" onclick=\"document.getElementById('form-AbhishekKumarBlockDropDynamicInference').submit();\">Abhishek Kumar</a>,\n</form>\n<form id=\"form-StevenRennieBlockDropDynamicInference\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Steven Rennie\">\n<a href=\"#\" onclick=\"document.getElementById('form-StevenRennieBlockDropDynamicInference').submit();\">Steven Rennie</a>,\n</form>\n<form id=\"form-LarryS.BlockDropDynamicInference\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Larry S. Davis\">\n<a href=\"#\" onclick=\"document.getElementById('form-LarryS.BlockDropDynamicInference').submit();\">Larry S. Davis</a>,\n</form>\n<form id=\"form-KristenGraumanBlockDropDynamicInference\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kristen Grauman\">\n<a href=\"#\" onclick=\"document.getElementById('form-KristenGraumanBlockDropDynamicInference').submit();\">Kristen Grauman</a>,\n</form>\n<form id=\"form-RogerioFerisBlockDropDynamicInference\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rogerio Feris\">\n<a href=\"#\" onclick=\"document.getElementById('form-RogerioFerisBlockDropDynamicInference').submit();\">Rogerio Feris</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wu_BlockDrop_Dynamic_Inference_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0167-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.08393\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wu_2018_CVPR,<br>\nauthor = {Wu, Zuxuan and Nagarajan, Tushar and Kumar, Abhishek and Rennie, Steven and Davis, Larry S. and Grauman, Kristen and Feris, Rogerio},<br>\ntitle = {BlockDrop: Dynamic Inference Paths in Residual Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Interpretable_Convolutional_Neural_CVPR_2018_paper.html\">Interpretable Convolutional Neural Networks</a></dt>\n<dd>\n<form id=\"form-QuanshiZhangInterpretableConvolutionalNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Quanshi Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-QuanshiZhangInterpretableConvolutionalNeural').submit();\">Quanshi Zhang</a>,\n</form>\n<form id=\"form-YingNianInterpretableConvolutionalNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ying Nian Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YingNianInterpretableConvolutionalNeural').submit();\">Ying Nian Wu</a>,\n</form>\n<form id=\"form-Song-ChunZhuInterpretableConvolutionalNeural\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Song-Chun Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Song-ChunZhuInterpretableConvolutionalNeural').submit();\">Song-Chun Zhu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Interpretable_Convolutional_Neural_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1807.10584\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Quanshi and Nian Wu, Ying and Zhu, Song-Chun},<br>\ntitle = {Interpretable Convolutional Neural Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Huang_Deep_Cross-Media_Knowledge_CVPR_2018_paper.html\">Deep Cross-Media Knowledge Transfer</a></dt>\n<dd>\n<form id=\"form-XinHuangDeepCrossMediaKnowledge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xin Huang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinHuangDeepCrossMediaKnowledge').submit();\">Xin Huang</a>,\n</form>\n<form id=\"form-YuxinPengDeepCrossMediaKnowledge\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuxin Peng\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuxinPengDeepCrossMediaKnowledge').submit();\">Yuxin Peng</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Huang_Deep_Cross-Media_Knowledge_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.03777\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Huang_2018_CVPR,<br>\nauthor = {Huang, Xin and Peng, Yuxin},<br>\ntitle = {Deep Cross-Media Knowledge Transfer},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xie_Interleaved_Structured_Sparse_CVPR_2018_paper.html\">Interleaved Structured Sparse Convolutional Neural Networks</a></dt>\n<dd>\n<form id=\"form-GuotianXieInterleavedStructuredSparse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guotian Xie\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuotianXieInterleavedStructuredSparse').submit();\">Guotian Xie</a>,\n</form>\n<form id=\"form-JingdongWangInterleavedStructuredSparse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jingdong Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingdongWangInterleavedStructuredSparse').submit();\">Jingdong Wang</a>,\n</form>\n<form id=\"form-TingZhangInterleavedStructuredSparse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ting Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-TingZhangInterleavedStructuredSparse').submit();\">Ting Zhang</a>,\n</form>\n<form id=\"form-JianhuangLaiInterleavedStructuredSparse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianhuang Lai\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianhuangLaiInterleavedStructuredSparse').submit();\">Jianhuang Lai</a>,\n</form>\n<form id=\"form-RichangHongInterleavedStructuredSparse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Richang Hong\">\n<a href=\"#\" onclick=\"document.getElementById('form-RichangHongInterleavedStructuredSparse').submit();\">Richang Hong</a>,\n</form>\n<form id=\"form-Guo-JunQiInterleavedStructuredSparse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guo-Jun Qi\">\n<a href=\"#\" onclick=\"document.getElementById('form-Guo-JunQiInterleavedStructuredSparse').submit();\">Guo-Jun Qi</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xie_Interleaved_Structured_Sparse_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.06202\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xie_2018_CVPR,<br>\nauthor = {Xie, Guotian and Wang, Jingdong and Zhang, Ting and Lai, Jianhuang and Hong, Richang and Qi, Guo-Jun},<br>\ntitle = {Interleaved Structured Sparse Convolutional Neural Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Esser_A_Variational_U-Net_CVPR_2018_paper.html\">A Variational U-Net for Conditional Appearance and Shape Generation</a></dt>\n<dd>\n<form id=\"form-PatrickEsserAVariationalUNet\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Patrick Esser\">\n<a href=\"#\" onclick=\"document.getElementById('form-PatrickEsserAVariationalUNet').submit();\">Patrick Esser</a>,\n</form>\n<form id=\"form-EkaterinaSutterAVariationalUNet\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ekaterina Sutter\">\n<a href=\"#\" onclick=\"document.getElementById('form-EkaterinaSutterAVariationalUNet').submit();\">Ekaterina Sutter</a>,\n</form>\n<form id=\"form-Bj\u00c3\u00b6rnOmmerAVariationalUNet\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bj\u00c3\u00b6rn Ommer\">\n<a href=\"#\" onclick=\"document.getElementById('form-Bj\u00c3\u00b6rnOmmerAVariationalUNet').submit();\">Bj\u00c3\u00b6rn Ommer</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Esser_A_Variational_U-Net_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1449-supp.zip\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.04694\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Esser_2018_CVPR,<br>\nauthor = {Esser, Patrick and Sutter, Ekaterina and Ommer, Bj\u00c3\u00b6rn},<br>\ntitle = {A Variational U-Net for Conditional Appearance and Shape Generation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_Detach_and_Adapt_CVPR_2018_paper.html\">Detach and Adapt: Learning Cross-Domain Disentangled Deep Representation</a></dt>\n<dd>\n<form id=\"form-Yen-ChengLiuDetachandAdapt\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yen-Cheng Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yen-ChengLiuDetachandAdapt').submit();\">Yen-Cheng Liu</a>,\n</form>\n<form id=\"form-Yu-YingYehDetachandAdapt\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu-Ying Yeh\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yu-YingYehDetachandAdapt').submit();\">Yu-Ying Yeh</a>,\n</form>\n<form id=\"form-Tzu-ChienFuDetachandAdapt\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tzu-Chien Fu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Tzu-ChienFuDetachandAdapt').submit();\">Tzu-Chien Fu</a>,\n</form>\n<form id=\"form-Sheng-DeWangDetachandAdapt\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sheng-De Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Sheng-DeWangDetachandAdapt').submit();\">Sheng-De Wang</a>,\n</form>\n<form id=\"form-Wei-ChenChiuDetachandAdapt\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei-Chen Chiu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Wei-ChenChiuDetachandAdapt').submit();\">Wei-Chen Chiu</a>,\n</form>\n<form id=\"form-Yu-ChiangFrankDetachandAdapt\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu-Chiang Frank Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yu-ChiangFrankDetachandAdapt').submit();\">Yu-Chiang Frank Wang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_Detach_and_Adapt_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1535-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1705.01314\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Yen-Cheng and Yeh, Yu-Ying and Fu, Tzu-Chien and Wang, Sheng-De and Chiu, Wei-Chen and Frank Wang, Yu-Chiang},<br>\ntitle = {Detach and Adapt: Learning Cross-Domain Disentangled Deep Representation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Marcos_Learning_Deep_Structured_CVPR_2018_paper.html\">Learning Deep Structured Active Contours End-to-End</a></dt>\n<dd>\n<form id=\"form-DiegoMarcosLearningDeepStructured\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Diego Marcos\">\n<a href=\"#\" onclick=\"document.getElementById('form-DiegoMarcosLearningDeepStructured').submit();\">Diego Marcos</a>,\n</form>\n<form id=\"form-DevisTuiaLearningDeepStructured\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Devis Tuia\">\n<a href=\"#\" onclick=\"document.getElementById('form-DevisTuiaLearningDeepStructured').submit();\">Devis Tuia</a>,\n</form>\n<form id=\"form-BenjaminKellenbergerLearningDeepStructured\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Benjamin Kellenberger\">\n<a href=\"#\" onclick=\"document.getElementById('form-BenjaminKellenbergerLearningDeepStructured').submit();\">Benjamin Kellenberger</a>,\n</form>\n<form id=\"form-LisaZhangLearningDeepStructured\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lisa Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LisaZhangLearningDeepStructured').submit();\">Lisa Zhang</a>,\n</form>\n<form id=\"form-MinBaiLearningDeepStructured\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Min Bai\">\n<a href=\"#\" onclick=\"document.getElementById('form-MinBaiLearningDeepStructured').submit();\">Min Bai</a>,\n</form>\n<form id=\"form-RenjieLiaoLearningDeepStructured\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Renjie Liao\">\n<a href=\"#\" onclick=\"document.getElementById('form-RenjieLiaoLearningDeepStructured').submit();\">Renjie Liao</a>,\n</form>\n<form id=\"form-RaquelUrtasunLearningDeepStructured\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Raquel Urtasun\">\n<a href=\"#\" onclick=\"document.getElementById('form-RaquelUrtasunLearningDeepStructured').submit();\">Raquel Urtasun</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Marcos_Learning_Deep_Structured_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.06329\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Marcos_2018_CVPR,<br>\nauthor = {Marcos, Diego and Tuia, Devis and Kellenberger, Benjamin and Zhang, Lisa and Bai, Min and Liao, Renjie and Urtasun, Raquel},<br>\ntitle = {Learning Deep Structured Active Contours End-to-End},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lambert_Deep_Learning_Under_CVPR_2018_paper.html\">Deep Learning Under Privileged Information Using Heteroscedastic Dropout</a></dt>\n<dd>\n<form id=\"form-JohnLambertDeepLearningUnder\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"John Lambert\">\n<a href=\"#\" onclick=\"document.getElementById('form-JohnLambertDeepLearningUnder').submit();\">John Lambert</a>,\n</form>\n<form id=\"form-OzanSenerDeepLearningUnder\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ozan Sener\">\n<a href=\"#\" onclick=\"document.getElementById('form-OzanSenerDeepLearningUnder').submit();\">Ozan Sener</a>,\n</form>\n<form id=\"form-SilvioSavareseDeepLearningUnder\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Silvio Savarese\">\n<a href=\"#\" onclick=\"document.getElementById('form-SilvioSavareseDeepLearningUnder').submit();\">Silvio Savarese</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lambert_Deep_Learning_Under_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2514-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.11614\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lambert_2018_CVPR,<br>\nauthor = {Lambert, John and Sener, Ozan and Savarese, Silvio},<br>\ntitle = {Deep Learning Under Privileged Information Using Heteroscedastic Dropout},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Luo_Smooth_Neighbors_on_CVPR_2018_paper.html\">Smooth Neighbors on Teacher Graphs for Semi-Supervised Learning</a></dt>\n<dd>\n<form id=\"form-YucenLuoSmoothNeighborson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yucen Luo\">\n<a href=\"#\" onclick=\"document.getElementById('form-YucenLuoSmoothNeighborson').submit();\">Yucen Luo</a>,\n</form>\n<form id=\"form-JunZhuSmoothNeighborson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jun Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunZhuSmoothNeighborson').submit();\">Jun Zhu</a>,\n</form>\n<form id=\"form-MengxiLiSmoothNeighborson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mengxi Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-MengxiLiSmoothNeighborson').submit();\">Mengxi Li</a>,\n</form>\n<form id=\"form-YongRenSmoothNeighborson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yong Ren\">\n<a href=\"#\" onclick=\"document.getElementById('form-YongRenSmoothNeighborson').submit();\">Yong Ren</a>,\n</form>\n<form id=\"form-BoZhangSmoothNeighborson\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bo Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoZhangSmoothNeighborson').submit();\">Bo Zhang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Luo_Smooth_Neighbors_on_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2905-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.00258\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Luo_2018_CVPR,<br>\nauthor = {Luo, Yucen and Zhu, Jun and Li, Mengxi and Ren, Yong and Zhang, Bo},<br>\ntitle = {Smooth Neighbors on Teacher Graphs for Semi-Supervised Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Interpret_Neural_Networks_CVPR_2018_paper.html\">Interpret Neural Networks by Identifying Critical Data Routing Paths</a></dt>\n<dd>\n<form id=\"form-YulongWangInterpretNeuralNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yulong Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-YulongWangInterpretNeuralNetworks').submit();\">Yulong Wang</a>,\n</form>\n<form id=\"form-HangSuInterpretNeuralNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hang Su\">\n<a href=\"#\" onclick=\"document.getElementById('form-HangSuInterpretNeuralNetworks').submit();\">Hang Su</a>,\n</form>\n<form id=\"form-BoZhangInterpretNeuralNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bo Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoZhangInterpretNeuralNetworks').submit();\">Bo Zhang</a>,\n</form>\n<form id=\"form-XiaolinHuInterpretNeuralNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaolin Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaolinHuInterpretNeuralNetworks').submit();\">Xiaolin Hu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Interpret_Neural_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2964-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Yulong and Su, Hang and Zhang, Bo and Hu, Xiaolin},<br>\ntitle = {Interpret Neural Networks by Identifying Critical Data Routing Paths},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chandra_Deep_Spatio-Temporal_Random_CVPR_2018_paper.html\">Deep Spatio-Temporal Random Fields for Efficient Video Segmentation</a></dt>\n<dd>\n<form id=\"form-SiddharthaChandraDeepSpatioTemporalRandom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Siddhartha Chandra\">\n<a href=\"#\" onclick=\"document.getElementById('form-SiddharthaChandraDeepSpatioTemporalRandom').submit();\">Siddhartha Chandra</a>,\n</form>\n<form id=\"form-CamilleCouprieDeepSpatioTemporalRandom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Camille Couprie\">\n<a href=\"#\" onclick=\"document.getElementById('form-CamilleCouprieDeepSpatioTemporalRandom').submit();\">Camille Couprie</a>,\n</form>\n<form id=\"form-IasonasKokkinosDeepSpatioTemporalRandom\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Iasonas Kokkinos\">\n<a href=\"#\" onclick=\"document.getElementById('form-IasonasKokkinosDeepSpatioTemporalRandom').submit();\">Iasonas Kokkinos</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chandra_Deep_Spatio-Temporal_Random_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1807.03148\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chandra_2018_CVPR,<br>\nauthor = {Chandra, Siddhartha and Couprie, Camille and Kokkinos, Iasonas},<br>\ntitle = {Deep Spatio-Temporal Random Fields for Efficient Video Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Shin_Customized_Image_Narrative_CVPR_2018_paper.html\">Customized Image Narrative Generation via Interactive Visual Question Generation and Answering</a></dt>\n<dd>\n<form id=\"form-AndrewShinCustomizedImageNarrative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrew Shin\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndrewShinCustomizedImageNarrative').submit();\">Andrew Shin</a>,\n</form>\n<form id=\"form-YoshitakaUshikuCustomizedImageNarrative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yoshitaka Ushiku\">\n<a href=\"#\" onclick=\"document.getElementById('form-YoshitakaUshikuCustomizedImageNarrative').submit();\">Yoshitaka Ushiku</a>,\n</form>\n<form id=\"form-TatsuyaHaradaCustomizedImageNarrative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tatsuya Harada\">\n<a href=\"#\" onclick=\"document.getElementById('form-TatsuyaHaradaCustomizedImageNarrative').submit();\">Tatsuya Harada</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Shin_Customized_Image_Narrative_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3815-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.00460\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Shin_2018_CVPR,<br>\nauthor = {Shin, Andrew and Ushiku, Yoshitaka and Harada, Tatsuya},<br>\ntitle = {Customized Image Narrative Generation via Interactive Visual Question Generation and Answering},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sun_PWC-Net_CNNs_for_CVPR_2018_paper.html\">PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume</a></dt>\n<dd>\n<form id=\"form-DeqingSunPWCNetCNNsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Deqing Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-DeqingSunPWCNetCNNsfor').submit();\">Deqing Sun</a>,\n</form>\n<form id=\"form-XiaodongYangPWCNetCNNsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaodong Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaodongYangPWCNetCNNsfor').submit();\">Xiaodong Yang</a>,\n</form>\n<form id=\"form-Ming-YuLiuPWCNetCNNsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming-Yu Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ming-YuLiuPWCNetCNNsfor').submit();\">Ming-Yu Liu</a>,\n</form>\n<form id=\"form-JanKautzPWCNetCNNsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jan Kautz\">\n<a href=\"#\" onclick=\"document.getElementById('form-JanKautzPWCNetCNNsfor').submit();\">Jan Kautz</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sun_PWC-Net_CNNs_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0266-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sun_2018_CVPR,<br>\nauthor = {Sun, Deqing and Yang, Xiaodong and Liu, Ming-Yu and Kautz, Jan},<br>\ntitle = {PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Fan_Revisiting_Deep_Intrinsic_CVPR_2018_paper.html\">Revisiting Deep Intrinsic Image Decompositions</a></dt>\n<dd>\n<form id=\"form-QingnanFanRevisitingDeepIntrinsic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Qingnan Fan\">\n<a href=\"#\" onclick=\"document.getElementById('form-QingnanFanRevisitingDeepIntrinsic').submit();\">Qingnan Fan</a>,\n</form>\n<form id=\"form-JiaolongYangRevisitingDeepIntrinsic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiaolong Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiaolongYangRevisitingDeepIntrinsic').submit();\">Jiaolong Yang</a>,\n</form>\n<form id=\"form-GangHuaRevisitingDeepIntrinsic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gang Hua\">\n<a href=\"#\" onclick=\"document.getElementById('form-GangHuaRevisitingDeepIntrinsic').submit();\">Gang Hua</a>,\n</form>\n<form id=\"form-BaoquanChenRevisitingDeepIntrinsic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Baoquan Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-BaoquanChenRevisitingDeepIntrinsic').submit();\">Baoquan Chen</a>,\n</form>\n<form id=\"form-DavidWipfRevisitingDeepIntrinsic\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"David Wipf\">\n<a href=\"#\" onclick=\"document.getElementById('form-DavidWipfRevisitingDeepIntrinsic').submit();\">David Wipf</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Fan_Revisiting_Deep_Intrinsic_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3626-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1701.02965\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Fan_2018_CVPR,<br>\nauthor = {Fan, Qingnan and Yang, Jiaolong and Hua, Gang and Chen, Baoquan and Wipf, David},<br>\ntitle = {Revisiting Deep Intrinsic Image Decompositions},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yellin_Multi-Cell_Detection_and_CVPR_2018_paper.html\">Multi-Cell Detection and Classification Using a Generative Convolutional Model</a></dt>\n<dd>\n<form id=\"form-FlorenceYellinMultiCellDetectionand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Florence Yellin\">\n<a href=\"#\" onclick=\"document.getElementById('form-FlorenceYellinMultiCellDetectionand').submit();\">Florence Yellin</a>,\n</form>\n<form id=\"form-BenjaminD.MultiCellDetectionand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Benjamin D. Haeffele\">\n<a href=\"#\" onclick=\"document.getElementById('form-BenjaminD.MultiCellDetectionand').submit();\">Benjamin D. Haeffele</a>,\n</form>\n<form id=\"form-SophieRothMultiCellDetectionand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sophie Roth\">\n<a href=\"#\" onclick=\"document.getElementById('form-SophieRothMultiCellDetectionand').submit();\">Sophie Roth</a>,\n</form>\n<form id=\"form-Ren\u00c3\u00a9VidalMultiCellDetectionand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ren\u00c3\u00a9 Vidal\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ren\u00c3\u00a9VidalMultiCellDetectionand').submit();\">Ren\u00c3\u00a9 Vidal</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yellin_Multi-Cell_Detection_and_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yellin_2018_CVPR,<br>\nauthor = {Yellin, Florence and Haeffele, Benjamin D. and Roth, Sophie and Vidal, Ren\u00c3\u00a9},<br>\ntitle = {Multi-Cell Detection and Classification Using a Generative Convolutional Model},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Sun_Learning_Spatial-Aware_Regressions_CVPR_2018_paper.html\">Learning Spatial-Aware Regressions for Visual Tracking</a></dt>\n<dd>\n<form id=\"form-ChongSunLearningSpatialAwareRegressions\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chong Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChongSunLearningSpatialAwareRegressions').submit();\">Chong Sun</a>,\n</form>\n<form id=\"form-DongWangLearningSpatialAwareRegressions\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dong Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-DongWangLearningSpatialAwareRegressions').submit();\">Dong Wang</a>,\n</form>\n<form id=\"form-HuchuanLuLearningSpatialAwareRegressions\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huchuan Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuchuanLuLearningSpatialAwareRegressions').submit();\">Huchuan Lu</a>,\n</form>\n<form id=\"form-Ming-HsuanYangLearningSpatialAwareRegressions\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming-Hsuan Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ming-HsuanYangLearningSpatialAwareRegressions').submit();\">Ming-Hsuan Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Sun_Learning_Spatial-Aware_Regressions_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1706.07457\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Sun_2018_CVPR,<br>\nauthor = {Sun, Chong and Wang, Dong and Lu, Huchuan and Yang, Ming-Hsuan},<br>\ntitle = {Learning Spatial-Aware Regressions for Visual Tracking},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_High_Performance_Visual_CVPR_2018_paper.html\">High Performance Visual Tracking With Siamese Region Proposal Network</a></dt>\n<dd>\n<form id=\"form-BoLiHighPerformanceVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bo Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoLiHighPerformanceVisual').submit();\">Bo Li</a>,\n</form>\n<form id=\"form-JunjieYanHighPerformanceVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junjie Yan\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunjieYanHighPerformanceVisual').submit();\">Junjie Yan</a>,\n</form>\n<form id=\"form-WeiWuHighPerformanceVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wei Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeiWuHighPerformanceVisual').submit();\">Wei Wu</a>,\n</form>\n<form id=\"form-ZhengZhuHighPerformanceVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zheng Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhengZhuHighPerformanceVisual').submit();\">Zheng Zhu</a>,\n</form>\n<form id=\"form-XiaolinHuHighPerformanceVisual\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaolin Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaolinHuHighPerformanceVisual').submit();\">Xiaolin Hu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_High_Performance_Visual_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Bo and Yan, Junjie and Wu, Wei and Zhu, Zheng and Hu, Xiaolin},<br>\ntitle = {High Performance Visual Tracking With Siamese Region Proposal Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hui_LiteFlowNet_A_Lightweight_CVPR_2018_paper.html\">LiteFlowNet: A Lightweight Convolutional Neural Network for Optical Flow Estimation</a></dt>\n<dd>\n<form id=\"form-Tak-WaiHuiLiteFlowNetALightweight\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tak-Wai Hui\">\n<a href=\"#\" onclick=\"document.getElementById('form-Tak-WaiHuiLiteFlowNetALightweight').submit();\">Tak-Wai Hui</a>,\n</form>\n<form id=\"form-XiaoouTangLiteFlowNetALightweight\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaoou Tang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaoouTangLiteFlowNetALightweight').submit();\">Xiaoou Tang</a>,\n</form>\n<form id=\"form-ChenChangeLiteFlowNetALightweight\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chen Change Loy\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChenChangeLiteFlowNetALightweight').submit();\">Chen Change Loy</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hui_LiteFlowNet_A_Lightweight_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.07036\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hui_2018_CVPR,<br>\nauthor = {Hui, Tak-Wai and Tang, Xiaoou and Change Loy, Chen},<br>\ntitle = {LiteFlowNet: A Lightweight Convolutional Neural Network for Optical Flow Estimation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Song_VITAL_VIsual_Tracking_CVPR_2018_paper.html\">VITAL: VIsual Tracking via Adversarial Learning</a></dt>\n<dd>\n<form id=\"form-YibingSongVITALVIsualTracking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yibing Song\">\n<a href=\"#\" onclick=\"document.getElementById('form-YibingSongVITALVIsualTracking').submit();\">Yibing Song</a>,\n</form>\n<form id=\"form-ChaoMaVITALVIsualTracking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chao Ma\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChaoMaVITALVIsualTracking').submit();\">Chao Ma</a>,\n</form>\n<form id=\"form-XiaoheWuVITALVIsualTracking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaohe Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaoheWuVITALVIsualTracking').submit();\">Xiaohe Wu</a>,\n</form>\n<form id=\"form-LijunGongVITALVIsualTracking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lijun Gong\">\n<a href=\"#\" onclick=\"document.getElementById('form-LijunGongVITALVIsualTracking').submit();\">Lijun Gong</a>,\n</form>\n<form id=\"form-LinchaoBaoVITALVIsualTracking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Linchao Bao\">\n<a href=\"#\" onclick=\"document.getElementById('form-LinchaoBaoVITALVIsualTracking').submit();\">Linchao Bao</a>,\n</form>\n<form id=\"form-WangmengZuoVITALVIsualTracking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wangmeng Zuo\">\n<a href=\"#\" onclick=\"document.getElementById('form-WangmengZuoVITALVIsualTracking').submit();\">Wangmeng Zuo</a>,\n</form>\n<form id=\"form-ChunhuaShenVITALVIsualTracking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chunhua Shen\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChunhuaShenVITALVIsualTracking').submit();\">Chunhua Shen</a>,\n</form>\n<form id=\"form-RynsonW.H.VITALVIsualTracking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rynson W.H. Lau\">\n<a href=\"#\" onclick=\"document.getElementById('form-RynsonW.H.VITALVIsualTracking').submit();\">Rynson W.H. Lau</a>,\n</form>\n<form id=\"form-Ming-HsuanYangVITALVIsualTracking\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming-Hsuan Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ming-HsuanYangVITALVIsualTracking').submit();\">Ming-Hsuan Yang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Song_VITAL_VIsual_Tracking_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.04273\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Song_2018_CVPR,<br>\nauthor = {Song, Yibing and Ma, Chao and Wu, Xiaohe and Gong, Lijun and Bao, Linchao and Zuo, Wangmeng and Shen, Chunhua and Lau, Rynson W.H. and Yang, Ming-Hsuan},<br>\ntitle = {VITAL: VIsual Tracking via Adversarial Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Jiang_Super_SloMo_High_CVPR_2018_paper.html\">Super SloMo: High Quality Estimation of Multiple Intermediate Frames for Video Interpolation</a></dt>\n<dd>\n<form id=\"form-HuaizuJiangSuperSloMoHigh\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Huaizu Jiang\">\n<a href=\"#\" onclick=\"document.getElementById('form-HuaizuJiangSuperSloMoHigh').submit();\">Huaizu Jiang</a>,\n</form>\n<form id=\"form-DeqingSunSuperSloMoHigh\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Deqing Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-DeqingSunSuperSloMoHigh').submit();\">Deqing Sun</a>,\n</form>\n<form id=\"form-VarunJampaniSuperSloMoHigh\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Varun Jampani\">\n<a href=\"#\" onclick=\"document.getElementById('form-VarunJampaniSuperSloMoHigh').submit();\">Varun Jampani</a>,\n</form>\n<form id=\"form-Ming-HsuanYangSuperSloMoHigh\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ming-Hsuan Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ming-HsuanYangSuperSloMoHigh').submit();\">Ming-Hsuan Yang</a>,\n</form>\n<form id=\"form-ErikLearned-MillerSuperSloMoHigh\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Erik Learned-Miller\">\n<a href=\"#\" onclick=\"document.getElementById('form-ErikLearned-MillerSuperSloMoHigh').submit();\">Erik Learned-Miller</a>,\n</form>\n<form id=\"form-JanKautzSuperSloMoHigh\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jan Kautz\">\n<a href=\"#\" onclick=\"document.getElementById('form-JanKautzSuperSloMoHigh').submit();\">Jan Kautz</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Jiang_Super_SloMo_High_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0325-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.00080\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Jiang_2018_CVPR,<br>\nauthor = {Jiang, Huaizu and Sun, Deqing and Jampani, Varun and Yang, Ming-Hsuan and Learned-Miller, Erik and Kautz, Jan},<br>\ntitle = {Super SloMo: High Quality Estimation of Multiple Intermediate Frames for Video Interpolation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Runia_Real-World_Repetition_Estimation_CVPR_2018_paper.html\">Real-World Repetition Estimation by Div, Grad and Curl</a></dt>\n<dd>\n<form id=\"form-TomF.RealWorldRepetitionEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tom F. H. Runia\">\n<a href=\"#\" onclick=\"document.getElementById('form-TomF.RealWorldRepetitionEstimation').submit();\">Tom F. H. Runia</a>,\n</form>\n<form id=\"form-CeesG.RealWorldRepetitionEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Cees G. M. Snoek\">\n<a href=\"#\" onclick=\"document.getElementById('form-CeesG.RealWorldRepetitionEstimation').submit();\">Cees G. M. Snoek</a>,\n</form>\n<form id=\"form-ArnoldW.RealWorldRepetitionEstimation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Arnold W. M. Smeulders\">\n<a href=\"#\" onclick=\"document.getElementById('form-ArnoldW.RealWorldRepetitionEstimation').submit();\">Arnold W. M. Smeulders</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Runia_Real-World_Repetition_Estimation_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Runia_2018_CVPR,<br>\nauthor = {Runia, Tom F. H. and Snoek, Cees G. M. and Smeulders, Arnold W. M.},<br>\ntitle = {Real-World Repetition Estimation by Div, Grad and Curl},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Kong_Recurrent_Pixel_Embedding_CVPR_2018_paper.html\">Recurrent Pixel Embedding for Instance Grouping</a></dt>\n<dd>\n<form id=\"form-ShuKongRecurrentPixelEmbedding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shu Kong\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShuKongRecurrentPixelEmbedding').submit();\">Shu Kong</a>,\n</form>\n<form id=\"form-CharlessC.RecurrentPixelEmbedding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Charless C. Fowlkes\">\n<a href=\"#\" onclick=\"document.getElementById('form-CharlessC.RecurrentPixelEmbedding').submit();\">Charless C. Fowlkes</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Kong_Recurrent_Pixel_Embedding_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0533-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.08273\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Kong_2018_CVPR,<br>\nauthor = {Kong, Shu and Fowlkes, Charless C.},<br>\ntitle = {Recurrent Pixel Embedding for Instance Grouping},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Deep_Unsupervised_Saliency_CVPR_2018_paper.html\">Deep Unsupervised Saliency Detection: A Multiple Noisy Labeling Perspective</a></dt>\n<dd>\n<form id=\"form-JingZhangDeepUnsupervisedSaliency\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jing Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-JingZhangDeepUnsupervisedSaliency').submit();\">Jing Zhang</a>,\n</form>\n<form id=\"form-TongZhangDeepUnsupervisedSaliency\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tong Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-TongZhangDeepUnsupervisedSaliency').submit();\">Tong Zhang</a>,\n</form>\n<form id=\"form-YuchaoDaiDeepUnsupervisedSaliency\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuchao Dai\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuchaoDaiDeepUnsupervisedSaliency').submit();\">Yuchao Dai</a>,\n</form>\n<form id=\"form-MehrtashHarandiDeepUnsupervisedSaliency\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mehrtash Harandi\">\n<a href=\"#\" onclick=\"document.getElementById('form-MehrtashHarandiDeepUnsupervisedSaliency').submit();\">Mehrtash Harandi</a>,\n</form>\n<form id=\"form-RichardHartleyDeepUnsupervisedSaliency\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Richard Hartley\">\n<a href=\"#\" onclick=\"document.getElementById('form-RichardHartleyDeepUnsupervisedSaliency').submit();\">Richard Hartley</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Deep_Unsupervised_Saliency_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.10910\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Jing and Zhang, Tong and Dai, Yuchao and Harandi, Mehrtash and Hartley, Richard},<br>\ntitle = {Deep Unsupervised Saliency Detection: A Multiple Noisy Labeling Perspective},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Learning_Intrinsic_Image_CVPR_2018_paper.html\">Learning Intrinsic Image Decomposition From Watching the World</a></dt>\n<dd>\n<form id=\"form-ZhengqiLiLearningIntrinsicImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhengqi Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhengqiLiLearningIntrinsicImage').submit();\">Zhengqi Li</a>,\n</form>\n<form id=\"form-NoahSnavelyLearningIntrinsicImage\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Noah Snavely\">\n<a href=\"#\" onclick=\"document.getElementById('form-NoahSnavelyLearningIntrinsicImage').submit();\">Noah Snavely</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Learning_Intrinsic_Image_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0110-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00582\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Zhengqi and Snavely, Noah},<br>\ntitle = {Learning Intrinsic Image Decomposition From Watching the World},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_TieNet_Text-Image_Embedding_CVPR_2018_paper.html\">TieNet: Text-Image Embedding Network for Common Thorax Disease Classification and Reporting in Chest X-Rays</a></dt>\n<dd>\n<form id=\"form-XiaosongWangTieNetTextImageEmbedding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaosong Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaosongWangTieNetTextImageEmbedding').submit();\">Xiaosong Wang</a>,\n</form>\n<form id=\"form-YifanPengTieNetTextImageEmbedding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yifan Peng\">\n<a href=\"#\" onclick=\"document.getElementById('form-YifanPengTieNetTextImageEmbedding').submit();\">Yifan Peng</a>,\n</form>\n<form id=\"form-LeLuTieNetTextImageEmbedding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Le Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeLuTieNetTextImageEmbedding').submit();\">Le Lu</a>,\n</form>\n<form id=\"form-ZhiyongLuTieNetTextImageEmbedding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhiyong Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhiyongLuTieNetTextImageEmbedding').submit();\">Zhiyong Lu</a>,\n</form>\n<form id=\"form-RonaldM.TieNetTextImageEmbedding\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ronald M. Summers\">\n<a href=\"#\" onclick=\"document.getElementById('form-RonaldM.TieNetTextImageEmbedding').submit();\">Ronald M. Summers</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_TieNet_Text-Image_Embedding_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.04334\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Xiaosong and Peng, Yifan and Lu, Le and Lu, Zhiyong and Summers, Ronald M.},<br>\ntitle = {TieNet: Text-Image Embedding Network for Common Thorax Disease Classification and Reporting in Chest X-Rays},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Teixeira_Generating_Synthetic_X-Ray_CVPR_2018_paper.html\">Generating Synthetic X-Ray Images of a Person From the Surface Geometry</a></dt>\n<dd>\n<form id=\"form-BrianTeixeiraGeneratingSyntheticXRay\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Brian Teixeira\">\n<a href=\"#\" onclick=\"document.getElementById('form-BrianTeixeiraGeneratingSyntheticXRay').submit();\">Brian Teixeira</a>,\n</form>\n<form id=\"form-VivekSinghGeneratingSyntheticXRay\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vivek Singh\">\n<a href=\"#\" onclick=\"document.getElementById('form-VivekSinghGeneratingSyntheticXRay').submit();\">Vivek Singh</a>,\n</form>\n<form id=\"form-TerrenceChenGeneratingSyntheticXRay\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Terrence Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-TerrenceChenGeneratingSyntheticXRay').submit();\">Terrence Chen</a>,\n</form>\n<form id=\"form-KaiMaGeneratingSyntheticXRay\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kai Ma\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaiMaGeneratingSyntheticXRay').submit();\">Kai Ma</a>,\n</form>\n<form id=\"form-BirgiTamersoyGeneratingSyntheticXRay\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Birgi Tamersoy\">\n<a href=\"#\" onclick=\"document.getElementById('form-BirgiTamersoyGeneratingSyntheticXRay').submit();\">Birgi Tamersoy</a>,\n</form>\n<form id=\"form-YifanWuGeneratingSyntheticXRay\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yifan Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YifanWuGeneratingSyntheticXRay').submit();\">Yifan Wu</a>,\n</form>\n<form id=\"form-ElenaBalashovaGeneratingSyntheticXRay\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Elena Balashova\">\n<a href=\"#\" onclick=\"document.getElementById('form-ElenaBalashovaGeneratingSyntheticXRay').submit();\">Elena Balashova</a>,\n</form>\n<form id=\"form-DorinComaniciuGeneratingSyntheticXRay\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dorin Comaniciu\">\n<a href=\"#\" onclick=\"document.getElementById('form-DorinComaniciuGeneratingSyntheticXRay').submit();\">Dorin Comaniciu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Teixeira_Generating_Synthetic_X-Ray_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.00553\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Teixeira_2018_CVPR,<br>\nauthor = {Teixeira, Brian and Singh, Vivek and Chen, Terrence and Ma, Kai and Tamersoy, Birgi and Wu, Yifan and Balashova, Elena and Comaniciu, Dorin},<br>\ntitle = {Generating Synthetic X-Ray Images of a Person From the Surface Geometry},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Xia_Gibson_Env_Real-World_CVPR_2018_paper.html\">Gibson Env: Real-World Perception for Embodied Agents</a></dt>\n<dd>\n<form id=\"form-FeiXiaGibsonEnvRealWorld\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fei Xia\">\n<a href=\"#\" onclick=\"document.getElementById('form-FeiXiaGibsonEnvRealWorld').submit();\">Fei Xia</a>,\n</form>\n<form id=\"form-AmirR.GibsonEnvRealWorld\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Amir R. Zamir\">\n<a href=\"#\" onclick=\"document.getElementById('form-AmirR.GibsonEnvRealWorld').submit();\">Amir R. Zamir</a>,\n</form>\n<form id=\"form-ZhiyangHeGibsonEnvRealWorld\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zhiyang He\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZhiyangHeGibsonEnvRealWorld').submit();\">Zhiyang He</a>,\n</form>\n<form id=\"form-AlexanderSaxGibsonEnvRealWorld\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexander Sax\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexanderSaxGibsonEnvRealWorld').submit();\">Alexander Sax</a>,\n</form>\n<form id=\"form-JitendraMalikGibsonEnvRealWorld\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jitendra Malik\">\n<a href=\"#\" onclick=\"document.getElementById('form-JitendraMalikGibsonEnvRealWorld').submit();\">Jitendra Malik</a>,\n</form>\n<form id=\"form-SilvioSavareseGibsonEnvRealWorld\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Silvio Savarese\">\n<a href=\"#\" onclick=\"document.getElementById('form-SilvioSavareseGibsonEnvRealWorld').submit();\">Silvio Savarese</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Xia_Gibson_Env_Real-World_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Xia_2018_CVPR,<br>\nauthor = {Xia, Fei and Zamir, Amir R. and He, Zhiyang and Sax, Alexander and Malik, Jitendra and Savarese, Silvio},<br>\ntitle = {Gibson Env: Real-World Perception for Embodied Agents},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Han_Reinforcement_Cutting-Agent_Learning_CVPR_2018_paper.html\">Reinforcement Cutting-Agent Learning for Video Object Segmentation</a></dt>\n<dd>\n<form id=\"form-JunweiHanReinforcementCuttingAgentLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junwei Han\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunweiHanReinforcementCuttingAgentLearning').submit();\">Junwei Han</a>,\n</form>\n<form id=\"form-LeYangReinforcementCuttingAgentLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Le Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeYangReinforcementCuttingAgentLearning').submit();\">Le Yang</a>,\n</form>\n<form id=\"form-DingwenZhangReinforcementCuttingAgentLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dingwen Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-DingwenZhangReinforcementCuttingAgentLearning').submit();\">Dingwen Zhang</a>,\n</form>\n<form id=\"form-XiaojunChangReinforcementCuttingAgentLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaojun Chang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaojunChangReinforcementCuttingAgentLearning').submit();\">Xiaojun Chang</a>,\n</form>\n<form id=\"form-XiaodanLiangReinforcementCuttingAgentLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaodan Liang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaodanLiangReinforcementCuttingAgentLearning').submit();\">Xiaodan Liang</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Han_Reinforcement_Cutting-Agent_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Han_2018_CVPR,<br>\nauthor = {Han, Junwei and Yang, Le and Zhang, Dingwen and Chang, Xiaojun and Liang, Xiaodan},<br>\ntitle = {Reinforcement Cutting-Agent Learning for Video Object Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Liu_Feature_Space_Transfer_CVPR_2018_paper.html\">Feature Space Transfer for Data Augmentation</a></dt>\n<dd>\n<form id=\"form-BoLiuFeatureSpaceTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bo Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-BoLiuFeatureSpaceTransfer').submit();\">Bo Liu</a>,\n</form>\n<form id=\"form-XudongWangFeatureSpaceTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xudong Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XudongWangFeatureSpaceTransfer').submit();\">Xudong Wang</a>,\n</form>\n<form id=\"form-MandarDixitFeatureSpaceTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mandar Dixit\">\n<a href=\"#\" onclick=\"document.getElementById('form-MandarDixitFeatureSpaceTransfer').submit();\">Mandar Dixit</a>,\n</form>\n<form id=\"form-RolandKwittFeatureSpaceTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Roland Kwitt\">\n<a href=\"#\" onclick=\"document.getElementById('form-RolandKwittFeatureSpaceTransfer').submit();\">Roland Kwitt</a>,\n</form>\n<form id=\"form-NunoVasconcelosFeatureSpaceTransfer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nuno Vasconcelos\">\n<a href=\"#\" onclick=\"document.getElementById('form-NunoVasconcelosFeatureSpaceTransfer').submit();\">Nuno Vasconcelos</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Liu_Feature_Space_Transfer_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.04356\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Liu_2018_CVPR,<br>\nauthor = {Liu, Bo and Wang, Xudong and Dixit, Mandar and Kwitt, Roland and Vasconcelos, Nuno},<br>\ntitle = {Feature Space Transfer for Data Augmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Bibi_Analytic_Expressions_for_CVPR_2018_paper.html\">Analytic Expressions for Probabilistic Moments of PL-DNN With Gaussian Input</a></dt>\n<dd>\n<form id=\"form-AdelBibiAnalyticExpressionsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Adel Bibi\">\n<a href=\"#\" onclick=\"document.getElementById('form-AdelBibiAnalyticExpressionsfor').submit();\">Adel Bibi</a>,\n</form>\n<form id=\"form-ModarAlfadlyAnalyticExpressionsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Modar Alfadly\">\n<a href=\"#\" onclick=\"document.getElementById('form-ModarAlfadlyAnalyticExpressionsfor').submit();\">Modar Alfadly</a>,\n</form>\n<form id=\"form-BernardGhanemAnalyticExpressionsfor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bernard Ghanem\">\n<a href=\"#\" onclick=\"document.getElementById('form-BernardGhanemAnalyticExpressionsfor').submit();\">Bernard Ghanem</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Bibi_Analytic_Expressions_for_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0487-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Bibi_2018_CVPR,<br>\nauthor = {Bibi, Adel and Alfadly, Modar and Ghanem, Bernard},<br>\ntitle = {Analytic Expressions for Probabilistic Moments of PL-DNN With Gaussian Input},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Saeedan_Detail-Preserving_Pooling_in_CVPR_2018_paper.html\">Detail-Preserving Pooling in Deep Networks</a></dt>\n<dd>\n<form id=\"form-FarazSaeedanDetailPreservingPoolingin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Faraz Saeedan\">\n<a href=\"#\" onclick=\"document.getElementById('form-FarazSaeedanDetailPreservingPoolingin').submit();\">Faraz Saeedan</a>,\n</form>\n<form id=\"form-NicolasWeberDetailPreservingPoolingin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nicolas Weber\">\n<a href=\"#\" onclick=\"document.getElementById('form-NicolasWeberDetailPreservingPoolingin').submit();\">Nicolas Weber</a>,\n</form>\n<form id=\"form-MichaelGoeseleDetailPreservingPoolingin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michael Goesele\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichaelGoeseleDetailPreservingPoolingin').submit();\">Michael Goesele</a>,\n</form>\n<form id=\"form-StefanRothDetailPreservingPoolingin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stefan Roth\">\n<a href=\"#\" onclick=\"document.getElementById('form-StefanRothDetailPreservingPoolingin').submit();\">Stefan Roth</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Saeedan_Detail-Preserving_Pooling_in_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1532-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.04076\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Saeedan_2018_CVPR,<br>\nauthor = {Saeedan, Faraz and Weber, Nicolas and Goesele, Michael and Roth, Stefan},<br>\ntitle = {Detail-Preserving Pooling in Deep Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wan_Rethinking_Feature_Distribution_CVPR_2018_paper.html\">Rethinking Feature Distribution for Loss Functions in Image Classification</a></dt>\n<dd>\n<form id=\"form-WeitaoWanRethinkingFeatureDistribution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Weitao Wan\">\n<a href=\"#\" onclick=\"document.getElementById('form-WeitaoWanRethinkingFeatureDistribution').submit();\">Weitao Wan</a>,\n</form>\n<form id=\"form-YuanyiZhongRethinkingFeatureDistribution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yuanyi Zhong\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuanyiZhongRethinkingFeatureDistribution').submit();\">Yuanyi Zhong</a>,\n</form>\n<form id=\"form-TianpengLiRethinkingFeatureDistribution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tianpeng Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-TianpengLiRethinkingFeatureDistribution').submit();\">Tianpeng Li</a>,\n</form>\n<form id=\"form-JianshengChenRethinkingFeatureDistribution\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiansheng Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianshengChenRethinkingFeatureDistribution').submit();\">Jiansheng Chen</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wan_Rethinking_Feature_Distribution_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.02988\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wan_2018_CVPR,<br>\nauthor = {Wan, Weitao and Zhong, Yuanyi and Li, Tianpeng and Chen, Jiansheng},<br>\ntitle = {Rethinking Feature Distribution for Loss Functions in Image Classification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wu_Shift_A_Zero_CVPR_2018_paper.html\">Shift: A Zero FLOP, Zero Parameter Alternative to Spatial Convolutions</a></dt>\n<dd>\n<form id=\"form-BichenWuShiftAZero\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bichen Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-BichenWuShiftAZero').submit();\">Bichen Wu</a>,\n</form>\n<form id=\"form-AlvinWanShiftAZero\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alvin Wan\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlvinWanShiftAZero').submit();\">Alvin Wan</a>,\n</form>\n<form id=\"form-XiangyuYueShiftAZero\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiangyu Yue\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiangyuYueShiftAZero').submit();\">Xiangyu Yue</a>,\n</form>\n<form id=\"form-PeterJinShiftAZero\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Peter Jin\">\n<a href=\"#\" onclick=\"document.getElementById('form-PeterJinShiftAZero').submit();\">Peter Jin</a>,\n</form>\n<form id=\"form-SichengZhaoShiftAZero\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Sicheng Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-SichengZhaoShiftAZero').submit();\">Sicheng Zhao</a>,\n</form>\n<form id=\"form-NoahGolmantShiftAZero\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Noah Golmant\">\n<a href=\"#\" onclick=\"document.getElementById('form-NoahGolmantShiftAZero').submit();\">Noah Golmant</a>,\n</form>\n<form id=\"form-AmirGholaminejadShiftAZero\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Amir Gholaminejad\">\n<a href=\"#\" onclick=\"document.getElementById('form-AmirGholaminejadShiftAZero').submit();\">Amir Gholaminejad</a>,\n</form>\n<form id=\"form-JosephGonzalezShiftAZero\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Joseph Gonzalez\">\n<a href=\"#\" onclick=\"document.getElementById('form-JosephGonzalezShiftAZero').submit();\">Joseph Gonzalez</a>,\n</form>\n<form id=\"form-KurtKeutzerShiftAZero\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kurt Keutzer\">\n<a href=\"#\" onclick=\"document.getElementById('form-KurtKeutzerShiftAZero').submit();\">Kurt Keutzer</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wu_Shift_A_Zero_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wu_2018_CVPR,<br>\nauthor = {Wu, Bichen and Wan, Alvin and Yue, Xiangyu and Jin, Peter and Zhao, Sicheng and Golmant, Noah and Gholaminejad, Amir and Gonzalez, Joseph and Keutzer, Kurt},<br>\ntitle = {Shift: A Zero FLOP, Zero Parameter Alternative to Spatial Convolutions},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Hu_Sketch-a-Classifier_Sketch-Based_Photo_CVPR_2018_paper.html\">Sketch-a-Classifier: Sketch-Based Photo Classifier Generation</a></dt>\n<dd>\n<form id=\"form-ConghuiHuSketchaClassifierSketchBasedPhoto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Conghui Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ConghuiHuSketchaClassifierSketchBasedPhoto').submit();\">Conghui Hu</a>,\n</form>\n<form id=\"form-DaLiSketchaClassifierSketchBasedPhoto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Da Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-DaLiSketchaClassifierSketchBasedPhoto').submit();\">Da Li</a>,\n</form>\n<form id=\"form-Yi-ZheSongSketchaClassifierSketchBasedPhoto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi-Zhe Song\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yi-ZheSongSketchaClassifierSketchBasedPhoto').submit();\">Yi-Zhe Song</a>,\n</form>\n<form id=\"form-TaoXiangSketchaClassifierSketchBasedPhoto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tao Xiang\">\n<a href=\"#\" onclick=\"document.getElementById('form-TaoXiangSketchaClassifierSketchBasedPhoto').submit();\">Tao Xiang</a>,\n</form>\n<form id=\"form-TimothyM.SketchaClassifierSketchBasedPhoto\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Timothy M. Hospedales\">\n<a href=\"#\" onclick=\"document.getElementById('form-TimothyM.SketchaClassifierSketchBasedPhoto').submit();\">Timothy M. Hospedales</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Hu_Sketch-a-Classifier_Sketch-Based_Photo_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.11182\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Hu_2018_CVPR,<br>\nauthor = {Hu, Conghui and Li, Da and Song, Yi-Zhe and Xiang, Tao and Hospedales, Timothy M.},<br>\ntitle = {Sketch-a-Classifier: Sketch-Based Photo Classifier Generation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Alperovich_Light_Field_Intrinsics_CVPR_2018_paper.html\">Light Field Intrinsics With a Deep Encoder-Decoder Network</a></dt>\n<dd>\n<form id=\"form-AnnaAlperovichLightFieldIntrinsics\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anna Alperovich\">\n<a href=\"#\" onclick=\"document.getElementById('form-AnnaAlperovichLightFieldIntrinsics').submit();\">Anna Alperovich</a>,\n</form>\n<form id=\"form-OleJohannsenLightFieldIntrinsics\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ole Johannsen\">\n<a href=\"#\" onclick=\"document.getElementById('form-OleJohannsenLightFieldIntrinsics').submit();\">Ole Johannsen</a>,\n</form>\n<form id=\"form-MichaelStreckeLightFieldIntrinsics\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Michael Strecke\">\n<a href=\"#\" onclick=\"document.getElementById('form-MichaelStreckeLightFieldIntrinsics').submit();\">Michael Strecke</a>,\n</form>\n<form id=\"form-BastianGoldlueckeLightFieldIntrinsics\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Bastian Goldluecke\">\n<a href=\"#\" onclick=\"document.getElementById('form-BastianGoldlueckeLightFieldIntrinsics').submit();\">Bastian Goldluecke</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Alperovich_Light_Field_Intrinsics_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2351-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Alperovich_2018_CVPR,<br>\nauthor = {Alperovich, Anna and Johannsen, Ole and Strecke, Michael and Goldluecke, Bastian},<br>\ntitle = {Light Field Intrinsics With a Deep Encoder-Decoder Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Gao_Learning_Generative_ConvNets_CVPR_2018_paper.html\">Learning Generative ConvNets via Multi-Grid Modeling and Sampling</a></dt>\n<dd>\n<form id=\"form-RuiqiGaoLearningGenerativeConvNets\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ruiqi Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-RuiqiGaoLearningGenerativeConvNets').submit();\">Ruiqi Gao</a>,\n</form>\n<form id=\"form-YangLuLearningGenerativeConvNets\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yang Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YangLuLearningGenerativeConvNets').submit();\">Yang Lu</a>,\n</form>\n<form id=\"form-JunpeiZhouLearningGenerativeConvNets\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Junpei Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunpeiZhouLearningGenerativeConvNets').submit();\">Junpei Zhou</a>,\n</form>\n<form id=\"form-Song-ChunZhuLearningGenerativeConvNets\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Song-Chun Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Song-ChunZhuLearningGenerativeConvNets').submit();\">Song-Chun Zhu</a>,\n</form>\n<form id=\"form-YingNianLearningGenerativeConvNets\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ying Nian Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YingNianLearningGenerativeConvNets').submit();\">Ying Nian Wu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Gao_Learning_Generative_ConvNets_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2425-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1709.08868\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Gao_2018_CVPR,<br>\nauthor = {Gao, Ruiqi and Lu, Yang and Zhou, Junpei and Zhu, Song-Chun and Nian Wu, Ying},<br>\ntitle = {Learning Generative ConvNets via Multi-Grid Modeling and Sampling},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Mehr_Manifold_Learning_in_CVPR_2018_paper.html\">Manifold Learning in Quotient Spaces</a></dt>\n<dd>\n<form id=\"form-\u00c3\u0089loiMehrManifoldLearningin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"\u00c3\u0089loi Mehr\">\n<a href=\"#\" onclick=\"document.getElementById('form-\u00c3\u0089loiMehrManifoldLearningin').submit();\">\u00c3\u0089loi Mehr</a>,\n</form>\n<form id=\"form-Andr\u00c3\u00a9LieutierManifoldLearningin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andr\u00c3\u00a9 Lieutier\">\n<a href=\"#\" onclick=\"document.getElementById('form-Andr\u00c3\u00a9LieutierManifoldLearningin').submit();\">Andr\u00c3\u00a9 Lieutier</a>,\n</form>\n<form id=\"form-FernandoSanchezManifoldLearningin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fernando Sanchez Bermudez\">\n<a href=\"#\" onclick=\"document.getElementById('form-FernandoSanchezManifoldLearningin').submit();\">Fernando Sanchez Bermudez</a>,\n</form>\n<form id=\"form-VincentGuittenyManifoldLearningin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vincent Guitteny\">\n<a href=\"#\" onclick=\"document.getElementById('form-VincentGuittenyManifoldLearningin').submit();\">Vincent Guitteny</a>,\n</form>\n<form id=\"form-NicolasThomeManifoldLearningin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Nicolas Thome\">\n<a href=\"#\" onclick=\"document.getElementById('form-NicolasThomeManifoldLearningin').submit();\">Nicolas Thome</a>,\n</form>\n<form id=\"form-MatthieuCordManifoldLearningin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Matthieu Cord\">\n<a href=\"#\" onclick=\"document.getElementById('form-MatthieuCordManifoldLearningin').submit();\">Matthieu Cord</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Mehr_Manifold_Learning_in_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2989-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Mehr_2018_CVPR,<br>\nauthor = {Mehr, \u00c3\u0089loi and Lieutier, Andr\u00c3\u00a9 and Sanchez Bermudez, Fernando and Guitteny, Vincent and Thome, Nicolas and Cord, Matthieu},<br>\ntitle = {Manifold Learning in Quotient Spaces},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Konyushkova_Learning_Intelligent_Dialogs_CVPR_2018_paper.html\">Learning Intelligent Dialogs for Bounding Box Annotation</a></dt>\n<dd>\n<form id=\"form-KseniaKonyushkovaLearningIntelligentDialogs\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ksenia Konyushkova\">\n<a href=\"#\" onclick=\"document.getElementById('form-KseniaKonyushkovaLearningIntelligentDialogs').submit();\">Ksenia Konyushkova</a>,\n</form>\n<form id=\"form-JasperUijlingsLearningIntelligentDialogs\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jasper Uijlings\">\n<a href=\"#\" onclick=\"document.getElementById('form-JasperUijlingsLearningIntelligentDialogs').submit();\">Jasper Uijlings</a>,\n</form>\n<form id=\"form-ChristophH.LearningIntelligentDialogs\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Christoph H. Lampert\">\n<a href=\"#\" onclick=\"document.getElementById('form-ChristophH.LearningIntelligentDialogs').submit();\">Christoph H. Lampert</a>,\n</form>\n<form id=\"form-VittorioFerrariLearningIntelligentDialogs\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vittorio Ferrari\">\n<a href=\"#\" onclick=\"document.getElementById('form-VittorioFerrariLearningIntelligentDialogs').submit();\">Vittorio Ferrari</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Konyushkova_Learning_Intelligent_Dialogs_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3741-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.08087\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Konyushkova_2018_CVPR,<br>\nauthor = {Konyushkova, Ksenia and Uijlings, Jasper and Lampert, Christoph H. and Ferrari, Vittorio},<br>\ntitle = {Learning Intelligent Dialogs for Bounding Box Annotation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Dong_Boosting_Adversarial_Attacks_CVPR_2018_paper.html\">Boosting Adversarial Attacks With Momentum</a></dt>\n<dd>\n<form id=\"form-YinpengDongBoostingAdversarialAttacks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yinpeng Dong\">\n<a href=\"#\" onclick=\"document.getElementById('form-YinpengDongBoostingAdversarialAttacks').submit();\">Yinpeng Dong</a>,\n</form>\n<form id=\"form-FangzhouLiaoBoostingAdversarialAttacks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fangzhou Liao\">\n<a href=\"#\" onclick=\"document.getElementById('form-FangzhouLiaoBoostingAdversarialAttacks').submit();\">Fangzhou Liao</a>,\n</form>\n<form id=\"form-TianyuPangBoostingAdversarialAttacks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tianyu Pang\">\n<a href=\"#\" onclick=\"document.getElementById('form-TianyuPangBoostingAdversarialAttacks').submit();\">Tianyu Pang</a>,\n</form>\n<form id=\"form-HangSuBoostingAdversarialAttacks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hang Su\">\n<a href=\"#\" onclick=\"document.getElementById('form-HangSuBoostingAdversarialAttacks').submit();\">Hang Su</a>,\n</form>\n<form id=\"form-JunZhuBoostingAdversarialAttacks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jun Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-JunZhuBoostingAdversarialAttacks').submit();\">Jun Zhu</a>,\n</form>\n<form id=\"form-XiaolinHuBoostingAdversarialAttacks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaolin Hu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaolinHuBoostingAdversarialAttacks').submit();\">Xiaolin Hu</a>,\n</form>\n<form id=\"form-JianguoLiBoostingAdversarialAttacks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jianguo Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-JianguoLiBoostingAdversarialAttacks').submit();\">Jianguo Li</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Dong_Boosting_Adversarial_Attacks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/4098-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1710.06081\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Dong_2018_CVPR,<br>\nauthor = {Dong, Yinpeng and Liao, Fangzhou and Pang, Tianyu and Su, Hang and Zhu, Jun and Hu, Xiaolin and Li, Jianguo},<br>\ntitle = {Boosting Adversarial Attacks With Momentum},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yu_NISP_Pruning_Networks_CVPR_2018_paper.html\">NISP: Pruning Networks Using Neuron Importance Score Propagation</a></dt>\n<dd>\n<form id=\"form-RuichiYuNISPPruningNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ruichi Yu\">\n<a href=\"#\" onclick=\"document.getElementById('form-RuichiYuNISPPruningNetworks').submit();\">Ruichi Yu</a>,\n</form>\n<form id=\"form-AngLiNISPPruningNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ang Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-AngLiNISPPruningNetworks').submit();\">Ang Li</a>,\n</form>\n<form id=\"form-Chun-FuChenNISPPruningNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chun-Fu Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-Chun-FuChenNISPPruningNetworks').submit();\">Chun-Fu Chen</a>,\n</form>\n<form id=\"form-Jui-HsinLaiNISPPruningNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jui-Hsin Lai\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jui-HsinLaiNISPPruningNetworks').submit();\">Jui-Hsin Lai</a>,\n</form>\n<form id=\"form-VladI.NISPPruningNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vlad I. Morariu\">\n<a href=\"#\" onclick=\"document.getElementById('form-VladI.NISPPruningNetworks').submit();\">Vlad I. Morariu</a>,\n</form>\n<form id=\"form-XintongHanNISPPruningNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xintong Han\">\n<a href=\"#\" onclick=\"document.getElementById('form-XintongHanNISPPruningNetworks').submit();\">Xintong Han</a>,\n</form>\n<form id=\"form-MingfeiGaoNISPPruningNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mingfei Gao\">\n<a href=\"#\" onclick=\"document.getElementById('form-MingfeiGaoNISPPruningNetworks').submit();\">Mingfei Gao</a>,\n</form>\n<form id=\"form-Ching-YungLinNISPPruningNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ching-Yung Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ching-YungLinNISPPruningNetworks').submit();\">Ching-Yung Lin</a>,\n</form>\n<form id=\"form-LarryS.NISPPruningNetworks\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Larry S. Davis\">\n<a href=\"#\" onclick=\"document.getElementById('form-LarryS.NISPPruningNetworks').submit();\">Larry S. Davis</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yu_NISP_Pruning_Networks_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0601-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.05908\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yu_2018_CVPR,<br>\nauthor = {Yu, Ruichi and Li, Ang and Chen, Chun-Fu and Lai, Jui-Hsin and Morariu, Vlad I. and Han, Xintong and Gao, Mingfei and Lin, Ching-Yung and Davis, Larry S.},<br>\ntitle = {NISP: Pruning Networks Using Neuron Importance Score Propagation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Le_PointGrid_A_Deep_CVPR_2018_paper.html\">PointGrid: A Deep Network for 3D Shape Understanding</a></dt>\n<dd>\n<form id=\"form-TrucLePointGridADeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Truc Le\">\n<a href=\"#\" onclick=\"document.getElementById('form-TrucLePointGridADeep').submit();\">Truc Le</a>,\n</form>\n<form id=\"form-YeDuanPointGridADeep\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ye Duan\">\n<a href=\"#\" onclick=\"document.getElementById('form-YeDuanPointGridADeep').submit();\">Ye Duan</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Le_PointGrid_A_Deep_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Le_2018_CVPR,<br>\nauthor = {Le, Truc and Duan, Ye},<br>\ntitle = {PointGrid: A Deep Network for 3D Shape Understanding},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_Tell_Me_Where_CVPR_2018_paper.html\">Tell Me Where to Look: Guided Attention Inference Network</a></dt>\n<dd>\n<form id=\"form-KunpengLiTellMeWhere\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kunpeng Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-KunpengLiTellMeWhere').submit();\">Kunpeng Li</a>,\n</form>\n<form id=\"form-ZiyanWuTellMeWhere\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ziyan Wu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZiyanWuTellMeWhere').submit();\">Ziyan Wu</a>,\n</form>\n<form id=\"form-Kuan-ChuanPengTellMeWhere\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kuan-Chuan Peng\">\n<a href=\"#\" onclick=\"document.getElementById('form-Kuan-ChuanPengTellMeWhere').submit();\">Kuan-Chuan Peng</a>,\n</form>\n<form id=\"form-JanErnstTellMeWhere\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jan Ernst\">\n<a href=\"#\" onclick=\"document.getElementById('form-JanErnstTellMeWhere').submit();\">Jan Ernst</a>,\n</form>\n<form id=\"form-YunFuTellMeWhere\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yun Fu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YunFuTellMeWhere').submit();\">Yun Fu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_Tell_Me_Where_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.10171\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Kunpeng and Wu, Ziyan and Peng, Kuan-Chuan and Ernst, Jan and Fu, Yun},<br>\ntitle = {Tell Me Where to Look: Guided Attention Inference Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Graham_3D_Semantic_Segmentation_CVPR_2018_paper.html\">3D Semantic Segmentation With Submanifold Sparse Convolutional Networks</a></dt>\n<dd>\n<form id=\"form-BenjaminGraham3DSemanticSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Benjamin Graham\">\n<a href=\"#\" onclick=\"document.getElementById('form-BenjaminGraham3DSemanticSegmentation').submit();\">Benjamin Graham</a>,\n</form>\n<form id=\"form-MartinEngelcke3DSemanticSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Martin Engelcke\">\n<a href=\"#\" onclick=\"document.getElementById('form-MartinEngelcke3DSemanticSegmentation').submit();\">Martin Engelcke</a>,\n</form>\n<form id=\"form-Laurensvan3DSemanticSegmentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Laurens van der Maaten\">\n<a href=\"#\" onclick=\"document.getElementById('form-Laurensvan3DSemanticSegmentation').submit();\">Laurens van der Maaten</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Graham_3D_Semantic_Segmentation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.10275\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Graham_2018_CVPR,<br>\nauthor = {Graham, Benjamin and Engelcke, Martin and van der Maaten, Laurens},<br>\ntitle = {3D Semantic Segmentation With Submanifold Sparse Convolutional Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_TOM-Net_Learning_Transparent_CVPR_2018_paper.html\">TOM-Net: Learning Transparent Object Matting From a Single Image</a></dt>\n<dd>\n<form id=\"form-GuanyingChenTOMNetLearningTransparent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guanying Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuanyingChenTOMNetLearningTransparent').submit();\">Guanying Chen</a>,\n</form>\n<form id=\"form-KaiHanTOMNetLearningTransparent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kai Han\">\n<a href=\"#\" onclick=\"document.getElementById('form-KaiHanTOMNetLearningTransparent').submit();\">Kai Han</a>,\n</form>\n<form id=\"form-Kwan-YeeK.TOMNetLearningTransparent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kwan-Yee K. Wong\">\n<a href=\"#\" onclick=\"document.getElementById('form-Kwan-YeeK.TOMNetLearningTransparent').submit();\">Kwan-Yee K. Wong</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_TOM-Net_Learning_Transparent_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.04636\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Guanying and Han, Kai and Wong, Kwan-Yee K.},<br>\ntitle = {TOM-Net: Learning Transparent Object Matting From a Single Image},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhang_Translating_and_Segmenting_CVPR_2018_paper.html\">Translating and Segmenting Multimodal Medical Volumes With Cycle- and Shape-Consistency Generative Adversarial Network</a></dt>\n<dd>\n<form id=\"form-ZizhaoZhangTranslatingandSegmenting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zizhao Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZizhaoZhangTranslatingandSegmenting').submit();\">Zizhao Zhang</a>,\n</form>\n<form id=\"form-LinYangTranslatingandSegmenting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Lin Yang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LinYangTranslatingandSegmenting').submit();\">Lin Yang</a>,\n</form>\n<form id=\"form-YefengZhengTranslatingandSegmenting\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yefeng Zheng\">\n<a href=\"#\" onclick=\"document.getElementById('form-YefengZhengTranslatingandSegmenting').submit();\">Yefeng Zheng</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhang_Translating_and_Segmenting_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.09655\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhang_2018_CVPR,<br>\nauthor = {Zhang, Zizhao and Yang, Lin and Zheng, Yefeng},<br>\ntitle = {Translating and Segmenting Multimodal Medical Volumes With Cycle- and Shape-Consistency Generative Adversarial Network},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Balakrishnan_An_Unsupervised_Learning_CVPR_2018_paper.html\">An Unsupervised Learning Model for Deformable Medical Image Registration</a></dt>\n<dd>\n<form id=\"form-GuhaBalakrishnanAnUnsupervisedLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guha Balakrishnan\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuhaBalakrishnanAnUnsupervisedLearning').submit();\">Guha Balakrishnan</a>,\n</form>\n<form id=\"form-AmyZhaoAnUnsupervisedLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Amy Zhao\">\n<a href=\"#\" onclick=\"document.getElementById('form-AmyZhaoAnUnsupervisedLearning').submit();\">Amy Zhao</a>,\n</form>\n<form id=\"form-MertR.AnUnsupervisedLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mert R. Sabuncu\">\n<a href=\"#\" onclick=\"document.getElementById('form-MertR.AnUnsupervisedLearning').submit();\">Mert R. Sabuncu</a>,\n</form>\n<form id=\"form-JohnGuttagAnUnsupervisedLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"John Guttag\">\n<a href=\"#\" onclick=\"document.getElementById('form-JohnGuttagAnUnsupervisedLearning').submit();\">John Guttag</a>,\n</form>\n<form id=\"form-AdrianV.AnUnsupervisedLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Adrian V. Dalca\">\n<a href=\"#\" onclick=\"document.getElementById('form-AdrianV.AnUnsupervisedLearning').submit();\">Adrian V. Dalca</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Balakrishnan_An_Unsupervised_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.02604\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Balakrishnan_2018_CVPR,<br>\nauthor = {Balakrishnan, Guha and Zhao, Amy and Sabuncu, Mert R. and Guttag, John and Dalca, Adrian V.},<br>\ntitle = {An Unsupervised Learning Model for Deformable Medical Image Registration},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Yan_Deep_Lesion_Graphs_CVPR_2018_paper.html\">Deep Lesion Graphs in the Wild: Relationship Learning and Organization of Significant Radiology Image Findings in a Diverse Large-Scale Lesion Database</a></dt>\n<dd>\n<form id=\"form-KeYanDeepLesionGraphs\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ke Yan\">\n<a href=\"#\" onclick=\"document.getElementById('form-KeYanDeepLesionGraphs').submit();\">Ke Yan</a>,\n</form>\n<form id=\"form-XiaosongWangDeepLesionGraphs\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xiaosong Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-XiaosongWangDeepLesionGraphs').submit();\">Xiaosong Wang</a>,\n</form>\n<form id=\"form-LeLuDeepLesionGraphs\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Le Lu\">\n<a href=\"#\" onclick=\"document.getElementById('form-LeLuDeepLesionGraphs').submit();\">Le Lu</a>,\n</form>\n<form id=\"form-LingZhangDeepLesionGraphs\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ling Zhang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LingZhangDeepLesionGraphs').submit();\">Ling Zhang</a>,\n</form>\n<form id=\"form-AdamP.DeepLesionGraphs\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Adam P. Harrison\">\n<a href=\"#\" onclick=\"document.getElementById('form-AdamP.DeepLesionGraphs').submit();\">Adam P. Harrison</a>,\n</form>\n<form id=\"form-MohammadhadiBagheriDeepLesionGraphs\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mohammadhadi Bagheri\">\n<a href=\"#\" onclick=\"document.getElementById('form-MohammadhadiBagheriDeepLesionGraphs').submit();\">Mohammadhadi Bagheri</a>,\n</form>\n<form id=\"form-RonaldM.DeepLesionGraphs\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ronald M. Summers\">\n<a href=\"#\" onclick=\"document.getElementById('form-RonaldM.DeepLesionGraphs').submit();\">Ronald M. Summers</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Yan_Deep_Lesion_Graphs_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2986-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.10535\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Yan_2018_CVPR,<br>\nauthor = {Yan, Ke and Wang, Xiaosong and Lu, Le and Zhang, Ling and Harrison, Adam P. and Bagheri, Mohammadhadi and Summers, Ronald M.},<br>\ntitle = {Deep Lesion Graphs in the Wild: Relationship Learning and Organization of Significant Radiology Image Findings in a Diverse Large-Scale Lesion Database},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Bone_Learning_Distributions_of_CVPR_2018_paper.html\">Learning Distributions of Shape Trajectories From Longitudinal Datasets: A Hierarchical Model on a Manifold of Diffeomorphisms</a></dt>\n<dd>\n<form id=\"form-AlexandreB\u00c3\u00b4neLearningDistributionsof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Alexandre B\u00c3\u00b4ne\">\n<a href=\"#\" onclick=\"document.getElementById('form-AlexandreB\u00c3\u00b4neLearningDistributionsof').submit();\">Alexandre B\u00c3\u00b4ne</a>,\n</form>\n<form id=\"form-OlivierColliotLearningDistributionsof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Olivier Colliot\">\n<a href=\"#\" onclick=\"document.getElementById('form-OlivierColliotLearningDistributionsof').submit();\">Olivier Colliot</a>,\n</form>\n<form id=\"form-StanleyDurrlemanLearningDistributionsof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Stanley Durrleman\">\n<a href=\"#\" onclick=\"document.getElementById('form-StanleyDurrlemanLearningDistributionsof').submit();\">Stanley Durrleman</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Bone_Learning_Distributions_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3035-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.10119\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{B\u00c3\u00b4ne_2018_CVPR,<br>\nauthor = {B\u00c3\u00b4ne, Alexandre and Colliot, Olivier and Durrleman, Stanley},<br>\ntitle = {Learning Distributions of Shape Trajectories From Longitudinal Datasets: A Hierarchical Model on a Manifold of Diffeomorphisms},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Jiang_CNN_Driven_Sparse_CVPR_2018_paper.html\">CNN Driven Sparse Multi-Level B-Spline Image Registration</a></dt>\n<dd>\n<form id=\"form-PinggeJiangCNNDrivenSparse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Pingge Jiang\">\n<a href=\"#\" onclick=\"document.getElementById('form-PinggeJiangCNNDrivenSparse').submit();\">Pingge Jiang</a>,\n</form>\n<form id=\"form-JamesA.CNNDrivenSparse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"James A. Shackleford\">\n<a href=\"#\" onclick=\"document.getElementById('form-JamesA.CNNDrivenSparse').submit();\">James A. Shackleford</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Jiang_CNN_Driven_Sparse_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Jiang_2018_CVPR,<br>\nauthor = {Jiang, Pingge and Shackleford, James A.},<br>\ntitle = {CNN Driven Sparse Multi-Level B-Spline Image Registration},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Dalca_Anatomical_Priors_in_CVPR_2018_paper.html\">Anatomical Priors in Convolutional Networks for Unsupervised Biomedical Segmentation</a></dt>\n<dd>\n<form id=\"form-AdrianV.AnatomicalPriorsin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Adrian V. Dalca\">\n<a href=\"#\" onclick=\"document.getElementById('form-AdrianV.AnatomicalPriorsin').submit();\">Adrian V. Dalca</a>,\n</form>\n<form id=\"form-JohnGuttagAnatomicalPriorsin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"John Guttag\">\n<a href=\"#\" onclick=\"document.getElementById('form-JohnGuttagAnatomicalPriorsin').submit();\">John Guttag</a>,\n</form>\n<form id=\"form-MertR.AnatomicalPriorsin\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mert R. Sabuncu\">\n<a href=\"#\" onclick=\"document.getElementById('form-MertR.AnatomicalPriorsin').submit();\">Mert R. Sabuncu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Dalca_Anatomical_Priors_in_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/4335-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Dalca_2018_CVPR,<br>\nauthor = {Dalca, Adrian V. and Guttag, John and Sabuncu, Mert R.},<br>\ntitle = {Anatomical Priors in Convolutional Networks for Unsupervised Biomedical Segmentation},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Raposo_3D_Registration_of_CVPR_2018_paper.html\">3D Registration of Curves and Surfaces Using Local Differential Information</a></dt>\n<dd>\n<form id=\"form-CarolinaRaposo3DRegistrationof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Carolina Raposo\">\n<a href=\"#\" onclick=\"document.getElementById('form-CarolinaRaposo3DRegistrationof').submit();\">Carolina Raposo</a>,\n</form>\n<form id=\"form-Jo\u00c3\u00a3oP.3DRegistrationof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jo\u00c3\u00a3o P. Barreto\">\n<a href=\"#\" onclick=\"document.getElementById('form-Jo\u00c3\u00a3oP.3DRegistrationof').submit();\">Jo\u00c3\u00a3o P. Barreto</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Raposo_3D_Registration_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1804.00637\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Raposo_2018_CVPR,<br>\nauthor = {Raposo, Carolina and Barreto, Jo\u00c3\u00a3o P.},<br>\ntitle = {3D Registration of Curves and Surfaces Using Local Differential Information},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Caicedo_Weakly_Supervised_Learning_CVPR_2018_paper.html\">Weakly Supervised Learning of Single-Cell Feature Embeddings</a></dt>\n<dd>\n<form id=\"form-JuanC.WeaklySupervisedLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Juan C. Caicedo\">\n<a href=\"#\" onclick=\"document.getElementById('form-JuanC.WeaklySupervisedLearning').submit();\">Juan C. Caicedo</a>,\n</form>\n<form id=\"form-ClaireMcQuinWeaklySupervisedLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Claire McQuin\">\n<a href=\"#\" onclick=\"document.getElementById('form-ClaireMcQuinWeaklySupervisedLearning').submit();\">Claire McQuin</a>,\n</form>\n<form id=\"form-AllenGoodmanWeaklySupervisedLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Allen Goodman\">\n<a href=\"#\" onclick=\"document.getElementById('form-AllenGoodmanWeaklySupervisedLearning').submit();\">Allen Goodman</a>,\n</form>\n<form id=\"form-ShantanuSinghWeaklySupervisedLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shantanu Singh\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShantanuSinghWeaklySupervisedLearning').submit();\">Shantanu Singh</a>,\n</form>\n<form id=\"form-AnneE.WeaklySupervisedLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anne E. Carpenter\">\n<a href=\"#\" onclick=\"document.getElementById('form-AnneE.WeaklySupervisedLearning').submit();\">Anne E. Carpenter</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Caicedo_Weakly_Supervised_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/4238-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Caicedo_2018_CVPR,<br>\nauthor = {Caicedo, Juan C. and McQuin, Claire and Goodman, Allen and Singh, Shantanu and Carpenter, Anne E.},<br>\ntitle = {Weakly Supervised Learning of Single-Cell Feature Embeddings},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Haehn_Guided_Proofreading_of_CVPR_2018_paper.html\">Guided Proofreading of Automatic Segmentations for Connectomics</a></dt>\n<dd>\n<form id=\"form-DanielHaehnGuidedProofreadingof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daniel Haehn\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanielHaehnGuidedProofreadingof').submit();\">Daniel Haehn</a>,\n</form>\n<form id=\"form-VerenaKaynigGuidedProofreadingof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Verena Kaynig\">\n<a href=\"#\" onclick=\"document.getElementById('form-VerenaKaynigGuidedProofreadingof').submit();\">Verena Kaynig</a>,\n</form>\n<form id=\"form-JamesTompkinGuidedProofreadingof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"James Tompkin\">\n<a href=\"#\" onclick=\"document.getElementById('form-JamesTompkinGuidedProofreadingof').submit();\">James Tompkin</a>,\n</form>\n<form id=\"form-JeffW.GuidedProofreadingof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jeff W. Lichtman\">\n<a href=\"#\" onclick=\"document.getElementById('form-JeffW.GuidedProofreadingof').submit();\">Jeff W. Lichtman</a>,\n</form>\n<form id=\"form-HanspeterPfisterGuidedProofreadingof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hanspeter Pfister\">\n<a href=\"#\" onclick=\"document.getElementById('form-HanspeterPfisterGuidedProofreadingof').submit();\">Hanspeter Pfister</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Haehn_Guided_Proofreading_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/0125-supp.zip\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1704.00848\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Haehn_2018_CVPR,<br>\nauthor = {Haehn, Daniel and Kaynig, Verena and Tompkin, James and Lichtman, Jeff W. and Pfister, Hanspeter},<br>\ntitle = {Guided Proofreading of Automatic Segmentations for Connectomics},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Wang_Wide_Compression_Tensor_CVPR_2018_paper.html\">Wide Compression: Tensor Ring Nets</a></dt>\n<dd>\n<form id=\"form-WenqiWangWideCompressionTensor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenqi Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenqiWangWideCompressionTensor').submit();\">Wenqi Wang</a>,\n</form>\n<form id=\"form-YifanSunWideCompressionTensor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yifan Sun\">\n<a href=\"#\" onclick=\"document.getElementById('form-YifanSunWideCompressionTensor').submit();\">Yifan Sun</a>,\n</form>\n<form id=\"form-BrianErikssonWideCompressionTensor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Brian Eriksson\">\n<a href=\"#\" onclick=\"document.getElementById('form-BrianErikssonWideCompressionTensor').submit();\">Brian Eriksson</a>,\n</form>\n<form id=\"form-WenlinWangWideCompressionTensor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wenlin Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenlinWangWideCompressionTensor').submit();\">Wenlin Wang</a>,\n</form>\n<form id=\"form-VaneetAggarwalWideCompressionTensor\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Vaneet Aggarwal\">\n<a href=\"#\" onclick=\"document.getElementById('form-VaneetAggarwalWideCompressionTensor').submit();\">Vaneet Aggarwal</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Wang_Wide_Compression_Tensor_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3989-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1802.09052\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Wang_2018_CVPR,<br>\nauthor = {Wang, Wenqi and Sun, Yifan and Eriksson, Brian and Wang, Wenlin and Aggarwal, Vaneet},<br>\ntitle = {Wide Compression: Tensor Ring Nets},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Mundhenk_Improvements_to_Context_CVPR_2018_paper.html\">Improvements to Context Based Self-Supervised Learning</a></dt>\n<dd>\n<form id=\"form-T.NathanImprovementstoContext\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"T. Nathan Mundhenk\">\n<a href=\"#\" onclick=\"document.getElementById('form-T.NathanImprovementstoContext').submit();\">T. Nathan Mundhenk</a>,\n</form>\n<form id=\"form-DanielHoImprovementstoContext\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Daniel Ho\">\n<a href=\"#\" onclick=\"document.getElementById('form-DanielHoImprovementstoContext').submit();\">Daniel Ho</a>,\n</form>\n<form id=\"form-BarryY.ImprovementstoContext\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Barry Y. Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-BarryY.ImprovementstoContext').submit();\">Barry Y. Chen</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Mundhenk_Improvements_to_Context_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/3991-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.06379\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Mundhenk_2018_CVPR,<br>\nauthor = {Nathan Mundhenk, T. and Ho, Daniel and Chen, Barry Y.},<br>\ntitle = {Improvements to Context Based Self-Supervised Learning},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Keshari_Learning_Structure_and_CVPR_2018_paper.html\">Learning Structure and Strength of CNN Filters for Small Sample Size Training</a></dt>\n<dd>\n<form id=\"form-RohitKeshariLearningStructureand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Rohit Keshari\">\n<a href=\"#\" onclick=\"document.getElementById('form-RohitKeshariLearningStructureand').submit();\">Rohit Keshari</a>,\n</form>\n<form id=\"form-MayankVatsaLearningStructureand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mayank Vatsa\">\n<a href=\"#\" onclick=\"document.getElementById('form-MayankVatsaLearningStructureand').submit();\">Mayank Vatsa</a>,\n</form>\n<form id=\"form-RichaSinghLearningStructureand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Richa Singh\">\n<a href=\"#\" onclick=\"document.getElementById('form-RichaSinghLearningStructureand').submit();\">Richa Singh</a>,\n</form>\n<form id=\"form-AfzelNooreLearningStructureand\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Afzel Noore\">\n<a href=\"#\" onclick=\"document.getElementById('form-AfzelNooreLearningStructureand').submit();\">Afzel Noore</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Keshari_Learning_Structure_and_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.11405\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Keshari_2018_CVPR,<br>\nauthor = {Keshari, Rohit and Vatsa, Mayank and Singh, Richa and Noore, Afzel},<br>\ntitle = {Learning Structure and Strength of CNN Filters for Small Sample Size Training},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Noroozi_Boosting_Self-Supervised_Learning_CVPR_2018_paper.html\">Boosting Self-Supervised Learning via Knowledge Transfer</a></dt>\n<dd>\n<form id=\"form-MehdiNorooziBoostingSelfSupervisedLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Mehdi Noroozi\">\n<a href=\"#\" onclick=\"document.getElementById('form-MehdiNorooziBoostingSelfSupervisedLearning').submit();\">Mehdi Noroozi</a>,\n</form>\n<form id=\"form-AnanthVinjimoorBoostingSelfSupervisedLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ananth Vinjimoor\">\n<a href=\"#\" onclick=\"document.getElementById('form-AnanthVinjimoorBoostingSelfSupervisedLearning').submit();\">Ananth Vinjimoor</a>,\n</form>\n<form id=\"form-PaoloFavaroBoostingSelfSupervisedLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Paolo Favaro\">\n<a href=\"#\" onclick=\"document.getElementById('form-PaoloFavaroBoostingSelfSupervisedLearning').submit();\">Paolo Favaro</a>,\n</form>\n<form id=\"form-HamedPirsiavashBoostingSelfSupervisedLearning\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Hamed Pirsiavash\">\n<a href=\"#\" onclick=\"document.getElementById('form-HamedPirsiavashBoostingSelfSupervisedLearning').submit();\">Hamed Pirsiavash</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Noroozi_Boosting_Self-Supervised_Learning_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1805.00385\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Noroozi_2018_CVPR,<br>\nauthor = {Noroozi, Mehdi and Vinjimoor, Ananth and Favaro, Paolo and Pirsiavash, Hamed},<br>\ntitle = {Boosting Self-Supervised Learning via Knowledge Transfer},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Beluch_The_Power_of_CVPR_2018_paper.html\">The Power of Ensembles for Active Learning in Image Classification</a></dt>\n<dd>\n<form id=\"form-WilliamH.ThePowerof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"William H. Beluch\">\n<a href=\"#\" onclick=\"document.getElementById('form-WilliamH.ThePowerof').submit();\">William H. Beluch</a>,\n</form>\n<form id=\"form-TimGeneweinThePowerof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tim Genewein\">\n<a href=\"#\" onclick=\"document.getElementById('form-TimGeneweinThePowerof').submit();\">Tim Genewein</a>,\n</form>\n<form id=\"form-AndreasN\u00c3\u00bcrnbergerThePowerof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andreas N\u00c3\u00bcrnberger\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndreasN\u00c3\u00bcrnbergerThePowerof').submit();\">Andreas N\u00c3\u00bcrnberger</a>,\n</form>\n<form id=\"form-JanM.ThePowerof\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jan M. K\u00c3\u00b6hler\">\n<a href=\"#\" onclick=\"document.getElementById('form-JanM.ThePowerof').submit();\">Jan M. K\u00c3\u00b6hler</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Beluch_The_Power_of_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/1487-supp.pdf\">supp</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Beluch_2018_CVPR,<br>\nauthor = {Beluch, William H. and Genewein, Tim and N\u00c3\u00bcrnberger, Andreas and K\u00c3\u00b6hler, Jan M.},<br>\ntitle = {The Power of Ensembles for Active Learning in Image Classification},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ye_Learning_Compact_Recurrent_CVPR_2018_paper.html\">Learning Compact Recurrent Neural Networks With Block-Term Tensor Decomposition</a></dt>\n<dd>\n<form id=\"form-JinmianYeLearningCompactRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jinmian Ye\">\n<a href=\"#\" onclick=\"document.getElementById('form-JinmianYeLearningCompactRecurrent').submit();\">Jinmian Ye</a>,\n</form>\n<form id=\"form-LinnanWangLearningCompactRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Linnan Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-LinnanWangLearningCompactRecurrent').submit();\">Linnan Wang</a>,\n</form>\n<form id=\"form-GuangxiLiLearningCompactRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Guangxi Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-GuangxiLiLearningCompactRecurrent').submit();\">Guangxi Li</a>,\n</form>\n<form id=\"form-DiChenLearningCompactRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Di Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-DiChenLearningCompactRecurrent').submit();\">Di Chen</a>,\n</form>\n<form id=\"form-ShandianZheLearningCompactRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shandian Zhe\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShandianZheLearningCompactRecurrent').submit();\">Shandian Zhe</a>,\n</form>\n<form id=\"form-XinqiChuLearningCompactRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Xinqi Chu\">\n<a href=\"#\" onclick=\"document.getElementById('form-XinqiChuLearningCompactRecurrent').submit();\">Xinqi Chu</a>,\n</form>\n<form id=\"form-ZenglinXuLearningCompactRecurrent\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Zenglin Xu\">\n<a href=\"#\" onclick=\"document.getElementById('form-ZenglinXuLearningCompactRecurrent').submit();\">Zenglin Xu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ye_Learning_Compact_Recurrent_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.05134\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ye_2018_CVPR,<br>\nauthor = {Ye, Jinmian and Wang, Linnan and Li, Guangxi and Chen, Di and Zhe, Shandian and Chu, Xinqi and Xu, Zenglin},<br>\ntitle = {Learning Compact Recurrent Neural Networks With Block-Term Tensor Decomposition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Tabernik_Spatially-Adaptive_Filter_Units_CVPR_2018_paper.html\">Spatially-Adaptive Filter Units for Deep Neural Networks</a></dt>\n<dd>\n<form id=\"form-DomenTabernikSpatiallyAdaptiveFilterUnits\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Domen Tabernik\">\n<a href=\"#\" onclick=\"document.getElementById('form-DomenTabernikSpatiallyAdaptiveFilterUnits').submit();\">Domen Tabernik</a>,\n</form>\n<form id=\"form-MatejKristanSpatiallyAdaptiveFilterUnits\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Matej Kristan\">\n<a href=\"#\" onclick=\"document.getElementById('form-MatejKristanSpatiallyAdaptiveFilterUnits').submit();\">Matej Kristan</a>,\n</form>\n<form id=\"form-Ale\u00c5\u00a1LeonardisSpatiallyAdaptiveFilterUnits\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ale\u00c5\u00a1 Leonardis\">\n<a href=\"#\" onclick=\"document.getElementById('form-Ale\u00c5\u00a1LeonardisSpatiallyAdaptiveFilterUnits').submit();\">Ale\u00c5\u00a1 Leonardis</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Tabernik_Spatially-Adaptive_Filter_Units_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1711.11473\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Tabernik_2018_CVPR,<br>\nauthor = {Tabernik, Domen and Kristan, Matej and Leonardis, Ale\u00c5\u00a1},<br>\ntitle = {Spatially-Adaptive Filter Units for Deep Neural Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Li_SO-Net_Self-Organizing_Network_CVPR_2018_paper.html\">SO-Net: Self-Organizing Network for Point Cloud Analysis</a></dt>\n<dd>\n<form id=\"form-JiaxinLiSONetSelfOrganizingNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Jiaxin Li\">\n<a href=\"#\" onclick=\"document.getElementById('form-JiaxinLiSONetSelfOrganizingNetwork').submit();\">Jiaxin Li</a>,\n</form>\n<form id=\"form-BenM.SONetSelfOrganizingNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ben M. Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-BenM.SONetSelfOrganizingNetwork').submit();\">Ben M. Chen</a>,\n</form>\n<form id=\"form-GimHeeSONetSelfOrganizingNetwork\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Gim Hee Lee\">\n<a href=\"#\" onclick=\"document.getElementById('form-GimHeeSONetSelfOrganizingNetwork').submit();\">Gim Hee Lee</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Li_SO-Net_Self-Organizing_Network_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2201-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.04249\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Li_2018_CVPR,<br>\nauthor = {Li, Jiaxin and Chen, Ben M. and Hee Lee, Gim},<br>\ntitle = {SO-Net: Self-Organizing Network for Point Cloud Analysis},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chavdarova_SGAN_An_Alternative_CVPR_2018_paper.html\">SGAN: An Alternative Training of Generative Adversarial Networks</a></dt>\n<dd>\n<form id=\"form-TatjanaChavdarovaSGANAnAlternative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Tatjana Chavdarova\">\n<a href=\"#\" onclick=\"document.getElementById('form-TatjanaChavdarovaSGANAnAlternative').submit();\">Tatjana Chavdarova</a>,\n</form>\n<form id=\"form-Fran\u00c3\u00a7oisFleuretSGANAnAlternative\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Fran\u00c3\u00a7ois Fleuret\">\n<a href=\"#\" onclick=\"document.getElementById('form-Fran\u00c3\u00a7oisFleuretSGANAnAlternative').submit();\">Fran\u00c3\u00a7ois Fleuret</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chavdarova_SGAN_An_Alternative_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2237-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1712.02330\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chavdarova_2018_CVPR,<br>\nauthor = {Chavdarova, Tatjana and Fleuret, Fran\u00c3\u00a7ois},<br>\ntitle = {SGAN: An Alternative Training of Generative Adversarial Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_SketchyGAN_Towards_Diverse_CVPR_2018_paper.html\">SketchyGAN: Towards Diverse and Realistic Sketch to Image Synthesis</a></dt>\n<dd>\n<form id=\"form-WenglingChenSketchyGANTowardsDiverse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Wengling Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-WenglingChenSketchyGANTowardsDiverse').submit();\">Wengling Chen</a>,\n</form>\n<form id=\"form-JamesHaysSketchyGANTowardsDiverse\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"James Hays\">\n<a href=\"#\" onclick=\"document.getElementById('form-JamesHaysSketchyGANTowardsDiverse').submit();\">James Hays</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_SketchyGAN_Towards_Diverse_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2335-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1801.02753\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Wengling and Hays, James},<br>\ntitle = {SketchyGAN: Towards Diverse and Realistic Sketch to Image Synthesis},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhou_Explicit_Loss-Error-Aware_Quantization_CVPR_2018_paper.html\">Explicit Loss-Error-Aware Quantization for Low-Bit Deep Neural Networks</a></dt>\n<dd>\n<form id=\"form-AojunZhouExplicitLossErrorAwareQuantization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Aojun Zhou\">\n<a href=\"#\" onclick=\"document.getElementById('form-AojunZhouExplicitLossErrorAwareQuantization').submit();\">Aojun Zhou</a>,\n</form>\n<form id=\"form-AnbangYaoExplicitLossErrorAwareQuantization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Anbang Yao\">\n<a href=\"#\" onclick=\"document.getElementById('form-AnbangYaoExplicitLossErrorAwareQuantization').submit();\">Anbang Yao</a>,\n</form>\n<form id=\"form-KuanWangExplicitLossErrorAwareQuantization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Kuan Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-KuanWangExplicitLossErrorAwareQuantization').submit();\">Kuan Wang</a>,\n</form>\n<form id=\"form-YurongChenExplicitLossErrorAwareQuantization\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yurong Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-YurongChenExplicitLossErrorAwareQuantization').submit();\">Yurong Chen</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhou_Explicit_Loss-Error-Aware_Quantization_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhou_2018_CVPR,<br>\nauthor = {Zhou, Aojun and Yao, Anbang and Wang, Kuan and Chen, Yurong},<br>\ntitle = {Explicit Loss-Error-Aware Quantization for Low-Bit Deep Neural Networks},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Zhu_Towards_Universal_Representation_CVPR_2018_paper.html\">Towards Universal Representation for Unseen Action Recognition</a></dt>\n<dd>\n<form id=\"form-YiZhuTowardsUniversalRepresentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yi Zhu\">\n<a href=\"#\" onclick=\"document.getElementById('form-YiZhuTowardsUniversalRepresentation').submit();\">Yi Zhu</a>,\n</form>\n<form id=\"form-YangLongTowardsUniversalRepresentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yang Long\">\n<a href=\"#\" onclick=\"document.getElementById('form-YangLongTowardsUniversalRepresentation').submit();\">Yang Long</a>,\n</form>\n<form id=\"form-YuGuanTowardsUniversalRepresentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu Guan\">\n<a href=\"#\" onclick=\"document.getElementById('form-YuGuanTowardsUniversalRepresentation').submit();\">Yu Guan</a>,\n</form>\n<form id=\"form-ShawnNewsamTowardsUniversalRepresentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Shawn Newsam\">\n<a href=\"#\" onclick=\"document.getElementById('form-ShawnNewsamTowardsUniversalRepresentation').submit();\">Shawn Newsam</a>,\n</form>\n<form id=\"form-LingShaoTowardsUniversalRepresentation\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ling Shao\">\n<a href=\"#\" onclick=\"document.getElementById('form-LingShaoTowardsUniversalRepresentation').submit();\">Ling Shao</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Zhu_Towards_Universal_Representation_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.08460\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Zhu_2018_CVPR,<br>\nauthor = {Zhu, Yi and Long, Yang and Guan, Yu and Newsam, Shawn and Shao, Ling},<br>\ntitle = {Towards Universal Representation for Unseen Action Recognition},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Ulyanov_Deep_Image_Prior_CVPR_2018_paper.html\">Deep Image Prior</a></dt>\n<dd>\n<form id=\"form-DmitryUlyanovDeepImagePrior\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Dmitry Ulyanov\">\n<a href=\"#\" onclick=\"document.getElementById('form-DmitryUlyanovDeepImagePrior').submit();\">Dmitry Ulyanov</a>,\n</form>\n<form id=\"form-AndreaVedaldiDeepImagePrior\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Andrea Vedaldi\">\n<a href=\"#\" onclick=\"document.getElementById('form-AndreaVedaldiDeepImagePrior').submit();\">Andrea Vedaldi</a>,\n</form>\n<form id=\"form-VictorLempitskyDeepImagePrior\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Victor Lempitsky\">\n<a href=\"#\" onclick=\"document.getElementById('form-VictorLempitskyDeepImagePrior').submit();\">Victor Lempitsky</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Ulyanov_Deep_Image_Prior_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"content_cvpr_2018/Supplemental/2711-supp.pdf\">supp</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1807.06920\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Ulyanov_2018_CVPR,<br>\nauthor = {Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},<br>\ntitle = {Deep Image Prior},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Lin_ST-GAN_Spatial_Transformer_CVPR_2018_paper.html\">ST-GAN: Spatial Transformer Generative Adversarial Networks for Image Compositing</a></dt>\n<dd>\n<form id=\"form-Chen-HsuanLinSTGANSpatialTransformer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Chen-Hsuan Lin\">\n<a href=\"#\" onclick=\"document.getElementById('form-Chen-HsuanLinSTGANSpatialTransformer').submit();\">Chen-Hsuan Lin</a>,\n</form>\n<form id=\"form-ErsinYumerSTGANSpatialTransformer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Ersin Yumer\">\n<a href=\"#\" onclick=\"document.getElementById('form-ErsinYumerSTGANSpatialTransformer').submit();\">Ersin Yumer</a>,\n</form>\n<form id=\"form-OliverWangSTGANSpatialTransformer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Oliver Wang\">\n<a href=\"#\" onclick=\"document.getElementById('form-OliverWangSTGANSpatialTransformer').submit();\">Oliver Wang</a>,\n</form>\n<form id=\"form-EliShechtmanSTGANSpatialTransformer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Eli Shechtman\">\n<a href=\"#\" onclick=\"document.getElementById('form-EliShechtmanSTGANSpatialTransformer').submit();\">Eli Shechtman</a>,\n</form>\n<form id=\"form-SimonLuceySTGANSpatialTransformer\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Simon Lucey\">\n<a href=\"#\" onclick=\"document.getElementById('form-SimonLuceySTGANSpatialTransformer').submit();\">Simon Lucey</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Lin_ST-GAN_Spatial_Transformer_CVPR_2018_paper.pdf\">pdf</a>]\n[<a href=\"https://arxiv.org/abs/arXiv:1803.01837\">arXiv</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Lin_2018_CVPR,<br>\nauthor = {Lin, Chen-Hsuan and Yumer, Ersin and Wang, Oliver and Shechtman, Eli and Lucey, Simon},<br>\ntitle = {ST-GAN: Spatial Transformer Generative Adversarial Networks for Image Compositing},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n<dt class=\"ptitle\"><br><a href=\"content_cvpr_2018/html/Chen_CartoonGAN_Generative_Adversarial_CVPR_2018_paper.html\">CartoonGAN: Generative Adversarial Networks for Photo Cartoonization</a></dt>\n<dd>\n<form id=\"form-YangChenCartoonGANGenerativeAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yang Chen\">\n<a href=\"#\" onclick=\"document.getElementById('form-YangChenCartoonGANGenerativeAdversarial').submit();\">Yang Chen</a>,\n</form>\n<form id=\"form-Yu-KunLaiCartoonGANGenerativeAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yu-Kun Lai\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yu-KunLaiCartoonGANGenerativeAdversarial').submit();\">Yu-Kun Lai</a>,\n</form>\n<form id=\"form-Yong-JinLiuCartoonGANGenerativeAdversarial\" action=\"./CVPR2018_search.py\" method=\"post\" class=\"authsearch\">\n<input type=\"hidden\" name=\"query\" value=\"Yong-Jin Liu\">\n<a href=\"#\" onclick=\"document.getElementById('form-Yong-JinLiuCartoonGANGenerativeAdversarial').submit();\">Yong-Jin Liu</a>\n</form>\n</dd>\n<dd>\n[<a href=\"content_cvpr_2018/papers/Chen_CartoonGAN_Generative_Adversarial_CVPR_2018_paper.pdf\">pdf</a>]\n<div class=\"link2\">[<a class=\"fakelink\" onclick=\"$(this).siblings('.bibref').slideToggle()\">bibtex</a>]\n<div class=\"bibref\">\n@InProceedings{Chen_2018_CVPR,<br>\nauthor = {Chen, Yang and Lai, Yu-Kun and Liu, Yong-Jin},<br>\ntitle = {CartoonGAN: Generative Adversarial Networks for Photo Cartoonization},<br>\nbooktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},<br>\nmonth = {June},<br>\nyear = {2018}<br>\n}\n</div>\n</div>\n</dd>\n</dl>\n</div>\n</body>\n</html>\n", "timestamp": "2019-12-18 22:30:58.638849", "expire_in_days": 1}}